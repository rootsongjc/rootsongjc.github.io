<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy Song&#39;s Blog – Cloud Native</title>
    <link>https://jimmysong.io/en/tags/cloud-native/</link>
    <description>Recent content in Cloud Native on Jimmy Song&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Apr 2024 18:54:49 +0800</lastBuildDate>
    
	  <atom:link href="https://jimmysong.io/en/tags/cloud-native/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Blogs</title>
      <link>https://jimmysong.io/en/blog/</link>
      <pubDate>Wed, 24 Apr 2024 18:54:49 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/</guid>
      <description>
        
        
        
      </description>
    </item>
    
    <item>
      <title>In-depth Analysis of CNCF&#39;s Cloud Native AI Whitepaper</title>
      <link>https://jimmysong.io/en/blog/cloud-native-ai-whitepaper/</link>
      <pubDate>Tue, 16 Apr 2024 12:54:49 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/cloud-native-ai-whitepaper/</guid>
      <description>
        
        
        &lt;p&gt;In March 2024, during KubeCon EU, the Cloud Native Computing Foundation (CNCF) released its first detailed &lt;a href=&#34;https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/&#34; title=&#34;whitepaper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;whitepaper&lt;/a&gt;
 on Cloud Native Artificial Intelligence (CNAI). This report thoroughly explores the current state, challenges, and future directions of integrating Cloud Native technologies with artificial intelligence. This article delves into the core content of this whitepaper.&lt;/p&gt;
&lt;h2 id=&#34;what-is-cloud-native-ai&#34;&gt;What is Cloud Native AI?&lt;/h2&gt;
&lt;p&gt;Cloud Native AI refers to the approach of building and deploying artificial intelligence applications and workloads using Cloud Native technology principles. This includes leveraging microservices, containerization, declarative APIs, and continuous integration/continuous deployment (CI/CD) to enhance the scalability, reusability, and operability of AI applications.&lt;/p&gt;
&lt;p&gt;The diagram below illustrates the architecture of Cloud Native AI, redrawn based on the whitepaper.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/cloud-native-ai-whitepaper/cloud-native-ai.svg&#34; data-img=&#34;/en/blog/cloud-native-ai-whitepaper/cloud-native-ai.svg&#34; alt=&#34;image&#34; data-caption=&#34;Cloud Native AI Architecture&#34;&gt;
    
  
  &lt;figcaption&gt;Cloud Native AI Architecture&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;relationship-between-cloud-native-ai-and-cloud-native-technologies&#34;&gt;Relationship Between Cloud Native AI and Cloud Native Technologies&lt;/h2&gt;
&lt;p&gt;Cloud Native technologies provide a flexible, scalable platform that makes the development and operation of AI applications more efficient. Through containerization and microservices architecture, developers can iterate and deploy AI models rapidly while ensuring high availability and scalability of systems. Kubernetes and other Cloud Native tools provide essential support such as resource scheduling, automatic scaling, and service discovery.&lt;/p&gt;
&lt;p&gt;The whitepaper provides two examples illustrating the relationship between Cloud Native AI and Cloud Native technologies, namely running AI on Cloud Native infrastructure:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://huggingface.co/blog/hugging-face-endpoints-on-azure&#34; title=&#34;Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openai.com/research/scaling-kubernetes-to-7500-nodes&#34; title=&#34;OpenAI Scaling Kubernetes to 7,500 nodes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenAI Scaling Kubernetes to 7,500 nodes&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;challenges-of-cloud-native-ai&#34;&gt;Challenges of Cloud Native AI&lt;/h2&gt;
&lt;p&gt;Despite providing a solid foundation for AI applications, Cloud Native technologies still face challenges when integrating AI workloads with Cloud Native platforms. These challenges include the complexity of data preparation, resource requirements for model training, and maintaining the security and isolation of models in multi-tenant environments. Additionally, resource management and scheduling in Cloud Native environments are crucial, especially for large-scale AI applications, and further optimization is needed to support efficient model training and inference.&lt;/p&gt;
&lt;h2 id=&#34;development-path-of-cloud-native-ai&#34;&gt;Development Path of Cloud Native AI&lt;/h2&gt;
&lt;p&gt;The whitepaper proposes several development paths for Cloud Native AI, including improving resource scheduling algorithms to better support AI workloads, developing new service mesh technologies to enhance the performance and security of AI applications, and driving innovation and standardization of Cloud Native AI technology through open-source projects and community collaboration.&lt;/p&gt;
&lt;h2 id=&#34;cloud-native-ai-technology-landscape&#34;&gt;Cloud Native AI Technology Landscape&lt;/h2&gt;
&lt;p&gt;Cloud Native AI involves a variety of technologies, from containers and microservices to service meshes and serverless computing. Kubernetes is a key platform for deploying and managing AI applications, while service mesh technologies like Istio and Envoy provide powerful traffic management and security features. Additionally, monitoring tools like Prometheus and Grafana are essential for maintaining the performance and reliability of AI applications.&lt;/p&gt;
&lt;p&gt;Below is the Cloud Native AI landscape provided in the whitepaper.&lt;/p&gt;
&lt;h3 id=&#34;general-orchestration&#34;&gt;General Orchestration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes&lt;/li&gt;
&lt;li&gt;Volcano&lt;/li&gt;
&lt;li&gt;Armada&lt;/li&gt;
&lt;li&gt;Kuberay&lt;/li&gt;
&lt;li&gt;Nvidia NeMo&lt;/li&gt;
&lt;li&gt;Yunikorn&lt;/li&gt;
&lt;li&gt;Kueue&lt;/li&gt;
&lt;li&gt;Flame&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;distributed-training&#34;&gt;Distributed Training&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kubeflow Training Operator&lt;/li&gt;
&lt;li&gt;Pytorch DDP&lt;/li&gt;
&lt;li&gt;TensorFlow Distributed&lt;/li&gt;
&lt;li&gt;Open MPI&lt;/li&gt;
&lt;li&gt;DeepSpeed&lt;/li&gt;
&lt;li&gt;Megatron&lt;/li&gt;
&lt;li&gt;Horovod&lt;/li&gt;
&lt;li&gt;Apla&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ml-serving&#34;&gt;ML Serving&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kserve&lt;/li&gt;
&lt;li&gt;Seldon&lt;/li&gt;
&lt;li&gt;VLLM&lt;/li&gt;
&lt;li&gt;TGT&lt;/li&gt;
&lt;li&gt;Skypilot&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;cicd---delivery&#34;&gt;CI/CD - Delivery&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kubeflow Pipelines&lt;/li&gt;
&lt;li&gt;Mlflow&lt;/li&gt;
&lt;li&gt;TFX&lt;/li&gt;
&lt;li&gt;BentoML&lt;/li&gt;
&lt;li&gt;MLRun&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-science&#34;&gt;Data Science&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Jupyter&lt;/li&gt;
&lt;li&gt;Kubeflow Notebooks&lt;/li&gt;
&lt;li&gt;PyTorch&lt;/li&gt;
&lt;li&gt;TensorFlow&lt;/li&gt;
&lt;li&gt;Apache Zeppelin&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;workload-observability&#34;&gt;Workload Observability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Prometheus&lt;/li&gt;
&lt;li&gt;Influxdb&lt;/li&gt;
&lt;li&gt;Grafana&lt;/li&gt;
&lt;li&gt;Weights and Biases (wandb)&lt;/li&gt;
&lt;li&gt;OpenTelemetry&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;automl&#34;&gt;AutoML&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Hyperopt&lt;/li&gt;
&lt;li&gt;Optuna&lt;/li&gt;
&lt;li&gt;Kubeflow Katib&lt;/li&gt;
&lt;li&gt;NNI&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;governance--policy&#34;&gt;Governance &amp;amp; Policy&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Kyverno&lt;/li&gt;
&lt;li&gt;Kyverno-JSON&lt;/li&gt;
&lt;li&gt;OPA/Gatekeeper&lt;/li&gt;
&lt;li&gt;StackRox Minder&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;data-architecture&#34;&gt;Data Architecture&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ClickHouse&lt;/li&gt;
&lt;li&gt;Apache Pinot&lt;/li&gt;
&lt;li&gt;Apache Druid&lt;/li&gt;
&lt;li&gt;Cassandra&lt;/li&gt;
&lt;li&gt;ScyllaDB&lt;/li&gt;
&lt;li&gt;Hadoop HDFS&lt;/li&gt;
&lt;li&gt;Apache HBase&lt;/li&gt;
&lt;li&gt;Presto&lt;/li&gt;
&lt;li&gt;Trino&lt;/li&gt;
&lt;li&gt;Apache Spark&lt;/li&gt;
&lt;li&gt;Apache Flink&lt;/li&gt;
&lt;li&gt;Kafka&lt;/li&gt;
&lt;li&gt;Pulsar&lt;/li&gt;
&lt;li&gt;Fluid&lt;/li&gt;
&lt;li&gt;Memcached&lt;/li&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;li&gt;Alluxio&lt;/li&gt;
&lt;li&gt;Apache Superset&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;vector-databases&#34;&gt;Vector Databases&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Milvus&lt;/li&gt;
&lt;li&gt;Chroma&lt;/li&gt;
&lt;li&gt;Weaviate&lt;/li&gt;
&lt;li&gt;Quadrant&lt;/li&gt;
&lt;li&gt;Pinecone&lt;/li&gt;
&lt;li&gt;Extensions
&lt;ul&gt;
&lt;li&gt;Redis&lt;/li&gt;
&lt;li&gt;Postgres SQL&lt;/li&gt;
&lt;li&gt;ElasticSearch&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;modelllm-observability&#34;&gt;Model/LLM Observability&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Trulens&lt;/li&gt;
&lt;li&gt;Langfuse&lt;/li&gt;
&lt;li&gt;Deepchecks&lt;/li&gt;
&lt;li&gt;OpenLLMetry&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Finally, let me summarizes the following key points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Role of the Open Source Community&lt;/strong&gt;: The whitepaper clearly points out the role of the open-source community in advancing Cloud Native AI, including accelerating innovation and reducing costs through open-source projects and extensive collaboration.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Importance of Cloud Native Technologies&lt;/strong&gt;: Cloud Native AI is built and deployed according to Cloud Native principles, highlighting the importance of repeatability and scalability. Cloud Native technologies provide an efficient development and runtime environment for AI applications, especially in terms of resource scheduling and service scalability.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Challenges Exist&lt;/strong&gt;: Despite the many advantages brought by Cloud Native AI, there are still challenges in data preparation, model training resource requirements, and model security and isolation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Future Development Directions&lt;/strong&gt;: The whitepaper proposes development paths including optimizing resource scheduling algorithms to support AI workloads, developing new service mesh technologies to enhance performance and security, and leveraging open-source projects and community collaboration to further promote technological innovation and standardization.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Key Technological Components&lt;/strong&gt;: Key technologies involved in Cloud Native AI include containers, microservices, service meshes, and serverless computing. Kubernetes plays a central role in deploying and managing AI applications, while service mesh technologies such as Istio and Envoy provide necessary traffic management and security.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For more details, please download the &lt;a href=&#34;https://www.cncf.io/reports/cloud-native-artificial-intelligence-whitepaper/&#34; title=&#34;Cloud Native AI Whitepaper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Native AI Whitepaper&lt;/a&gt;
.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Service Mesh in 2021: The Ecosystem Is Emerging</title>
      <link>https://jimmysong.io/en/blog/service-mesh-in-2021/</link>
      <pubDate>Wed, 12 Jan 2022 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/service-mesh-in-2021/</guid>
      <description>
        
        
        &lt;p&gt;As the service mesh architecture concept gains traction and the scenarios for its applications emerge, there is no shortage of discussions about it in the community. I have worked on service mesh with the community for 4 years now, and will summarize the development of service mesh in 2021 from this perspective. Since Istio is the most popular service mesh, this article will focus on the technical and ecological aspects of Istio.&lt;/p&gt;
&lt;h2 id=&#34;service-mesh-a-critical-tech-for-cloud-native-infrastructure&#34;&gt;Service mesh: a critical tech for Cloud Native Infrastructure&lt;/h2&gt;
&lt;p&gt;As one of the vital technologies &lt;a href=&#34;https://github.com/cncf/toc/blob/main/DEFINITION.md&#34; title=&#34;defined by CNCF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;defined by CNCF&lt;/a&gt;
 for cloud native, Istio has been around for five years now. Their development has gone through the following periods.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Exploration phase: 2017-2018&lt;/li&gt;
&lt;li&gt;Early adopter phase: 2019-2020&lt;/li&gt;
&lt;li&gt;Large-scale landing and ecological development phase: 2021-present&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Service mesh has crossed the “chasm”(refer &lt;a href=&#34;https://thinkinsights.net/strategy/crossing-the-chasm/&#34; title=&#34;Crossing the Chasm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crossing the Chasm&lt;/a&gt;
 theory) and is in between the “early majority” and “late majority” phases of adoption. Based on feedback from the audience of &lt;a href=&#34;https://github.com/tetratelabs/istio-weekly/&#34; title=&#34;Istio Weekly,&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Weekly,&lt;/a&gt;
 users are no longer blindly following new technologies for experimentation and are starting to consider whether they need them in their organization dialectically.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-in-2021/008i3skNly1gysddnj9i2j30sg0fqaaz.jpg&#34; data-img=&#34;/en/blog/service-mesh-in-2021/008i3skNly1gysddnj9i2j30sg0fqaaz.jpg&#34; data-width=&#34;1024&#34; data-height=&#34;566&#34; alt=&#34;image&#34; data-caption=&#34;Cross the chasm&#34;&gt;
    
  
  &lt;figcaption&gt;Cross the chasm&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;While new technologies and products continue to emerge, the service mesh, as part of the cloud native technology stack, has continued to solidify its position as the “cloud native network infrastructure” over the past year. The diagram below illustrates the cloud native technology stack model, where each layer has several representative technologies that define the standard. As new-age middleware, the service mesh mirrors other cloud native technologies, such as &lt;a href=&#34;https://dapr.io/&#34; title=&#34;Dapr&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Dapr&lt;/a&gt;
 (Distributed Application Runtime), which represents the capability model for cloud native middleware, &lt;a href=&#34;https://oam.dev/&#34; title=&#34;OAM&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM&lt;/a&gt;
, which defines the cloud native application model, and the service mesh, which defines the L7 network model.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-in-2021/008i3skNly1gysddogtenj30sg0qlwgs.jpg&#34; data-img=&#34;/en/blog/service-mesh-in-2021/008i3skNly1gysddogtenj30sg0qlwgs.jpg&#34; data-width=&#34;1024&#34; data-height=&#34;957&#34; alt=&#34;image&#34; data-caption=&#34;Cloud Native Stack&#34;&gt;
    
  
  &lt;figcaption&gt;Cloud Native Stack&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;A layered view of the cloud native application platform technology stack&lt;/p&gt;
&lt;h2 id=&#34;optimizing-the-mesh-for-large-scale-production-applications-with-different-deployment-models&#34;&gt;Optimizing the mesh for large scale production applications with different deployment models&lt;/h2&gt;
&lt;p&gt;Over the past year, the community focused on the following areas.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performance optimization: performance issues of service mesh in large-scale application scenarios.&lt;/li&gt;
&lt;li&gt;Protocol and extensions: enabling service mesh to support arbitrary L7 network protocols.&lt;/li&gt;
&lt;li&gt;Deployment models: Proxyless vs. Node model vs. Sidecar model.&lt;/li&gt;
&lt;li&gt;eBPF: putting some of the service mesh’s capabilities to the kernel layer.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;performance-optimization&#34;&gt;Performance optimization&lt;/h3&gt;
&lt;p&gt;Istio was designed to serve service to service traffic by “proto-protocol forwarding”. The goal is making the service mesh as “transparent” as possible to applications. Thus using IPtables to hijack the traffic, according to the community-provided test results Istio 1.2 adds only 3 ms to the baseline latency for a mesh with 1000 RPS on 16 connections. However, because of issues inherent in the IPtables conntrack module, Istio’s performance issues begin to emerge as the mesh size increases. To optimize the performance of the Istio sidecar for resource usage and network latency, the community gave the following solutions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sidecar configuration: By configuring service dependencies manually or by adding an Operator to the control plane, the number of service configurations sent to Sidecar can be reduced, thus reducing the resource footprint of the data plane; for more automatic and intelligent configuration of Sidecar, the open source projects &lt;a href=&#34;https://github.com/slime-io/slime&#34; title=&#34;Slime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime&lt;/a&gt;
 and &lt;a href=&#34;https://github.com/aeraki-framework/aeraki&#34; title=&#34;Aeraki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aeraki&lt;/a&gt;
 both offer their innovative configuration loading solutions.&lt;/li&gt;
&lt;li&gt;The introduction of eBPF: eBPF can be a viable solution to optimize the performance of the service mesh. Some Cilium-based startups even radically propose to use eBPF to replace the Sidecar proxy completely. Still, the Envoy proxy/xDS protocol has become the proxy for the service mesh implementation and supports the Layer 7 protocol very well. We can use eBPF to improve network performance, but complex protocol negotiation, parsing, and user scaling remain challenging to implement on the user side.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;protocol-and-extensions&#34;&gt;Protocol and extensions&lt;/h3&gt;
&lt;p&gt;Extensibility of Istio has always been a significant problem, and there are two aspects to Istio’s extensibility.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Protocol level: allowing Istio to support all L7 protocols&lt;/li&gt;
&lt;li&gt;Ecological: allowing Istio to run more extensions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Istio uses Envoy as its data plane. Extending Istio is essentially an extension of Envoy’s functionality. Istio’s official solution is to use WebAssembly, and in Istio 1.12, the &lt;a href=&#34;https://www.tetrate.io/blog/istio-wasm-extensions-and-ecosystem/&#34; title=&#34;Wasm plugin configuration API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wasm plugin configuration API&lt;/a&gt;
 was introduced to extend the Istio ecosystem. Istio’s extension mechanism uses the &lt;a href=&#34;https://github.com/proxy-wasm/spec&#34; title=&#34;Proxy-Wasm Application Binary Interface (ABI)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Proxy-Wasm Application Binary Interface (ABI)&lt;/a&gt;
 specification to provide a set of proxy-independent streaming APIs and utilities that can be implemented in any language with an appropriate SDK. Today, Proxy-Wasm’s SDKs are AssemblyScript (similar to TypeScript), C++, Rust, Zig, and Go (using the TinyGo WebAssembly System Interface).&lt;/p&gt;
&lt;p&gt;There are still relatively few WebAssembly extensions available, and many enterprises choose to customize their CRD and build a service mesh management plane based on Istio. In addition, making Istio support heterogeneous environments for all workloads, such as virtual machines and containers, is also in strong demand for end-users. It allows them to migrate applications from traditional loads to service mesh easily. Finally, there is the hybrid cloud traffic management with multiple clusters and mesh, which is a more advanced requirement.&lt;/p&gt;
&lt;h3 id=&#34;deployment-models&#34;&gt;Deployment models&lt;/h3&gt;
&lt;p&gt;When the service mesh concept first emerged, there was a debate between the Per-node and Sidecar models, represented by Linkerd and Istio. eBPF later proposed a kernel to sink the service mesh, which led to more service mesh deployment models, as shown in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-in-2021/008i3skNly1gysddpco2mj30qz0sgwhk.jpg&#34; data-img=&#34;/en/blog/service-mesh-in-2021/008i3skNly1gysddpco2mj30qz0sgwhk.jpg&#34; data-width=&#34;971&#34; data-height=&#34;1024&#34; alt=&#34;image&#34; data-caption=&#34;Service Mesh Deployment Models&#34;&gt;
    
  
  &lt;figcaption&gt;Service Mesh Deployment Models&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;These four deployment methods have their own advantages and disadvantages, the specific choice of which depends on the actual situation.&lt;/p&gt;
&lt;h3 id=&#34;development-of-the-istio-ecosystem-and-the-projects-that-support-istio&#34;&gt;Development of the Istio ecosystem and the projects that support Istio&lt;/h3&gt;
&lt;p&gt;2021 was also an exciting year for the Istio community, with a series of events and tutorials.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;February, the first Istio distribution, &lt;a href=&#34;https://istio.tetratelabs.io/&#34; title=&#34;Tetrate Istio Distro (TID)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Istio Distro (TID)&lt;/a&gt;
.&lt;/li&gt;
&lt;li&gt;February, the first &lt;a href=&#34;https://events.istio.io/istiocon-2021/&#34; title=&#34;IstioCon&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IstioCon&lt;/a&gt;
 was held online, with over 2,000 participants.&lt;/li&gt;
&lt;li&gt;March, the first free online &lt;a href=&#34;https://academy.tetrate.io/courses/istio-fundamentals&#34; title=&#34;Istio Fundamentals Course&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Fundamentals Course&lt;/a&gt;
 is released.&lt;/li&gt;
&lt;li&gt;May, the first &lt;a href=&#34;https://academy.tetrate.io/courses/certified-istio-administrator&#34; title=&#34;Certification Istio Administrator exam&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Certification Istio Administrator exam&lt;/a&gt;
 be released.&lt;/li&gt;
&lt;li&gt;May, ServiceMeshCon Europe was held online.&lt;/li&gt;
&lt;li&gt;July, &lt;a href=&#34;https://istio.io/latest/zh/blog/2021/istiomeetups-china/&#34; title=&#34;Istio Meetup China&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Meetup China&lt;/a&gt;
 was held in Beijing with more than 100 attendees.&lt;/li&gt;
&lt;li&gt;October, ServiceMeshCon North America was held in Los Angeles.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are also numerous open source projects related to Istio Service Mesh, as shown in the table below.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Project&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Value&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Relationship with Istio&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Category&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Launch Date&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Dominant company&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Number of stars&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy&#34; title=&#34;Envoy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Cloud native high-performance edge/middle-service proxy&lt;/td&gt;
&lt;td&gt;The default data plane&lt;/td&gt;
&lt;td&gt;proxy&lt;/td&gt;
&lt;td&gt;September 2016&lt;/td&gt;
&lt;td&gt;Lyft&lt;/td&gt;
&lt;td&gt;18700&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/istio/istio/&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Connection, secure, control, and observation services.&lt;/td&gt;
&lt;td&gt;Control plane&lt;/td&gt;
&lt;td&gt;service mesh&lt;/td&gt;
&lt;td&gt;May 2017&lt;/td&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;td&gt;29100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/emissary-ingress/emissary&#34; title=&#34;Emissary Gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Emissary Gateway&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Kubernetes native API gateway for microservices, built on Envoy&lt;/td&gt;
&lt;td&gt;Connectable to Istio&lt;/td&gt;
&lt;td&gt;gateway&lt;/td&gt;
&lt;td&gt;February 2018&lt;/td&gt;
&lt;td&gt;Ambassador&lt;/td&gt;
&lt;td&gt;3600&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/apache/apisix&#34; title=&#34;APISIX&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;APISIX&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Cloud native API gateways&lt;/td&gt;
&lt;td&gt;It can run as a data plane for Istio or as a gateway on its own&lt;/td&gt;
&lt;td&gt;gateway&lt;/td&gt;
&lt;td&gt;June 2019&lt;/td&gt;
&lt;td&gt;API7&lt;/td&gt;
&lt;td&gt;8100&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/mosn/mosn&#34; title=&#34;MOSN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MOSN&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Cloud native edge gateways &amp;amp; agents&lt;/td&gt;
&lt;td&gt;Available as Istio data plane&lt;/td&gt;
&lt;td&gt;proxy&lt;/td&gt;
&lt;td&gt;December 2019&lt;/td&gt;
&lt;td&gt;Ant&lt;/td&gt;
&lt;td&gt;3500&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/slime-io/slime&#34; title=&#34;Slime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Intelligent service mesh manager based on Istio&lt;/td&gt;
&lt;td&gt;Adding a management plane to Istio&lt;/td&gt;
&lt;td&gt;extensions&lt;/td&gt;
&lt;td&gt;January 2021&lt;/td&gt;
&lt;td&gt;NetEase&lt;/td&gt;
&lt;td&gt;236&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tetratelabs/getmesh&#34; title=&#34;GetMesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GetMesh&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Istio integration and command-line management tools&lt;/td&gt;
&lt;td&gt;Utility for Istio multi-version management&lt;/td&gt;
&lt;td&gt;tools&lt;/td&gt;
&lt;td&gt;February 2021&lt;/td&gt;
&lt;td&gt;Tetrate&lt;/td&gt;
&lt;td&gt;95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/aeraki-framework/aeraki&#34; title=&#34;Aeraki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aeraki&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Manage any of Istio’s seven layers of load&lt;/td&gt;
&lt;td&gt;Extended multi-protocol support&lt;/td&gt;
&lt;td&gt;extensions&lt;/td&gt;
&lt;td&gt;March 2021&lt;/td&gt;
&lt;td&gt;Tencent&lt;/td&gt;
&lt;td&gt;330&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/mosn/layotto/&#34; title=&#34;Layotto&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Layotto&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;Cloud native application runtime&lt;/td&gt;
&lt;td&gt;Using as a data plane for Istio&lt;/td&gt;
&lt;td&gt;runtime&lt;/td&gt;
&lt;td&gt;June 2021&lt;/td&gt;
&lt;td&gt;Ant&lt;/td&gt;
&lt;td&gt;393&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/hango-io/hango-gateway&#34; title=&#34;Hango Gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hango Gateway&lt;/a&gt;
&lt;/td&gt;
&lt;td&gt;API gateways built on Envoy and Istio&lt;/td&gt;
&lt;td&gt;Integrates with Istio&lt;/td&gt;
&lt;td&gt;gateway&lt;/td&gt;
&lt;td&gt;August 2021&lt;/td&gt;
&lt;td&gt;NetEase&lt;/td&gt;
&lt;td&gt;253&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note: Data is as of January 6, 2022&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Looking back, we can see that, unlike previous years where users were experimenting, users in 2021 looked for more practical uses for service mesh before implementing them. Their position as the infrastructure of cloud native networks is further strengthened, and more importantly, the service mesh ecosystem is emerging. Looking ahead, in 2022, two technologies to watch are eBPF and WebAssembly(Wasm). We believe that more good examples of service mesh practices will emerge, taking the ecology and standardization a step further.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>The Debate in the Community About Istio and Service Mesh</title>
      <link>https://jimmysong.io/en/blog/the-debate-in-the-community-about-istio-and-service-mesh/</link>
      <pubDate>Fri, 17 Dec 2021 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/the-debate-in-the-community-about-istio-and-service-mesh/</guid>
      <description>
        
        
        &lt;p&gt;You can use Istio to do &lt;a href=&#34;https://www.tetrate.io/blog/multicluster-management-with-kubernetes-and-istio/&#34; title=&#34;multi-cluster management&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;multi-cluster management&lt;/a&gt;
, &lt;a href=&#34;https://www.tetrate.io/blog/istio-servicemesh-api-gateway/&#34; title=&#34;API Gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;API Gateway&lt;/a&gt;
, and manage applications on Kubernetes or &lt;a href=&#34;https://www.tetrate.io/blog/istio-18-a-virtual-machine-integration-odyssey/&#34; title=&#34;virtual machines&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;virtual machines&lt;/a&gt;
. In my &lt;a href=&#34;https://www.tetrate.io/blog/why-is-service-mesh-a-necessary-part-of-cloud-native/&#34; title=&#34;last blog&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;last blog&lt;/a&gt;
, I talked about how service mesh is an integral part of cloud native applications. However, building infrastructure can be a big deal. There is no shortage of debate in the community about the practicability of service mesh and Istio– here’s a list of common questions and concerns, and how to address them.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is anyone using Istio in production?&lt;/li&gt;
&lt;li&gt;What is the impact on application performance due to the many resources consumed by injecting sidecar into the pod?&lt;/li&gt;
&lt;li&gt;Istio supports a limited number of protocols; is it scalable?&lt;/li&gt;
&lt;li&gt;Will Istio be manageable? – Or is it too complex, old services too costly to migrate, and the learning curve too steep?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will answer each of these questions below.&lt;/p&gt;
&lt;h3 id=&#34;istio-is-architecturally-stable-production-ready-and-ecologically-emerging&#34;&gt;Istio is architecturally stable, production-ready, and ecologically emerging&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.tetrate.io/blog/istio-wasm-extensions-and-ecosystem/&#34; title=&#34;Istio 1.12&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 1.12&lt;/a&gt;
 was just released in November – and has evolved significantly since the explosion of service mesh in 2018 (the year Istio co-founders established Tetrate). Istio has a large community of providers and &lt;a href=&#34;https://istio.io/latest/about/case-studies/&#34; title=&#34;users&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;users&lt;/a&gt;
. The Istio SIG of Cloud Native Community has held eight &lt;a href=&#34;https://cloudnative.to/sig-istio/big-talk/overview.html&#34; title=&#34;Istio Big Talk (Istio 大咖说)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Big Talk (Istio 大咖说)&lt;/a&gt;
, with Baidu, Tencent, NetEase, Xiaohongshu(小红书), and Xiaodian Technology(小电科技) sharing their Istio practices. According to &lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Survey_Report_2020.pdf&#34; title=&#34;CNCF Survey Report 2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Survey Report 2020&lt;/a&gt;
, about 50% of the companies surveyed are using a service mesh in production or planning to in the next year, and about half (47%) of organizations using a service mesh in production are using Istio.&lt;/p&gt;
&lt;p&gt;Many companies have developed extensions or plugins for Istio, such as Ant, NetEase, eBay, and Airbnb. Istio’s architecture has been stable since the 1.5 release, and the release cycle is fixed quarterly, with the current project’s main task being Day-2 Operations.&lt;/p&gt;
&lt;p&gt;The Istio community has also hosted various events, with the first IstioCon in March 2021, the Istio Meetup China in Beijing in July, and the Service Mesh Summit 2022 in Shanghai in January 2022.&lt;/p&gt;
&lt;p&gt;So we can say that the Istio architecture is stable and production-ready, and the ecosystem is budding.&lt;/p&gt;
&lt;h3 id=&#34;the-impact-of-service-mesh-on-application-performance&#34;&gt;The impact of service mesh on application performance&lt;/h3&gt;
&lt;p&gt;A service mesh uses iptables to do traffic hijacking by default to be transparent to applications. When the number of services is large, there are a lot of iptables rules that affect network performance. You can use techniques like &lt;a href=&#34;https://cloudnative.to/blog/how-ebpf-streamlines-the-service-mesh/&#34; title=&#34;eBPF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;eBPF&lt;/a&gt;
 to provide application performance, but the method requires a high version of the operating system kernel, which few enterprises can achieve.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/the-debate-in-the-community-about-istio-and-service-mesh/008i3skNly1gxgyfcfm5oj30sg0djmxt.jpg&#34; data-img=&#34;/en/blog/the-debate-in-the-community-about-istio-and-service-mesh/008i3skNly1gxgyfcfm5oj30sg0djmxt.jpg&#34; data-width=&#34;1024&#34; data-height=&#34;487&#34; alt=&#34;image&#34; data-caption=&#34;Istio DNS&#34;&gt;
    
  
  &lt;figcaption&gt;Istio DNS&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;In the early days, Istio distributed the routing information of all services in the mesh to all proxy sidecars, which caused &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/sidecar/&#34; title=&#34;sidecar&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sidecar&lt;/a&gt;
s to take up a lot of resources. &lt;a href=&#34;https://github.com/aeraki-framework/aeraki&#34; title=&#34;Aeraki&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aeraki&lt;/a&gt;
 and &lt;a href=&#34;https://github.com/slime-io/slime&#34; title=&#34;Slime&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Slime&lt;/a&gt;
 can achieve configuration lazy loading. We will introduce these two open-source projects in the Istio open-source ecosystem.&lt;/p&gt;
&lt;p&gt;Finally, there is a problem related to Sidecar proxy operation and maintenance: upgrading all Envoy proxies while ensuring constant traffic. A solution is using the &lt;a href=&#34;https://xie.infoq.cn/article/23ae6d3f0d0260b4797a708a0&#34; title=&#34;SidecarSet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SidecarSet&lt;/a&gt;
 resource in the open-source project &lt;a href=&#34;https://github.com/openkruise/kruise&#34; title=&#34;OpenKruise&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenKruise&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;The resource consumption and network latency associated with the introduction of Sidecar are also within reasonable limits, as you can see from the &lt;a href=&#34;https://istio.io/latest/blog/2019/performance-best-practices/&#34; title=&#34;service mesh benchmark performance tests&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;service mesh benchmark performance tests&lt;/a&gt;
.&lt;/p&gt;
&lt;h3 id=&#34;extending-the-istio-service-mesh&#34;&gt;Extending the Istio service mesh&lt;/h3&gt;
&lt;p&gt;The next question is about extending the Istio service mesh. The current solution given by the Istio community is to use &lt;a href=&#34;https://www.tetrate.io/blog/istio-wasm-extensions-and-ecosystem/&#34; title=&#34;WebAssembly&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebAssembly&lt;/a&gt;
, an extension that is still relatively little used in production by now and has performance concerns. Most of the answers I’ve observed are CRDs that build a service mesh management plane based on Istio.&lt;/p&gt;
&lt;p&gt;Also, making Istio support heterogeneous environments for all workloads, such as virtual machines and containers, is in strong demand for end-users. It allows them to migrate applications from traditional loads to cloud native easily. Finally, hybrid cloud traffic management for multiple clusters and meshes is a more advanced requirement.&lt;/p&gt;
&lt;h3 id=&#34;steep-learning-curve&#34;&gt;Steep learning curve&lt;/h3&gt;
&lt;p&gt;Many people complain that Istio has too little learning material. Istio has been open source for four years, and there are a lot of learning resources now:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/&#34; title=&#34;Istio Documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Documentation&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://events.istio.io/istiocon-2021/&#34; title=&#34;IstioCon 2021&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IstioCon 2021&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tetratelabs/istio-weekly&#34; title=&#34;Istio Big Talk/Istio Weekly&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Big Talk/Istio Weekly&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://academy.tetrate.io/courses/istio-fundamentals&#34; title=&#34;Istio Fundamentals Course&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Fundamentals Course&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://academy.tetrate.io/courses/certified-istio-administrator&#34; title=&#34;Certified Istio Administrator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Certified Istio Administrator&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Yes, Istio is complex, but it’s been getting more and more manageable with every release. In my next blog, I will introduce you to two open source projects that extend Istio and give you some insight into what’s going on in the Istio community.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Service Mesh - An Integral Part of Cloud-Native Applications</title>
      <link>https://jimmysong.io/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/</link>
      <pubDate>Sun, 12 Dec 2021 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/</guid>
      <description>
        
        
        &lt;p&gt;If you don’t know what Istio is, you can read my previous articles below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/blog/what-is-istio-and-why-does-kubernetes-need-it/&#34; title=&#34;What Is Istio and Why Does Kubernetes Need it?&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What Is Istio and Why Does Kubernetes Need it?&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/&#34; title=&#34;Why do you need Istio when you already have Kubernetes?&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Why do you need Istio when you already have Kubernetes?&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This article will explore the relationship between service mesh and cloud native.&lt;/p&gt;
&lt;h3 id=&#34;service-mesh--the-product-of-the-container-orchestration-war&#34;&gt;Service mesh – the product of the container orchestration war&lt;/h3&gt;
&lt;p&gt;If you’ve been following the cloud-native space since its early days, you’ll remember the container orchestration wars of 2015 to 2017. Kubernetes won the container wars in 2017, the idea of microservices had taken hold, and the trend toward containerization was unstoppable. Kubernetes architecture matured and slowly became boring, and service mesh technologies, represented by Linkerd and Istio, entered the CNCF-defined cloud-native critical technologies on the horizon.&lt;/p&gt;
&lt;p&gt;Kubernetes was designed with the concept of cloud-native in mind. A critical idea in cloud-native is the architectural design of microservices. When a single application is split into microservices, how can microservices be managed to ensure the SLA of the service as the number of services increases? The service mesh was born to solve this problem at the architectural level, free programmers’ creativity, and avoid tedious service discovery, monitoring, distributed tracing, and other matters.&lt;/p&gt;
&lt;p&gt;The service mesh takes the standard functionality of microservices down to the infrastructure layer, allowing developers to focus more on business logic and thus speed up service delivery, which is consistent with the whole idea of cloud-native. You no longer need to integrate bulky SDKs in your application, develop and maintain SDKs for different languages, and just use the service mesh for Day 2 operations after the application is deployed.&lt;/p&gt;
&lt;p&gt;The service mesh is regarded as the next generation of microservices. In the diagram, we can see that many of the concerns of microservices overlap with the functionality of Kubernetes. Kubernetes focuses on the application lifecycle, managing resources and deployments with little control over services. The service mesh fills this gap. The service mesh can connect, control, observe and protect microservices.&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;&lt;strong&gt;Kubernetes vs. xDS vs. Istio&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;This diagram shows the layered architecture of Kubernetes and Istio.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/008i3skNly1gxgxss9mamj30n90d73zs.jpg&#34; data-img=&#34;/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/008i3skNly1gxgxss9mamj30n90d73zs.jpg&#34; data-width=&#34;837&#34; data-height=&#34;475&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes vs xDS vs Istio&#34;&gt;
    
  
  &lt;figcaption&gt;Kubernetes vs xDS vs Istio&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The diagram indicates that the kube-proxy settings are global and cannot be controlled at a granular level for each service. All Kubernetes can do is topology-aware routing, routing traffic closer to the Pod, and setting network policies in and out of the Pod.&lt;/p&gt;
&lt;p&gt;In contrast, the service mesh takes traffic control out of the service layer in Kubernetes through sidecar proxies, injects proxies into each Pod, and manipulates these distributed proxies through a control plane. It allows for more excellent resiliency.&lt;/p&gt;
&lt;p&gt;Kube-proxy implements traffic load balancing between multiple pod instances of a Kubernetes service. But how do you finely control the traffic between these services — such as dividing the traffic by percentage to different application versions (which are all part of the same service, but on other deployments), or doing canary releases and blue-green releases?&lt;/p&gt;
&lt;p&gt;The Kubernetes community gives a way to do canary releases using Deployment, assigning different pods to deployed services by modifying the pod’s label.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/008i3skNly1gxgxsswmoij30sg0kl76r.jpg&#34; data-img=&#34;/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/008i3skNly1gxgxsswmoij30sg0kl76r.jpg&#34; data-width=&#34;1024&#34; data-height=&#34;741&#34; alt=&#34;image&#34; data-caption=&#34;Envoy Architecture&#34;&gt;
    
  
  &lt;figcaption&gt;Envoy Architecture&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Currently, the most popular open-source implementation of service mesh in the world is Istio. From the &lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Survey_Report_2020.pdf&#34; title=&#34;CNCF Survey Report 2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Survey Report 2020&lt;/a&gt;
, we know that Istio is the most used service mesh in production today. Many companies have built their service mesh based on Istio, such as Ant, Airbnb, eBay, NetEase, Tencent, etc.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/008i3skNly1gxgxstgg4qj30sg0gg0ts.jpg&#34; data-img=&#34;/en/blog/service-mesh-an-integral-part-of-cloud-native-apps/008i3skNly1gxgxstgg4qj30sg0gg0ts.jpg&#34; data-width=&#34;1024&#34; data-height=&#34;592&#34; alt=&#34;image&#34; data-caption=&#34;CNCF Survey Report 2020&#34;&gt;
    
  
  &lt;figcaption&gt;CNCF Survey Report 2020&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Figure from &lt;a href=&#34;https://www.cncf.io/wp-content/uploads/2020/11/CNCF_Survey_Report_2020.pdf&#34; title=&#34;CNCF Survey Report 2020&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Survey Report 2020&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Istio is developed based on Envoy, which has been used by default as its distributed proxy since the first day it was open-sourced. Envoy pioneered the creation of the xDS protocol for distributed gateway configuration, greatly simplifying the configuration of large-scale distributed networks. Ant Group open source MOSN also supported xDS In 2019. Envoy was also one of the first projects to graduate from CNCF, tested by large-scale production applications.&lt;/p&gt;
&lt;h3 id=&#34;service-mesh--the-cloud-native-networking-infrastructure&#34;&gt;Service mesh – the cloud-native networking infrastructure&lt;/h3&gt;
&lt;p&gt;With the above comparison between Kubernetes and service mesh in mind, we can see the place of service mesh in the cloud-native application architecture. That is, building a cloud-native network infrastructure specifically provides:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Traffic management: controlling the flow of traffic and API calls between services, making calls more reliable, and enhancing network robustness in different environments.&lt;/li&gt;
&lt;li&gt;Observability: understanding the dependencies between services and the nature and flow of traffic between them provides the ability to identify problems quickly.&lt;/li&gt;
&lt;li&gt;Policy enforcement: controlling access policies between services by configuring the mesh rather than by changing the code.&lt;/li&gt;
&lt;li&gt;Service Identification and Security: providing service identifiability and security protection in the mesh.&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 1.8: A Virtual Machine Integration Odyssey</title>
      <link>https://jimmysong.io/en/blog/istio-18-a-virtual-machine-integration-odyssey/</link>
      <pubDate>Sat, 23 Jan 2021 08:27:17 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/istio-18-a-virtual-machine-integration-odyssey/</guid>
      <description>
        
        
        &lt;p&gt;In this article, I’ll give you an overview of &lt;a href=&#34;https://istio.io/&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
‘s history of virtual machine integration support. In particular, the introduction of the smart DNS proxy and WorkloadGroup in Istio 1.8, which makes virtual machines and containers equivalent at the resource abstraction level.&lt;/p&gt;
&lt;p&gt;I will show you a tumultuous odyssey of Istio’s virtual machine integration. Tetrate, the enterprise service mesh company that made pushing Istio to run everywhere part of its founding mission, has used VM features extensively in customer deployments and has been instrumental in pushing VMs to Istio upstream.&lt;/p&gt;
&lt;h2 id=&#34;preface&#34;&gt;Preface&lt;/h2&gt;
&lt;p&gt;In my &lt;a href=&#34;https://thenewstack.io/how-to-integrate-virtual-machines-into-istio-service-mesh/&#34; title=&#34;previous article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;previous article&lt;/a&gt;
, I talked about how Istio 1.7 supported virtual machines. But at that time, late October, virtual machines were still not seamlessly integrated into Istio — there was still a lot of manual work required. Now, Istio 1.8 has added WorkloadGroup and smart DNS proxy, which allows non-Kubernetes workloads like VMs to become first-class citizens in Istio — just like pods.&lt;/p&gt;
&lt;p&gt;With or without a sidecar installed for virtual machines, until 1.7 you could not resolve the DNS name of a Kubernetes service unless a kube-external DNS was configured — which is the last piece of virtual machine integration in Istio. This shortcoming has finally been fixed in Istio 1.8.&lt;/p&gt;
&lt;h2 id=&#34;why-is-virtual-machine-support-important&#34;&gt;Why Is Virtual Machine Support Important?&lt;/h2&gt;
&lt;p&gt;In the process of migrating our applications to cloud native architectures and continuously containerizing them, we will go through three phases as shown in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6t775lj31s80k8go8.jpg&#34; data-img=&#34;/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6t775lj31s80k8go8.jpg&#34; data-width=&#34;2312&#34; data-height=&#34;728&#34; alt=&#34;image&#34; data-caption=&#34;Cloud Native Stages&#34;&gt;
    
  
  &lt;figcaption&gt;Cloud Native Stages&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Stage 1: All applications are deployed on virtual machines&lt;/li&gt;
&lt;li&gt;Stage 2: Applications are deployed on both virtual machines and containers, are migrating from virtual machines to containers, and are using Kubernetes to manage containers.&lt;/li&gt;
&lt;li&gt;Stage 3: All applications are deployed in containers first, using Kubernetes to manage containers and Istio to manage service-to-service communication.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The above diagram is artificially simplified: in reality, there might be multiple hybrid clouds, multiple regions, multiple clusters, etc. Plus, at stage 3 containers and virtual machines may remain in long-term coexistence, but the trend of containerization remains unchanged.&lt;/p&gt;
&lt;h2 id=&#34;istios-history-of-virtual-machine-support&#34;&gt;Istio’s History of Virtual Machine Support&lt;/h2&gt;
&lt;p&gt;Istio’s support for virtual machines is a long process, an odyssey of sorts.&lt;/p&gt;
&lt;h3 id=&#34;02-istio-mesh-expansion&#34;&gt;0.2: Istio Mesh Expansion&lt;/h3&gt;
&lt;p&gt;As of version 0.2, Istio added virtual machines to the Mesh via &lt;a href=&#34;https://istio.io/v0.2/docs/setup/kubernetes/mesh-expansion.html&#34; title=&#34;Istio Mesh Expansion&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Mesh Expansion&lt;/a&gt;
, provided that the following prerequisites were met.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Virtual machines must have direct access to the application’s pods via IP address, which requires a flat network between the container and the VM via VPC or VPN; and virtual machines do not need access to the Cluster IP, but rather direct access to the service’s endpoints.&lt;/li&gt;
&lt;li&gt;Virtual machines must have access to Istio’s control plane services (Pilot, Mixer, CA, now being integrated as Istiod), which can expose the control plane endpoints to virtual machines by deploying load balancers in the Istio Mesh.&lt;/li&gt;
&lt;li&gt;(optional) the virtual machine has access to the DNS server inside the Mesh (deployed in Kubernetes).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The steps to integrate a virtual machine are as follows.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Create an internal load balancer for the Istio control plane service and the DNS service for the Kubernetes cluster.&lt;/li&gt;
&lt;li&gt;Generate a configuration file for the Istio Service CIDR, Service Account token, security certificate, and IP of the Istio Control Plane Service (the IP exposed through the Internal Load Balancer) and send it to the virtual machine.&lt;/li&gt;
&lt;li&gt;Setup the Istio component, dnsmaq (for DNS discovery), in the virtual machine; so that the virtual machine can access the services in the mesh using FQDN, to ensure that the virtual machine can correctly resolve the Cluster IP of the services in the mesh.&lt;/li&gt;
&lt;li&gt;To run the service in a virtual machine, you need to configure the sidecar, add inbound ports to be intercepted, then restart Istio and also run istioctl to register the service.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The following figure shows the detailed flow from integrating a virtual machine to accessing services in the virtual machine in a mesh.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6rogojj30u00yhdil.jpg&#34; data-img=&#34;/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6rogojj30u00yhdil.jpg&#34; data-width=&#34;1080&#34; data-height=&#34;1241&#34; alt=&#34;image&#34; data-caption=&#34;Figure 1&#34;&gt;
    
  
  &lt;figcaption&gt;Figure 1&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Figure 1&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The DNS is hijacked by dnsmasq deployed in the virtual machine, which allows it to correctly obtain the Cluster IP of the Istio service (Kubernetes’ built-in DNS).&lt;/li&gt;
&lt;li&gt;Access to Kubernetes’ built-in DNS service (which is exposed outside the cluster via the Internal Load Balancer and can be accessed directly).&lt;/li&gt;
&lt;li&gt;Return the Cluster IP resolved by &lt;code&gt;productpage.bookinfo.svc.cluster.local&lt;/code&gt;, noting that the IP address is not directly accessible, but failure to be DNS resolved will result in a failed VM request for the service.&lt;/li&gt;
&lt;li&gt;The virtual machine’s call to services in a mesh is hijacked by the sidecar proxy.&lt;/li&gt;
&lt;li&gt;Since the proxy is connected to the Istio control plane, the endpoints of the service can be queried via xDS, so traffic will be forwarded to one of the endpoints.&lt;/li&gt;
&lt;li&gt;To access VM services in mesh, you need to manually add VM services to mesh using the istioctl register command, which essentially registers the VM services to the service and endpoint in Kubernetes.&lt;/li&gt;
&lt;li&gt;Services in the mesh can be accessed using the VM-registered service name (FQDN, e.g. &lt;code&gt;mysql.vm.svc.cluster.local&lt;/code&gt;).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above Istio support for virtual machines continued with Istio 1.0, which introduced a new API &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/service-entry/&#34; title=&#34;ServiceEntry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ServiceEntry&lt;/a&gt;
 with Istio 1.1, that allows additional entries to be added to Istio’s internal service registry so that services in the mesh can access/route to these manually specified services. The istioctl register command is no longer needed and will be deprecated in Istio 1.9.&lt;/p&gt;
&lt;p&gt;The istioctl experimental add-to-mesh command has been added to Istio 1.5 to add services from a virtual machine to a mesh, and it works just like the istioctl register.&lt;/p&gt;
&lt;h3 id=&#34;16-to-17-new-resource-abstractions&#34;&gt;1.6 to 1.7: New Resource Abstractions&lt;/h3&gt;
&lt;p&gt;Istio introduced a new resource type, &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/workload-entry/&#34; title=&#34;WorkloadEntry&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WorkloadEntry&lt;/a&gt;
, in traffic management from &lt;a href=&#34;https://istio.io/latest/news/releases/1.6.x/announcing-1.6/&#34; title=&#34;version 1.6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;version 1.6&lt;/a&gt;
, to abstract virtual machines so that they can be added to the mesh as equivalent loads to the pods in Kubernetes; with traffic management, security management, observability, etc. The mesh configuration process for virtual machines is simplified with WorkloadEntry, which selects multiple workload entries and Kubernetes pods based on the label selector specified in the service entry.&lt;/p&gt;
&lt;p&gt;Istio 1.8 adds a resource object for &lt;a href=&#34;http://istio.io/latest/docs/reference/config/networking/workload-group/&#34; title=&#34;WorkloadGroup&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WorkloadGroup&lt;/a&gt;
 that provides a specification that can include both virtual machines and Kubernetes workloads, designed to mimic the existing sidecar injection and deployment specification model for Kubernetes workloads to bootstrap Istio agents on the VMs.&lt;/p&gt;
&lt;p&gt;Below is a comparison of resource abstraction levels for virtual machines versus workloads in Kubernetes.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Item&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Virtual Machine&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Basic schedule unit&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Pod&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Component&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Deployment&lt;/td&gt;
&lt;td&gt;WorkloadGroup&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Service register and discovery&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;From the above diagram, we can see that for virtual machine workloads there is a one-to-one correspondence with the workloads in Kubernetes.&lt;/p&gt;
&lt;p&gt;Everything seems perfect at this point. However, exposing the DNS server in the Kubernetes cluster directly is a big &lt;a href=&#34;https://blog.aquasec.com/dns-spoofing-kubernetes-clusters&#34; title=&#34;security risk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;security risk&lt;/a&gt;
, so we usually manually write the domain name and Cluster IP pair of the service the virtual machine needs to access to the local /etc/hosts — but this is not practical for a distributed cluster with a large number of nodes.&lt;/p&gt;
&lt;p&gt;The process of accessing the services inside mesh by configuring the local /etc/hosts of the virtual machine is shown in the following figure.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6qx2o0j30sq0v440v.jpg&#34; data-img=&#34;/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6qx2o0j30sq0v440v.jpg&#34; data-width=&#34;1034&#34; data-height=&#34;1120&#34; alt=&#34;image&#34; data-caption=&#34;Figure 2&#34;&gt;
    
  
  &lt;figcaption&gt;Figure 2&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Figure 2&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Registration of services in the virtual machine into the mesh.&lt;/li&gt;
&lt;li&gt;Manually write the domain name and Cluster IP pairs of the service to be accessed to the local /etc/hosts file in the virtual machine.&lt;/li&gt;
&lt;li&gt;Cluster IP where the virtual machine gets access to the service.&lt;/li&gt;
&lt;li&gt;The traffic is intercepted by the sidecar proxy and the endpoint address of the service to be accessed is resolved by Envoy.&lt;/li&gt;
&lt;li&gt;Access to designated endpoints of the service.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In Kubernetes, we generally use the Service object for service registration and discovery; each service has a separate DNS name that allows applications to call each other by using the service name. We can use ServiceEntry to register a service in a virtual machine into Istio’s service registry, but a virtual machine cannot access a DNS server in a Kubernetes cluster to get the Cluster IP if the DNS server is not exposed externally to the mesh, which causes the virtual machine to fail to access the services in the mesh. Wouldn’t the problem be solved if we could add a sidecar to the virtual machine that would transparently intercept DNS requests and get the Cluster IP of all services in the mesh, similar to the role of dnsmasq in Figure 1?&lt;/p&gt;
&lt;h3 id=&#34;as-of-istio-18--smart-dns-proxy&#34;&gt;As of Istio 1.8 — Smart DNS Proxy&lt;/h3&gt;
&lt;p&gt;With the introduction of smart &lt;a href=&#34;https://cloudnative.to/blog/istio-dns-proxy/&#34; title=&#34;DNS proxy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DNS proxy&lt;/a&gt;
 in Istio 1.8, virtual machines can access services within the mesh without the need to configure /etc/hosts, as shown in the following figure.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6sgfpxj30oi0rsjt5.jpg&#34; data-img=&#34;/en/blog/istio-18-a-virtual-machine-integration-odyssey/0081Kckwly1gm0d6sgfpxj30oi0rsjt5.jpg&#34; data-width=&#34;882&#34; data-height=&#34;1000&#34; alt=&#34;image&#34; data-caption=&#34;Figure 3&#34;&gt;
    
  
  &lt;figcaption&gt;Figure 3&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Figure 3&lt;/p&gt;
&lt;p&gt;The Istio agent on the sidecar will come with a cached DNS proxy dynamically programmed by Istiod. DNS queries from the application are transparently intercepted and served by the Istio proxy in the pod or VM, with the response to DNS query requests, enabling seamless access from the virtual machine to the service mesh.&lt;/p&gt;
&lt;p&gt;The WorkloadGroup and smart DNS proxy introduced in Istio 1.8 provide powerful support for virtual machine workloads, making legacy applications deployed in virtual machines fully equivalent to pods in Kubernetes.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;In this odyssey of Istio’s virtual machine support, we can see the gradual realization of unified management of virtual machines and pods — starting with exposing the DNS server in the mesh and setting up dnsmasq in the virtual machine, and ending with using smart DNS proxies and abstracting resources such as &lt;code&gt;WorkloadEntry&lt;/code&gt;, &lt;code&gt;WorkloadGroup&lt;/code&gt; and &lt;code&gt;ServiceEntry&lt;/code&gt;. This article only focuses on the single cluster situation, which is not enough to be used in real production. We also need to deal with security, multicluster, multitenancy, etc.&lt;/p&gt;
&lt;h2 id=&#34;referenced-resources&#34;&gt;Referenced resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34; title=&#34;Tetrate Service Bridge — Across all compute bridging Kubernetes clusters, VMs, and bare metal&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Service Bridge — Across all compute bridging Kubernetes clusters, VMs, and bare metal&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/blog/2020/dns-proxy/&#34; title=&#34;Expanding into New Frontiers — Smart DNS Proxying in Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Expanding into New Frontiers — Smart DNS Proxying in Istio&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/setup/install/virtual-machine/&#34; title=&#34;Virtual Machine Installation — Istio documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Virtual Machine Installation — Istio documentation&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://thenewstack.io/how-to-integrate-virtual-machines-into-istio-service-mesh/&#34; title=&#34;How to Integrate Virtual Machines into Istio Service Mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;How to Integrate Virtual Machines into Istio Service Mesh&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>What Is a Service Mesh?</title>
      <link>https://jimmysong.io/en/blog/what-is-a-service-mesh/</link>
      <pubDate>Fri, 22 Jan 2021 08:27:17 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/what-is-a-service-mesh/</guid>
      <description>
        
        
        &lt;p&gt;A service mesh is a relatively simple concept, consisting of a bunch of network proxies paired with each service in an application, plus a set of task management processes. The proxies are called the data plane and the management processes are called the control plane in the Service Mesh. The data plane intercepts calls between different services and “processes” them; the control plane is the brain of the mesh that coordinates the behavior of proxies and provides APIs for operations and maintenance personnel to manipulate and observe the entire network.&lt;/p&gt;
&lt;p&gt;The diagram below shows the architecture of a service mesh.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/what-is-a-service-mesh/service-mesh-architecture.png&#34; data-img=&#34;/en/blog/what-is-a-service-mesh/service-mesh-architecture.png&#34; data-width=&#34;2676&#34; data-height=&#34;1328&#34; alt=&#34;image&#34; data-caption=&#34;Service Mesh Architecture&#34;&gt;
    
  
  &lt;figcaption&gt;Service Mesh Architecture&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Further, the service mesh is a dedicated infrastructure layer designed to enable reliable, fast, and secure inter-service invocation in microservices architectures. It is not a mesh of “services” but rather a mesh of “proxies” that services can plug into, thus abstracting the network from the application code. In a typical service mesh, these proxies are injected into each service deployment as a sidecar (and also may be deployed at the edge of the mesh). Instead of invoking services directly over the network, services invoke their local sidecar proxy, which in turn manages requests on behalf of the service, pushing the complexities of inter-service communications into a networking layer that can resolve them at scale. The set of interconnected sidecar proxies implements a so-called data plane, while on the other hand the service mesh control plane is used to configure proxies. The infrastructure introduced by a service mesh provides an opportunity, too, to collect metrics about the traffic that is flowing through the application.&lt;/p&gt;
&lt;h2 id=&#34;the-architecture-of-a-service-mesh&#34;&gt;The architecture of a service mesh&lt;/h2&gt;
&lt;p&gt;The infrastructure layer of a service mesh is divided into two main parts: the control plane and the data plane.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Characteristics of the control plane&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do not parse packets directly.&lt;/li&gt;
&lt;li&gt;Communicates with proxies in the control plane to issue policies and configurations.&lt;/li&gt;
&lt;li&gt;Visualizes network behavior.&lt;/li&gt;
&lt;li&gt;Typically provides APIs or command-line tools for configuration versioning and management for continuous integration and deployment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Characteristics of the data plane&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is usually designed with the goal of statelessness (though in practice some data needs to be cached to improve traffic forwarding performance).&lt;/li&gt;
&lt;li&gt;Directly handles inbound and outbound packets, forwarding, routing, health checking, load balancing, authentication, authentication, generating monitoring data, etc.&lt;/li&gt;
&lt;li&gt;Is transparent to the application, i.e., can be deployed senselessly.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;changes-brought-by-the-service-mesh&#34;&gt;Changes brought by the service mesh&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Decoupling of microservice governance from business logic&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;A service mesh takes most of the capabilities in the SDK out of the application, disassembles them into separate processes, and deploys them in a sidecar model. By separating service communication and related control functions from the business process and synching them to the infrastructure layer, a service mesh &lt;strong&gt;mostly&lt;/strong&gt; decouples them from the business logic, allowing application developers to focus more on the business itself.&lt;/p&gt;
&lt;p&gt;Note that the word “mostly” is mentioned here and that the SDK often needs to retain protocol coding and decoding logic, or even a lightweight SDK to implement fine-grained governance and monitoring policies in some scenarios. For example, to implement method-level call distributed tracing, the service mesh requires the business application to implement trace ID passing, and this part of the implementation logic can also be implemented through a lightweight SDK. Therefore, the service mesh is not zero-intrusive from a code level.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unified governance of heterogeneous environments&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With the development of new technologies and staff turnover, there are often applications and services in different languages and frameworks in the same company, and in order to control these services uniformly, the previous practice was to develop a complete set of SDKs for each language and framework, which is very costly to maintain. With a service mesh, multilingual support is much easier by synching the main service governance capabilities to the infrastructure. By providing a very lightweight SDK, and in many cases, not even a separate SDK, it is easy to achieve unified traffic control and monitoring requirements for multiple languages and protocols.&lt;/p&gt;
&lt;h2 id=&#34;features-of-service-mesh&#34;&gt;Features of service mesh&lt;/h2&gt;
&lt;p&gt;Service mesh also has three major technical advantages over traditional microservice frameworks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Observability&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because the service mesh is a dedicated infrastructure layer through which all inter-service communication passes, it is uniquely positioned in the technology stack to provide uniform telemetry at the service invocation level. This means that all services are monitored as “black boxes.” The service mesh captures route data such as source, destination, protocol, URL, status codes, latency, duration, etc. This is essentially the same data that web server logs can provide, but the service mesh captures this data for all services, not just the web layer of individual services. It is important to note that collecting data is only part of the solution to the observability problem in microservice applications. Storing and analyzing this data needs to be complemented by mechanisms for additional capabilities, which then act as alerts or automatic instance scaling, for example.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Traffic control&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With a service mesh, services can be provided with various control capabilities such as intelligent routing (blue-green deployment, canary release, A/B test), timeout retries, circuit breaking, fault injection, traffic mirroring, etc. These are often features that are not available in traditional microservices frameworks but are critical to the system. For example, the service mesh carries the communication traffic between microservices, so it is possible to test the robustness of the whole application by simulating the failure of some microservices through rules for fault injection in the grid. Since the service mesh is designed to efficiently connect source request calls to their optimal destination service instances, these traffic control features are “destination-oriented.” This is a key feature of the service mesh’s traffic control capabilities.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Security&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To some extent, monolithic applications are protected by their single address space. However, once a monolithic application is broken down into multiple microservices, the network becomes a significant attack surface. More services mean more network traffic, which means more opportunities for hackers to attack the information flow. And service mesh provides the capabilities and infrastructure to protect network calls. The security-related benefits of service mesh are in three core areas: authentication of services, encryption of inter-service communications, and enforcement of security-related policies.&lt;/p&gt;
&lt;p&gt;Service mesh has brought about tremendous change and has strong technical advantages, and has been called the second generation of “microservice architecture.” However, there is no silver bullet in software development. Traditional microservices architecture has many pain points, and service mesh is no exception. It has its limitations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Increased complexity&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Service mesh introduces sidecar proxies and other components into an already complex, distributed environment, which can greatly increase the overall chain and operational O&amp;amp;M complexity. Ops needs to be more specialized. Adding a service mesh such as Istio to a container orchestrator such as Kubernetes often requires Ops to become an expert in both technologies in order to fully utilize the capabilities of both and to troubleshoot the problems encountered in the environment.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Latency&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At the link level, a service mesh is an invasive, complex technology that can add significant latency to system calls. This latency is on the millisecond level, but it can also be intolerable in special business scenarios.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Platform adaptation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The intrusive nature of service mesh forces developers and operators to adapt to highly autonomous platforms and adhere to the platform’s rules.&lt;/p&gt;
&lt;h2 id=&#34;the-relationship-between-service-mesh-and-kubernetes&#34;&gt;The relationship between service mesh and Kubernetes&lt;/h2&gt;
&lt;p&gt;Kubernetes is essentially application lifecycle management, specifically the deployment and management (scaling, auto-recovery, publishing) of containerized applications. Service mesh decouples traffic management from Kubernetes, eliminating the need for a kube-proxy component for internal traffic, and manages inter-service and ingress traffic, security, and observability through an abstraction closer to the microservice application layer. The xDS used by Istio and Envoy is one of the protocol standards for service mesh configuration.&lt;/p&gt;
&lt;p&gt;Organizations that use Kubernetes often turn to a service mesh to address the networking issues that arise with containerization — but notably, a service mesh can work with a legacy or a modern workload, and can be put in place prior to containerization for a faster, safer path to modernization.&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Readers should look dialectically at the advantages and disadvantages of a service mesh compared with traditional microservices architecture. A service mesh can be a critical part of the evolutionary path of application architecture, from the earliest monolith to distributed, to microservices, containerization, container orchestration, to hybrid workloads and multi-cloud.&lt;/p&gt;
&lt;p&gt;Looking ahead, Kubernetes is exploding, and it has become the container orchestration of choice for enterprise greenfield applications. If Kubernetes has completely won the market and the size and complexity of Kubernetes-based applications continue to grow, there will be a tipping point, and service mesh will be necessary to effectively manage these applications. As service mesh technology continues to evolve and the architecture and functionality of its implementation products, such as Istio, continue to be optimized, service mesh will completely replace traditional microservice architectures as the architecture of choice for microservices and transformation to the cloud for enterprises.&lt;/p&gt;
&lt;p&gt;This article was co-authored by Guangming Luo, a member of the ServiceMesher community and the CNC steering community.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 1.8: A Smart DNS Proxy Takes Support For Virtual Machines A Step Further</title>
      <link>https://jimmysong.io/en/blog/istio-1-8-a-smart-dns-proxy-takes-support-for-virtual-machines-a-step-further/</link>
      <pubDate>Thu, 19 Nov 2020 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/istio-1-8-a-smart-dns-proxy-takes-support-for-virtual-machines-a-step-further/</guid>
      <description>
        
        
        &lt;p&gt;1.8 is the last version of Istio to be released in 2020 and it has the following major updates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Supports installation and upgrades using Helm 3.&lt;/li&gt;
&lt;li&gt;Mixer was officially removed.&lt;/li&gt;
&lt;li&gt;Added Istio DNS proxy to transparently intercept DNS queries from applications.&lt;/li&gt;
&lt;li&gt;WorkloadGroup has been added to simplify the integration of virtual machines.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;WorkloadGroup is a new API object. It is intended to be used with non-Kubernetes workloads like Virtual Machines and is meant to mimic the existing sidecar injection and deployment specification model used for Kubernetes workloads to bootstrap Istio proxies.&lt;/p&gt;
&lt;h2 id=&#34;installation-and-upgrades&#34;&gt;Installation and Upgrades&lt;/h2&gt;
&lt;p&gt;Istio starts to officially support the use of &lt;a href=&#34;https://istio.io/latest/docs/setup/install/helm/&#34; title=&#34;Helm&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Helm&lt;/a&gt;
 v3 for installations and upgrades. In previous versions, the installation was done with the istioctl command-line tool or Operator. With version 1.8, Istio supports in-place and canary upgrades with Helm.&lt;/p&gt;
&lt;h2 id=&#34;enhancing-istios-usability&#34;&gt;Enhancing Istio’s Usability&lt;/h2&gt;
&lt;p&gt;The istioctl command-line tool has a new bug reporting feature (&lt;a href=&#34;https://istio.io/latest/docs/reference/commands/istioctl/#istioctl-bug-report&#34; title=&#34;istioctl bug-report&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;istioctl bug-report&lt;/a&gt;
), which can be used to collect debugging information and get cluster status.&lt;/p&gt;
&lt;p&gt;The way to install the &lt;a href=&#34;https://istio.io/latest/blog/2020/addon-rework/&#34; title=&#34;add-on&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;add-on&lt;/a&gt;
 has changed: 1.7 istioctl is no longer recommended and has been removed in 1.8, to help solve the problem of add-on lagging upstream and to make it easier to maintain.&lt;/p&gt;
&lt;p&gt;Tetrate is an enterprise service mesh company. Our flagship product, TSB, enables customers to bridge their workloads across bare metal, VMs, K8s, &amp;amp; cloud at the application layer and provide a resilient, feature-rich service mesh fabric powered by Istio, Envoy, and Apache SkyWalking.&lt;/p&gt;
&lt;p&gt;Mixer, the Istio component that had been responsible for policy controls and telemetry collection, has been removed. Its functionalities are now being served by the Envoy proxies. For extensibility, service mesh experts recommend using &lt;a href=&#34;https://istio.io/latest/blog/2020/wasm-announce/&#34; title=&#34;WebAssembly&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WebAssembly&lt;/a&gt;
 (Wasm) to extend Envoy; and you can also try the &lt;a href=&#34;https://www.getenvoy.io/reference/getenvoy_extension_toolkit_reference/&#34; title=&#34;GetEnvoy Toolkit&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GetEnvoy Toolkit&lt;/a&gt;
, which makes it easier for developers to create Wasm extensions for Envoy. If you still want to use Mixer, you must use version 1.7 or older. Mixer continued receiving bug fixes and security fixes until Istio 1.7. Many features supported by Mixer have alternatives as specified in the &lt;a href=&#34;https://tinyurl.com/mixer-deprecation&#34; title=&#34;Mixer Deprecation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mixer Deprecation&lt;/a&gt;
 document, including the &lt;a href=&#34;https://github.com/istio/proxy/tree/master/extensions&#34; title=&#34;in-proxy extensions&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;in-proxy extensions&lt;/a&gt;
 based on the Wasm sandbox API.&lt;/p&gt;
&lt;h2 id=&#34;support-for-virtual-machines&#34;&gt;Support for Virtual Machines&lt;/h2&gt;
&lt;p&gt;Istio’s recent upgrades have steadily focused on making virtual machines first-class citizens in the mesh. &lt;a href=&#34;https://thenewstack.io/how-to-integrate-virtual-machines-into-istio-service-mesh/&#34; title=&#34;Istio 1.7 made progress to support virtual machines&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 1.7 made progress to support virtual machines&lt;/a&gt;
 and Istio 1.8 adds a &lt;a href=&#34;https://istio.io/latest/blog/2020/dns-proxy/&#34; title=&#34;smart DNS proxy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;smart DNS proxy&lt;/a&gt;
, which is an Istio sidecar agent written in Go. The Istio agent on the sidecar will come with a cache that is dynamically programmed by Istiod DNS Proxy. DNS queries from applications are transparently intercepted and served by an Istio proxy in a pod or VM that intelligently responds to DNS query requests, enabling seamless multicluster access from virtual machines to the service mesh.&lt;/p&gt;
&lt;p&gt;Istio 1.8 adds a &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/workload-group/&#34; title=&#34;WorkloadGroup&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WorkloadGroup&lt;/a&gt;
, which describes a collection of workload instances. It provides a specification that the workload instances can use to bootstrap their proxies, including the metadata and identity. It is only intended to be used with non-k8s workloads like Virtual Machines, and is meant to mimic the existing sidecar injection and deployment specification model used for Kubernetes workloads to bootstrap Istio proxies. Using WorkloadGroups, Istio has started to help automate VM registration with &lt;a href=&#34;https://istio.io/latest/docs/setup/install/virtual-machine/#create-files-to-transfer-to-the-virtual-machine&#34; title=&#34;istioctl experimental workload group&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;istioctl experimental workload group&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.tetrate.io/&#34; title=&#34;Tetrate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate&lt;/a&gt;
, the enterprise service mesh company, uses these &lt;a href=&#34;https://www.tetrate.io/blog/whats-new-in-istio-1-8-dns-proxy-helps-expand-mesh-to-vms-and-multicluster/&#34; title=&#34;VM features&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VM features&lt;/a&gt;
 extensively in customers’ multicluster deployments, to enable sidecars to resolve DNS for hosts exposed at ingress gateways of all the clusters in a mesh; and to access them over mutual TLS.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;All in all, the Istio team has kept the promise made at the beginning of the year to maintain a regular release cadence of one release every three months since the 1.1 release in 2018, with continuous optimizations in performance and user experience for a seamless experience of brownfield and greenfield apps on Istio. We look forward to more progress from Istio in 2021.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>How to Integrate Virtual Machines Into Istio Service Mesh</title>
      <link>https://jimmysong.io/en/blog/how-to-integrate-virtual-machines-into-istio-service-mesh/</link>
      <pubDate>Mon, 02 Nov 2020 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/how-to-integrate-virtual-machines-into-istio-service-mesh/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://istio.io/&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
 is a popular service mesh to connect, secure, control, and observe services. When it was first introduced as open source in 2017, Kubernetes was winning the container orchestration battle and Istio answered the needs of organizations moving to microservices. Although Istio claims to support heterogeneous environments such as Nomad, Consul, Eureka, Cloud Foundry, Mesos, etc., in reality, it has always worked best with Kubernetes — on which its service discovery is based.&lt;/p&gt;
&lt;p&gt;Istio was criticized for a number of issues early in its development, for the large number of components, the complexity of installation and maintenance, the difficulty of debugging, a steep learning curve due to the introduction of too many new concepts and objects (up to 50 CRDs), and the impact of Mixer components on performance. But these issues are gradually being overcome by the Istio team. As you can see from the &lt;a href=&#34;https://istio.io/latest/zh/blog/2020/tradewinds-2020/&#34; title=&#34;roadmap&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;roadmap&lt;/a&gt;
 released in early 2020, Istio has come a long way.&lt;/p&gt;
&lt;p&gt;Better integration of VM-based workloads into the mesh is a major focus for the Istio team this year. Tetrate also offers seamless multicloud connectivity, security, and observability, including for VMs, via its product &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34; title=&#34;Tetrate Service Bridge&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Service Bridge&lt;/a&gt;
. This article will take you through why Istio needs to integrate with virtual machines and how you can do so.&lt;/p&gt;
&lt;h2 id=&#34;why-should-istio-support-virtual-machines&#34;&gt;Why Should Istio Support Virtual Machines?&lt;/h2&gt;
&lt;p&gt;Although containers and Kubernetes are now widely used, there are still many services deployed on virtual machines and APIs outside of the Kubernetes cluster that needs to be managed by Istio mesh. It’s a huge challenge to unify the management of the brownfield environment with the greenfield.&lt;/p&gt;
&lt;h2 id=&#34;what-is-needed-to-add-vms-to-the-mesh&#34;&gt;What Is Needed to Add VMs to the Mesh?&lt;/h2&gt;
&lt;p&gt;Before the “how,” I’ll describe &lt;em&gt;what&lt;/em&gt; is needed to add virtual machines to the mesh. There are a couple of things that Istio must know when supporting virtual machine traffic: which VMs have services that should be part of the mesh, and how to reach the VMs. Each VM also needs an identity, in order to communicate securely with the rest of the mesh. These requirements could work with Kubernetes CRDs, as well as a full-blown Service Registry like Consul. And the service account based identity bootstrapping could work as a mechanism for assigning workload identities to VMs that do not have a platform identity. For VMs that do have a platform identity (like EC2, GCP, Azure, etc.), work is underway in Istio to exchange the platform identity with a Kubernetes identity for ease of setting up mTLS communication.&lt;/p&gt;
&lt;h2 id=&#34;how-does-istio-support-virtual-machines&#34;&gt;How Does Istio Support Virtual Machines?&lt;/h2&gt;
&lt;p&gt;Istio’s support for virtual machines starts with its service registry mechanism. The information about services and instances in the Istio mesh comes from Istio’s service registries, which up to this point have only looked at or tracked pods. In newer versions, Istio now has resource types to track and watch VMs. The sidecars inside the mesh cannot observe and control traffic to services outside the mesh, because they do not have any information about them.&lt;/p&gt;
&lt;p&gt;The Istio community and &lt;a href=&#34;https://www.tetrate.io/&#34; title=&#34;Tetrate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate&lt;/a&gt;
 have done a lot of &lt;a href=&#34;https://www.tetrate.io/blog/istio-bringing-vms-into-the-mesh-with-cynthia-coan/&#34; title=&#34;work&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;work&lt;/a&gt;
 on Istio’s support for virtual machines. The 1.6 release included the addition of WorkloadEntry, which allows you to describe a VM exactly as you would a host running in Kubernetes. In 1.7, the release started to add the foundations for bootstrapping VMs into the mesh automatically through tokens, with Istio doing the heavy lifting. Istio 1.8 will debut another abstraction called WorkloadGroup, which is similar to a Kubernetes Deployment object — but for VMs.&lt;/p&gt;
&lt;p&gt;The following diagram shows how Istio models services in the mesh. The predominant source of information comes from a platform service registry like Kubernetes, or a system like Consul. In addition, the ServiceEntry serves as a user-defined service registry, modeling services on VMs or external services outside the organization.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/how-to-integrate-virtual-machines-into-istio-service-mesh/0081Kckwgy1gkp0fvr3orj30p30ehabc.jpg&#34; data-img=&#34;/en/blog/how-to-integrate-virtual-machines-into-istio-service-mesh/0081Kckwgy1gkp0fvr3orj30p30ehabc.jpg&#34; data-width=&#34;903&#34; data-height=&#34;521&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
    
  
  &lt;figcaption&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why install Istio in a virtual machine when you can just use ServiceEntry to bring in the services in the VMs?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Using ServiceEntry, you can enable services inside the mesh to discover and access external services; and in addition, manage the traffic to those external services. In conjunction with VirtualService, you can also configure access rules for the corresponding external service — such as request timeouts, fault injection, etc. — to enable controlled access to the specified external service.&lt;/p&gt;
&lt;p&gt;Even so, it only controls the traffic on the client-side, not access to the introduced external service to other services. That is, it cannot control the behavior of the service as the call initiator. Deploying sidecars in a virtual machine and introducing the virtual machine workload via workload selector allows the virtual machine to be managed indiscriminately, like a pod in Kubernetes.&lt;/p&gt;
&lt;h2 id=&#34;future&#34;&gt;Future&lt;/h2&gt;
&lt;p&gt;As you can see from the &lt;a href=&#34;https://istio.io/latest/docs/examples/virtual-machines/bookinfo/&#34; title=&#34;bookinfo demo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bookinfo demo&lt;/a&gt;
, there is too much manual work involved in the process and it’s easy to go wrong. In the future, Istio will improve VM testing to be realistic, automate bootstrapping based on platform identity, improve DNS support and istioctl debugging, and more. You can follow the &lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md&#34; title=&#34;Istio Environment Working Group&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Environment Working Group&lt;/a&gt;
 for more details about virtual machine support.&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/setup/install/virtual-machine/&#34; title=&#34;Virtual Machine Installation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Virtual Machine Installation&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/examples/virtual-machines/single-network/&#34; title=&#34;Virtual Machines in Single-Network Meshes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Virtual Machines in Single-Network Meshes&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/blog/istio-bringing-vms-into-the-mesh-with-cynthia-coan/&#34; title=&#34;Istio: Bringing VMs into the Mesh (with Cynthia Coan)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio: Bringing VMs into the Mesh (with Cynthia Coan)&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/blog/bridging-traditional-and-modern-workloads/&#34; title=&#34;Bridging Traditional and Modern Workloads&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bridging Traditional and Modern Workloads&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>New Beginning - Goodbye Ant, Hello Tetrate</title>
      <link>https://jimmysong.io/en/blog/moving-on-from-ant-group/</link>
      <pubDate>Mon, 31 Aug 2020 08:27:17 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/moving-on-from-ant-group/</guid>
      <description>
        
        
        &lt;p&gt;Today is my 914th day and also the last day with &lt;a href=&#34;https://www.antgroup.com/&#34; title=&#34;Ant Group&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ant Group&lt;/a&gt;
, tomorrow is September 1st, which is usually the day school starts, and everyone at Alibaba is known as &amp;ldquo;classmate&amp;rdquo;, tomorrow I will join &lt;a href=&#34;https://tetrate.io&#34; title=&#34;Tetrate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate&lt;/a&gt;
, and that&amp;rsquo;s kind of starting my new semester!&lt;/p&gt;
&lt;h2 id=&#34;antalibaba-and-the-cloud-native-community&#34;&gt;Ant/Alibaba and the Cloud Native Community&lt;/h2&gt;
&lt;p&gt;To date, Ant/Alibaba Group has had a profound impact on my career, especially its corporate culture and values, and the Alibaba recruiting philosophy of &amp;ldquo;finding like-minded people&amp;rdquo;, and isn&amp;rsquo;t the process of creating the Cloud Native Community also a process of finding like-minded people? &lt;a href=&#34;https://cloudnative.to&#34; title=&#34;Cloud Native Community&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Native Community&lt;/a&gt;
 is like a small society, I don&amp;rsquo;t want it to have much social value, but only want it to make a small but beautiful change to individuals, to enterprises and to society. I constantly think about myself as an individual and as an employee, especially as an initiator of the community. What is my mission as an individual, an employee, and especially as an initiator of a community? What role should I play in the company? Where is this community going? I&amp;rsquo;m fumbling along, but because of your support, it makes me stronger and more committed to the adoption and application of cloud native technology in China, outside of me I may have gone faster, but now with the community together we will go further!&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/moving-on-from-ant-group/20190624.jpg&#34; data-img=&#34;/en/blog/moving-on-from-ant-group/20190624.jpg&#34; data-width=&#34;1200&#34; data-height=&#34;559&#34; alt=&#34;image&#34; data-caption=&#34;24 June 2019, Shanghai, KubeCon China 2019&#34;&gt;
    
  
  &lt;figcaption&gt;24 June 2019, Shanghai, KubeCon China 2019&lt;/figcaption&gt;
&lt;/figure&gt;

&lt;em&gt;June 24, 2019, Shanghai, KubeCon China 2019&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;joining-tetrate&#34;&gt;Joining Tetrate&lt;/h2&gt;
&lt;p&gt;Over the past two years, I&amp;rsquo;ve been working hard to promote Istio and Service Mesh technology, and with funding from Ant Group, I started the &lt;a href=&#34;https://www.servicemesher.com&#34; title=&#34;ServiceMesher Community&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ServiceMesher Community&lt;/a&gt;
 to bring Service Mesh technology to China. Next I want to bring Chinese practice to the world.&lt;/p&gt;
&lt;p&gt;As a Developer Advocate, the most important thing is not to stop learning, but to listen and take stock. Over the past two years, I&amp;rsquo;ve seen a lot of people show interest in Service Mesh, but not enough to understand the risks and lack of knowledge about the new technology. I&amp;rsquo;m excited to join this Service Mesh-focused startup &lt;a href=&#34;https://tetrate.io&#34; title=&#34;Tetrate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate&lt;/a&gt;
, a global telecommuting startup with products built around open source &lt;a href=&#34;https://istio.io&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
, [Envoy](https:/ /envoyproxy.io) and &lt;a href=&#34;https://skywalking.apache.org/&#34; title=&#34;Apache SkyWalking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Apache SkyWalking&lt;/a&gt;
, it aims to make it to be the cloud native network infrastructure. Here are several maintainers of these open source projects, such as &lt;a href=&#34;https://twitter.com/wusheng1108&#34; title=&#34;Sheng Wu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sheng Wu&lt;/a&gt;
, &lt;a href=&#34;https://twitter.com/ZackButcher&#34; title=&#34;Zack Butcher&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Zack Butcher&lt;/a&gt;
, &lt;a href=&#34;https://twitter.com/zlizan&#34; title=&#34;Lizan Zhou&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lizan Zhou&lt;/a&gt;
, etc., and I believe that working with them can help you understand and apply Service Mesh quickly and effectively across cloud native.&lt;/p&gt;
&lt;h2 id=&#34;more&#34;&gt;More&lt;/h2&gt;
&lt;p&gt;Earlier this year as I was preparing for the Cloud Native community, I set the course for the next three years - cloud native, open source and community. The road to pursue my dream is full of thorns, not only need courage and perseverance, but also need you to be my strong backing, I will overcome the thorns and move forward. Open source belongs to the world, to let the world understand us better, we must be more active into the world. I hope that China&amp;rsquo;s open source tomorrow will be better, I hope that Service Mesh technology will be better applied by the enterprises in China, I hope that cloud native can benefit the public, and I hope that we can all find our own mission.&lt;/p&gt;
&lt;p&gt;We are hiring now, if you are interested with &lt;a href=&#34;https://jimmysong.io/en/job/tetrate&#34; title=&#34;Tetrate&#34;&gt;Tetrate&lt;/a&gt;
, please send your resume to &lt;a href=&#34;mailto:careers@tetrate.io&#34; title=&#34;careers@tetrate.io&#34;&gt;careers@tetrate.io&lt;/a&gt;
.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Service Mesh - The Microservices in Post Kubernetes Era</title>
      <link>https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/</link>
      <pubDate>Wed, 01 Apr 2020 11:56:04 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/</guid>
      <description>
        
        
        &lt;p&gt;This article is a rework of previously written content and is included in the &lt;a href=&#34;https://www.servicemesher.com/istio-handbook&#34; title=&#34;Istio Handbook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Handbook&lt;/a&gt;
 of the ServiceMesher community . Other chapters are still being compiled.&lt;/p&gt;
&lt;p&gt;People who have just heard of Service Mesh and tried &lt;a href=&#34;https://istio.io/&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
 may have the following questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Why does Istio bind Kubernetes?&lt;/li&gt;
&lt;li&gt;What roles do Kubernetes and Service Mesh play in cloud native?&lt;/li&gt;
&lt;li&gt;What aspects of Kubernetes has Istio extended? What problems have been solved?&lt;/li&gt;
&lt;li&gt;What is the relationship between Kubernetes, xDS protocols (&lt;a href=&#34;https://github.com/envoyproxy/envoy&#34; title=&#34;Envoy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt;
 , &lt;a href=&#34;https://github.com/mosn/mosn&#34; title=&#34;MOSN,&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MOSN,&lt;/a&gt;
 etc) and Istio?&lt;/li&gt;
&lt;li&gt;Should I use Service Mesh?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In this section, we will try to guide you through the internal connections between Kubernetes, the xDS protocol, and Istio Service Mesh. In addition, this section will also introduce the load balancing methods in Kubernetes, the significance of the xDS protocol for Service Mesh, and why Istio is needed in time for Kubernetes.&lt;/p&gt;
&lt;p&gt;Using Service Mesh is not to say that it will break with Kubernetes, but that it will happen naturally. The essence of Kubernetes is to perform application lifecycle management through declarative configuration, while the essence of Service Mesh is to provide traffic and security management and observability between applications. If you have built a stable microservice platform using Kubernetes, how do you set up load balancing and flow control for calls between services?&lt;/p&gt;
&lt;p&gt;The xDS protocol created by Envoy is supported by many open source software, such as &lt;a href=&#34;https://github.com/istio/istio&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
 , &lt;a href=&#34;https://linkerd.io/&#34; title=&#34;Linkerd&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linkerd&lt;/a&gt;
 , &lt;a href=&#34;https://github.com/mosn/mosn&#34; title=&#34;MOSN,&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MOSN,&lt;/a&gt;
 etc. Envoy&amp;rsquo;s biggest contribution to Service Mesh or cloud native is the definition of xDS. Envoy is essentially a proxy. It is a modern version of proxy that can be configured through APIs. Based on it, many different usage scenarios are derived, such as API Gateway, Service Mesh. Sidecar proxy and Edge proxy in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This section contains the following&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Explain the role of kube-proxy.&lt;/li&gt;
&lt;li&gt;Kubernetes&amp;rsquo; limitations in microservice management.&lt;/li&gt;
&lt;li&gt;Describe the features of Istio Service Mesh.&lt;/li&gt;
&lt;li&gt;Describe what xDS includes.&lt;/li&gt;
&lt;li&gt;Compare some concepts in Kubernetes, Envoy and Istio Service Mesh.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;key-takeaways&#34;&gt;Key takeaways&lt;/h2&gt;
&lt;p&gt;If you want to know everything in advance, here are some of the key points from this article:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The essence of Kubernetes is application lifecycle management, specifically deployment and management (scaling, scaling, automatic recovery, release).&lt;/li&gt;
&lt;li&gt;Kubernetes provides a scalable and highly resilient deployment and management platform for microservices.&lt;/li&gt;
&lt;li&gt;The foundation of Service Mesh is a transparent proxy. After the traffic between microservices is intercepted through sidecar proxy, the behavior of microservices is managed through the control plane configuration.&lt;/li&gt;
&lt;li&gt;Service Mesh decoupled from Kubernetes traffic management, the internal flow without the need of Service Mesh &lt;code&gt;kube-proxy &lt;/code&gt;supporting components, micro-services closer to abstract the application layer by, for traffic between management services, security and observability.&lt;/li&gt;
&lt;li&gt;xDS defines the protocol standards for Service Mesh configuration.&lt;/li&gt;
&lt;li&gt;Service Mesh is a higher-level abstraction of services in Kubernetes. Its next step is serverless.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-service-mesh&#34;&gt;Kubernetes vs Service Mesh&lt;/h2&gt;
&lt;p&gt;The following figure shows the service access relationship between Kubernetes and Service Mesh (one sidecar per pod mode).&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/kubernetes-vs-service-mesh.png&#34; data-img=&#34;/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/kubernetes-vs-service-mesh.png&#34; data-width=&#34;1928&#34; data-height=&#34;986&#34; alt=&#34;image&#34; data-caption=&#34;kubernetes vs service mesh&#34;&gt;
    
  
  &lt;figcaption&gt;kubernetes vs service mesh&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Traffic forwarding&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Each node of the cluster Kubernetes a deployed &lt;code&gt;kube-proxy&lt;/code&gt; assembly Kubernetes API Server may communicate with the cluster acquired &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html&#34; title=&#34;service&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;service&lt;/a&gt;
 information, and then set iptables rules, sends a request for a service directly to the corresponding Endpoint (belonging to the same group service pod).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service discovery&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/istio-service-registry.png&#34; data-img=&#34;/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/istio-service-registry.png&#34; data-width=&#34;761&#34; data-height=&#34;552&#34; alt=&#34;image&#34; data-caption=&#34;Service registration in Service Mesh&#34;&gt;
    
  
  &lt;figcaption&gt;Service registration in Service Mesh&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Istio Service Mesh can use the service in Kubernetes for service registration. It can also connect to other service discovery systems through the platform adapter of the control plane, and then generate the configuration of the data plane (using CRD statements, stored in etcd), a &lt;strong&gt;transparent proxy&lt;/strong&gt; for the data plane. (Transparent proxy) is deployed in the sidecar container in each application service pod. These proxy need to request the control plane to synchronize the proxy configuration. The reason why is a transparent proxy, because there is no application container fully aware agent, the process kube-proxy components like the need to block traffic, but &lt;code&gt;kube-proxy&lt;/code&gt;that blocks traffic to Kubernetes node and sidecar proxy that blocks out of the Pod For more information, see &lt;a href=&#34;https://jimmysong.io/en/blog/envoy-sidecar-routing-of-istio-service-mesh-deep-dive/&#34; title=&#34;Understanding Route Forwarding by the Envoy Sidecar Proxy in Istio Service Mesh&#34;&gt;Understanding Route Forwarding by the Envoy Sidecar Proxy in Istio Service Mesh&lt;/a&gt;
 .&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Disadvantages of Service Mesh&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Because each node on Kubernetes many runs Pod, the original &lt;code&gt;kube-proxy&lt;/code&gt;routing forwarding placed in each pod, the distribution will lead to a lot of configuration, synchronization, and eventual consistency problems. In order to perform fine-grained traffic management, a series of new abstractions will be added, which will further increase the user&amp;rsquo;s learning costs. However, with the popularization of technology, this situation will gradually ease.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Advantages of Service Mesh&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kube-proxy&lt;/code&gt; The settings are globally effective, and fine-grained control of each service cannot be performed. Service Mesh uses sidecar proxy to extract the control of traffic in Kubernetes from the service layer, which can be further expanded.&lt;/p&gt;
&lt;h2 id=&#34;kube-proxy-component&#34;&gt;kube-proxy component&lt;/h2&gt;
&lt;p&gt;In Kubernetes cluster, each Node to run a &lt;code&gt;kube-proxy &lt;/code&gt; process. &lt;code&gt;kube-proxy&lt;/code&gt; Responsible for the &lt;code&gt;Service&lt;/code&gt; realization of a VIP (virtual IP) form. In Kubernetes v1.0, the proxy is implemented entirely in userspace. Kubernetes v1.1 adds the &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html#iptables-%e4%bb%a3%e7%90%86%e6%a8%a1%e5%bc%8f&#34; title=&#34;iptables proxy mode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;iptables proxy mode&lt;/a&gt;
 , but it is not the default operating mode. As of Kubernetes v1.2, the iptables proxy is used by default. In Kubernetes v1.8.0-beta.0, the &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html#ipvs-%e4%bb%a3%e7%90%86%e6%a8%a1%e5%bc%8f&#34; title=&#34;ipvs proxy mode was added&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ipvs proxy mode was added&lt;/a&gt;
 . More about kube-proxy component description please refer &lt;a href=&#34;https://cizixs.com/2017/03/30/kubernetes-introduction-service-and-kube-proxy/&#34; title=&#34;kubernetes Description: service and kube-proxy principle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kubernetes Description: service and kube-proxy principle&lt;/a&gt;
 and &lt;a href=&#34;https://jishu.io/kubernetes/ipvs-loadbalancer-for-kubernetes/&#34; title=&#34;use IPVS achieve Kubernetes inlet flow load balancing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;use IPVS achieve Kubernetes inlet flow load balancing&lt;/a&gt;
 .&lt;/p&gt;
&lt;h3 id=&#34;kube-proxy-flaws&#34;&gt;kube-proxy flaws&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://cizixs.com/2017/03/30/kubernetes-introduction-service-and-kube-proxy/&#34; title=&#34;The disadvantages of kube-proxy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The disadvantages of kube-proxy&lt;/a&gt;
 :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;First, if forwarded pod can not provide normal service, it does not automatically try another pod, of course, this can &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/guide/configure-liveness-readiness-probes.html&#34; title=&#34;&amp;lt;code&amp;gt;liveness probes&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;liveness probes&lt;/code&gt;&lt;/a&gt;
 be solved. Each pod has a health check mechanism. When there is a problem with the health of the pod, kube-proxy will delete the corresponding forwarding rule. In addition, &lt;code&gt;nodePort&lt;/code&gt;types of services cannot add TLS or more sophisticated message routing mechanisms.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Kube-proxy implements load balancing of traffic among multiple pod instances of the Kubernetes service, but how to fine-grained control the traffic between these services, such as dividing the traffic into different application versions by percentage (these applications belong to the same service , But on a different deployment), do canary release and blue-green release? Kubernetes community gives the &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments&#34; title=&#34;method using the Deployment do canary release&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;method using the Deployment do canary release&lt;/a&gt;
 , essentially by modifying the pod of the method &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/label.html&#34; title=&#34;label&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;label&lt;/a&gt;
 different pod to be classified into the Deployment of Service.&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-ingress-vs-istio-gateway&#34;&gt;Kubernetes Ingress vs. Istio Gateway&lt;/h2&gt;
&lt;p&gt;Speaking above &lt;code&gt;kube-proxy&lt;/code&gt;the flow inside the only route Kubernetes clusters, and we know that Pod Kubernetes cluster located &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/cni.html&#34; title=&#34;CNI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNI&lt;/a&gt;
 outside the network created, external cluster is unable to communicate directly with, so Kubernetes created in the &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/ingress.html&#34; title=&#34;ingress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ingress&lt;/a&gt;
 of this resource object, which is located by the Kubernetes &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/edge-node-configuration.html&#34; title=&#34;edge nodes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;edge nodes&lt;/a&gt;
 (such nodes can be many or a group) are driven by the Ingress controller, which is responsible for managing &lt;strong&gt;north-south traffic&lt;/strong&gt; . Ingress must be &lt;a href=&#34;https://traefik.io/&#34; title=&#34;connected to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;connected to&lt;/a&gt;
 various ingress controllers, such as &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34; title=&#34;nginx ingress controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nginx ingress controller&lt;/a&gt;
 and &lt;a href=&#34;https://traefik.io/&#34; title=&#34;traefik&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;traefik&lt;/a&gt;
 . Ingress is only applicable to HTTP traffic, and its usage is also very simple. It can only route traffic by matching limited fields such as service, port, and HTTP path, which makes it unable to route TCP traffic such as MySQL, Redis, and various private RPCs. To directly route north-south traffic, you can only use Service&amp;rsquo;s LoadBalancer or NodePort. The former requires cloud vendor support, while the latter requires additional port management. Some Ingress controllers support exposing TCP and UDP services, but they can only be exposed using Services. Ingress itself does not support it, such as the &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/&#34; title=&#34;nginx ingress controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nginx ingress controller&lt;/a&gt;
 . The exposed port of the service is configured by creating a ConfigMap.&lt;/p&gt;
&lt;p&gt;Istio Gateway is similar to Kubernetes Ingress in that it is responsible for north-south traffic to the cluster. &lt;code&gt;Gateway&lt;/code&gt;The load balancer described by Istio is used to carry connections in and out of the edge of the mesh. The specification describes a series of open ports and the protocols used by these ports, SNI configuration for load balancing, and so on. Gateway is a &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/crd.html&#34; title=&#34;CRD extension&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRD extension&lt;/a&gt;
 . It also &lt;a href=&#34;https://istio.io/docs/reference/config/networking/gateway/&#34; title=&#34;reuses&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;reuses&lt;/a&gt;
 the capability of sidecar proxy. For detailed configuration, please refer to &lt;a href=&#34;https://istio.io/docs/reference/config/networking/gateway/&#34; title=&#34;Istio official website&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio official website&lt;/a&gt;
 .&lt;/p&gt;
&lt;h2 id=&#34;xds-protocol&#34;&gt;xDS protocol&lt;/h2&gt;
&lt;p&gt;You may have seen the following picture when you understand Service Mesh. Each block represents an instance of a service, such as a Pod in Kubernetes (which contains a sidecar proxy). The xDS protocol controls all traffic in Istio Service Mesh. The specific behavior is to link the squares in the figure below.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/service-mesh-schematic-diagram.png&#34; data-img=&#34;/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/service-mesh-schematic-diagram.png&#34; data-width=&#34;736&#34; data-height=&#34;626&#34; alt=&#34;image&#34; data-caption=&#34;Service Mesh diagram&#34;&gt;
    
  
  &lt;figcaption&gt;Service Mesh diagram&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The xDS protocol was proposed by &lt;a href=&#34;https://envoyproxy.io/&#34; title=&#34;Envoy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt;
 . The original xDS protocols in the Envoy v2 API refer to CDS (Cluster Discovery Service), EDS (Endpoint Discovery Service), LDS (Listener Discovery Service), and RDS (Route Discovery Service). Later, in the v3 version, Scoped Route Discovery Service (SRDS), Virtual Host Discovery Service (VHDS), Secret Discovery Service (SDS), and Runtime Discovery Service (RTDS) were developed. See the &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol&#34; title=&#34;xDS REST and gRPC protocol for&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS REST and gRPC protocol for&lt;/a&gt;
 details .&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a look at the xDS protocol with a service with two instances each.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/00831rSTly1gde7ydng3ij30s80j4aba.jpg&#34; data-img=&#34;/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/00831rSTly1gde7ydng3ij30s80j4aba.jpg&#34; data-width=&#34;1016&#34; data-height=&#34;688&#34; alt=&#34;image&#34; data-caption=&#34;xDS protocol&#34;&gt;
    
  
  &lt;figcaption&gt;xDS protocol&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The arrow in the figure above is not the path or route after the traffic enters the proxy, nor is it the actual sequence. It is an imagined xDS interface processing sequence. In fact, there are cross references between xDS.&lt;/p&gt;
&lt;p&gt;Agents that support the xDS protocol dynamically discover resources by querying files or managing servers. In summary, the corresponding discovery service and its corresponding API are called  xDS. Envoy by &lt;strong&gt;subscription (subscription)&lt;/strong&gt; to get the resources the way, there are three ways to subscribe:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;File subscription&lt;/strong&gt; : Monitor files in the specified path, the easiest way to find dynamic resource is to save it in a file and path configuration in &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/core/config_source.proto#core-configsource&#34; title=&#34;ConfigSource&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ConfigSource&lt;/a&gt;
 the &lt;code&gt;path&lt;/code&gt;parameter.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gRPC streaming subscription&lt;/strong&gt; : Each xDS API can be individually configured &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/core/config_source.proto#core-apiconfigsource&#34; title=&#34;&amp;lt;code&amp;gt;ApiConfigSource&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;ApiConfigSource&lt;/code&gt;&lt;/a&gt;
to point to the cluster address of the corresponding upstream management server.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Polling REST-JSON polling subscription&lt;/strong&gt; : A single xDS API can perform synchronous (long) polling of REST endpoints.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For details of the above xDS subscription methods, please refer to the &lt;a href=&#34;https://jimmysong.io/istio-handbook/concepts/envoy-xds-protocol.html&#34; title=&#34;xDS protocol analysis&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS protocol analysis&lt;/a&gt;
 . Istio uses gRPC streaming subscriptions to configure sidecar proxy for all data planes.&lt;/p&gt;
&lt;p&gt;The article introduces the overall architecture of the Istio pilot, the generation of proxy configuration, the function of the pilot-discovery module, and the CDS, EDS, and ADS in the xDS protocol. For details on ADS, please refer to the &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v2/service/discovery/v2/ads.proto&#34; title=&#34;official Envoy documentation&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;official Envoy documentation&lt;/a&gt;
 .&lt;/p&gt;
&lt;h3 id=&#34;xds-protocol-highlights&#34;&gt;xDS protocol highlights&lt;/h3&gt;
&lt;p&gt;Finally, summarize the main points about the xDS protocol:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CDS, EDS, LDS, and RDS are the most basic xDS protocols, and they can be updated independently.&lt;/li&gt;
&lt;li&gt;All Discovery Services can connect to different Management Servers, which means that there can be multiple servers managing xDS.&lt;/li&gt;
&lt;li&gt;Envoy has made a series of extensions based on the original xDS protocol, adding SDS (Key Discovery Service), ADS (Aggregated Discovery Service), HDS (Health Discovery Service), MS (Metric Service), RLS (Rate Limiting Service) Wait for the API.&lt;/li&gt;
&lt;li&gt;To ensure data consistency, if used directly xDS original API, it needs to ensure that such sequential update: CDS -&amp;gt; EDS -&amp;gt; LDS -&amp;gt; RDS, which is to follow the electronic engineering &lt;strong&gt;before-break&lt;/strong&gt; (Make-Before-Break) The principle is to establish a new connection before disconnecting the original connection. The application in routing is to prevent the situation where the upstream cluster cannot be found and the traffic is dropped when a new routing rule is set, similar to the circuit Open circuit.&lt;/li&gt;
&lt;li&gt;CDS sets which services are in the service mesh.&lt;/li&gt;
&lt;li&gt;EDS sets which instances (Endpoints) belong to these services (Cluster).&lt;/li&gt;
&lt;li&gt;LDS sets the listening port on the instance to configure routing.&lt;/li&gt;
&lt;li&gt;The routing relationship between RDS final services should ensure that RDS is updated last.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;envoy&#34;&gt;Envoy&lt;/h2&gt;
&lt;p&gt;Envoy is the default sidecar in Istio Service Mesh. Based on Enovy, Istio has extended its control plane in accordance with Envoy&amp;rsquo;s xDS protocol. Before talking about the Envoy xDS protocol, we need to be familiar with the basic terms of Envoy. The following lists the basic terms and data structure analysis in Envoy. For a detailed introduction to &lt;a href=&#34;http://www.servicemesher.com/envoy/&#34; title=&#34;Envoy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt;
 , please refer to the &lt;a href=&#34;http://www.servicemesher.com/envoy/&#34; title=&#34;official Envoy document&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;official Envoy document&lt;/a&gt;
 . As for how Envoy works as a forwarding proxy in Service Mesh (not limited to Istio), please refer to NetEase Cloud Liu Chao this &lt;a href=&#34;https://www.cnblogs.com/163yun/p/8962278.html&#34; title=&#34;in-depth interpretation of the technical details behind the Service Mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;in-depth interpretation of the technical details behind the Service Mesh&lt;/a&gt;
 and &lt;a href=&#34;https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34; title=&#34;understanding Istio Service Mesh Envoy agent in Sidecar injection and traffic hijacking&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;understanding Istio Service Mesh Envoy agent in Sidecar injection and traffic hijacking&lt;/a&gt;
 , in which the article refers to some of the points, the details will not be repeated.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/envoy-arch.png&#34; data-img=&#34;/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/envoy-arch.png&#34; data-width=&#34;1456&#34; data-height=&#34;1070&#34; alt=&#34;image&#34; data-caption=&#34;Envoy proxy architecture diagram&#34;&gt;
    
  
  &lt;figcaption&gt;Envoy proxy architecture diagram&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;basic-terminology&#34;&gt;Basic terminology&lt;/h3&gt;
&lt;p&gt;Here are the basic terms in Enovy you should know:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Downstream&lt;/strong&gt; : The downstream host connects to Envoy, sends a request and receives a response, that is, the host sending the request.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upstream&lt;/strong&gt; : The upstream host receives the connection and request from Envoy and returns a response, that is, the host that accepted the request.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Listener&lt;/strong&gt; : The listener is a named network address (for example, port, unix domain socket, etc.), and downstream clients can connect to these listeners. Envoy exposes one or more listeners to connect to downstream hosts.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cluster&lt;/strong&gt; : A cluster is a group of logically identical upstream hosts connected to Envoy. Envoy &lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/service_discovery.html#arch-overview-service-discovery&#34; title=&#34;discovers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;discovers&lt;/a&gt;
 members of the cluster through &lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/service_discovery.html#arch-overview-service-discovery&#34; title=&#34;service discovery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;service discovery&lt;/a&gt;
 . You can choose to determine the health status of cluster members through &lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/health_checking.html#arch-overview-health-checking&#34; title=&#34;active health checks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;active health checks&lt;/a&gt;
 . Envoy uses &lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/load_balancing.html#arch-overview-load-balancing&#34; title=&#34;load balancing policies&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;load balancing policies&lt;/a&gt;
 to decide which member of the cluster to route requests to.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Envoy can set multiple Listeners, and each Listener can also set a filter chain, and the filters are extensible, which can make it easier for us to manipulate traffic behavior, such as setting encryption, private RPC, and so on.&lt;/p&gt;
&lt;p&gt;The xDS protocol was proposed by Envoy and is now the default sidecar proxy in Istio. However, as long as the xDS protocol is implemented, it can theoretically be used as a sidecar proxy in Istio, such as the open source proxy &lt;a href=&#34;https://github.com/mosn/mosn&#34; title=&#34;MOSN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MOSN&lt;/a&gt;
 by &lt;a href=&#34;https://www.antfin.com&#34; title=&#34;Ant Group&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ant Group&lt;/a&gt;
 .&lt;/p&gt;
&lt;h2 id=&#34;istio-service-mesh&#34;&gt;Istio Service Mesh&lt;/h2&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/istio-mesh-arch.png&#34; data-img=&#34;/en/blog/service-mesh-the-microservices-in-post-kubernetes-era/istio-mesh-arch.png&#34; data-width=&#34;1424&#34; data-height=&#34;784&#34; alt=&#34;image&#34; data-caption=&#34;Istio service mesh architecture diagram&#34;&gt;
    
  
  &lt;figcaption&gt;Istio service mesh architecture diagram&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Istio is a very feature-rich Service Mesh, which includes the following functions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Traffic Management: This is the most basic feature of Istio.&lt;/li&gt;
&lt;li&gt;Policy control: Implemented through Mixer components and various adapters to implement access control systems, telemetry capture, quota management, and billing.&lt;/li&gt;
&lt;li&gt;Observability: Achieved through Mixer.&lt;/li&gt;
&lt;li&gt;Security certification: Citadel components do key and certificate management.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;traffic-management-in-istio&#34;&gt;Traffic Management in Istio&lt;/h3&gt;
&lt;p&gt;Istio defined as the &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/custom-resource.html&#34; title=&#34;CRD&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CRD&lt;/a&gt;
 to help users perform traffic management:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gateway&lt;/strong&gt; : &lt;a href=&#34;https://istio.io/docs/reference/config/networking/gateway/&#34; title=&#34;Gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway&lt;/a&gt;
 describes a load balancer running at the edge of the network for receiving incoming or outgoing HTTP / TCP connections.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VirtualService&lt;/strong&gt; : &lt;a href=&#34;https://istio.io/docs/reference/config/networking/virtual-service/&#34; title=&#34;VirtualService&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VirtualService&lt;/a&gt;
 actually connects Kubernetes services to Istio Gateway. It can also do more, such as defining a set of traffic routing rules to apply when a host is addressed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DestinationRule&lt;/strong&gt; : &lt;a href=&#34;https://istio.io/zh/docs/reference/config/networking/destination-rule/&#34; title=&#34;&amp;lt;code&amp;gt;DestinationRule&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;DestinationRule&lt;/code&gt;&lt;/a&gt;
The defined policy determines the access policy of the traffic after routing processing. Simply put, it defines how the traffic is routed. These policies can define load balancing configurations, connection pool sizes, and external detection (used to identify and evict unhealthy hosts in a load balancing pool) configuration.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EnvoyFilter&lt;/strong&gt; : The &lt;a href=&#34;https://istio.io/docs/reference/config/networking/envoy-filter/&#34; title=&#34;&amp;lt;code&amp;gt;EnvoyFilter&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;EnvoyFilter&lt;/code&gt;&lt;/a&gt;
object describes filters for proxy services that can customize the proxy configuration generated by Istio Pilot. This configuration is rarely used by beginning users.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ServiceEntry&lt;/strong&gt; : By default, services in Istio Service Mesh cannot discover services outside Mesh. It &lt;a href=&#34;https://istio.io/docs/reference/config/networking/service-entry/&#34; title=&#34;&amp;lt;code&amp;gt;ServiceEntry&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;ServiceEntry&lt;/code&gt;&lt;/a&gt;
can add additional entries to the service registry inside Istio, so that services automatically discovered in the mesh can access and route to these manual Joined services.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;Kubernetes vs xDS vs Istio&lt;/h2&gt;
&lt;p&gt;After the reading of the above Kubernetes &lt;code&gt;kube-proxy&lt;/code&gt;after abstraction component, and XDS Istio in traffic management, we will take you far as the traffic management aspect of comparison components corresponding to the three / protocol (note, not completely three equivalents).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Governors&lt;/th&gt;
&lt;th&gt;xDS&lt;/th&gt;
&lt;th&gt;Istio Service Mesh&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;VirtualService&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;DestinationRule&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;EnvoyFilter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ingress&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;If you say that the objects managed by Kubernetes are Pods, then the objects managed by Service Mesh are Service. Therefore, it is a natural thing to apply Service Mesh after using Kubernetes to manage microservices. If you do n’t want to manage even the Service, use &lt;a href=&#34;https://github.com/knative/&#34; title=&#34;serverless&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;serverless&lt;/a&gt;
 platforms like knative, but that&amp;rsquo;s what comes next.&lt;/p&gt;
&lt;p&gt;The function of Envoy/MOSN is not just for traffic forwarding. The above concepts are just the tip of the iceberg in Istio&amp;rsquo;s new layer of abstraction over Kubernetes. This will be the beginning of the book.&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/163yun/p/8962278.html&#34; title=&#34;In-depth interpretation of the technical details behind Service Mesh-cnblogs.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;In-depth interpretation of the technical details behind Service Mesh-cnblogs.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34; title=&#34;Understanding Envoy Proxy Sidecar Injection and Traffic Hijacking in Istio Service Mesh - jimmysong.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Understanding Envoy Proxy Sidecar Injection and Traffic Hijacking in Istio Service Mesh - jimmysong.io&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cizixs.com/2017/03/30/kubernetes-introduction-service-and-kube-proxy/&#34; title=&#34;Introduction to kubernetes: service and kube-proxy principles - cizixs.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to kubernetes: service and kube-proxy principles - cizixs.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jishu.io/kubernetes/ipvs-loadbalancer-for-kubernetes/&#34; title=&#34;Kubernetes Ingress Traffic Load Balancing Using IPVS - jishu.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Ingress Traffic Load Balancing Using IPVS - jishu.io&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol&#34; title=&#34;xDS REST and gRPC protocol - envoyproxy.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS REST and gRPC protocol - envoyproxy.io&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>High Level Cloud Native From Kevin Hoffman</title>
      <link>https://jimmysong.io/en/blog/high-level-cloud-native-from-kevin-hoffman/</link>
      <pubDate>Fri, 15 Sep 2017 20:32:47 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/high-level-cloud-native-from-kevin-hoffman/</guid>
      <description>
        
        
        &lt;p&gt;Kevin Hoffman(From Capital One, twitter &lt;a href=&#34;https://twitter.com/KevinHoffman&#34; title=&#34;@KevinHoffman&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@KevinHoffman&lt;/a&gt;
) was making a speech on &lt;em&gt;TalkingData T11 Smart Data Summit&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;He addressed that &lt;strong&gt;15 Factors of Cloud Native&lt;/strong&gt; which based on Heroku&amp;rsquo;s original &lt;a href=&#34;https://12factor.net&#34; title=&#34;Twelve-Factor App&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Twelve-Factor App&lt;/a&gt;
, but he add more 3 another factors on it.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s have a look at the 15 factors of Cloud Native.&lt;/p&gt;
&lt;h2 id=&#34;1-one-codebase-one-app&#34;&gt;1. One codebase, one App&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Single version-controlled codebase, many deploys&lt;/li&gt;
&lt;li&gt;Multiple apps should not share code
&lt;ul&gt;
&lt;li&gt;Microservices need separate release schedules&lt;/li&gt;
&lt;li&gt;Upgrade, deploy one without impacting others&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Tie build and deploy pipelines to single codebase&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-api-first&#34;&gt;2. API first&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Service ecosystem requires a contract
&lt;ul&gt;
&lt;li&gt;Public API&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Multiple teams on different schedulers
&lt;ul&gt;
&lt;li&gt;Code to contract/API, not code dependencies&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use well-documented contract standards
&lt;ul&gt;
&lt;li&gt;Protobuf IDL, Swagger, Apiary, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;API First != REST first
&lt;ul&gt;
&lt;li&gt;RPC can be more appropriate in some situations&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3-dependency-management&#34;&gt;3. Dependency Management&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Explicitly declare dependencies&lt;/li&gt;
&lt;li&gt;Include all dependencies with app release&lt;/li&gt;
&lt;li&gt;Create immutable build artifact (e.g. docker image)&lt;/li&gt;
&lt;li&gt;Rely on smallest docker image
&lt;ul&gt;
&lt;li&gt;Base on scratch if possible&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;App cannot rely on host for system tools or libraries&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;4-design-build-release-run&#34;&gt;4. Design, Build, Release, Run&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Design part of iterative cycle
&lt;ul&gt;
&lt;li&gt;Agile doesn’t mean random or undesigned&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mature CI/CD pipeline and teams
&lt;ul&gt;
&lt;li&gt;Design to production in days not months&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Build immutable artifacts&lt;/li&gt;
&lt;li&gt;Release automatically deploys to environment
&lt;ul&gt;
&lt;li&gt;Environments contains config, not release artifact&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;5-configuration-credentials-code&#34;&gt;5. Configuration, Credentials, Code&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;3 Cs&amp;rdquo; volatile substances that explode when combinded&lt;/li&gt;
&lt;li&gt;Password in a config file is as bad as password in code&lt;/li&gt;
&lt;li&gt;App must accept &amp;ldquo;3 Cs&amp;rdquo; from &lt;strong&gt;environment&lt;/strong&gt; and only use harmless defaults&lt;/li&gt;
&lt;li&gt;Test - Could you expose code on Github and not reveal passwords, URLs, credentials?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;6-logs&#34;&gt;6. Logs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Emit formatted logs to stdout&lt;/li&gt;
&lt;li&gt;Code should not know about destination or purpose of log emissions&lt;/li&gt;
&lt;li&gt;Use downstream log aggregator
&lt;ul&gt;
&lt;li&gt;collect, store, process, expose logs&lt;/li&gt;
&lt;li&gt;ELK, Splunk, Sumo, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use &lt;strong&gt;structured&lt;/strong&gt; logs to allow query and analysis
&lt;ul&gt;
&lt;li&gt;JSON, csv, KV, etc&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Logs are not metrics&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;7-disposability&#34;&gt;7. Disposability&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;App must start as quickly as possible&lt;/li&gt;
&lt;li&gt;App must stop quickly and gracefully&lt;/li&gt;
&lt;li&gt;Processes start and stop all the time in the cloud&lt;/li&gt;
&lt;li&gt;Every scale up/down disposes of processes&lt;/li&gt;
&lt;li&gt;Slow dispose == slow scale&lt;/li&gt;
&lt;li&gt;Slow dispose or startup can cause availability gaps&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;8-backing-services&#34;&gt;8. Backing Services&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Assume all resources supplied by backingservices&lt;/li&gt;
&lt;li&gt;Cannotassume mutable file system
&lt;ul&gt;
&lt;li&gt;“Disk as a Service” (e.g. S3, virtual mounts, etc)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Every backing service is bound resource
&lt;ul&gt;
&lt;li&gt;URL, credentials, etc-&amp;gt; environment config&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Host does not satisfy NFRs
&lt;ul&gt;
&lt;li&gt;Backing services and cloud infrastructure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;9-environment-parity&#34;&gt;9. Environment Parity&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;“Works on my machine”
&lt;ul&gt;
&lt;li&gt;Cloud-native anti-pattern. Must &lt;strong&gt;work everywhere&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Every commit is candidate for deployment&lt;/li&gt;
&lt;li&gt;Automated acceptance tests
&lt;ul&gt;
&lt;li&gt;Provide no confidence if environments don’t match&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;10-administrative-processes&#34;&gt;10. Administrative Processes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Database migrations&lt;/li&gt;
&lt;li&gt;Run-once scripts or jobs&lt;/li&gt;
&lt;li&gt;Avoid using for batch operations, consider instead:
&lt;ul&gt;
&lt;li&gt;Event sourcing&lt;/li&gt;
&lt;li&gt;Schedulers&lt;/li&gt;
&lt;li&gt;Triggers from queues, etc&lt;/li&gt;
&lt;li&gt;Lambdas/functions&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;11-port-binding&#34;&gt;11. Port Binding&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In cloud, infrastructure determines port&lt;/li&gt;
&lt;li&gt;App must accept port assigned by platform&lt;/li&gt;
&lt;li&gt;Containers have internal/external ports
&lt;ul&gt;
&lt;li&gt;App design must embrace this&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Never use reserved ports&lt;/li&gt;
&lt;li&gt;Beware of container “host mode” networking&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;12-stateless-processes&#34;&gt;12. Stateless Processes&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;What is stateless?&lt;/li&gt;
&lt;li&gt;Long-term state handled by a backing service&lt;/li&gt;
&lt;li&gt;In-memory state lives onlyas long as request&lt;/li&gt;
&lt;li&gt;Requests from same client routed to different instances
&lt;ul&gt;
&lt;li&gt;“Sticky sessions” cloud native anti-pattern&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;13-concurency&#34;&gt;13. Concurency&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Scale horizontally using the process model&lt;/li&gt;
&lt;li&gt;Build disposable, stateless, share-nothing processes&lt;/li&gt;
&lt;li&gt;Avoid adding CPU/RAM to increase scale/throughput&lt;/li&gt;
&lt;li&gt;Where possible, let platform/libraries do threading
&lt;ul&gt;
&lt;li&gt;Many single-threaded services &amp;gt; 1 multi-threaded monolith&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;14-telemetry&#34;&gt;14. Telemetry&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Monitor apps in the cloud like satellite in orbit&lt;/li&gt;
&lt;li&gt;No tether, no live debugger&lt;/li&gt;
&lt;li&gt;Application Perf Monitoring (APM)&lt;/li&gt;
&lt;li&gt;Domain Telemetry&lt;/li&gt;
&lt;li&gt;Health and system logs&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;15-authentication--authorization&#34;&gt;15. Authentication &amp;amp; Authorization&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Security should never be an afterthought&lt;/li&gt;
&lt;li&gt;Auth should be explicit, documented decision
&lt;ul&gt;
&lt;li&gt;Even if anonymous access is allowed&lt;/li&gt;
&lt;li&gt;Don’t allow anonymous access&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bearer tokens/OAuth/OIDC best practices&lt;/li&gt;
&lt;li&gt;Audit all attempts to access&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;migrating-monoliths-to-the-cloud&#34;&gt;Migrating Monoliths to the Cloud&lt;/h2&gt;
&lt;p&gt;After this 15 factors, he also gave us some tips about how to &lt;strong&gt;migrate monoliths to the Cloud&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make a rule - stop adding to the monolith
&lt;ul&gt;
&lt;li&gt;All new code must be cloud native&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Prioritize features
&lt;ul&gt;
&lt;li&gt;Where will you get most benefit from cloud native?&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Come up with a plan
&lt;ul&gt;
&lt;li&gt;Decompose monolith over time&lt;/li&gt;
&lt;li&gt;Fast, agile iterations toward ultimate goal&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use multiple strategies and patterns&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;go---the-best-language-for-building-cloud-native-app&#34;&gt;Go - the Best Language for Building Cloud Native App&lt;/h2&gt;
&lt;p&gt;At last, he advise us the programming language Go is the best language to build Cloud Native applications for these reasons below:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Lightweight&lt;/li&gt;
&lt;li&gt;Easily learning curve&lt;/li&gt;
&lt;li&gt;Compiles to native binaries&lt;/li&gt;
&lt;li&gt;Very fast&lt;/li&gt;
&lt;li&gt;Large, thriving, engaged community
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://gopherize.me&#34; title=&#34;http://gopherize.me&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://gopherize.me&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kevin also wrote a book &lt;strong&gt;Cloud Native Go&lt;/strong&gt; to show how to &lt;strong&gt;Building Web Applications and Microservices for the Cloud with Go and React&lt;/strong&gt;. This book has been translated to Chinese by four guys from TalkingData with ❤️. 《Cloud Native Go 构建基于 Go 和 React 的云原生 Web 应用与微服务》published by PHEI publisher house.&lt;/p&gt;
&lt;p&gt;Kevin was signing his name on the book&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/high-level-cloud-native-from-kevin-hoffman/kevin-hoffman-siging-on-the-book.jpg&#34; data-img=&#34;/en/blog/high-level-cloud-native-from-kevin-hoffman/kevin-hoffman-siging-on-the-book.jpg&#34; data-width=&#34;599&#34; data-height=&#34;400&#34; alt=&#34;image&#34; data-caption=&#34;kevin siging on the book&#34;&gt;
    
  
  &lt;figcaption&gt;kevin siging on the book&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This is his first visit to China, as a main translator of this book I an honored to be with him to take this photo.&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/en/blog/high-level-cloud-native-from-kevin-hoffman/kevin-hoffman-with-me.jpg&#34; data-img=&#34;/en/blog/high-level-cloud-native-from-kevin-hoffman/kevin-hoffman-with-me.jpg&#34; data-width=&#34;539&#34; data-height=&#34;355&#34; alt=&#34;image&#34; data-caption=&#34;kevin hoffman with me&#34;&gt;
    
  
  &lt;figcaption&gt;kevin hoffman with me&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
