<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy Song - Cloud Native | Open Source | Community – service mesh</title>
    <link>https://jimmysong.io/en/tags/service-mesh/</link>
    <description>Recent content in service mesh on Jimmy Song - Cloud Native | Open Source | Community</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>Copyright &amp;copy; 2021 Jimmy Song All Right Reserved;&lt;/br&gt; Powerd by Hugo with [educenter](https://github.com/themefisher/educenter-hugo) theme</copyright>
    <lastBuildDate>Mon, 24 May 2021 08:00:00 +0800</lastBuildDate>
    
	  <atom:link href="https://jimmysong.io/en/tags/service-mesh/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Happy Istio 4th Anniversary -- Retrospect and Outlook</title>
      <link>https://jimmysong.io/en/blog/istio-4-year-birthday/</link>
      <pubDate>Mon, 24 May 2021 08:00:00 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/istio-4-year-birthday/</guid>
      <description>
        
        
        &lt;p&gt;Istio was named by &lt;a href=&#34;https://tetrate.io/&#34;&gt;Tetrate&lt;/a&gt; founder Varun Talwar and Google lead engineer Louis Ryan in 2017 and was open sourced on May 24, 2017. Today is the fourth anniversary of Istio’s open source arrival. Let’s take a look back at Istio’s four years of development — and look forward to Istio’s future.&lt;/p&gt;
&lt;h3 id=&#34;istios-open-source-history&#34;&gt;Istio’s open source history&lt;/h3&gt;
&lt;p&gt;In 2017, the year Kubernetes ended the container orchestration battle, Google took the opportunity to consolidate its dominance in the cloud native space and compensate for Kubernetes’ disadvantage in service-to-service traffic management by open-sourcing Istio. Istio released its 1.10 last week — but here are some of the most important releases in Istio’s history to date.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Date&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Version&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Note&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;May 24, 2017&lt;/td&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;Officially open source; established the architectural foundation of Control Plane, Data Plane and sidecar proxy.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;October 10, 2017&lt;/td&gt;
&lt;td&gt;0.2&lt;/td&gt;
&lt;td&gt;Started to support multiple runtime environments, such as virtual machines.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;June 1, 2018&lt;/td&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;API refactoring&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;July 31, 2018&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;Production-ready, after which the Istio team underwent a massive reorganization.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;March 19, 2019&lt;/td&gt;
&lt;td&gt;1.1&lt;/td&gt;
&lt;td&gt;Enterprise-ready. Support for multiple Kubernetes clusters, with performance optimizations.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;March 3, 2020&lt;/td&gt;
&lt;td&gt;1.5&lt;/td&gt;
&lt;td&gt;Back to monolith, with microservice components merged into istiod, making Istio’s architecture cleaner and easier to maintain. Support for WebAssembly extension, making Istio’s ecology much stronger.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;November 18, 2020&lt;/td&gt;
&lt;td&gt;1.8&lt;/td&gt;
&lt;td&gt;Officially deprecated Mixer and focused on adding support for virtual machines.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A year after its inception– and two months before the 1.0 release, version 0.8 was released with a massive refactoring of the API. In late July 2018, when 1.0 was released, Istio reached a production-ready tipping point. Since then, Google has massively reorganized the Istio team and several Istio-based service mesh startups were born, making 2018 the booming year of the service mesh industry.&lt;/p&gt;
&lt;p&gt;Istio 1.1 was released in March 2019, almost 9 months after 1.0 was released, which is far beyond the average release cycle of an open-source project. We know that the speed of iteration and evolution is a core competency of basic software. Since then, Istio has started a regular &lt;a href=&#34;https://istio.io/v1.7/about/release-cadence/&#34;&gt;release cadence&lt;/a&gt; of one version per quarter and has become the &lt;a href=&#34;https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors&#34;&gt;#4 fastest growing project in GitHub’s top 10 in 2019&lt;/a&gt;!&lt;/p&gt;
&lt;h3 id=&#34;the-istio-community&#34;&gt;The Istio community&lt;/h3&gt;
&lt;p&gt;In 2020, Istio’s project management began to mature and its governance reached a stage of evolution. We saw the first &lt;a href=&#34;https://istio.io/latest/blog/2020/steering-election-results/&#34;&gt;election&lt;/a&gt; of a steering committee for the Istio community and the transfer of the trademark to &lt;a href=&#34;https://istio.io/latest/blog/2020/open-usage/&#34;&gt;Open Usage Commons&lt;/a&gt;. The first &lt;a href=&#34;https://events.istio.io/istiocon-2021/&#34;&gt;IstioCon&lt;/a&gt; was successfully held in February 2021, with thousands of people attending the online conference. There is also a &lt;a href=&#34;https://www.youtube.com/watch?v=6m-rhyfy8sg&amp;amp;list=PL7wB27eZmdffS-g_xh7X-b0echc_XZMKV&amp;amp;index=8&#34;&gt;large Istio community in China&lt;/a&gt;, and face-to-face Istio community meetups will be held there in 2021. Stay tuned for more.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gquicfqg14j31lw0smwl2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;According to the CNCF 2020 Survey, 46% of organizations were either using a service mesh in production or planning to use it in the next 12 months. Istio was the top used mesh among those using a mesh in production.&lt;/p&gt;
&lt;h3 id=&#34;the-future&#34;&gt;The future&lt;/h3&gt;
&lt;p&gt;After 4 years of development, there is not only a large user base around Istio, but also several Istio vendors, as you can see on the &lt;a href=&#34;https://istio.io/&#34;&gt;homepage&lt;/a&gt; of the recently revamped Istio website. In the last few releases, Istio has shifted its development focus to improving the Day 2 Operation experience. We also expect to see more Istio adoption path recommendations, case studies, learning materials, training, and certifications (such as the industry’s first &lt;a href=&#34;https://academy.tetrate.io/courses/certified-istio-administrator&#34;&gt;Certified Istio Administrator&lt;/a&gt; from Tetrate) that will facilitate the adoption of Istio.&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Why Do You Need Istio When You Already Have Kubernetes?</title>
      <link>https://jimmysong.io/en/blog/why-do-you-need-istio-when-you-already-have-kubernetes/</link>
      <pubDate>Wed, 07 Apr 2021 08:27:17 +0800</pubDate>
      
      <guid>https://jimmysong.io/en/blog/why-do-you-need-istio-when-you-already-have-kubernetes/</guid>
      <description>
        
        
        &lt;p&gt;If you’ve heard of service mesh and tried &lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt;, you may have the following questions:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Why is Istio running on Kubernetes?&lt;/li&gt;
&lt;li&gt;What is the role of Kubernetes and a service mesh in the cloud native application architecture, respectively?&lt;/li&gt;
&lt;li&gt;What aspects of Kubernetes does Istio extend? What problems does it solve?&lt;/li&gt;
&lt;li&gt;What is the relationship between Kubernetes, Envoy, and Istio?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This article will take you through the inner workings of Kubernetes and Istio. In addition, I will introduce the load balancing approach in Kubernetes, and explain why you need Istio when you have Kubernetes.&lt;/p&gt;
&lt;p&gt;Kubernetes is essentially about application lifecycle management through declarative configuration, while a service mesh is essentially about providing inter-application traffic, security management and observability. If you have already built a stable application platform using Kubernetes, how do you set up load balancing and traffic control for calls between services? This is where a service mesh comes into the picture.&lt;/p&gt;
&lt;p&gt;Envoy introduces the xDS protocol, which is supported by various open source software, such as &lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt;, &lt;a href=&#34;https://github.com/mosn/mosn&#34;&gt;MOSN&lt;/a&gt;, etc. Envoy contributes xDS to a service mesh or cloud native infrastructure. Envoy is essentially a modern version of a proxy that can be configured through APIs, based on which many different usage scenarios are derived — such as API Gateway, sidecar proxy in service mesh, and edge proxy.&lt;/p&gt;
&lt;p&gt;This article contains the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A description of the role of kube-proxy.&lt;/li&gt;
&lt;li&gt;The limitations of Kubernetes for microservice management.&lt;/li&gt;
&lt;li&gt;An introduction to the capabilities of Istio service mesh.&lt;/li&gt;
&lt;li&gt;A comparison of some of the concepts in Kubernetes, Envoy, and the Istio service mesh.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-service-mesh&#34;&gt;Kubernetes vs Service Mesh&lt;/h2&gt;
&lt;p&gt;The following diagram shows the service access relationship in Kubernetes and service mesh (one sidecar per pod model).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008eGmZEly1gpb7knfo4dj31hk0redrz.jpg&#34; alt=&#34;Kubernetes vs Service Mesh&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;traffic-forwarding&#34;&gt;Traffic Forwarding&lt;/h3&gt;
&lt;p&gt;Each node in a Kubernetes cluster deploys a kube-proxy component that communicates with the Kubernetes API Server, gets information about the services in the cluster, and then sets iptables rules to send requests for service directly to the corresponding Endpoint (a pod belonging to the same group of services).&lt;/p&gt;
&lt;h3 id=&#34;service-discovery&#34;&gt;Service Discovery&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008eGmZEly1gpb7knwb79j30kq0fcjs9.jpg&#34; alt=&#34;Service Discovery&#34;&gt;&lt;/p&gt;
&lt;p&gt;Istio can follow the service registration in Kubernetes and can also interface with other service discovery systems via platform adapters in the control plane; and then generate data plane configurations (using CRD, which are stored in etcd) with transparent proxies for the data plane. The transparent proxy of the data plane is deployed as a sidecar container in the pod of each application service, and all these proxies need to request the control plane to synchronize the proxy configuration. The proxy is “transparent” because the application container is completely unaware of the presence of the proxy. The kube-proxy component in the process needs to intercept traffic as well, except that the kube-proxy intercepts traffic to and from the Kubernetes node — while the sidecar proxy intercepts traffic to and from the pod.&lt;/p&gt;
&lt;h3 id=&#34;disadvantages-of-a-service-mesh&#34;&gt;Disadvantages of a Service Mesh&lt;/h3&gt;
&lt;p&gt;Since Kubernetes has many pods running on each node, putting the original kube-proxy route forwarding function in each pod will increase the response latency — due to more hops when the sidecar intercepts the traffic — and consume more resources. In order to manage traffic in a fine-grained manner, a series of new abstractions will be added. This will further increase the learning cost for users, but as the technology becomes more popular this situation will be slowly alleviated.&lt;/p&gt;
&lt;h3 id=&#34;advantages-of-a-service-mesh&#34;&gt;Advantages of a Service Mesh&lt;/h3&gt;
&lt;p&gt;The kube-proxy settings are global and cannot be controlled at a granular level for each service, while service mesh takes the traffic control out of the service layer in Kubernetes by means of sidecar proxy — allowing for more elasticity.&lt;/p&gt;
&lt;h3 id=&#34;shortcomings-of-kube-proxy&#34;&gt;Shortcomings of Kube-Proxy&lt;/h3&gt;
&lt;p&gt;First, it does not automatically try another pod if the forwarded pod is not serving properly. Each pod has a health check mechanism and when a pod has health problems, kubelet will restart the pod and kube-proxy will remove the corresponding forwarding rules. Also, nodePort-type services cannot add TLS or more complex message routing mechanisms.&lt;/p&gt;
&lt;p&gt;Kube-proxy implements load balancing of traffic across multiple pod instances of a Kubernetes service, but how do you do fine-grained control of traffic between these services — such as dividing traffic by percentage to different application versions (which are all part of the same service but on different deployments), or doing canary releases (grayscale releases) and blue-green releases?&lt;/p&gt;
&lt;p&gt;The Kubernetes community gives a way to &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments&#34;&gt;do canary releases using Deployment&lt;/a&gt;, which is essentially a way to assign different pods to a deployment’s service by modifying the pod’s label.&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-ingress-vs-istio-gateway&#34;&gt;Kubernetes Ingress vs. Istio Gateway&lt;/h2&gt;
&lt;p&gt;As mentioned above, kube-proxy can only route traffic within a Kubernetes cluster. The pods of a Kubernetes cluster are located in a network created by CNI. An ingress — a resource object created in Kubernetes — is created for communication outside the cluster. It’s driven by an ingress controller located on Kubernetes edge nodes responsible for managing north-south traffic. Ingress must be docked to various Ingress Controllers, such as the &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;nginx ingress controller&lt;/a&gt; and &lt;a href=&#34;https://traefik.io/&#34;&gt;traefik&lt;/a&gt;. Ingress is only applicable to HTTP traffic and is simple to use. It can only route traffic by matching a limited number of fields — such as service, port, HTTP path, etc. This makes it impossible to route TCP traffic such as MySQL, Redis, and various RPCs. This is why you see people writing nginx config language in ingress resource annotations.The only way to directly route north-south traffic is to use the service’s LoadBalancer or NodePort, the former requiring cloud vendor support and the latter requiring additional port management.&lt;/p&gt;
&lt;p&gt;Istio Gateway functions similarly to Kubernetes Ingress, in that it is responsible for north-south traffic to and from the cluster. Istio Gateway describes a load balancer for carrying connections to and from the edge of the mesh. The specification describes a set of open ports and the protocols used by those ports, the SNI configuration for load balancing, etc. Gateway is a CRD extension that also reuses the capabilities of the sidecar proxy; see the &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/gateway/&#34;&gt;Istio website&lt;/a&gt; for detailed configuration.&lt;/p&gt;
&lt;h2 id=&#34;envoy&#34;&gt;Envoy&lt;/h2&gt;
&lt;p&gt;Envoy is the default sidecar proxy in Istio. Istio extends its control plane based on Enovy’s xDS protocol. We need to familiarize ourselves with Envoy’s basic terminology before talking about Envoy’s xDS protocol. The following is a list of basic terms and their data structures in Envoy; please refer to the &lt;a href=&#34;https://envoyproxy.io/&#34;&gt;Envoy documentation&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008eGmZEly1gpb7koah95j31450tetta.jpg&#34; alt=&#34;Envoy&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;basic-terminology&#34;&gt;Basic Terminology&lt;/h3&gt;
&lt;p&gt;The following are the basic terms in Enovy that you should know.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Downstream&lt;/strong&gt;: The downstream host connects to Envoy, sends the request, and receives the response; i.e., the host that sent the request.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upstream&lt;/strong&gt;: The upstream host receives connections and requests from Envoy and returns responses; i.e., the host that receives the requests.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Listener&lt;/strong&gt;: Listener is a named network address (for example, port, UNIX domain socket, etc.); downstream clients can connect to these listeners. Envoy exposes one or more listeners to the downstream hosts to connect.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cluster&lt;/strong&gt;: A cluster is a group of logically identical upstream hosts to which Envoy connects. Envoy discovers the members of a cluster through service discovery. Optionally, the health status of cluster members can be determined through proactive health checks. Envoy decides which member of the cluster to route requests through a load balancing policy.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Multiple listeners can be set in Envoy, each listener can set a filter chain (filter chain table), and the filter is scalable so that we can more easily manipulate the behavior of traffic — such as setting encryption, private RPC, etc.&lt;/p&gt;
&lt;p&gt;The xDS protocol was proposed by Envoy and is the default sidecar proxy in Istio, but as long as the xDS protocol is implemented, it can theoretically be used as a sidecar proxy in Istio — such as the &lt;a href=&#34;https://github.com/mosn/mosn&#34;&gt;MOSN&lt;/a&gt; open source by Ant Group.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cdn.thenewstack.io/media/2021/03/b800bf17-image3.png&#34;&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/008eGmZEly1gpb7kk7wk4j31060lqgqx.jpg&#34; alt=&#34;img&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Istio is a very feature-rich service mesh that includes the following capabilities.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Traffic Management: This is the most basic feature of Istio.&lt;/li&gt;
&lt;li&gt;Policy Control: Enables access control systems, telemetry capture, quota management, billing, etc.&lt;/li&gt;
&lt;li&gt;Observability: Implemented in the sidecar proxy.&lt;/li&gt;
&lt;li&gt;Security Authentication: The Citadel component does key and certificate management.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;traffic-management-in-istio&#34;&gt;Traffic Management in Istio&lt;/h2&gt;
&lt;p&gt;The following CRDs are defined in Istio to help users with traffic management.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Gateway: Gateway describes a load balancer that runs at the edge of the network and is used to receive incoming or outgoing HTTP/TCP connections.&lt;/li&gt;
&lt;li&gt;VirtualService: VirtualService actually connects the Kubernetes service to the Istio Gateway. It can also perform additional operations, such as defining a set of traffic routing rules to be applied when a host is addressed.&lt;/li&gt;
&lt;li&gt;DestinationRule: The policy defined by the DestinationRule determines the access policy for the traffic after it has been routed. Simply put, it defines how traffic is routed. Among others, these policies can be defined as load balancing configurations, connection pool sizes, and external detection (for identifying and expelling unhealthy hosts in the load balancing pool) configurations.&lt;/li&gt;
&lt;li&gt;EnvoyFilter: The EnvoyFilter object describes filters for proxy services that can customize the proxy configuration generated by Istio Pilot. This configuration is generally rarely used by primary users.&lt;/li&gt;
&lt;li&gt;ServiceEntry: By default, services in the Istio service mesh are unable to discover services outside of the Mesh. ServiceEntry enables additional entries to be added to the service registry inside Istio, thus allowing automatically discovered services in the mesh to access and route to these manually added services.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;Kubernetes vs. xDS vs. Istio&lt;/h2&gt;
&lt;p&gt;Having reviewed the abstraction of traffic management in Kubernetes’ kube-proxy component, xDS, and Istio, let’s look now at a comparison of the three components/protocols in terms of traffic management only (note that the three are not exactly equivalent).&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;xDS&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Istio service mesh&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;VirtualService&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;DestinationRule&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;EnvoyFilter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ingress&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;takeaways&#34;&gt;Takeaways&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The essence of Kubernetes is application lifecycle management, specifically deployment and management (scaling up and down, auto-recovery, release).&lt;/li&gt;
&lt;li&gt;Kubernetes provides a scalable and highly resilient deployment and management platform for microservices.&lt;/li&gt;
&lt;li&gt;A service mesh is based on transparent proxies that intercept traffic between services through sidecar proxies, and then manage the behavior of them through control plane configuration.&lt;/li&gt;
&lt;li&gt;A service mesh decouples traffic management from Kubernetes, eliminating the need for a kube-proxy component to support traffic within service mesh; and managing inter-service traffic, security and observability by providing an abstraction closer to the microservice application layer.&lt;/li&gt;
&lt;li&gt;xDS is one of the protocol standards for service mesh configuration.&lt;/li&gt;
&lt;li&gt;A service mesh is a higher-level abstraction of service in Kubernetes.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;If the object managed by Kubernetes is a pod, then the object managed in service mesh is a service, so it’s just a matter of using Kubernetes to manage microservices and then applying service mesh. If you don’t even want to manage a service, then use a serverless platform like &lt;a href=&#34;https://knative.dev/&#34;&gt;Knative&lt;/a&gt; — but that’s an afterthought.&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
