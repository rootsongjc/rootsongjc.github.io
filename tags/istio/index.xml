<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy Song - 云原生|开源|社区 – istio</title>
    <link>https://jimmysong.io/tags/istio/</link>
    <description>Recent content in istio on Jimmy Song - 云原生|开源|社区</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <copyright>Copyright &amp;copy; 2017-2022 Jimmy Song 保留所有权利</copyright>
    <lastBuildDate>Tue, 26 Apr 2022 09:27:49 +0800</lastBuildDate>
    
	  <atom:link href="https://jimmysong.io/tags/istio/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Istio 捐献给 CNCF 意味着什么？</title>
      <link>https://jimmysong.io/blog/istio-has-applied-to-join-the-cncf/</link>
      <pubDate>Tue, 26 Apr 2022 09:27:49 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-has-applied-to-join-the-cncf/</guid>
      <description>
        
        
        &lt;p&gt;在 2022 年 4 月 25 日， IstioCon 2022 开幕的当天，Istio 社区宣布正在&lt;a href=&#34;https://istio.io/latest/blog/2022/istio-has-applied-to-join-the-cncf/&#34;&gt;申请将项目捐献给 CNCF&lt;/a&gt;，这是 Istio 项目的一个里程碑，企业级服务网格公司 Tetrate 的 CEO/Istio 项目联合创始人 Varun Talwar 对此进行了解读。&lt;/p&gt;
&lt;p&gt;以下是来自 Varun 对 Istio 捐献给 CNCF 的&lt;a href=&#34;https://www.tetrate.io/blog/istio-has-applied-to-join-the-cncf/&#34;&gt;解读&lt;/a&gt;。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;将 Istio 纳入 CNCF，使得 Istio 和 Envoy 的发展更容易同步推进。它还有助于将 Istio 与 Envoy 一起定位为 CNCF 验证的 &amp;ldquo;云原生技术栈&amp;rdquo; 的一部分。根据 CNCF 的年度&lt;a href=&#34;https://www.cncf.io/reports/cncf-annual-survey-2021/&#34;&gt;调查&lt;/a&gt;，到目前为止，Istio 是生产中最受欢迎和使用最多的服务网格。有 20 多家不同的公司在推动 Istio 社区的发展，这一宣布为 CNCF 管理下的持续创新和增长创造了条件。&lt;/p&gt;
&lt;h2 id=&#34;2016istio-的起源&#34;&gt;2016：Istio 的起源&lt;/h2&gt;
&lt;p&gt;我想借此机会解释一下 Istio 的起源。Istio 来自谷歌的 API 平台团队，名为 One Platform。(今天，具有讽刺意味的是，Istio 是美国政府项目 &lt;a href=&#34;https://www.tetrate.io/blog/tetrate-first-to-provide-hardened-istio-to-dods-iron-bank/&#34;&gt;Platform One&lt;/a&gt; 的一部分，它使用 Tetrate 产品和服务）。一个平台利用了谷歌所有的基础设施优势（stubby、monarch、loas 等），并增加了最初的服务管理经验，并将其全部暴露给应用团队。&lt;/p&gt;
&lt;p&gt;每个团队都会编写他们的方案和方法，并定义他们的 &amp;ldquo;One Platform API&amp;rdquo;。一旦与 API 平台团队达成一致，各团队就不必再处理任何跨领域的问题，因为 Istio 处理了这些服务：流量管理、弹性、可观察性（使用具有一致名词的每个服务的预建仪表板）、认证、授权、速率限制等等。&lt;/p&gt;
&lt;p&gt;Istio 的想法来自于此；我们基本上采用了 One Platform 的想法，将 Envoy 加入其中（作为一个更好的数据平面），并将其与 LOAS 服务身份概念相结合，也就是今天世人所知的 Spiffe）。我们把这个想法告诉了 12 家公司，他们都很喜欢这个想法。这些公司包括大型互联网公司、金融服务公司和科技公司，特别是 SaaS 供应商。&lt;/p&gt;
&lt;h3 id=&#34;2017形成核心&#34;&gt;2017：形成核心&lt;/h3&gt;
&lt;p&gt;2017 年 5 月的，Istio 在 Gluecon 上&lt;a href=&#34;https://cloud.google.com/blog/products/gcp/istio-modern-approach-to-developing-and&#34;&gt;首次公布&lt;/a&gt;。0.1 展示了 Istio 的潜力，引发了大量的关注和讨论。&lt;/p&gt;
&lt;h3 id=&#34;2018-2019稳定核心增加能力&#34;&gt;2018-2019：稳定核心，增加能力&lt;/h3&gt;
&lt;p&gt;接下来的两年里，我们收集了客户的需求，将使用反馈内化，并稳定了核心功能。此外，我们还做出了一些关键的架构决定，如定义多集群模型，并将代码重新架构为一个单一的二进制文件，以方便使用。&lt;/p&gt;
&lt;h3 id=&#34;2020团结社区&#34;&gt;2020：团结社区&lt;/h3&gt;
&lt;p&gt;随着 Istio 的采用和用户生态系统的发展，人们对管理和商标保护的担忧也越来越大。然而，正如我们在&lt;a href=&#34;https://www.tetrate.io/blog/istio-ouc/&#34;&gt;这里&lt;/a&gt;所提到的，作为一个社区保持团结是项目成功的关键。我可以自豪地说，Istio 就是这样做的。因此，今天加入 CNCF 的行动是发展社区和建立最终用户信任的又一步骤。&lt;/p&gt;
&lt;h3 id=&#34;2021向-wasm-和其他领域发展&#34;&gt;2021：向 Wasm 和其他领域发展&lt;/h3&gt;
&lt;p&gt;人们对加入其他基础设施，如虚拟机、功能和裸机工作负载，以及使用 Wasm 等技术的定制和其他功能作为本地 API 的兴趣越来越大，这样用户就不必再使用 Envoy 过滤器了。2021 年见证了其中一些功能的建立和推广。&lt;/p&gt;
&lt;p&gt;&amp;ldquo;Varun Talwar 是项目的创始人之一，他一直认为 Istio 是云原生生态系统的一个重要组成部分。今天的公告验证了他对项目的愿景，我要感谢 Tetrate 成为 Istio 和我们社区的有力支持者。&amp;quot;——Louis Ryan（Istio 联合创始人，谷歌工程负责人）&lt;/p&gt;
&lt;h3 id=&#34;零信任的基础&#34;&gt;零信任的基础&lt;/h3&gt;
&lt;p&gt;关于零信任的话题已经有很多讨论，但很少有明确的说法。正如 Eric Brewer 今天在 IstioCon 的&lt;a href=&#34;https://events.istio.io/istiocon-2022/sessions/zero-trust-istio/&#34;&gt;主题演讲&lt;/a&gt;中提到的，Istio 正在成为零信任的一个重要组成部分。其中最主要的是面向身份的控制，而不是面向网络的控制。这方面的核心原则在谷歌白皮书&lt;a href=&#34;https://cloud.google.com/blog/products/identity-security/beyondprod-whitepaper-discusses-cloud-native-security-at-google&#34;&gt;《BeyondProd：云原生安全的新方法》&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;然而，作为一个行业，这里有更多的事情要做。我们需要确保我们可以把应用用户和数据服务都带进来。如果我们能将身份概念扩展到用户，并为我们提供灵活而丰富的策略机制来指定、监控和跟踪访问控制，我们就能达到一个可操作的零信任结构 —— 一个将用户、服务和数据统一到一个管理层的结构。我在 2020 年为美国国家标准与技术研究院（NIST）举办的围绕信任云原生应用的主题演讲中也提到了这一点。这就是为什么我们在 Tetrate 创建了 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt;—— 一个管理平面，使大型组织可操作。&lt;/p&gt;
&lt;p&gt;Tetrate Service Bridge 的基础是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户、服务和数据的身份。每个人都有一个加密身份，构成所有政策的骨干。&lt;/li&gt;
&lt;li&gt;策略和访问控制。定义 Istio 策略，也包括应用和组织策略，包括用户和设备，以及大规模管理它们的能力。&lt;/li&gt;
&lt;li&gt;自动化。在运行时自动化、测量和持续监测策略的能力。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果我们能让企业以这种方式为云原生工作负载部署和运营安全，我们就能作为一个行业取得巨大进步。&lt;/p&gt;
&lt;h3 id=&#34;人才&#34;&gt;人才&lt;/h3&gt;
&lt;p&gt;归根结底，没有高素质、富有创造性的人才，任何项目或技术都不会成为主流。在 Tetrate，我们相信我们需要对社区进行有关这项技术的教育，并为负责任的采用路径做出贡献。因此，我们提供世界级的认证和免费的在线培训课程，使社区中的任何人都可以在 &lt;a href=&#34;https://academy.tetrate.io/&#34;&gt;academy.terate.io&lt;/a&gt; 轻松参加 Istio 和 Envoy 的初级和高级课程。&lt;/p&gt;
&lt;p&gt;我们 Tetrate 的所有人，特别是我自己，都期待着下一步的发展，我们将始终支持 Istio 项目和社区。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 中的 Sidecar 注入、透明流量劫持及流量路由过程详解</title>
      <link>https://jimmysong.io/blog/sidecar-injection-iptables-and-traffic-routing/</link>
      <pubDate>Mon, 27 Apr 2020 21:08:59 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/sidecar-injection-iptables-and-traffic-routing/</guid>
      <description>
        
        
        &lt;p&gt;本文最早是基于 Istio 1.11 撰写，之后随着 Istio 的版本陆续更新，最新更新时间为 2022 年 4 月 24 日，关于本文历史版本的更新说明请见文章最后。本文记录了详细的实践过程，力图能够让读者复现，因此事无巨细，想要理解某个部分过程的读者可以使用目录跳转到对应的小节阅读。&lt;/p&gt;
&lt;p&gt;为了使读者能够更加直观的了解本文中执行的操作，在阅读本文前你也可以先观看下 &lt;a href=&#34;https://bilibili.com/video/BV1cF411T72o/&#34;&gt;Istio Workshop 第八讲视频&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://bilibili.com/video/BV1cF411T72o/&#34;&gt;&lt;img src=&#34;bilibili.jpg&#34; alt=&#34;Istio Workshop第八讲&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;内容介绍&#34;&gt;内容介绍&lt;/h2&gt;
&lt;p&gt;本文基于 Istio 1.13 版本，将为大家介绍以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;什么是 sidecar 模式和它的优势在哪里。&lt;/li&gt;
&lt;li&gt;Istio 中是如何做 sidecar 注入的。&lt;/li&gt;
&lt;li&gt;Sidecar 代理是如何做透明流量劫持的。&lt;/li&gt;
&lt;li&gt;iptables 的路由规则。&lt;/li&gt;
&lt;li&gt;Envoy 代理是如何路由流量到上游的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;请大家结合下图理解本文中的内容，本图基于 Istio 官方提供的 Bookinfo 示例绘制，展示的是 &lt;code&gt;reviews&lt;/code&gt; Pod 的内部结构，包括 Linux Kernel 空间中的 iptables 规则、Sidecar 容器、应用容器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-sidecar-traffic-interception-zh-20220424.jpg&#34; alt=&#34;Sidecar 流量劫持示意图&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;productpage&lt;/code&gt; 访问 &lt;code&gt;reviews&lt;/code&gt; Pod，入站流量处理过程对应于图示上的步骤：1、2、3、4、Envoy Inbound Handler、5、6、7、8、应用容器。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reviews&lt;/code&gt; Pod 访问 &lt;code&gt;rating&lt;/code&gt; 服务的出站流量处理过程对应于图示上的步骤是：9、10、11、12、Envoy Outbound Handler、13、14、15。&lt;/p&gt;
&lt;p&gt;上图中关于流量路由部分，包含：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;productpage&lt;/code&gt; 服务请求访问 &lt;code&gt;http://reviews.default.svc.cluster.local:9080/&lt;/code&gt;，当流量进入 &lt;code&gt;reviews&lt;/code&gt; Pod 内部时，流量是如何被 iptables 劫持到 Envoy 代理被 Inbound Handler 处理的；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reviews&lt;/code&gt; 请求访问 &lt;code&gt;ratings&lt;/code&gt; 服务的 Pod，应用程序发出的出站流量被 iptables 劫持到 Envoy 代理的 Outbound Handler 的处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在阅读下文时，请大家确立以下已知点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;首先，&lt;code&gt;productpage&lt;/code&gt; 发出的对 &lt;code&gt;reivews&lt;/code&gt; 的访问流量，是在 Envoy 已经通过 EDS 选择出了要请求的 &lt;code&gt;reviews&lt;/code&gt; 服务的某个 Pod，知晓了其 IP 地址，直接向该 IP 发送的 TCP 连接请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;reviews&lt;/code&gt; 服务有三个版本，每个版本有一个实例，三个版本中的 sidecar 工作步骤类似，下文只以其中一个 Pod 中的 sidecar 流量转发步骤来说明。&lt;/li&gt;
&lt;li&gt;所有进入 &lt;code&gt;reviews&lt;/code&gt; Pod 的 TCP 流量都根据 Pod 中的 iptables 规则转发到了 Envoy 代理的 15006 端口，然后经过 Envoy 的处理确定转发给 Pod 内的应用容器还是透传。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;sidecar-模式&#34;&gt;Sidecar 模式&lt;/h2&gt;
&lt;p&gt;将应用程序的功能划分为单独的进程运行在同一个最小调度单元中（例如 Kubernetes 中的 Pod）可以被视为 &lt;strong&gt;sidecar 模式&lt;/strong&gt;。如下图所示，sidecar 模式允许您在应用程序旁边添加更多功能，而无需额外第三方组件配置或修改应用程序代码。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sidecar-pattern.jpg&#34; alt=&#34;Sidecar 模式示意图&#34;&gt;&lt;/p&gt;
&lt;p&gt;就像连接了 Sidecar 的三轮摩托车一样，在软件架构中， Sidecar 连接到父应用并且为其添加扩展或者增强功能。Sidecar 应用与主应用程序松散耦合。它可以屏蔽不同编程语言的差异，统一实现微服务的可观察性、监控、日志记录、配置、断路器等功能。&lt;/p&gt;
&lt;h3 id=&#34;使用-sidecar-模式的优势&#34;&gt;使用 Sidecar 模式的优势&lt;/h3&gt;
&lt;p&gt;使用 sidecar 模式部署服务网格时，无需在节点上运行代理，但是集群中将运行多个相同的 sidecar 副本。在 sidecar 部署方式中，每个应用的容器旁都会部署一个伴生容器（如 Envoy 或 MOSN），这个容器称之为 sidecar 容器。Sidecar 接管进出应用容器的所有流量。在 Kubernetes 的 Pod 中，在原有的应用容器旁边注入一个 Sidecar 容器，两个容器共享存储、网络等资源，可以广义的将这个包含了 sidecar 容器的 Pod 理解为一台主机，两个容器共享主机资源。&lt;/p&gt;
&lt;p&gt;因其独特的部署结构，使得 sidecar 模式具有以下优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将与应用业务逻辑无关的功能抽象到共同基础设施，降低了微服务代码的复杂度。&lt;/li&gt;
&lt;li&gt;因为不再需要编写相同的第三方组件配置文件和代码，所以能够降低微服务架构中的代码重复度。&lt;/li&gt;
&lt;li&gt;Sidecar 可独立升级，降低应用程序代码和底层平台的耦合度。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;istio-中的-sidecar-注入&#34;&gt;Istio 中的 sidecar 注入&lt;/h2&gt;
&lt;p&gt;Istio 中提供了以下两种 sidecar 注入方式：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;istioctl&lt;/code&gt; 手动注入。&lt;/li&gt;
&lt;li&gt;基于 Kubernetes 的 &lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/&#34;&gt;突变 webhook 准入控制器（mutating webhook addmission controller&lt;/a&gt; 的自动 sidecar 注入方式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;不论是手动注入还是自动注入，sidecar 的注入过程都需要遵循如下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Kubernetes 需要了解待注入的 sidecar 所连接的 Istio 集群及其配置；&lt;/li&gt;
&lt;li&gt;Kubernetes 需要了解待注入的 sidecar 容器本身的配置，如镜像地址、启动参数等；&lt;/li&gt;
&lt;li&gt;Kubernetes 根据 sidecar 注入模板和以上配置填充 sidecar 的配置参数，将以上配置注入到应用容器的一侧；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;使用下面的命令可以手动注入 sidecar。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl kube-inject -f &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;YAML_FILE&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; kuebectl apply -f -
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该命令会使用 Istio 内置的 sidecar 配置来注入，下面使用 Istio详细配置请参考 &lt;a href=&#34;https://istio.io/latest/docs/setup/additional-setup/sidecar-injection/#manual-sidecar-injection&#34;&gt;Istio 官网&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;注入完成后您将看到 Istio 为原有 pod template 注入了 &lt;code&gt;initContainer&lt;/code&gt; 及 sidecar proxy相关的配置。&lt;/p&gt;
&lt;h3 id=&#34;init-容器&#34;&gt;Init 容器&lt;/h3&gt;
&lt;p&gt;Init 容器是一种专用容器，它在应用程序容器启动之前运行，用来包含一些应用镜像中不存在的实用工具或安装脚本。&lt;/p&gt;
&lt;p&gt;一个 Pod 中可以指定多个 Init 容器，如果指定了多个，那么 Init 容器将会按顺序依次运行。只有当前面的 Init 容器必须运行成功后，才可以运行下一个 Init 容器。当所有的 Init 容器运行完成后，Kubernetes 才初始化 Pod 和运行应用容器。&lt;/p&gt;
&lt;p&gt;Init 容器使用 Linux Namespace，所以相对应用程序容器来说具有不同的文件系统视图。因此，它们能够具有访问 Secret 的权限，而应用程序容器则不能。&lt;/p&gt;
&lt;p&gt;在 Pod 启动过程中，Init 容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。如果由于运行时或失败退出，将导致容器启动失败，它会根据 Pod 的 &lt;code&gt;restartPolicy&lt;/code&gt; 指定的策略进行重试。然而，如果 Pod 的 &lt;code&gt;restartPolicy&lt;/code&gt; 设置为 Always，Init 容器失败时会使用 &lt;code&gt;RestartPolicy&lt;/code&gt; 策略。&lt;/p&gt;
&lt;p&gt;在所有的 Init 容器没有成功之前，Pod 将不会变成 &lt;code&gt;Ready&lt;/code&gt; 状态。Init 容器的端口将不会在 Service中进行聚集。 正在初始化中的 Pod 处于 &lt;code&gt;Pending&lt;/code&gt; 状态，但应该会将 &lt;code&gt;Initializing&lt;/code&gt; 状态设置为 true。Init 容器运行完成以后就会自动终止。&lt;/p&gt;
&lt;p&gt;关于 Init 容器的详细信息请参考 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/init-containers.html&#34;&gt;Init 容器 - Kubernetes 中文指南/云原生应用架构实践手册&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;sidecar-注入示例分析&#34;&gt;Sidecar 注入示例分析&lt;/h2&gt;
&lt;p&gt;以 Istio 官方提供的 &lt;code&gt;bookinfo&lt;/code&gt; 中 &lt;code&gt;productpage&lt;/code&gt; 的 YAML 为例，关于 &lt;code&gt;bookinfo&lt;/code&gt; 应用的详细 YAML 配置请参考 &lt;a href=&#34;https://github.com/istio/istio/blob/master/samples/bookinfo/platform/kube/bookinfo.yaml&#34;&gt;bookinfo.yaml&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下文将从以下几个方面讲解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sidecar 容器的注入&lt;/li&gt;
&lt;li&gt;iptables 规则的创建&lt;/li&gt;
&lt;li&gt;路由的详细过程&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;apps/v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Deployment&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage-v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;app&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;replicas&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;selector&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;matchLabels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;app&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;template&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;app&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;serviceAccountName&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;bookinfo-productpage&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;containers&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;docker.io/istio/examples-bookinfo-productpage-v1&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.15&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;imagePullPolicy&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;IfNotPresent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;containerPort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;volumeMounts&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;tmp&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;mountPath&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/tmp&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;volumes&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;tmp&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;emptyDir&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;再查看下 &lt;code&gt;productpage&lt;/code&gt; 容器的 &lt;a href=&#34;https://github.com/istio/istio/blob/master/samples/bookinfo/src/productpage/Dockerfile&#34;&gt;Dockerfile&lt;/a&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-docker&#34; data-lang=&#34;docker&#34;&gt;&lt;span class=&#34;k&#34;&gt;FROM&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; python:3.7.4-slim&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; requirements.txt ./&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; pip install --no-cache-dir -r requirements.txt&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; test-requirements.txt ./&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; pip install --no-cache-dir -r test-requirements.txt&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; productpage.py /opt/microservices/&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; tests/unit/* /opt/microservices/&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; templates /opt/microservices/templates&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; static /opt/microservices/static&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;COPY&lt;/span&gt; requirements.txt /opt/microservices/&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ARG&lt;/span&gt; flood_factor&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ENV&lt;/span&gt; FLOOD_FACTOR &lt;span class=&#34;si&#34;&gt;${&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;flood_factor&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;:-&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;si&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;EXPOSE&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; 9080&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;WORKDIR&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; /opt/microservices&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;RUN&lt;/span&gt; python -m unittest discover&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;USER&lt;/span&gt;&lt;span class=&#34;s&#34;&gt; 1&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;CMD&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;python&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;productpage.py&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到 &lt;code&gt;Dockerfile&lt;/code&gt; 中没有配置 &lt;code&gt;ENTRYPOINT&lt;/code&gt;，所以 &lt;code&gt;CMD&lt;/code&gt; 的配置 &lt;code&gt;python productpage.py 9080&lt;/code&gt; 将作为默认的 &lt;code&gt;ENTRYPOINT&lt;/code&gt;，记住这一点，再看下注入 sidecar 之后的配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ istioctl kube-inject -f samples/bookinfo/platform/kube/bookinfo.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们只截取其中与 &lt;code&gt;productpage&lt;/code&gt; 相关的 &lt;code&gt;Deployment&lt;/code&gt; 配置中的部分 YAML 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;containers&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;docker.io/istio/examples-bookinfo-productpage-v1&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.15&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 应用镜像&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;containerPort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;args&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;proxy&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;sidecar&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--domain&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;$(POD_NAMESPACE).svc.cluster.local&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--configPath&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/etc/istio/proxy&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--binaryPath&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/usr/local/bin/envoy&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--serviceCluster&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;productpage.$(POD_NAMESPACE)&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--drainDuration&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;45s&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--parentShutdownDuration&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;1m0s&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--discoveryAddress&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istiod.istio-system.svc&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--zipkinAddress&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;zipkin.istio-system&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9411&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--proxyLogLevel=warning&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--proxyComponentLogLevel=misc&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;error&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--connectTimeout&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;10s&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--proxyAdminPort&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15000&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--concurrency&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;2&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--controlPlaneAuthPolicy&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;NONE&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--dnsRefreshRate&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;300s&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--statusPort&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15020&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--trust-domain=cluster.local&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--controlPlaneBootstrap=&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;docker.io/istio/proxyv2&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# sidecar proxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istio-proxy&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;containerPort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15090&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;http-envoy-prom&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;protocol&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;TCP&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;initContainers&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;command&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istio-iptables&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-p&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15001&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-z&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;15006&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-u&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;1337&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-m&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;REDIRECT&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-i&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-x&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-b&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-d&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15090&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15020&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;docker.io/istio/proxyv2&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.5&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;.1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# init 容器&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istio-init&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Istio 给应用 Pod 注入的配置主要包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Init 容器 &lt;code&gt;istio-init&lt;/code&gt;：用于 pod 中设置 iptables 端口转发&lt;/li&gt;
&lt;li&gt;Sidecar 容器 &lt;code&gt;istio-proxy&lt;/code&gt;：运行 sidecar 代理，如 Envoy 或 MOSN。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来将分别解析下这两个容器。&lt;/p&gt;
&lt;h2 id=&#34;init-容器解析&#34;&gt;Init 容器解析&lt;/h2&gt;
&lt;p&gt;Istio 在 pod 中注入的 Init 容器名为 &lt;code&gt;istio-init&lt;/code&gt;，我们在上面 Istio 注入完成后的 YAML 文件中看到了该容器的启动命令是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istio-iptables -p &lt;span class=&#34;m&#34;&gt;15001&lt;/span&gt; -z &lt;span class=&#34;m&#34;&gt;15006&lt;/span&gt; -u &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; -m REDIRECT -i &lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt; -x &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; -b &lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt; -d 15090,15020
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们再检查下该容器的 &lt;a href=&#34;https://github.com/istio/istio/blob/master/pilot/docker/Dockerfile.proxyv2&#34;&gt;Dockerfile&lt;/a&gt; 看看 &lt;code&gt;ENTRYPOINT&lt;/code&gt; 是怎么确定启动时执行的命令。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-docker&#34; data-lang=&#34;docker&#34;&gt;&lt;span class=&#34;c&#34;&gt;# 前面的内容省略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# The pilot-agent will bootstrap Envoy.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;ENTRYPOINT&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/usr/local/bin/pilot-agent&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到 &lt;code&gt;istio-init&lt;/code&gt; 容器的入口是 &lt;code&gt;/usr/local/bin/istio-iptables&lt;/code&gt; 命令行，该命令行工具的代码的位置在 Istio 源码仓库的 &lt;a href=&#34;https://github.com/istio/istio/tree/master/tools/istio-iptables&#34;&gt;tools/istio-iptables&lt;/a&gt; 目录。&lt;/p&gt;
&lt;p&gt;注意：在 Istio 1.1 版本时还是使用 &lt;code&gt;isito-iptables.sh&lt;/code&gt; 命令行来操作 IPtables。&lt;/p&gt;
&lt;h3 id=&#34;init-容器启动入口&#34;&gt;Init 容器启动入口&lt;/h3&gt;
&lt;p&gt;Init 容器的启动入口是 &lt;code&gt;istio-iptables&lt;/code&gt; 命令行，该命令行工具的用法如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ istio-iptables &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;flags&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
  -p: 指定重定向所有 TCP 流量的 sidecar 端口（默认为 &lt;span class=&#34;nv&#34;&gt;$ENVOY_PORT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 15001）
  -m: 指定入站连接重定向到 sidecar 的模式，“REDIRECT” 或 “TPROXY”（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_INBOUND_INTERCEPTION_MODE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
  -b: 逗号分隔的入站端口列表，其流量将重定向到 Envoy（可选）。使用通配符 “*” 表示重定向所有端口。为空时表示禁用所有入站重定向（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_INBOUND_PORTS&lt;/span&gt;）
  -d: 指定要从重定向到 sidecar 中排除的入站端口列表（可选），以逗号格式分隔。使用通配符“*” 表示重定向所有入站流量（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_LOCAL_EXCLUDE_PORTS&lt;/span&gt;）
  -o：逗号分隔的出站端口列表，不包括重定向到 Envoy 的端口。
  -i: 指定重定向到 sidecar 的 IP 地址范围（可选），以逗号分隔的 CIDR 格式列表。使用通配符 “*” 表示重定向所有出站流量。空列表将禁用所有出站重定向（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_SERVICE_CIDR&lt;/span&gt;）
  -x: 指定将从重定向中排除的 IP 地址范围，以逗号分隔的 CIDR 格式列表。使用通配符 “*” 表示重定向所有出站流量（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_SERVICE_EXCLUDE_CIDR&lt;/span&gt;）。
  -k：逗号分隔的虚拟接口列表，其入站流量（来自虚拟机的）将被视为出站流量。
  -g：指定不应用重定向的用户的 GID。&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;默认值与 -u param 相同&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
  -u：指定不应用重定向的用户的 UID。通常情况下，这是代理容器的 UID（默认值是 1337，即 istio-proxy 的 UID）。
  -z: 所有进入 pod/VM 的 TCP 流量应被重定向到的端口（默认 &lt;span class=&#34;nv&#34;&gt;$INBOUND_CAPTURE_PORT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 15006）。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上传入的参数都会重新组装成 &lt;a href=&#34;https://wangchujiang.com/linux-command/c/iptables.html&#34;&gt;&lt;code&gt;iptables&lt;/code&gt; &lt;/a&gt;规则，关于该命令的详细用法请访问 &lt;a href=&#34;https://github.com/istio/istio/blob/master/tools/istio-iptables/pkg/cmd/root.go&#34;&gt;tools/istio-iptables/pkg/cmd/root.go&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;该容器存在的意义就是让 sidecar 代理可以拦截所有的进出 pod 的流量，15090 端口（Mixer 使用）和 15092 端口（Ingress Gateway）除外的所有入站（inbound）流量重定向到 15006 端口（sidecar），再拦截应用容器的出站（outbound）流量经过 sidecar 处理（通过 15001 端口监听）后再出站。关于 Istio 中端口用途请参考 &lt;a href=&#34;https://istio.io/latest/zh/docs/ops/deployment/requirements/&#34;&gt;Istio 官方文档&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;命令解析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这条启动命令的作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将应用容器的所有流量都转发到 sidecar 的 15006 端口。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;istio-proxy&lt;/code&gt; 用户身份运行， UID 为 1337，即 sidecar 所处的用户空间，这也是 &lt;code&gt;istio-proxy&lt;/code&gt; 容器默认使用的用户，见 YAML 配置中的 &lt;code&gt;runAsUser&lt;/code&gt; 字段。&lt;/li&gt;
&lt;li&gt;使用默认的 &lt;code&gt;REDIRECT&lt;/code&gt; 模式来重定向流量。&lt;/li&gt;
&lt;li&gt;将所有出站流量都重定向到 sidecar 代理（通过 15001 端口）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因为 Init 容器初始化完毕后就会自动终止，因为我们无法登陆到容器中查看 iptables 信息，但是 Init 容器初始化结果会保留到应用容器和 sidecar 容器中。&lt;/p&gt;
&lt;h2 id=&#34;iptables-规则注入解析&#34;&gt;iptables 规则注入解析&lt;/h2&gt;
&lt;p&gt;为了查看 iptables 配置，我们需要登陆到 sidecar 容器中使用 root 用户来查看，因为 &lt;code&gt;kubectl&lt;/code&gt; 无法使用特权模式来远程操作 docker 容器，所以我们需要登陆到 &lt;code&gt;productpage&lt;/code&gt; pod 所在的主机上使用 &lt;code&gt;docker&lt;/code&gt; 命令登陆容器中查看。&lt;/p&gt;
&lt;p&gt;如果您使用 minikube 部署的 Kubernetes，可以直接登录到 minikube 的虚拟机中并切换为 root 用户。查看 iptables 配置，列出 NAT（网络地址转换）表的所有规则，因为在 Init 容器启动的时候选择给 &lt;code&gt;istio-iptables&lt;/code&gt; 传递的参数中指定将入站流量重定向到 sidecar 的模式为 &lt;code&gt;REDIRECT&lt;/code&gt;，因此在 iptables 中将只有 NAT 表的规格配置，如果选择 &lt;code&gt;TPROXY&lt;/code&gt; 还会有 &lt;code&gt;mangle&lt;/code&gt; 表配置。&lt;code&gt;iptables&lt;/code&gt; 命令的详细用法请参考 &lt;a href=&#34;https://wangchujiang.com/linux-command/c/iptables.html&#34;&gt;iptables&lt;/a&gt; 命令。&lt;/p&gt;
&lt;p&gt;我们仅查看与 &lt;code&gt;productpage&lt;/code&gt; 有关的 iptables 规则如下，因为这些规则是运行在该容器特定的网络空间下，因此需要使用 &lt;code&gt;nsenter&lt;/code&gt; 命令进入其网络空间。进入的时候需要指定进程 ID（PID），因此首先我们需要找到 &lt;code&gt;productpage&lt;/code&gt; 容器的 PID。对于在不同平台上安装的 Kubernetes，查找容器的方式会略有不同，例如在 GKE 上，执行 &lt;code&gt;docker ps -a&lt;/code&gt; 命令是查看不到任何容器进程的。下面已 minikube 和 GKE 两个典型的平台为例，指导你如何进入容器的网络空间。&lt;/p&gt;
&lt;h3 id=&#34;在-minikube-中查看容器中的-iptabes-规则&#34;&gt;在 minikube 中查看容器中的 iptabes 规则&lt;/h3&gt;
&lt;p&gt;对于 minikube，因为所有的进程都运行在单个节点上，因此你只需要登录到 minikube 虚拟机，切换为 root 用户然后查找 &lt;code&gt;productpage&lt;/code&gt; 进程即可，参考下面的步骤。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 进入 minikube 并切换为 root 用户，minikube 默认用户为 docker&lt;/span&gt;
$ minikube ssh
$ sudo -i

&lt;span class=&#34;c1&#34;&gt;# 查看 productpage pod 的 istio-proxy 容器中的进程&lt;/span&gt;
$ docker top &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;docker ps&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;grep &lt;span class=&#34;s2&#34;&gt;&amp;#34;istio-proxy_productpage&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;cut -d &lt;span class=&#34;s2&#34;&gt;&amp;#34; &amp;#34;&lt;/span&gt; -f1&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;
UID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD
&lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;10576&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;10517&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;                   08:09               ?                   00:00:07            /usr/local/bin/pilot-agent proxy sidecar --domain default.svc.cluster.local --configPath /etc/istio/proxy --binaryPath /usr/local/bin/envoy --serviceCluster productpage.default --drainDuration 45s --parentShutdownDuration 1m0s --discoveryAddress istiod.istio-system.svc:15012 --zipkinAddress zipkin.istio-system:9411 --proxyLogLevel&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;warning --proxyComponentLogLevel&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;misc:error --connectTimeout 10s --proxyAdminPort &lt;span class=&#34;m&#34;&gt;15000&lt;/span&gt; --concurrency &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; --controlPlaneAuthPolicy NONE --dnsRefreshRate 300s --statusPort &lt;span class=&#34;m&#34;&gt;15020&lt;/span&gt; --trust-domain&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;cluster.local --controlPlaneBootstrap&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;false&lt;/span&gt;
&lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt;                &lt;span class=&#34;m&#34;&gt;10660&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;10576&lt;/span&gt;               &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;                   08:09               ?                   00:00:33            /usr/local/bin/envoy -c /etc/istio/proxy/envoy-rev0.json --restart-epoch &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; --drain-time-s &lt;span class=&#34;m&#34;&gt;45&lt;/span&gt; --parent-shutdown-time-s &lt;span class=&#34;m&#34;&gt;60&lt;/span&gt; --service-cluster productpage.default --service-node sidecar~172.17.0.16~productpage-v1-7f44c4d57c-ksf9b.default~default.svc.cluster.local --max-obj-name-len &lt;span class=&#34;m&#34;&gt;189&lt;/span&gt; --local-address-ip-version v4 --log-format &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;Envoy &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;Epoch 0&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;%Y-%m-%d %T.%e&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;%t&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;%l&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;%n&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; %v -l warning --component-log-level misc:error --concurrency &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 使用 nsenter 进入 sidecar 容器的命名空间（以上任何一个都可以）&lt;/span&gt;
$ nsenter -n --target &lt;span class=&#34;m&#34;&gt;10660&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# 查看 NAT 表中规则配置的详细信息。&lt;/span&gt;
$ iptables -t nat -L
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;在-gke-中查看容器的-iptables-规则&#34;&gt;在 GKE 中查看容器的 iptables 规则&lt;/h3&gt;
&lt;p&gt;如果你在 GKE 中安装的多节点的 Kubernetes 集群，首先你需要确定这个 Pod 运行在哪个节点上，然后登陆到那台主机，使用下面的命令查找进程的 PID，你会得到类似下面的输出。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ ps aux&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;grep &lt;span class=&#34;s2&#34;&gt;&amp;#34;productpage&amp;#34;&lt;/span&gt;
chronos     &lt;span class=&#34;m&#34;&gt;4268&lt;/span&gt;  0.0  0.6  &lt;span class=&#34;m&#34;&gt;43796&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;24856&lt;/span&gt; ?        Ss   Apr22   0:00 python productpage.py &lt;span class=&#34;m&#34;&gt;9080&lt;/span&gt;
chronos     &lt;span class=&#34;m&#34;&gt;4329&lt;/span&gt;  0.9  0.6 &lt;span class=&#34;m&#34;&gt;117524&lt;/span&gt; &lt;span class=&#34;m&#34;&gt;24616&lt;/span&gt; ?        Sl   Apr22  13:43 /usr/local/bin/python /opt/microservices/productpage.py &lt;span class=&#34;m&#34;&gt;9080&lt;/span&gt;
root      &lt;span class=&#34;m&#34;&gt;361903&lt;/span&gt;  0.0  0.0   &lt;span class=&#34;m&#34;&gt;4536&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;812&lt;/span&gt; pts/0    S+   01:54   0:00 grep --colour&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;auto productpage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后在终端中输出 &lt;code&gt;iptables -t nat -L&lt;/code&gt; 即可查看 iptables 规则。&lt;/p&gt;
&lt;h2 id=&#34;iptables-流量劫持过程详解&#34;&gt;iptables 流量劫持过程详解&lt;/h2&gt;
&lt;p&gt;经过上面的步骤，你已经可以查看到 init 容器向 Pod 中注入的 iptables 规则，如下所示。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# PREROUTING 链：用于目标地址转换（DNAT），将所有入站 TCP 流量跳转到 ISTIO_INBOUND 链上。&lt;/span&gt;
Chain PREROUTING &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;2701&lt;/span&gt; packets, 162K bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
 &lt;span class=&#34;m&#34;&gt;2701&lt;/span&gt;  162K ISTIO_INBOUND  tcp  --  any    any     anywhere             anywhere

&lt;span class=&#34;c1&#34;&gt;# INPUT 链：处理输入数据包，非 TCP 流量将继续 OUTPUT 链。&lt;/span&gt;
Chain INPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;2701&lt;/span&gt; packets, 162K bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

&lt;span class=&#34;c1&#34;&gt;# OUTPUT 链：将所有出站数据包跳转到 ISTIO_OUTPUT 链上。&lt;/span&gt;
Chain OUTPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;79&lt;/span&gt; packets, &lt;span class=&#34;m&#34;&gt;6761&lt;/span&gt; bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
   &lt;span class=&#34;m&#34;&gt;15&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;900&lt;/span&gt; ISTIO_OUTPUT  tcp  --  any    any     anywhere             anywhere

&lt;span class=&#34;c1&#34;&gt;# POSTROUTING 链：所有数据包流出网卡时都要先进入 POSTROUTING 链，内核根据数据包目的地判断是否需要转发出去，我们看到此处未做任何处理。&lt;/span&gt;
Chain POSTROUTING &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;79&lt;/span&gt; packets, &lt;span class=&#34;m&#34;&gt;6761&lt;/span&gt; bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

&lt;span class=&#34;c1&#34;&gt;# ISTIO_INBOUND 链：将所有入站流量重定向到 ISTIO_IN_REDIRECT 链上。目的地为 15090（Prometheus 使用）和 15020（Ingress gateway 使用，用于 Pilot 健康检查）端口的流量除外，发送到以上两个端口的流量将返回 iptables 规则链的调用点，即 PREROUTING 链的后继 POSTROUTING 后直接调用原始目的地。&lt;/span&gt;
Chain ISTIO_INBOUND &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     tcp  --  any    any     anywhere             anywhere             tcp dpt:ssh
    &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;120&lt;/span&gt; RETURN     tcp  --  any    any     anywhere             anywhere             tcp dpt:15090
 &lt;span class=&#34;m&#34;&gt;2699&lt;/span&gt;  162K RETURN     tcp  --  any    any     anywhere             anywhere             tcp dpt:15020
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; ISTIO_IN_REDIRECT  tcp  --  any    any     anywhere             anywhere

&lt;span class=&#34;c1&#34;&gt;# ISTIO_IN_REDIRECT 链：将所有的入站流量跳转到本地的 15006 端口，至此成功的拦截了流量到 sidecar 代理的 Inbound Handler 中。&lt;/span&gt;
Chain ISTIO_IN_REDIRECT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; REDIRECT   tcp  --  any    any     anywhere             anywhere             redir ports &lt;span class=&#34;m&#34;&gt;15006&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# ISTIO_OUTPUT 链：规则比较复杂，将在下文解释&lt;/span&gt;
Chain ISTIO_OUTPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    lo      127.0.0.6            anywhere &lt;span class=&#34;c1&#34;&gt;#规则1&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; ISTIO_IN_REDIRECT  all  --  any    lo      anywhere            !localhost            owner UID match &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#规则2&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    lo      anywhere             anywhere             ! owner UID match &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#规则3&lt;/span&gt;
   &lt;span class=&#34;m&#34;&gt;15&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;900&lt;/span&gt; RETURN     all  --  any    any     anywhere             anywhere             owner UID match &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#规则4&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; ISTIO_IN_REDIRECT  all  --  any    lo      anywhere            !localhost            owner GID match &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#规则5&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    lo      anywhere             anywhere             ! owner GID match &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#规则6&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    any     anywhere             anywhere             owner GID match &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;#规则7&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    any     anywhere             localhost &lt;span class=&#34;c1&#34;&gt;#规则8&lt;/span&gt;
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; ISTIO_REDIRECT  all  --  any    any     anywhere             anywhere &lt;span class=&#34;c1&#34;&gt;#规则9&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# ISTIO_REDIRECT 链：将所有流量重定向到 Envoy 代理的 15001 端口。&lt;/span&gt;
Chain ISTIO_REDIRECT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; REDIRECT   tcp  --  any    any     anywhere             anywhere             redir ports &lt;span class=&#34;m&#34;&gt;15001&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里着重需要解释的是 &lt;code&gt;ISTIO_OUTPUT&lt;/code&gt; 链中的 9 条规则，为了便于阅读，我将以上规则中的部分内容使用表格的形式来展示如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;规则&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;target&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;in&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;out&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;source&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;destination&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;RETURN&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;lo&lt;/td&gt;
&lt;td&gt;127.0.0.6&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;ISTIO_IN_REDIRECT&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;lo&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;!localhost owner UID match 1337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;RETURN&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;lo&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;anywhere !owner UID match 1337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;RETURN&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;anywhere owner UID match 1337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;ISTIO_IN_REDIRECT&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;lo&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;!localhost owner GID match 1337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;6&lt;/td&gt;
&lt;td&gt;RETURN&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;lo&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;anywhere !owner GID match 1337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;7&lt;/td&gt;
&lt;td&gt;RETURN&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;anywhere owner GID match 1337&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8&lt;/td&gt;
&lt;td&gt;RETURN&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;localhost&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;ISTIO_REDIRECT&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;any&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;td&gt;anywhere&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;下图展示了 &lt;code&gt;ISTIO_ROUTE&lt;/code&gt; 规则的详细流程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio-route-iptables.jpg&#34; alt=&#34;ISTIO_ROUTE iptables 规则流程图&#34;&gt;&lt;/p&gt;
&lt;p&gt;我将按照规则的出现顺序来解释每条规则的目的、对应文章开头图示中的步骤及详情。其中规则 5、6、7 是分别对规则 2、3、4 的应用范围扩大（从 UID 扩大为 GID），作用是类似的，将合并解释。注意，其中的规则是按顺序执行的，也就是说排序越靠后的规则将作为默认值。出站网卡（out）为 &lt;code&gt;lo&lt;/code&gt; （本地回环地址，loopback 接口）时，表示流量的目的地是本地 Pod，对于 Pod 向外部发送的流量就不会经过这个接口。所有 &lt;code&gt;review&lt;/code&gt; Pod 的出站流量只适用于规则 4、7、8、9。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;规则 1&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：&lt;strong&gt;透传&lt;/strong&gt; Envoy 代理发送到本地应用容器的流量，使其绕过 Envoy 代理，直达应用容器。&lt;/li&gt;
&lt;li&gt;对应图示中的步骤：6 到 7。&lt;/li&gt;
&lt;li&gt;详情：该规则使得所有来自 &lt;code&gt;127.0.0.6&lt;/code&gt;（该 IP 地址将在下文解释） 的请求，跳出该链，返回 iptables 的调用点（即 &lt;code&gt;OUTPUT&lt;/code&gt;）后继续执行其余路由规则，即 &lt;code&gt;POSTROUTING&lt;/code&gt; 规则，把流量发送到任意目的地址，如本地 Pod 内的应用容器。如果没有这条规则，由 Pod 内 Envoy 代理发出的对 Pod 内容器访问的流量将会执行下一条规则，即规则 2，流量将再次进入到了 Inbound Handler 中，从而形成了死循环。将这条规则放在第一位可以避免流量在 Inbound Handler 中死循环的问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;规则 2、5&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：处理 Envoy 代理发出的站内流量（Pod 内部的流量），但不是对 localhost 的请求，通过后续规则将其转发给 Envoy 代理的 Inbound Handler。该规则适用于 Pod 对自身 IP 地址调用的场景。&lt;/li&gt;
&lt;li&gt;对应图示中的步骤：6 到 7。&lt;/li&gt;
&lt;li&gt;详情：如果流量的目的地非 localhost，且数据包是由 1337 UID（即 &lt;code&gt;istio-proxy&lt;/code&gt; 用户，Envoy 代理）发出的，流量将被经过 &lt;code&gt;ISTIO_IN_REDIRECT&lt;/code&gt; 最终转发到 Envoy 的 Inbound Handler。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;规则 3、6&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：&lt;strong&gt;透传&lt;/strong&gt; Pod 内的应用容器的站内流量。适用于在应用容器中发出的对本地 Pod 的流量。&lt;/li&gt;
&lt;li&gt;详情：如果流量不是由 Envoy 用户发出的，那么就跳出该链，返回 &lt;code&gt;OUTPUT&lt;/code&gt; 调用 &lt;code&gt;POSTROUTING&lt;/code&gt;，直达目的地。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;规则 4、7&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：&lt;strong&gt;透传&lt;/strong&gt;  Envoy 代理发出的出站请求。&lt;/li&gt;
&lt;li&gt;对应图示中的步骤：14 到 15。&lt;/li&gt;
&lt;li&gt;详情：如果请求是由 Envoy 代理发出的，则返回 &lt;code&gt;OUTPUT&lt;/code&gt; 继续调用 &lt;code&gt;POSTROUTING&lt;/code&gt; 规则，最终直接访问目的地。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;规则 8&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：&lt;strong&gt;透传&lt;/strong&gt; Pod 内部对 localhost 的请求。&lt;/li&gt;
&lt;li&gt;详情：如果请求的目的地是 localhost，则返回 OUTPUT 调用 &lt;code&gt;POSTROUTING&lt;/code&gt;，直接访问 localhost。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;规则 9&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;目的：所有其他的流量将被转发到 &lt;code&gt;ISTIO_REDIRECT&lt;/code&gt; 后，最终达到 Envoy 代理的 Outbound Handler。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上规则避免了 Envoy 代理到应用程序的路由在 iptables 规则中的死循环，保障了流量可以被正确的路由到 Envoy 代理上，也可以发出真正的出站请求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于 RETURN target&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你可能留意到上述规则中有很多 RETURN target，它的意思是，指定到这条规则时，跳出该规则链，返回 iptables 的调用点（在我们的例子中即 &lt;code&gt;OUTPUT&lt;/code&gt;）后继续执行其余路由规则，在我们的例子中即 &lt;code&gt;POSTROUTING&lt;/code&gt; 规则，把流量发送到任意目的地址，你可以把它直观的理解为&lt;strong&gt;透传&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关于 127.0.0.6 IP 地址&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;127.0.0.6 这个 IP 是 Istio 中默认的 &lt;code&gt;InboundPassthroughClusterIpv4&lt;/code&gt;，在 Istio 的代码中指定。即流量在进入 Envoy 代理后被绑定的 IP 地址，作用是让 Outbound 流量重新发送到  Pod 中的应用容器，即 &lt;strong&gt;Passthought（透传），绕过 Outbound Handler&lt;/strong&gt;。该流量是对 Pod 自身的访问，而不是真正的对外流量。至于为什么选择这个 IP 作为流量透传，请参考 &lt;a href=&#34;https://github.com/istio/istio/issues/29603&#34;&gt;Istio Issue-29603&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;理解-iptables&#34;&gt;理解 iptables&lt;/h3&gt;
&lt;p&gt;为了帮助大家理解以上 iptables 规则的含义，这里特别为大家简单介绍下 iptbles。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;iptables&lt;/code&gt; 是 Linux 内核中的防火墙软件 netfilter 的管理工具，位于用户空间，同时也是 netfilter 的一部分。Netfilter 位于内核空间，不仅有网络地址转换的功能，也具备数据包内容修改、以及数据包过滤等防火墙功能。&lt;/p&gt;
&lt;p&gt;在了解 Init 容器初始化的 iptables 之前，我们先来了解下 iptables 和规则配置。&lt;/p&gt;
&lt;p&gt;下图展示了 iptables 调用链。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;iptables.jpg&#34; alt=&#34;iptables 调用链&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;iptables-中的表&#34;&gt;iptables 中的表&lt;/h3&gt;
&lt;p&gt;Init 容器中使用的的 iptables 版本是 &lt;code&gt;v1.6.0&lt;/code&gt;，共包含 5 张表：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;raw&lt;/code&gt; 用于配置数据包，&lt;code&gt;raw&lt;/code&gt; 中的数据包不会被系统跟踪。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter&lt;/code&gt; 是用于存放所有与防火墙相关操作的默认表。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nat&lt;/code&gt; 用于 &lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation&#34;&gt;网络地址转换&lt;/a&gt;（例如：端口转发）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mangle&lt;/code&gt; 用于对特定数据包的修改（参考&lt;a href=&#34;https://en.wikipedia.org/wiki/Mangled_packet&#34;&gt;损坏数据包&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;security&lt;/code&gt; 用于&lt;a href=&#34;https://wiki.archlinux.org/index.php/Security#Mandatory_access_control&#34;&gt;强制访问控制&lt;/a&gt; 网络规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：在本示例中只用到了 &lt;code&gt;nat&lt;/code&gt; 表。&lt;/p&gt;
&lt;p&gt;不同的表中的具有的链类型如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;规则名称&lt;/th&gt;
&lt;th&gt;raw&lt;/th&gt;
&lt;th&gt;filter&lt;/th&gt;
&lt;th&gt;nat&lt;/th&gt;
&lt;th&gt;mangle&lt;/th&gt;
&lt;th&gt;security&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PREROUTING&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;INPUT&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OUTPUT&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;POSTROUTING&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FORWARD&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;理解-iptables-规则&#34;&gt;理解 iptables 规则&lt;/h3&gt;
&lt;p&gt;查看 &lt;code&gt;istio-proxy&lt;/code&gt; 容器中的默认的 iptables 规则，默认查看的是 filter 表中的规则。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ iptables -L -v
Chain INPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT 350K packets, 63M bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

Chain FORWARD &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; packets, &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

Chain OUTPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT 18M packets, 1916M bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到三个默认的链，分别是 INPUT、FORWARD 和 OUTPUT，每个链中的第一行输出表示链名称（在本例中为INPUT/FORWARD/OUTPUT），后跟默认策略（ACCEPT）。&lt;/p&gt;
&lt;p&gt;下图是 iptables 的建议结构图，流量在经过 INPUT 链之后就进入了上层协议栈，比如&lt;/p&gt;
&lt;p&gt;每条链中都可以添加多条规则，规则是按照顺序从前到后执行的。我们来看下规则的表头定义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;pkts&lt;/strong&gt;：处理过的匹配的报文数量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bytes&lt;/strong&gt;：累计处理的报文大小（字节数）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;target&lt;/strong&gt;：如果报文与规则匹配，指定目标就会被执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;prot&lt;/strong&gt;：协议，例如 &lt;code&gt;tdp&lt;/code&gt;、&lt;code&gt;udp&lt;/code&gt;、&lt;code&gt;icmp&lt;/code&gt; 和 &lt;code&gt;all&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;opt&lt;/strong&gt;：很少使用，这一列用于显示 IP 选项。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;in&lt;/strong&gt;：入站网卡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;out&lt;/strong&gt;：出站网卡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source&lt;/strong&gt;：流量的源 IP 地址或子网，或者是 &lt;code&gt;anywhere&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;destination&lt;/strong&gt;：流量的目的地 IP 地址或子网，或者是 &lt;code&gt;anywhere&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还有一列没有表头，显示在最后，表示规则的选项，作为规则的扩展匹配条件，用来补充前面的几列中的配置。&lt;code&gt;prot&lt;/code&gt;、&lt;code&gt;opt&lt;/code&gt;、&lt;code&gt;in&lt;/code&gt;、&lt;code&gt;out&lt;/code&gt;、&lt;code&gt;source&lt;/code&gt; 和 &lt;code&gt;destination&lt;/code&gt; 和显示在 &lt;code&gt;destination&lt;/code&gt; 后面的没有表头的一列扩展条件共同组成匹配规则。当流量匹配这些规则后就会执行 &lt;code&gt;target&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;target 支持的类型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;target&lt;/code&gt; 类型包括 ACCEPT&lt;code&gt;、REJECT&lt;/code&gt;、&lt;code&gt;DROP&lt;/code&gt;、&lt;code&gt;LOG&lt;/code&gt; 、&lt;code&gt;SNAT&lt;/code&gt;、&lt;code&gt;MASQUERADE&lt;/code&gt;、&lt;code&gt;DNAT&lt;/code&gt;、&lt;code&gt;REDIRECT&lt;/code&gt;、&lt;code&gt;RETURN&lt;/code&gt; 或者跳转到其他规则等。只要执行到某一条链中只有按照顺序有一条规则匹配后就可以确定报文的去向了，除了 &lt;code&gt;RETURN&lt;/code&gt; 类型，类似编程语言中的 &lt;code&gt;return&lt;/code&gt; 语句，返回到它的调用点，继续执行下一条规则。&lt;code&gt;target&lt;/code&gt; 支持的配置详解请参考 &lt;a href=&#34;http://www.zsythink.net/archives/1199&#34;&gt;iptables 详解（1）：iptables 概念&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;从输出结果中可以看到 Init 容器没有在 iptables 的默认链路中创建任何规则，而是创建了新的链路。&lt;/p&gt;
&lt;h2 id=&#34;流量路由过程详解&#34;&gt;流量路由过程详解&lt;/h2&gt;
&lt;p&gt;通过上文，你已经了解了 Istio 是如何在 Pod 中做透明流量劫持的，那么流量被劫持到 Envoy 代理中之后是如何被处理的呢？流量路由分为 Inbound 和 Outbound 两个过程，下面将根据上文中的示例及 sidecar 的配置为读者详细分析此过程。&lt;/p&gt;
&lt;h3 id=&#34;理解-inbound-handler&#34;&gt;理解 Inbound Handler&lt;/h3&gt;
&lt;p&gt;Inbound Handler 的作用是将 iptables 拦截到的 downstream 的流量转发给 Pod 内的应用程序容器。在我们的实例中，假设其中一个 Pod 的名字是 &lt;code&gt;reviews-v1-545db77b95-jkgv2&lt;/code&gt;，运行 &lt;code&gt;istioctl proxy-config listener reviews-v1-545db77b95-jkgv2 --port 15006&lt;/code&gt; 查看该 Pod 中 15006 端口上的监听器情况 ，你将看到下面的输出。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;ADDRESS PORT  MATCH                                                                                           DESTINATION&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Addr: *:15006                                                                                   Non-HTTP/Non-TCP&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: tls; App: istio-http/1.0,istio-http/1.1,istio-h2; Addr: 0.0.0.0/0                        InboundPassthroughClusterIpv4&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: raw_buffer; App: http/1.1,h2c; Addr: 0.0.0.0/0                                           InboundPassthroughClusterIpv4&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: tls; App: TCP TLS; Addr: 0.0.0.0/0                                                       InboundPassthroughClusterIpv4&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: raw_buffer; Addr: 0.0.0.0/0                                                              InboundPassthroughClusterIpv4&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: tls; Addr: 0.0.0.0/0                                                                     InboundPassthroughClusterIpv4&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: tls; App: istio,istio-peer-exchange,istio-http/1.0,istio-http/1.1,istio-h2; Addr: *:9080 Cluster: inbound|9080||&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0 15006 Trans: raw_buffer; Addr: *:9080                                                                 Cluster: inbound|9080||&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面列出了以上输出中各字段的含义：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ADDRESS：下游地址&lt;/li&gt;
&lt;li&gt;PORT：Envoy 监听器监听的端口&lt;/li&gt;
&lt;li&gt;MATCH：请求使用的传输协议或匹配的下游地址&lt;/li&gt;
&lt;li&gt;DESTINATION：路由目的地&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;reviews&lt;/code&gt; Pod 中的 Iptables 将入站流量劫持到 15006 端口上，从上面的输出我们可以看到 Envoy 的 Inbound Handler 在 15006 端口上监听，对目的地为任何 IP 的 9080 端口的请求将路由到 &lt;code&gt;inbound|9080||&lt;/code&gt; Cluster 上。&lt;/p&gt;
&lt;p&gt;从该 Pod 的 Listener 列表的最后两行中可以看到，&lt;code&gt;0.0.0.0:15006/TCP&lt;/code&gt; 的 Listener（其实际名字是 &lt;code&gt;virtualInbound&lt;/code&gt;）监听所有的 Inbound 流量，其中包含了匹配规则，来自任意 IP 的对 &lt;code&gt;9080&lt;/code&gt; 端口的访问流量，将会路由到 &lt;code&gt;inbound|9080||&lt;/code&gt; Cluster，如果你想以 Json 格式查看该 Listener 的详细配置，可以执行 &lt;code&gt;istioctl proxy-config listeners reviews-v1-545db77b95-jkgv2 --port 15006 -o json&lt;/code&gt; 命令，你将获得类似下面的输出。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
    &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;virtualInbound&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;socketAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.0.0.0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;15006&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterChains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
            &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterChainMatch&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;destinationPort&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;9080&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;transportProtocol&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;tls&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;applicationProtocols&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;istio&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;istio-peer-exchange&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;istio-http/1.0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;istio-http/1.1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;istio-h2&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;filters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                    &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;envoy.filters.network.http_connection_manager&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;typedConfig&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;@type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;statPrefix&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound_0.0.0.0_9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;routeConfig&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;virtualHosts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|http|9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;domains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                            &lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
                                        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;routes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                            &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;prefix&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
                                                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;route&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxStreamDuration&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxStreamDuration&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;grpcTimeoutHeaderMax&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;
                                                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;decorator&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;reviews.default.svc.cluster.local:9080/*&amp;#34;&lt;/span&gt;
                                                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;validateClusters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;
                            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
                        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
        &lt;span class=&#34;err&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;listenerFilters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;listenerFiltersTimeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;continueOnListenerFiltersTimeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;trafficDirection&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;INBOUND&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;既然 Inbound Handler 的流量中将来自任意地址的对该 Pod &lt;code&gt;9080&lt;/code&gt; 端口的流量路由到 &lt;code&gt;inbound|9080||&lt;/code&gt; Cluster，那么我们运行 &lt;code&gt;istioctl pc cluster reviews-v1-545db77b95-jkgv2 --port 9080 --direction inbound -o json&lt;/code&gt; 查看下该 Cluster 配置，你将获得类似下面的输出。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ORIGINAL_DST&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;connectTimeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;10s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;lbPolicy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;CLUSTER_PROVIDED&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;circuitBreakers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;thresholds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxConnections&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxPendingRequests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxRequests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxRetries&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;trackRemaining&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;cleanupInterval&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;60s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;upstreamBindConfig&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;sourceAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;127.0.0.6&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterMetadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;istio&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;services&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;host&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;reviews.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;reviews&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;namespace&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;
                        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看其中的 &lt;code&gt;TYPE&lt;/code&gt; 为 &lt;code&gt;ORIGINAL_DST&lt;/code&gt;，将流量发送到原始目标地址（Pod IP），因为原始目标地址即当前 Pod，你还应该注意到 &lt;code&gt;upstreamBindConfig.sourceAddress.address&lt;/code&gt; 的值被改写为了 &lt;code&gt;127.0.0.6&lt;/code&gt;，而且对于 Pod 内流量是通过 &lt;code&gt;lo&lt;/code&gt; 网卡发送的，这刚好呼应了上文中的 iptables &lt;code&gt;ISTIO_OUTPUT&lt;/code&gt; 链中的第一条规则，根据该规则，流量将被透传到 Pod 内的应用容器。&lt;/p&gt;
&lt;h3 id=&#34;理解-outbound-handler&#34;&gt;理解 Outbound Handler&lt;/h3&gt;
&lt;p&gt;在本示例中 &lt;code&gt;reviews&lt;/code&gt; 会向 &lt;code&gt;ratings&lt;/code&gt; 服务发送 HTTP 请求，请求的地址是：&lt;code&gt;http://ratings.default.svc.cluster.local:9080/&lt;/code&gt;，Outbound Handler 的作用是将 iptables 拦截到的本地应用程序向外发出的流量，经由 Envoy 代理路由到上游。&lt;/p&gt;
&lt;p&gt;Envoy 监听在 15001 端口上监听所有 Outbound 流量，Outbound Handler 处理，然后经过 &lt;code&gt;virtualOutbound&lt;/code&gt; Listener、&lt;code&gt;0.0.0.0_9080&lt;/code&gt; Listener，然后通过 Route 9080 找到上游的 cluster，进而通过 EDS 找到 Endpoint 执行路由动作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;ratings.default.svc.cluster.local:9080&lt;/code&gt; 路由&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;运行 &lt;code&gt;istioctl proxy-config routes reviews-v1-545db77b95-jkgv2 --name 9080 -o json&lt;/code&gt; 查看 route 配置，因为 sidecar 会根据 HTTP header 中的 domains 来匹配 VirtualHost，所以下面只列举了 &lt;code&gt;ratings.default.svc.cluster.local:9080&lt;/code&gt; 这一个 VirtualHost。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;virtualHosts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
       &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
           &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
           &lt;span class=&#34;nt&#34;&gt;&amp;#34;domains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;10.8.8.106&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
               &lt;span class=&#34;s2&#34;&gt;&amp;#34;10.8.8.106:9080&amp;#34;&lt;/span&gt;
           &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
           &lt;span class=&#34;nt&#34;&gt;&amp;#34;routes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
               &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                   &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;nt&#34;&gt;&amp;#34;match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                       &lt;span class=&#34;nt&#34;&gt;&amp;#34;prefix&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
                   &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;nt&#34;&gt;&amp;#34;route&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                       &lt;span class=&#34;nt&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;outbound|9080||ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                       &lt;span class=&#34;nt&#34;&gt;&amp;#34;timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                       &lt;span class=&#34;nt&#34;&gt;&amp;#34;retryPolicy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;retryOn&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;numRetries&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;retryHostPredicate&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                               &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                   &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;envoy.retry_host_predicates.previous_hosts&amp;#34;&lt;/span&gt;
                               &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                           &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;hostSelectionRetryMaxAttempts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;5&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;retriableStatusCodes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                               &lt;span class=&#34;mi&#34;&gt;503&lt;/span&gt;
                           &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                       &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                       &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxStreamDuration&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxStreamDuration&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                           &lt;span class=&#34;nt&#34;&gt;&amp;#34;grpcTimeoutHeaderMax&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0s&amp;#34;&lt;/span&gt;
                       &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                   &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                   &lt;span class=&#34;nt&#34;&gt;&amp;#34;decorator&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                       &lt;span class=&#34;nt&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local:9080/*&amp;#34;&lt;/span&gt;
                   &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
               &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
           &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
           &lt;span class=&#34;nt&#34;&gt;&amp;#34;includeRequestAttemptCount&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;
       &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
       &lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;省&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;略&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;部&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;分&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;内&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;容&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;/&lt;/span&gt;
     &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
     &lt;span class=&#34;nt&#34;&gt;&amp;#34;validateClusters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从该 Virtual Host 配置中可以看到将流量路由到&lt;code&gt;outbound|9080||ratings.default.svc.cluster.local&lt;/code&gt; 集群。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;outbound|9080||ratings.default.svc.cluster.local&lt;/code&gt; 集群的端点&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;运行 &lt;code&gt;istioctl proxy-config endpoint reviews-v1-545db77b95-jkgv2 --port 9080 -o json --cluster &amp;quot;outbound|9080||ratings.default.svc.cluster.local&amp;quot;&lt;/code&gt; 查看集群的 Endpoint 配置，结果如下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;outbound|9080||ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;addedViaApi&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;hostStatuses&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;socketAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;10.4.1.12&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;9080&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;stats&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;cx_connect_fail&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;cx_total&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rq_error&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rq_success&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rq_timeout&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rq_total&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;GAUGE&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;cx_active&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;type&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;GAUGE&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;rq_active&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;healthStatus&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;edsHealthStatus&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;HEALTHY&amp;#34;&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;weight&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;locality&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;region&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;us-west2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;zone&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;us-west2-a&amp;#34;&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;circuitBreakers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;thresholds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxConnections&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxPendingRequests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxRequests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxRetries&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4294967295&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;priority&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;HIGH&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxConnections&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxPendingRequests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxRequests&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxRetries&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;observabilityName&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;outbound|9080||ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到端点的地址是 &lt;code&gt;10.4.1.12&lt;/code&gt;。实际上，Endpoint 可以是一个或多个，sidecar 将根据一定规则选择适当的 Endpoint 来路由。至此 &lt;code&gt;review&lt;/code&gt; Pod找到了它上游服务 &lt;code&gt;rating&lt;/code&gt; 的 Endpoint。&lt;/p&gt;
&lt;h2 id=&#34;小结&#34;&gt;小结&lt;/h2&gt;
&lt;p&gt;本文使用了 Istio 官方提供的 bookinfo 示例，按图索骥得带领读者了解了 sidecar 注入、iptables 透明流量劫持及 sidecar 中流量路由背后的实现细节。Sidecar 模式和流量透明劫持是 Istio 服务网格的特色和基础功能，理解该功能的背后过程及实现细节，将有助于大家理解 Service Mesh 的原理和 &lt;a href=&#34;https://www.servicemesher.com/istio-handbook/&#34;&gt;Istio Handbook&lt;/a&gt; 后面章节中的内容，因此希望读者可以在自己的环境中从头来试验一遍以加深理解。&lt;/p&gt;
&lt;p&gt;使用 iptables 做流量劫持只是 service mesh 的数据平面中做流量劫持的方式之一，还有更多的流量劫持方案，下面引用自 &lt;a href=&#34;https://mosn.io/docs/concept/traffic-hijack/&#34;&gt;云原生网络代理 MOSN 官网中给出的流量劫持&lt;/a&gt;部分的描述。&lt;/p&gt;
&lt;h3 id=&#34;使用-iptables-做流量劫持时存在的问题&#34;&gt;使用 iptables 做流量劫持时存在的问题&lt;/h3&gt;
&lt;p&gt;目前 Istio 使用 iptables 实现透明劫持，主要存在以下三个问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;需要借助于 conntrack 模块实现连接跟踪，在连接数较多的情况下，会造成较大的消耗，同时可能会造成 track 表满的情况，为了避免这个问题，业内有关闭 conntrack 的做法。&lt;/li&gt;
&lt;li&gt;iptables 属于常用模块，全局生效，不能显式的禁止相关联的修改，可管控性比较差。&lt;/li&gt;
&lt;li&gt;iptables 重定向流量本质上是通过 loopback 交换数据，outbond 流量将两次穿越协议栈，在大并发场景下会损失转发性能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述几个问题并非在所有场景中都存在，比方说某些场景下，连接数并不多，且 NAT 表未被使用到的情况下，iptables 是一个满足要求的简单方案。为了适配更加广泛的场景，透明劫持需要解决上述三个问题。&lt;/p&gt;
&lt;h3 id=&#34;透明劫持方案优化&#34;&gt;透明劫持方案优化&lt;/h3&gt;
&lt;p&gt;为了优化 Istio 中的透明流量劫持的性能，业界提出了以下方案。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用 Merbridge 开源项目利用 eBPF 劫持流量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/merbridge/merbridge&#34;&gt;Merbridge&lt;/a&gt; 是由 DaoCloud 在 2022 年初开源的的一款利用 eBPF 加速 Istio 服务网格的插件。使用 Merbridge 可以在一定程度上优化数据平面的网络性能。&lt;/p&gt;
&lt;p&gt;Merbridge 利用 eBPF 的 &lt;code&gt;sockops&lt;/code&gt; 和 &lt;code&gt;redir&lt;/code&gt; 能力，可以直接将数据包从 inbound socket 传输到 outbound socket。eBPF 提供了 &lt;code&gt;bpf_msg_redirect_hash&lt;/code&gt; 函数可以直接转发应用程序的数据包。&lt;/p&gt;
&lt;p&gt;详见 &lt;a href=&#34;https://jimmysong.io/istio-handbook/ecosystem/merbridge.html&#34;&gt;Istio 服务网格 —— 云原生应用网络构建指南&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用 tproxy 处理 inbound 流量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;tproxy 可以用于 inbound 流量的重定向，且无需改变报文中的目的 IP/端口，不需要执行连接跟踪，不会出现 conntrack 模块创建大量连接的问题。受限于内核版本，tproxy 应用于 outbound 存在一定缺陷。目前 Istio 支持通过 tproxy 处理 inbound 流量。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用 hook connect 处理 outbound 流量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;为了适配更多应用场景，outbound 方向通过 hook connect 来实现，实现原理如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;hook-connect.jpg&#34; alt=&#34;hook-connect 原理示意图&#34;&gt;&lt;/p&gt;
&lt;p&gt;无论采用哪种透明劫持方案，均需要解决获取真实目的 IP/端口的问题，使用 iptables 方案通过 getsockopt 方式获取，tproxy 可以直接读取目的地址，通过修改调用接口，hook connect 方案读取方式类似于 tproxy。&lt;/p&gt;
&lt;p&gt;实现透明劫持后，在内核版本满足要求（4.16以上）的前提下，通过 sockmap 可以缩短报文穿越路径，进而改善 outbound 方向的转发性能。&lt;/p&gt;
&lt;h2 id=&#34;更新说明&#34;&gt;更新说明&lt;/h2&gt;
&lt;p&gt;下面是本文的几次更新说明。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2020 年 4 月 27 日，第一版，基于 Istio 1.5&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文的第一版，基于 Istio 1.5 创作，在此之前，我曾写过基于 Istio 1.1 版本的&lt;a href=&#34;https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34;&gt;理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持&lt;/a&gt;，为了更细致的理解 Istio 中透明流量劫持的全过程，专门创作本文。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2022 年  1 月 17 日，第二版，基于 Istio 1.11&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本文第一版发布后，在社区里获得了比较大的反响，收到了很多读者的评论和留言。基于这些评论，我也发现了第一版中的很多错误，在加上 Istio 版本发布频繁，在近两年的时间内，Istio 已经作出了众多更新，其中不乏重大更新。因此笔者撰写了本文的第二版，修改了之前版本中的纰漏并根据时下 Istio 的最新版本更新了本文。&lt;/p&gt;
&lt;p&gt;Istio 1.11 与 Istio 1.1 中的 sidecar 注入和流量劫持环节最大的变化是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;iptables 改用命令行工具，不再使用 shell 脚本。&lt;/li&gt;
&lt;li&gt;sidecar inbound 和 outbound 分别指定了端口，而之前是使用同一个端口（15001）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;2022 年 4 月 24，第三版，基于 Istio  1.13&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这个版本的文章主要是根据当时 Istio 的最新版本更新了文章的部分内容，并重新排版，增加更新说明。&lt;/p&gt;
&lt;p&gt;Istio 1.13 相比 Istio 1.11 的变化是 &lt;code&gt;istioctl proxy-config&lt;/code&gt; 命令的输出有了较大变化。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/ops/diagnostic-tools/proxy-cmd/&#34;&gt;Debugging Envoy and Istiod - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/zh/blog/2019/data-plane-setup/&#34;&gt;揭开 Istio Sidecar 注入模型的神秘面纱 - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mosn.io/docs/concept/traffic-hijack/&#34;&gt;MOSN 作为 Sidecar 使用时的流量劫持方案 - mosn.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 1.13 有哪些值得注意的更新？</title>
      <link>https://jimmysong.io/blog/what-is-new-in-istio-1-13/</link>
      <pubDate>Tue, 22 Mar 2022 17:16:50 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/what-is-new-in-istio-1-13/</guid>
      <description>
        
        
        &lt;p&gt;2022 年 2 月 Istio 发布 &lt;a href=&#34;https://istio.io/latest/news/releases/1.13.x/announcing-1.13/&#34;&gt;1.13.0&lt;/a&gt; 和 &lt;a href=&#34;https://istio.io/latest/news/releases/1.13.x/announcing-1.13.1/&#34;&gt;1.13.1&lt;/a&gt;，这篇博客将想你介绍这两个版本中有哪些值得注意的新特性。&lt;/p&gt;
&lt;p&gt;Istio 1.13 是 2022 年的第一个版本，不出意外的话，Istio 团队会依然按照每个季度的频率发布新版本。总体来看，这个版本中的新特性包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对 Kubernetes 更新版本的支持&lt;/li&gt;
&lt;li&gt;引入了一个新的 API——ProxyConfig，用来配置 sidecar proxy&lt;/li&gt;
&lt;li&gt;完善了 Telemetry API&lt;/li&gt;
&lt;li&gt;支持多网络网关的基于主机名的负载均衡器&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;对-kubernetes-版本的支持&#34;&gt;对 Kubernetes 版本的支持&lt;/h2&gt;
&lt;p&gt;我经常看到有人在社区里问 Istio 支持哪些 Kubernetes 版本，其实 Istio 官网中已经明确列出了支持的 Kubernetes 版本，你可以在&lt;a href=&#34;https://istio.io/latest/docs/releases/supported-releases/#support-status-of-istio-releases&#34;&gt;这里&lt;/a&gt;看到，Istio 1.13 支持 Kubernetes 1.20、1.21、1.22 和 1.23 版本，并在 Kubernetes 1.16、1.17、1.18、1.19 中测试过，但并得到官方支持。&lt;/p&gt;
&lt;p&gt;在配置 Istio 的时候，其实还有很多检查列表，我将他们都记录到了 &lt;a href=&#34;https://github.com/tetratelabs/istio-cheatsheet&#34;&gt;Istio cheatsheet&lt;/a&gt; 中，这个项目中整理了很多关于配置 Istio、资源对象的使用、常见问题处理等相关的 cheatsheet，将于近期上线，敬请期待。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio-cheatsheet.jpg&#34; alt=&#34;Istio cheatsheet 页面截图&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;引入新的-proxyconfig-api&#34;&gt;引入新的 ProxyConfig API&lt;/h2&gt;
&lt;p&gt;在 Istio 1.13 版本之前，如果你想自定义 sidecar proxy 的配置，有两种方式。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;方式一：MeshConfig&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 &lt;code&gt;MeshConfig&lt;/code&gt;，在 Mesh 级别使用 IstioOperator 来修改。例如，使用下面的配置来修改 &lt;code&gt;istiod&lt;/code&gt; 的默认发现端口。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install.istio.io/v1alpha1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;IstioOperator&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;meshConfig&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;	  &lt;/span&gt;defaultConfig&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;discoveryAddress&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istiod&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;方式二：Pod 中的 annotation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;你也可以在 Pod 级别使用 annotation 的方式自定义配置，例如在 Pod 中增加下面的配置同样可以修改工作负载所有连接的 &lt;code&gt;istiod&lt;/code&gt; 的默认端口。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;anannotations&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;proxy.istio.io/config&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;|
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;   &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;discoveryAddress: istiod:15012&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当你同时使用了以上两种方式配置了 sidecar，&lt;code&gt;annotations&lt;/code&gt; 中设置的字段将完全覆盖 &lt;code&gt;MeshConfig&lt;/code&gt; 默认的字段。关于 &lt;code&gt;ProxyConfig&lt;/code&gt; 的所有配置项请参考 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/istio.mesh.v1alpha1/#ProxyConfig&#34;&gt;Istio 文档&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;新方式：&lt;code&gt;ProxyConfig&lt;/code&gt; API&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;但是在 1.13 版本中，新增了一个顶级自定义资源 &lt;code&gt;ProxyConfig&lt;/code&gt;，你可以一站式的在一个地方来自定义 sidecar proxy 的配置，你可以通过指定 namespace、使用 &lt;code&gt;selector&lt;/code&gt; 来选择工作负载的范围，就像其他 CRD 一样。目前 Istio 对该 API 的支持有限，关于 &lt;code&gt;ProxyConfig&lt;/code&gt; API 的详细信息请参考 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/proxy-config/&#34;&gt;Istio 文档&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;但是不论你用哪种方式自定义 sidecar proxy 的配置，该配置都无法动态生效，需要重启工作负载才可以生效。例如，对于上面的配置，因为你修改了 &lt;code&gt;istiod&lt;/code&gt; 的默认端口，mesh 中的所有工作负载都需要重启才可以与 control plane 建立连接。&lt;/p&gt;
&lt;h2 id=&#34;telemetry-api&#34;&gt;Telemetry API&lt;/h2&gt;
&lt;p&gt;在 Istio 服务网格中，很多扩展和自定义的配置都是通过 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/istio.mesh.v1alpha1/#MeshConfig-ExtensionProvider&#34;&gt;&lt;code&gt;MeshConfig&lt;/code&gt;&lt;/a&gt; 的方式来完成的。可观察性的三种类型 Metric、遥测和日志，分别可以对接不同的提供者，&lt;a href=&#34;https://istio.io/latest/docs/tasks/observability/telemetry/&#34;&gt;Telemetry API&lt;/a&gt; 可以让你有一个一站式的灵活的配置它们。与 ProxyConfig API 类似，Telemetry API 也遵循着工作负载选择器&amp;gt;本地命名空间&amp;gt;根配置命名空间的配置层级关系。该 API 是在 Istio 1.11 中引入，在该版本中得到了进一步完善，增加了 &lt;code&gt;OpenTelemetry&lt;/code&gt; 日志、过滤访问日志以及自定义跟踪服务名称的支持。详见 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/telemetry/&#34;&gt;Telemetry 配置&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;自动解析多网络网关主机名&#34;&gt;自动解析多网络网关主机名&lt;/h2&gt;
&lt;p&gt;2021 年 9 月，Istio 社区里&lt;a href=&#34;https://szabo.jp/2021/09/22/multicluster-istio-on-eks/&#34;&gt;有人报告&lt;/a&gt;，在 AWS EKS 中运行多集群多主的 Istio 时，出现 EKS 的负载均衡器无法解析的问题。对于多集群多网络的网格，跨集群边界的服务负载，需要通过专用的东西向网关，以间接的方式通讯。你可以按照 &lt;a href=&#34;https://istio.io/latest/docs/setup/install/multicluster/multi-primary_multi-network/&#34;&gt;Istio 官网上的说明&lt;/a&gt;配置多网络的 primary-remote 集群，Istio 会根据主机名自动解析负载均衡器的 IP 地址。&lt;/p&gt;
&lt;h2 id=&#34;istio-1131-修复重大安全漏洞&#34;&gt;Istio 1.13.1 修复重大安全漏洞&lt;/h2&gt;
&lt;p&gt;当月，Istio 1.13.1 发布，修复了一个已知的&lt;a href=&#34;https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=CVE-2022-23635&#34;&gt;重大漏洞&lt;/a&gt;，该漏洞可能导致未经认证的控制平面拒绝服务攻击。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;primary-remote-cluster-mesh.jpg&#34; alt=&#34;跨网络的主从集群&#34;&gt;&lt;/p&gt;
&lt;p&gt;在安装多网络的 &lt;a href=&#34;https://istio.io/latest/docs/setup/install/multicluster/multi-primary_multi-network/&#34;&gt;primary-remote&lt;/a&gt; 模式的 Istio 网格时，为了让 remote Kubernetes 集群能够访问控制平面，需要在 primary 集群中安装一个东西向的 Gateway，将控制平面 &lt;code&gt;istiod&lt;/code&gt; 的 15012 端口暴露到互联网。攻击者可能向该端口发送特制的消息，导致控制平面崩溃。如果你设置了防火墙，只允许来自部分 IP 的流量访问该端口，将可以缩小该问题的影响范围。建议你立即升级到 Istio 1.13.1 来彻底解决该问题。&lt;/p&gt;
&lt;h2 id=&#34;istiocon-2022&#34;&gt;IstioCon 2022&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;istiocon-2022.jpg&#34; alt=&#34;IstioCon 2022&#34;&gt;&lt;/p&gt;
&lt;p&gt;最后，作为上一届和本届 IstioCon 的筹备委员会成员之一，我号召大家报名参加 4 月 25 日在线上举行的 &lt;a href=&#34;https://events.istio.io/istiocon-2022/&#34;&gt;IstioCon 2022&lt;/a&gt;！IstioCon 2022是一个以行业为重点的活动，一个连接贡献者和用户的平台，讨论Istio在不同架构设置中的用途，有哪些限制，以及项目的下一步发展方向。主要的焦点将是在最终用户公司，因为我们期待着分享多样化的案例研究，展示如何在生产中使用Istio。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>网易开源 Istio 扩展项目 Slime 简介——基于 Istio 的智能服务网格管理器</title>
      <link>https://jimmysong.io/blog/slime-intro/</link>
      <pubDate>Wed, 24 Nov 2021 14:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/slime-intro/</guid>
      <description>
        
        
        &lt;p&gt;最近我在研究 Istio 生态中的开源项目，&lt;a href=&#34;https://github.com/slime-io/slime/&#34;&gt;Slime&lt;/a&gt; 这个项目开源与 2021 年初，是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器。Slime 基于 Kubernetes Operator 实现，可作为 Istio 的 CRD 管理器，无须对 Istio 做任何定制化改造，就可以定义动态的服务治理策略，从而达到自动便捷使用 Istio 和 Envoy 高阶功能的目的。&lt;/p&gt;
&lt;h2 id=&#34;slime-试图解决的问题&#34;&gt;Slime 试图解决的问题&lt;/h2&gt;
&lt;p&gt;Slime 项目的诞生主要为了解决以下问题：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;网格内所有服务配置全量下到所有 Sidecar Proxy，导致其消耗大量资源使得应用性能变差的问题&lt;/li&gt;
&lt;li&gt;如何在 Istio 中实现高阶扩展的问题：比如扩展 HTTP 插件；根据服务的资源使用率做到自适应限流&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Slime 解决以上问题的答案是构建 Istio 的控制平面，具体做法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建可拔插控制器&lt;/li&gt;
&lt;li&gt;数据平面监控&lt;/li&gt;
&lt;li&gt;CRD 转换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过以上方式 Slime 可以实现&lt;strong&gt;配置懒加载&lt;/strong&gt;和&lt;strong&gt;插件管理器&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&#34;slime-架构&#34;&gt;Slime 架构&lt;/h2&gt;
&lt;p&gt;Slime 内部分为三大模块，其架构图如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;slime-internal-arch.jpg&#34; alt=&#34;Slime 内部架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;Slime 内部三大组件为：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;slime-boot&lt;/code&gt;：在 Kubernetes 上部署 Slime 模块的 operator。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slime-controller&lt;/code&gt;：Slime 的核心组件，监听 Slime CRD 并将其转换为Istio CRD。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;slime-metric&lt;/code&gt;：用于获取服务 metrics 信息的组件，&lt;code&gt;slime-controller&lt;/code&gt; 会根据其获取的信息动态调整服务治理规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;目前 Slime 内置了三个控制器子模块：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;配置懒加载（按需加载）&lt;/strong&gt;：用户无须手动配置 &lt;code&gt;SidecarScope&lt;/code&gt;，Istio 可以按需加载服务配置和服务发现信息；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HTTP 插件管理&lt;/strong&gt;：使用新的 CRD——&lt;code&gt;pluginmanager/envoyplugin&lt;/code&gt; 包装了可读性，摒弃了可维护性较差的 &lt;code&gt;envoyfilter&lt;/code&gt;，使得插件扩展更为便捷；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;自适应限流&lt;/strong&gt;：结合监控信息自动调整限流策略；&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;什么是 SidecarScope？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SidecarScope 是在 Istio 1.1 版本中引入的，它并不是一个直接面向用户的配置项，而是 Sidecar 资源的包装器，具体来说就是 &lt;a href=&#34;../config/networking/sidecar.md&#34;&gt;Sidecar 资源&lt;/a&gt;中的 &lt;code&gt;egress&lt;/code&gt; 选项。通过该配置可以减少 Istio 向 Sidecar 下发的数据量，例如只向某个命名空间中的某些服务下发某些 hosts 的访问配置，从而提高应用提高性能。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;使用-slime-作为-istio-的控制平面&#34;&gt;使用 Slime 作为 Istio 的控制平面&lt;/h2&gt;
&lt;p&gt;为了解决这些问题，Slime 在 Istio 之上构建了更高层次的抽象，相当于为 Istio 构建了一层管理平面，其工作流程图如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;slime-flow-chart.jpg&#34; alt=&#34;Slime 工作流程图&#34;&gt;&lt;/p&gt;
&lt;p&gt;具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Slime Operator 根据管理员的配置在 Kubernetes 中完成 Slime 组件的初始化；&lt;/li&gt;
&lt;li&gt;开发者创建符合 Slime CRD 规范的配置并应用到 Kubernetes 集群中；&lt;/li&gt;
&lt;li&gt;Slime 查询 Prometheus 中保存的相关服务的监控数据，结合 Slime CRD 中自适应部分的配置，将 Slime CRD 转换为 Istio CRD，同时将其推送到 Global Proxy 中；&lt;/li&gt;
&lt;li&gt;Istio 监听 Istio CRD 的创建；&lt;/li&gt;
&lt;li&gt;Istio 将 Sidecar Proxy 的配置信息推送到数据平面相应的 Sidecar Proxy 中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上只是一个对 Slime 工作流程的一个笼统的介绍，更多详细信息请参考 &lt;a href=&#34;https://github.com/slime-io/slime/&#34;&gt;Slime GitHub&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;配置懒加载&#34;&gt;配置懒加载&lt;/h2&gt;
&lt;p&gt;为了解决数据平面中 Sidecar Proxy 资源消耗过大及网络延迟问题，Slime 使用了配置懒加载（按需加载 Sidecar 配置）的方案。该方案的核心思想是向每个 Sidecar Proxy 中只下发其所 Pod 中服务所需的配置，而不是将网格中的所有服务信息全量下发。所以 Slime 需要获取每个服务的调用关系这样才能得到其所需的 Sidecar Proxy 配置。&lt;/p&gt;
&lt;p&gt;Slime 实现 Sidecar Proxy 配置懒加载的方法是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;让数据平面中的所有服务的首次调用都通过一个 Global Proxy，该 Proxy 可以记录所有服务的调用和依赖信息，根据该依赖信息更新 Istio 中 Sidecar 资源的配置；&lt;/li&gt;
&lt;li&gt;当某个服务的调用链被 VirtualService 中的路由信息重新定义时， Global Proxy 原有记录就失效了，需要一个新的数据结构来维护该服务的调用关系。Slime 创建了名为 &lt;code&gt;ServiceFence&lt;/code&gt;  的 CRD 来维护服务调用关系以解决服务信息缺失问题。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;使用-global-proxy-初始化服务调用拓扑&#34;&gt;使用 Global Proxy 初始化服务调用拓扑&lt;/h3&gt;
&lt;p&gt;Slime 在数据平面中部署 Global Proxy（也叫做 Global Sidecar，但其与应用的 Pod 不是一对一的关系，笔者更倾向于称其为 Global Proxy），该代理同样使用 Envoy 构建，在每个需要启动配置懒加载的命名空间中部署一个或在整个网格中只部署一个，所有缺失服务发现信息的调用（你也可以手动配置服务调用关系），都会被兜底路由劫持到 Global Proxy，经过其首次转发后，Slime 便可感知到被调用方的信息，然后根据其对应服务的 VirtualService，找到服务名和真实后端的映射关系，将两者的都加入 SidecarScope，以后该服务的调用就不再需要经过 Global Proxy 了。&lt;/p&gt;
&lt;h3 id=&#34;使用-servicefence-维护服务调用拓扑&#34;&gt;使用 ServiceFence 维护服务调用拓扑&lt;/h3&gt;
&lt;p&gt;在使用 Global Proxy 初始化服务调用拓扑后，一旦服务调用链有变动的话怎么办？对此 Slime 创建了 ServiceFence 的 CRD。使用 ServiceFence 可以维护服务名和后端服务的映射关系。Slime 根据其对应服务的 VirtualService，找到 Kubernetes 服务名和真实后端（host）的映射关系，将两者的都加入 Sidecar 的配置中。ServiceFence 管理生成的 SidecarScope 的生命周期，自动清理长时间不用的调用关系，从而避免上述问题。&lt;/p&gt;
&lt;h3 id=&#34;如何开启配置懒加载&#34;&gt;如何开启配置懒加载&lt;/h3&gt;
&lt;p&gt;配置懒加载功能对于终端用户是透明的，只需要 Kubernetes  Service 上打上 &lt;code&gt;istio.dependency.servicefence/status:&amp;quot;true&amp;quot;&lt;/code&gt; 的标签，表明该服务需要开启配置懒加载，剩下的事情交给 Slime Operator 来完成即可。&lt;/p&gt;
&lt;h2 id=&#34;http-插件管理&#34;&gt;HTTP 插件管理&lt;/h2&gt;
&lt;p&gt;Istio 中的插件扩展只能通过 EnvoyFilter 来实现，因为它是 xDS 层面的配置，管理和维护这样的配置需要耗费大量的精力，也极容易出错。因此，Slime 在 EnvoyFilter 的基础上做了一层面向插件的抽象。&lt;/p&gt;
&lt;p&gt;Slime 共有两个 CRD 用于 HTTP 插件管理，分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;PluginManager&lt;/strong&gt;：配置为哪些负载开启哪些插件，插件的配置顺序即为执行顺序；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EnvoyPlugin&lt;/strong&gt;：EnvoyPlugin 不关心每个插件的具体配置，具体配置会被放在 EnvoyFilter 资源的 &lt;code&gt;patch.typed_config&lt;/code&gt; 结构中透传），EnvoyPlugin 的核心思想是将插件配置在需要的维度中做聚合，从而限定插件的生鲜范围。这样做一方面更加贴合插件使用者的习惯，另一方面也降低了上层配置的冗余，&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;关于 Slime 中插件管理的详细使用方式请见 &lt;a href=&#34;https://github.com/slime-io/slime/blob/master/doc/zh/plugin_manager.md&#34;&gt;Slime GitHub&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;自适应限流&#34;&gt;自适应限流&lt;/h2&gt;
&lt;p&gt;Envoy 内置的限流组件功能单一，只能以实例维度配置限流值，无法做到根据应用负载的自适应限流。Slime 通过与 Prometheus metric server 对接，实时的获取监控情况，来动态配置限流值。&lt;/p&gt;
&lt;p&gt;Slime 自适应限流的流程图如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;slime-smart-limiter.jpg&#34; alt=&#34;Slime 的自适应限流流程图&#34;&gt;&lt;/p&gt;
&lt;p&gt;Slime 的自适应限流的流程分为两部分，一部分为 SmartLimiter 到 EnvoyFilter 的转换，另一部分为获取监控数据。目前 Slime 支持从 Kubernetes Metric Server 获取服务的CPU、内存、副本数等数据。Slime 还对外提供了一套监控数据接口（Metric Discovery Server），通过 MDS，可以将自定义的监控指标同步给限流组件。&lt;/p&gt;
&lt;p&gt;Slime 创建的 CRD &lt;code&gt;SmartLimiter&lt;/code&gt; 用于配置自适应限流。其的配置是接近自然语义，例如希望在 CPU 超过 80% 时触发服务 A 的访问限制，限额为 30QPS，对应的SmartLimiter 定义如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;microservice.netease.com/v1alpha1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;SmartLimiter&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;a&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;namespace&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;default&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;descriptors&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;action&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;fill_interval&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;seconds&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;quota&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;30/{pod}&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 30为该服务的额度，将其均分给每个 pod，加入有 3 个 pod，则每个 pod 的限流为 10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;condition&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{cpu}&amp;gt;0.8&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 根据监控项{cpu}的值自动填充该模板&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;p&gt;Slime 开源于 2021 年初，本文发稿时该项目仍处于初级阶段，本文大量参考了杨笛航在云原生社区中的分享 &lt;a href=&#34;https://cloudnative.to/blog/netease-slime/&#34;&gt;Slime：让 Istio 服务网格变得更加高效与智能&lt;/a&gt; 及 Slime 的 &lt;a href=&#34;https://github.com/slime-io/slime&#34;&gt;GitHub&lt;/a&gt;。感兴趣的读者可以关注下这个项目的 GitHub，进一步了解它。&lt;/p&gt;
&lt;p&gt;另外欢迎关注服务网格和 Istio 的朋友加入&lt;a href=&#34;https://cloudnative.to/sig-istio/&#34;&gt;云原生社区 Istio SIG&lt;/a&gt;，一起参与讨论和交流。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/netease-slime/&#34;&gt;Slime：让 Istio 服务网格变得更加高效与智能 - cloudnative.to&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/slime-io/slime/blob/master/README_ZH.md&#34;&gt;Slime GitHub 文档 - github.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/sidecar/&#34;&gt;Sidecar - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>服务网格现状之我见</title>
      <link>https://jimmysong.io/blog/service-mesh-insight/</link>
      <pubDate>Tue, 23 Nov 2021 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/service-mesh-insight/</guid>
      <description>
        
        
        &lt;p&gt;本文根据 2021 年 11 月 22 日晚我应极客邦邀请在「极客时间训练营」的直播分享《云原生漫谈：聊聊 Service Mesh 的现状》整理而成。&lt;/p&gt;
&lt;p&gt;本来极客时间是想邀请我分享云原生的，但我觉得那个范围太大，在一次分享中只能泛泛而谈，无法聚焦到一个具体的点，因此我想还是先聚焦在服务网格这一个专题上吧。云原生社区最近倒是在做一个&lt;a href=&#34;https://mp.weixin.qq.com/s/FWUkc1HJobhZgb26pG73Cg&#34;&gt;云原生系列的分享&lt;/a&gt;，大家可以关注下。&lt;/p&gt;
&lt;p&gt;这是我今天分享的大纲：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;第一探讨下服务网格跟云原生的关系&lt;/li&gt;
&lt;li&gt;第二是给大家陈述下我观察到的目前社区里关于服务网格有哪些争论&lt;/li&gt;
&lt;li&gt;第三是给大家介绍几个服务网格的相关的开源项目&lt;/li&gt;
&lt;li&gt;最后是畅想下服务网格未来的发展&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;服务网格与云原生的关系&#34;&gt;服务网格与云原生的关系&lt;/h2&gt;
&lt;p&gt;首先我们将探讨下服务网格与云原生的关系。&lt;/p&gt;
&lt;h3 id=&#34;服务网格容器编排大战后的产物&#34;&gt;服务网格——容器编排大战后的产物&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp7oq2980j313w0eqq56.jpg&#34; alt=&#34;Docker Swarm vs Kubernetes vs Mesos&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果你关注云原生领域足够早的话，应该还会对 2015 到 2017 年间的容器编排大战记忆犹新。关于服务网格的起源已经无需多言。2017 年 Kubernetes 获得了容器大战的胜利，微服务的理念已经深入人心，容器化的趋势可谓势不可挡。Kubernetes 架构趋向成熟，慢慢变得无聊，以 Linkerd、Istio 为代表的服务网格技术进入了 CNCF 定义的云原生关键技术视野中。&lt;/p&gt;
&lt;p&gt;服务网格将微服务中的通用的功能给下沉到了基础设施层，让开发者可以更加专注于业务逻辑，从而加快服务交付，这与整个云原生的理念的一致的。你不需要再在应用中集成笨重的 SDK，为不同语言开发和维护 SDK，应用部署完后，使用服务网格进行 Day 2 操作即可。&lt;/p&gt;
&lt;p&gt;Kubernetes 设计之初就是按照云原生的理念设计的，云原生中有个重要概念就是微服务的架构设计，当将单体应用拆分微服务后， 随着服务数量的增多，如何微服务进行管理以保证服务的 SLA 呢？为了从架构层面上解决这个问题，解放程序员的创造性，避免繁琐的服务发现、监控、分布式追踪等事务，服务网格应运而生。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp7qas2vtj30v70u0whb.jpg&#34; alt=&#34;微服务关注点&#34;&gt;&lt;/p&gt;
&lt;p&gt;来源：&lt;em&gt;&lt;a href=&#34;https://developers.redhat.com/blog/2016/12/09/spring-cloud-for-microservices-compared-to-kubernetes&#34;&gt;https://developers.redhat.com/blog/2016/12/09/spring-cloud-for-microservices-compared-to-kubernetes&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;服务网格被誉为下一代微服务，从右面这幅图里我们可以看到微服务的一些关注点，这些关注点很多与 Kubernetes 的功能是重合的，既然这些作为平台级的功能 Kubernetes 已经提供了，为什么还要使用服务网格呢？其实 Kubernetes 关注的还是应用的生命周期，它管理的对象是资源和部署，对于服务的管控力度很小。而服务网格正好弥补了这个缺陷。服务网格可以连接、控制、观察和保护微服务。&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;Kubernetes vs xDS vs Istio&lt;/h3&gt;
&lt;p&gt;这幅图展示的是 Kubernetes 和 Istio 的分层架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gxdhnnh4lxj31820p0gps.jpg&#34; alt=&#34;Kubernetes vs Service mesh&#34;&gt;&lt;/p&gt;
&lt;p&gt;从图中我们可以看到 kube-proxy 的设置是全局的，无法对每个服务进行细粒度的控制，Kubernetes 可以做的只有拓扑感知路由、将流量就近路由，为 Pod 设置进出站的网络策略。&lt;/p&gt;
&lt;p&gt;而服务网格通过 sidecar proxy 的方式将 Kubernetes 中的流量控制从服务层中抽离出来，为每个 Pod 中注入代理，并通过一个控制平面来操控这些分布式代理。这样可以实现更大的弹性。&lt;/p&gt;
&lt;p&gt;Kube-proxy 实现了一个 Kubernetes 服务的多个 pod 实例之间的流量负载均衡，但如何对这些服务之间的流量进行精细化控制–比如将流量按百分比划分给不同的应用版本（这些应用版本都是同一个服务的一部分，但在不同的部署上），或者做金丝雀发布（灰度发布）和蓝绿发布？&lt;/p&gt;
&lt;p&gt;Kubernetes 社区给出了一个使用 Deployment 做金丝雀发布的方法，本质上是通过修改 pod 的标签来给部署的服务分配不同的 pod。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-arch.jpg&#34; alt=&#34;Envoy 架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;目前在中国最流行的服务网格开源实现是 Istio，也有很多公司对 Istio 进行了二次开发，比如蚂蚁、网易、腾讯等，其实 Istio 是在 Envoy 的基础上开发的，从它开源的第一天起就默认使用了 Envoy 作为它的分布式代理。Envoy 开创性的创造了 xDS 协议，用于分布式网关配置，大大简化了大规模分布式网络的配置。2019 年蚂蚁开源的 MOSN 同样支持了 xDS。Envoy 还是 CNCF 中最早毕业的项目之一，经过大规模的生产应用考验。可以说 Istio 的诞生已经有了很好的基础。&lt;/p&gt;
&lt;p&gt;下表是 Kubernetes、xDS、Istio 三者之间的资源抽象对比。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;xDS&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Istio 服务网格&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;VirtualService&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;DestinationRule&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;EnvoyFilter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ingress&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;kube-proxy 组件、xDS 和 Istio 对流量管理的抽象后，现在我们仅从流量管理的角度来看看这三个组件 / 协议的比较。请注意，三者并不完全等同。Kubernetes 更加注重的是应用层面的流量管理，xDS 是更加抽象的协议层面的配置下发，而 Istio 是服务层面的配置。&lt;/p&gt;
&lt;h3 id=&#34;服务网格云原生网络基础设施&#34;&gt;服务网格——云原生网络基础设施&lt;/h3&gt;
&lt;p&gt;在列举过以上 Kubernetes 和服务网格的对比后，我们可以看出服务网格在云原生应用架构中的地位。那就是构建一个云原生网络基础设施，具体来说就是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量管理：控制服务间的流量和API调用流，使调用更可靠，增强不同环境下的网络鲁棒性。&lt;/li&gt;
&lt;li&gt;可观测性：了解服务之间的依赖关系和它们之间的性质和流量，提供快速识别定位问题的能力。&lt;/li&gt;
&lt;li&gt;策略实施：通过配置网格而不是以改变代码的方式来控制服务之间的访问策略。&lt;/li&gt;
&lt;li&gt;服务识别与安全：提供在网格里的服务可识别性和安全性保护。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;社区里关于-istio-和服务网格的争论&#34;&gt;社区里关于 Istio 和服务网格的争论&lt;/h2&gt;
&lt;p&gt;然而构建基础设施，可谓牵一发而动全身。理想很丰满，现实很骨感。关于服务网格和 Istio，在社区中也不乏争论。我们来看看有这些争论主要有哪些。&lt;/p&gt;
&lt;p&gt;这里列举了我在社区中观察到的关于 Istio 和服务网格最常见的几个问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;有人在生产使用 Istio 吗？&lt;/li&gt;
&lt;li&gt;为 pod 注入 sidecar 后带来的大量资源消耗，影响应用性能？&lt;/li&gt;
&lt;li&gt;Istio 支持的协议有限，不易扩展？&lt;/li&gt;
&lt;li&gt;Istio 太过复杂，老的服务迁移成本太高，业界经验太少，学习曲线陡峭？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;第一个问题，也是很多人刚加入社区和了解这门技术的时候，问的第一个问题，那是有人在生产使用 Istio 吗？&lt;/p&gt;
&lt;p&gt;随着对 Istio 研究的深入，很多人就会抛出第二个问题，为 pod 注入 sidecar 后带来的大量资源消耗，会影响应用性能吗？&lt;/p&gt;
&lt;p&gt;如果能问到第三个问题，说明对 Istio 有比较强的需求了，大多是使用了自定义的 RPC，对 Istio 的协议扩展有需求。
最后一个问题是抱怨 Istio 的概念太过复杂，也没有一个清晰的迁移路径可以使用，学习曲线太过陡峭。&lt;/p&gt;
&lt;p&gt;下面我将一一回答这些问题。&lt;/p&gt;
&lt;h3 id=&#34;istio-架构稳定生产可用生态渐起&#34;&gt;Istio 架构稳定，生产可用，生态渐起&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp7wvt1g8j32yo0nk78g.jpg&#34; alt=&#34;Istio 发布时间表&#34;&gt;&lt;/p&gt;
&lt;p&gt;首先我们来看下 Istio 的发布时间表，1.12 版本在上周刚刚发布，这里列举了从它开源到 1.8 版本发布的时间表。2018 年可以说是服务网格爆发之年，Tetrate 也在这一年成立。自1.5 版本起 Istio 正式确立了当前的架构。Istio 社区也也举办了丰富多彩的活动，2021 年 3 月首届 IstioCon 召开，7 月 Istio Meetup China 在北京举行，2022 年 1 月，Service Mesh Summit 2022 也将在上海举行。&lt;/p&gt;
&lt;p&gt;Istio 有着庞大的社区以及&lt;a href=&#34;https://istio.io/latest/about/case-studies/&#34;&gt;供应商和用户群体&lt;/a&gt;。目前主流公有云全都支持了 Istio 服务网格，如阿里云、华为云、腾讯云、网易云等，Istio 的官网上也列举了几十个社区用户，云原生社区 Istio SIG 还陆续举办了八场 &lt;a href=&#34;https://cloudnative.to/sig-istio/big-talk/overview.html&#34;&gt;Istio 大咖说&lt;/a&gt;，百度、腾讯、网易、小红书、小电科技都来分享过他们的 Istio 实践。&lt;/p&gt;
&lt;p&gt;还有很多企业基于 Istio 做了二次开发或者适配或者为其开发插件，可以说是 Istio 架构已稳定，生产可用，生态正在萌芽中。&lt;/p&gt;
&lt;h3 id=&#34;服务网格对应用性能的影响&#34;&gt;服务网格对应用性能的影响&lt;/h3&gt;
&lt;p&gt;服务网格为了做到对应用程序透明，默认采用了 iptables 流量劫持的方式，当服务数量大的时候会有大量的 iptables 规则，影响网络性能，你可以使用 &lt;a href=&#34;https://cloudnative.to/blog/how-ebpf-streamlines-the-service-mesh/&#34;&gt;eBPF&lt;/a&gt; 这样的技术来提高应用性能，但是该技术对操作系统内核的版本要求比较高，很少有企业能够达到。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp81fy0vqj31lq0nq41q.jpg&#34; alt=&#34;Istio 中的智能 DNS 代理&#34;&gt;&lt;/p&gt;
&lt;p&gt;来源：&lt;a href=&#34;https://cloudnative.to/blog/istio-dns-proxy/&#34;&gt;https://cloudnative.to/blog/istio-dns-proxy/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;还有一种方式，也是&lt;a href=&#34;https://cloudnative.to/sig-istio/big-talk/ep08.html&#34;&gt;小红书使用的方式&lt;/a&gt;，那就是利用 Istio 1.8 中引入的智能 DNS 代理功能。首先使用 ServiceEntry 定义服务，让所有服务属于一个 VIP 范围，再利用 Istio 的智能 DNS 代理功能，让sidecar只拦截 VIP 网段的流量，这样可以减少 iptables 规则，从而提高性能。如果想深入了解这个做法的细节，大家可以去浏览 &lt;a href=&#34;https://www.bilibili.com/video/BV12b4y187ae/&#34;&gt;Istio 大咖说第八期的分享视频&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Istio 在初期是将整个网格内的所有服务的路由信息全量下发到所有的 proxy sidecar 中，会导致 sidecar 占用大量资源，后来 Istio 引入了 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/sidecar/&#34;&gt;Sidecar 资源&lt;/a&gt;来精细化控制需要下发的代理配置范围，另外还有企业自己开发了配置懒加载功能，例如腾讯云开源的 &lt;a href=&#34;https://github.com/aeraki-framework/aeraki&#34;&gt;Aeraki&lt;/a&gt;、网易开源的 &lt;a href=&#34;https://github.com/slime-io/slime&#34;&gt;Slime&lt;/a&gt; 都可以实现配置懒加载。我们会在 Istio 开源生态中介绍这两个开源项目。&lt;/p&gt;
&lt;p&gt;最后是一个涉及到 Sidecar proxy 运维的问题，如何在保证流量不断的情况下，升级所有 Envoy 代理，这个阿里开源的 &lt;a href=&#34;https://github.com/openkruise/kruise&#34;&gt;OpenKruise&lt;/a&gt; 中的 &lt;a href=&#34;https://xie.infoq.cn/article/23ae6d3f0d0260b4797a708a0&#34;&gt;SidecarSet&lt;/a&gt; 资源已经给出了解决方案。&lt;/p&gt;
&lt;p&gt;另外 Sidecar 的引入带来的资源消耗以及网络延迟也是在合理的范围内，大家可以参考 Istio 官方博客上的 &lt;a href=&#34;https://istio.io/latest/zh/blog/2019/performance-best-practices/&#34;&gt;Service Mesh 基准性能测试&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;扩展-istio-服务网格&#34;&gt;扩展 Istio 服务网格&lt;/h3&gt;
&lt;p&gt;下一个问题是关于扩展 Istio 服务网格的。目前官方社区给出的方案是使用 WebAssembly，目前这种扩展方式在国内用的还比较少，而且性能也堪忧。我观察到的大部分解决方案都是自定义 CRD，基于 Istio 构建服务网格管理平面。&lt;/p&gt;
&lt;p&gt;另外，让 Istio 支持异构环境，适用于一切工作负载，如虚拟机、容器，这个对于终端用户来说也有很强的需求，因为这可以让用户很方便的从传统负载迁移应用到服务网格中。最后是多集群、多网格的混合云流量管理，这个属于比较高阶的需求了。&lt;/p&gt;
&lt;h3 id=&#34;陡峭的学习曲线&#34;&gt;陡峭的学习曲线&lt;/h3&gt;
&lt;p&gt;以下列举的是 Istio 学习资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/zh/&#34;&gt;Istio 官网中文文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://events.istio.io/istiocon-2021/&#34;&gt;IstioCon 2021&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Istio Meetup China&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tetratelabs/istio-weekly&#34;&gt;Istio 大咖说/Istio Weekly&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/sig-istio/&#34;&gt;云原生社区 Istio SIG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://academy.tetrate.io/courses/istio-fundamentals-zh&#34;&gt;Istio 基础教程（中文）&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://academy.tetrate.io/courses/certified-istio-administrator&#34;&gt;Certified Istio Administrator&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Istio 开源至今已有 4 年时间，2018 年时我和敖小剑一起创建了 ServiceMesher 社区，当时组织过 9 次 Service Mesh Meetup，同其他服务网格爱好者一起翻译了 Istio 的官方文档。我还在今年初参与了 IstioCon 2021 的筹办及首届 Istio Meetup China。可以说是亲眼目睹了国内服务网格技术的应用和发展，在这期间也写过和翻译过大量的文章，加入 Tetrate 后，我还参与发布了 Istio 基础教程，免费提供给大家学习。同时 Tetrate 也推出了认证 Istio 管理员考试，用于培养更多行业人才。&lt;/p&gt;
&lt;p&gt;云原生社区组织了 Istio SIG，还推出了 Istio 大咖说直播栏目，为大家分享 Istio 服务网格实践经验。&lt;/p&gt;
&lt;p&gt;下图是 &lt;a href=&#34;https://academy.tetrate.io/courses/istio-fundamentals-zh&#34;&gt;Istio 基础教程&lt;/a&gt;的首页截图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp8rr51ikj31ah0u043i.jpg&#34; alt=&#34;Istio 基础教程（Tetrate 出品）&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果你是刚开始接触服务网格和 Istio，可以先从 Istio 基础教程开始学起。这个线上系列课程是图文并茂的中文课程，可以免费参加。&lt;/p&gt;
&lt;p&gt;好了，我们再来了解下服务网格的社区项目。&lt;/p&gt;
&lt;h2 id=&#34;istio-开源生态&#34;&gt;Istio 开源生态&lt;/h2&gt;
&lt;p&gt;下表中罗列的是基于 Istio 的开源项目。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;项目名称&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;开源时间&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;类别&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;描述&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;主导公司&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Star 数量&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;与 Istio 的关系&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/envoyproxy/envoy&#34;&gt;Envoy&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2016年 9 月&lt;/td&gt;
&lt;td&gt;网络代理&lt;/td&gt;
&lt;td&gt;云原生高性能边缘/中间服务代理&lt;/td&gt;
&lt;td&gt;Lyft&lt;/td&gt;
&lt;td&gt;18300&lt;/td&gt;
&lt;td&gt;默认的数据平面&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/istio/istio/&#34;&gt;Istio&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2017 年 5 月&lt;/td&gt;
&lt;td&gt;服务网格&lt;/td&gt;
&lt;td&gt;连接、保护、控制和观察服务。&lt;/td&gt;
&lt;td&gt;Google&lt;/td&gt;
&lt;td&gt;28400&lt;/td&gt;
&lt;td&gt;控制平面&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/emissary-ingress/emissary&#34;&gt;Emissary Gateway&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2018 年 2 月&lt;/td&gt;
&lt;td&gt;网关&lt;/td&gt;
&lt;td&gt;用于微服务的 Kubernetes 原生 API 网关，基于 Envoy 构建&lt;/td&gt;
&lt;td&gt;Ambassador&lt;/td&gt;
&lt;td&gt;3500&lt;/td&gt;
&lt;td&gt;可连接 Istio&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/apache/apisix&#34;&gt;APISIX&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2019 年 6 月&lt;/td&gt;
&lt;td&gt;网关&lt;/td&gt;
&lt;td&gt;云原生 API 网关&lt;/td&gt;
&lt;td&gt;API7&lt;/td&gt;
&lt;td&gt;7400&lt;/td&gt;
&lt;td&gt;可作为 Istio 的数据平面运行也可以单独作为网关&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/mosn/mosn&#34;&gt;MOSN&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2019 年 12 月&lt;/td&gt;
&lt;td&gt;代理&lt;/td&gt;
&lt;td&gt;云原生边缘网关及代理&lt;/td&gt;
&lt;td&gt;蚂蚁&lt;/td&gt;
&lt;td&gt;3400&lt;/td&gt;
&lt;td&gt;可作为 Istio 数据平面&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/slime-io/slime&#34;&gt;Slime&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2021 年 1月&lt;/td&gt;
&lt;td&gt;扩展&lt;/td&gt;
&lt;td&gt;基于 Istio 的智能服务网格管理器&lt;/td&gt;
&lt;td&gt;网易&lt;/td&gt;
&lt;td&gt;204&lt;/td&gt;
&lt;td&gt;为 Istio 增加一个管理平面&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/tetratelabs/getmesh&#34;&gt;GetMesh&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2021 年 2 月&lt;/td&gt;
&lt;td&gt;工具&lt;/td&gt;
&lt;td&gt;Istio 集成和命令行管理工具&lt;/td&gt;
&lt;td&gt;Tetrate&lt;/td&gt;
&lt;td&gt;91&lt;/td&gt;
&lt;td&gt;实用工具，可用于 Istio 多版本管理&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/aeraki-framework/aeraki&#34;&gt;Aeraki&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2021 年 3 月&lt;/td&gt;
&lt;td&gt;扩展&lt;/td&gt;
&lt;td&gt;管理 Istio 的任何七层负载&lt;/td&gt;
&lt;td&gt;腾讯&lt;/td&gt;
&lt;td&gt;280&lt;/td&gt;
&lt;td&gt;扩展多协议支持&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/mosn/layotto/&#34;&gt;Layotto&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2021 年 6 月&lt;/td&gt;
&lt;td&gt;运行时&lt;/td&gt;
&lt;td&gt;云原生应用运行时&lt;/td&gt;
&lt;td&gt;蚂蚁&lt;/td&gt;
&lt;td&gt;325&lt;/td&gt;
&lt;td&gt;可以作为 Istio 的数据平面&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;a href=&#34;https://github.com/hango-io/hango-gateway&#34;&gt;Hango Gateway&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;2021 年 8 月&lt;/td&gt;
&lt;td&gt;网关&lt;/td&gt;
&lt;td&gt;基于 Envoy 和 Istio 构建的 API 网关&lt;/td&gt;
&lt;td&gt;网易&lt;/td&gt;
&lt;td&gt;187&lt;/td&gt;
&lt;td&gt;可与 Istio 集成&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;从 2017 年 5 月 Istio 开源至今也有 4 年多了，虽然该项目在 GitHub 上已经有很高的关注度，并发布了 10 几个版本，但其开源生态还在萌芽期。这张表列举了 Istio 生态中的开源项目，统计截止到 2021 年 11 月 11 日，表格按照开源时间排序。这些项目在 Istio 服务网格之上增强了网关、扩展和实用工具等。我将挑选其中 2 个来着重分享下。&lt;/p&gt;
&lt;h3 id=&#34;slime基于-istio-的智能服务网格管理器&#34;&gt;Slime：基于 Istio 的智能服务网格管理器&lt;/h3&gt;
&lt;p&gt;Slime 是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器。Slime 基于 Kubernetes Operator 实现，可作为 Istio 的 CRD 管理器，无缝对接 Istio，无须做任何定制化改造，定义动态的服务治理策略，从而达到自动便捷使用 Istio 和 Envoy 高阶功能的目的。&lt;/p&gt;
&lt;p&gt;Slime 试图解决以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 Istio 中如何实现高阶扩展的问题，比如扩展 HTTP 插件，限流功能比较单薄，无法根据服务的资源使用率做到自适应限流&lt;/li&gt;
&lt;li&gt;解决 Sidecar 配置全量下发消耗大量资源导致应用性能变差的问题&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Slime 解决以上问题的答案是构建 Istio 的管理平面，其核心思路是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;构建可拔插控制器&lt;/li&gt;
&lt;li&gt;数据平面监控&lt;/li&gt;
&lt;li&gt;CRD 转换&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图是 Istio 作为 Istio 管理平面的流程图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp8td6cowj31i90u0aei.jpg&#34; alt=&#34;Slime 如何作为 Istio 的控制平面&#34;&gt;&lt;/p&gt;
&lt;p&gt;Slime 管理 Istio 的具体步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Slime Operator 根据管理员的配置在 Kubernetes 中完成 Slime 组件的初始化；&lt;/li&gt;
&lt;li&gt;开发者创建符合 Slime CRD 规范的配置并应用到 Kubernetes 集群中；&lt;/li&gt;
&lt;li&gt;Slime 查询 Prometheus 中保存的相关服务的监控数据，结合 Slime CRD 中自适应部分的配置，将 Slime CRD 转换为 Istio CRD，同时将其推送到 Global Proxy 中；&lt;/li&gt;
&lt;li&gt;Istio 监听 Istio CRD 的创建；&lt;/li&gt;
&lt;li&gt;Istio 将 Sidecar Proxy 的配置信息推送到数据平面相应的 Sidecar Proxy 中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示的 Slime 的内部架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp8uzsj2wj31ac0oktb4.jpg&#34; alt=&#34;Slime 内部架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;作为 Istio 的管理平面，可以将 Slime 的核心看做是 Istio 的一个 Operator。&lt;/p&gt;
&lt;p&gt;Slime 内部分为三大组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;slime-boot&lt;/strong&gt;：在 Kubernetes 上部署 Slime 模块的 operator。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;slime-controller&lt;/strong&gt;：Slime 的核心组件，监听 Slime CRD 并将其转换为Istio CRD。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;slime-metric&lt;/strong&gt;：用于获取服务 metrics 信息的组件，slime-controller 会根据其获取的信息动态调整服务治理规则。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图展示的是 Slime 自适应限流的架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp8xghoh2j311k0u0dim.jpg&#34; alt=&#34;Slime 自适应限流架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;Envoy 内置的限流组件功能单一，只能以实例维度配置限流值，无法做到根据应用负载的自适应限流。Slime 通过与 Prometheus metric server 对接，实时的获取监控情况，来动态配置限流值。&lt;/p&gt;
&lt;p&gt;Slime 的自适应限流的流程分为两部分，一部分为 SmartLimiter 到 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/envoy-filter/&#34;&gt;EnvoyFilter&lt;/a&gt; 的转换，另一部分为获取监控数据。目前 Slime 支持从 Kubernetes Metric Server 获取服务的CPU、内存、副本数等数据。Slime 还对外提供了一套监控数据接口（Metric Discovery Server），通过 MDS，可以将自定义的监控指标同步给限流组件。&lt;/p&gt;
&lt;p&gt;Slime 创建的 CRD SmartLimiter 用于配置自适应限流。其的配置是接近自然语义，例如希望在 CPU 超过 80% 时触发服务 A 的访问限制，限额为 30QPS，对应的 SmartLimiter 定义如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;microservice.netease.com/v1alpha1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;SmartLimiter&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;a&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;namespace&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;default&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;descriptors&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;action&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;fill_interval&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;seconds&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;quota&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;30/{pod}&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 30 为该服务的额度，将其均分给每个 pod，加入有 3 个 pod，则每个 pod 的限流为 10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;condition&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{cpu}&amp;gt;0.8&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 根据监控项{cpu}的值自动填充该模板&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;aeraki在-istio-中管理任何七层协议&#34;&gt;Aeraki：在 Istio 中管理任何七层协议&lt;/h3&gt;
&lt;p&gt;Aeraki 是腾讯云在 2021 年 3 月开源的一个服务网格领域的项目。Aeraki 提供了一个端到端的云原生服务网格协议扩展解决方案，以一种非侵入的方式为 Istio 提供了强大的第三方协议扩展能力，支持在 Istio 中对 Dubbo、Thrift、Redis，以及对私有协议进行流量管理。Aeraki 的架构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp8ytw57sj31f40u0785.png&#34; alt=&#34;Aeraki 架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;来源：&lt;a href=&#34;https://istio.io/latest/blog/2021/aeraki/&#34;&gt;https://istio.io/latest/blog/2021/aeraki/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;从 Aeraki 架构图中可以看到，Aeraki 协议扩展解决方案包含了两个组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aeraki：Aeraki 作为一个 Istio 增强组件运行在控制面，通过自定义 CRD 向运维提供了用户友好的流量规则配置。Aeraki 将这些流量规则配置翻译为 Envoy 配置，通过 Istio 下发到数据面的 sidecar 代理上。Aeraki 还作为一个 RDS 服务器为数据面的 MetaProtocol Proxy 提供动态路由。Aeraki 提供的 RDS 和 Envoy 的 RDS 有所不同，Envoy RDS 主要为 HTTP 协议提供动态路由，而 Aeraki RDS 旨在为所有基于 MetaProtocol 框架开发的七层协议提供动态路由能力。&lt;/li&gt;
&lt;li&gt;MetaProtocol Proxy：基于 Envoy 实现的一个通用七层协议代理。依托 Envoy 成熟的基础库，MetaProtocol Proxy 是在 Envoy 代码基础上的扩展。它为七层协议统一实现了服务发现、负载均衡、RDS 动态路由、流量镜像、故障注入、本地/全局限流等基础能力，大大降低了在 Envoy 上开发第三方协议的难度，只需要实现编解码的接口，就可以基于 MetaProtocol 快速开发一个第三方协议插件。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果没有使用 MetaProtocol Proxy，要让 Envoy 识别一个七层协议，则需要编写一个完整的 TCP filter，这个 filter 需要实现路由、限流、遥测等能力，需要投入大量的人力。对于大部分的七层协议来说，需要的流量管理能力是类似的，因此没有必要在每个七层协议的 filter 实现中重复这部分工作。Aeraki 项目采用了一个 MetaProtocol Proxy 来统一实现这些能力，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;metaprotocol-proxy.png&#34; alt=&#34;MetaProtocol Proxy 架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;基于 MetaProtocol Proxy，只需要实现编解码接口部分的代码就可以编写一个新的七层协议 Envoy Filter。除此之外，无需添加一行代码，Aeraki 就可以在控制面提供该七层协议的配置下发和 RDS 动态路由配置。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;metaprotocol-proxy-codec.png&#34; alt=&#34;采用 MetaProtocol 编写 Envoy Filter 的对比&#34;&gt;&lt;/p&gt;
&lt;p&gt;Aeraki + MetaProtocol 套件降低了在 Istio 中管理第三方协议的难度，将 Istio 扩展成为一个支持所有协议的全栈服务网格。目前 Aeraki 项目已经基于 MetaProtocol 实现了 Dubbo 和 Thrift 协议。相对 Envoy 自带的 Dubbo 和 Thrift Filter，基于 MetaProtocol 的 Dubbo 和 Thrift 实现功能更为强大，提供了 RDS 动态路由，可以在不中断存量链接的情况下对流量进行高级的路由管理，并且提供了非常灵活的 Metadata 路由机制，理论上可以采用协议数据包中携带的任意字段进行路由。QQ 音乐和央视频 APP 等业务也正在基于 Aeraki 和 MetaProtocol 进行开发，以将一些私有协议纳入到服务网格中进行管理。&lt;/p&gt;
&lt;p&gt;除此之外，&lt;a href=&#34;https://github.com/aeraki-framework&#34;&gt;Aeraki Framework&lt;/a&gt; 中还提供了 xDS 配置下发优化的 lazyXDS 插件、Consul、etcd、Zookeeper 等各种第三方服务注册表对接适配，Istio 运维实战电子书等工具，旨在解决 Istio 在落地中遇到的各种实际问题，加速服务网格的成熟和产品化。&lt;/p&gt;
&lt;h2 id=&#34;服务网格的未来发展&#34;&gt;服务网格的未来发展&lt;/h2&gt;
&lt;p&gt;最后我想讲一下对于服务网格未来发展的一些看法。&lt;/p&gt;
&lt;h3 id=&#34;让-istio-适用于一切环境和一切工作负载&#34;&gt;让 Istio 适用于一切环境和一切工作负载&lt;/h3&gt;
&lt;p&gt;我们看到了网易、腾讯主要是通过构建 Operator 来扩展 Istio，然而这种扩展对于多集群管理来说并不够用。我们知道我们目前的基础设施很多是在向云原生化或者是容器化转型，那么就存在一个容器、虚拟机等共存的环境。这就是异构环境，这些不同环境的流量如何统一管理呢？其实使用 Istio 是可以做到的。同样是要在 Istio 之上构建一个管理平面，并增加一个抽象层，增加适用于集群管理的 CRD，比如集群流量配置、集群策略配置等。另外还要在每个集群中部署一个 Gateway，统一连接到一个边缘代理，让所有的集群互联。这也是 Tetrate Service Bridge 的产品理念。&lt;/p&gt;
&lt;p&gt;下图展示的 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt; 架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;tsb.png&#34; alt=&#34;image-20211123181346493&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;api-网关与服务网格的融合&#34;&gt;API 网关与服务网格的融合&lt;/h3&gt;
&lt;p&gt;下图展示了使用 Istio Gateway、Kubernetes Ingress、API Gateway 及 NodePort/LB 暴露 Istio mesh 中服务的四种方式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gwp935mcd0j31200u0n10.jpg&#34; alt=&#34;访问 Istio 网格中服务的几种方式&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中阴影表示的是 Istio mesh，mesh 中的的流量属于集群内部（东西向）流量，而客户端访问 Kubernetes 集群内服务的流量属于外部（南北向）流量。不过因为 Ingress、Gateway 也是部署在 Kubernetes 集群内的，这些节点访问集群内其他服务的流量就难以归属了。&lt;/p&gt;
&lt;p&gt;在 Istio mesh 中你可以使用多种 Kubernetes Ingress Controller 来充当入口网关，当然你还可以直接使用 Istio 内置的 Istio 网关，对于策略控制、流量管理和用量监控可以直接通过 Istio 网关来完成，这样做的好处是通过 Istio 的控制平面来直接管理网关，而不需要再借助其他工具。但是对于 API 声明周期管理、复杂的计费、协议转换和认证等功能，传统的 API 网关可能更适合你。所以，你可以根据自己的需求来选择，也可以组合使用。&lt;/p&gt;
&lt;p&gt;下表中列出了 Istio Mesh 中暴露服务的四种方式。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;方式&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;控制器&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;功能&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NodePort/LoadBalancer&lt;/td&gt;
&lt;td&gt;Kubernetes&lt;/td&gt;
&lt;td&gt;负载均衡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kubernetes Ingress&lt;/td&gt;
&lt;td&gt;Ingress Controller&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、流量路由&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Istio Gateway&lt;/td&gt;
&lt;td&gt;Istio&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、高级流量路由、其他 Istio 的高级功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;API 网关&lt;/td&gt;
&lt;td&gt;API Gateway&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、流量路由、API 生命周期管理、权限认证、数据聚合、账单和速率限制&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;目前有些传统的反向代理也在向 Service Mesh 方向发展，如 Nginx 构建了 Nginx Service Mesh，Traefik 构建了 Traefik Mesh。还有的 API 网关产品也向 Service Mesh 方向挺进，比如 Kong 发展出了 Kuma。在未来，我们会看到更多 API 网关、反向代理和服务网格的融合产品出现。&lt;/p&gt;
&lt;h3 id=&#34;你是否真的需要服务网格&#34;&gt;你是否真的需要服务网格？&lt;/h3&gt;
&lt;p&gt;在使用服务网格前，请考虑以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你的团队多少人里投入服务网格开发？使用 Kubernetes、Istio 的经验？&lt;/li&gt;
&lt;li&gt;你有多少微服务？这些微服务使用什么语言？&lt;/li&gt;
&lt;li&gt;你的服务都运行在哪些平台上？&lt;/li&gt;
&lt;li&gt;你的应用已经容器化并使用 Kubernetes 管理了吗？&lt;/li&gt;
&lt;li&gt;你的服务有多少是部署在虚拟机、有多少是部署到 Kubernetes 集群上，比例如何？&lt;/li&gt;
&lt;li&gt;你的团队有制定转移到云原生架构的计划吗？&lt;/li&gt;
&lt;li&gt;你想使用 Istio 的什么功能？Istio 的稳定性是否能够满足你的需求？&lt;/li&gt;
&lt;li&gt;你是否可以忍受 Istio 带来的性能损耗？&lt;/li&gt;
&lt;li&gt;你选择自建或者采购？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;最后总结一下今天的分享：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;从容器编排争霸到服务网格，我们可以看到云原生乃至整个云计算就是标准之争。&lt;/li&gt;
&lt;li&gt;服务网格的目标是成为云原生的网络基础设施，任重而道远。&lt;/li&gt;
&lt;li&gt;服务网格只是云原生庞大技术栈中的一环，不要一叶障目，技术的发展是永无止境的。&lt;/li&gt;
&lt;li&gt;Istio 架构已经稳定，生产可用，生态正处于萌芽中。&lt;/li&gt;
&lt;li&gt;对于终端用户来说适合自己的才是最好的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;本人才疏学浅，因为时间的原因，很多内容没有深入展开和探讨，最后欢迎大家加入&lt;a href=&#34;https://cloudnative.to/sig-istio/&#34;&gt;云原生社区 Istio SIG&lt;/a&gt; 一起交流学习 Istio 和服务网格技术。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>如何理解 Istio Ingress， 它与 API Gateway 有什么区别？</title>
      <link>https://jimmysong.io/blog/istio-servicemesh-api-gateway/</link>
      <pubDate>Fri, 06 Aug 2021 10:22:00 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-servicemesh-api-gateway/</guid>
      <description>
        
        
        &lt;p&gt;API 网关作为客户端访问后端的入口，已经存在很长时间了，它主要是用来管理”南北向“的流量；近几年服务网格开始流行，它主要是管理系统内部，即“东西向”流量，而像 Istio 这样的服务网格还内置了网关，从而将系统内外部的流量纳入了统一管控。这经常给初次接触 Istio 的人带来困惑——服务网格与 API 网关之间是什么关系？是不是使用了 Istio 就可以替代了 API 网关？Istio 的 API 网关是如何运作的？有哪些方式暴露 Istio mesh 中的服务？这篇文章给为你解答。&lt;/p&gt;
&lt;h2 id=&#34;主要观点&#34;&gt;主要观点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;服务网格诞生的初衷是为了解决分布式应用的内部流量的管理问题，而在此之前 API 网关已存在很久了。&lt;/li&gt;
&lt;li&gt;虽然 Istio 中内置了Gateway，但是你仍可以使用自定义的 Ingress Controller 来代理外部流量。&lt;/li&gt;
&lt;li&gt;API 网关和服务网格正朝着融合的方向发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;如何暴露-istio-mesh-中的服务&#34;&gt;如何暴露 Istio mesh 中的服务？&lt;/h2&gt;
&lt;p&gt;下图展示了使用 Istio Gateway、Kubernetes Ingress、API Gateway 及 NodePort/LB 暴露 Istio mesh 中服务的四种方式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;api-gateway-istio-service-mesh.jpg&#34; alt=&#34;暴露 Kubernetes 中服务的几种方式&#34;&gt;&lt;/p&gt;
&lt;p&gt;其中阴影表示的是 Istio mesh，mesh 中的的流量属于集群内部（东西向）流量，而客户端访问 Kubernetes 集群内服务的流量属于外部（南北向）流量。不过因为 Ingress、Gateway 也是部署在 Kubernetes 集群内的，这些节点访问集群内其他服务的流量就难以归属了。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;控制器&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NodePort/LoadBalancer&lt;/td&gt;
&lt;td&gt;Kubernetes&lt;/td&gt;
&lt;td&gt;负载均衡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kubernetes Ingress&lt;/td&gt;
&lt;td&gt;Ingress Controller&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、流量路由&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Istio Gateway&lt;/td&gt;
&lt;td&gt;Istio&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、高级流量路由、其他 Istio 的高级功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;API 网关&lt;/td&gt;
&lt;td&gt;API Gateway&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、流量路由、API 生命周期管理、权限认证、数据聚合、账单和速率限制&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;由于 NodePort/LoadBalancer 是 Kubernetes 内置的基本的暴露服务的方式，本文就不讨论这种方式了。下文将对其他三种方式分别作出说明。&lt;/p&gt;
&lt;h2 id=&#34;使用-kubernetes-ingress-暴露服务&#34;&gt;使用 Kubernetes Ingress 暴露服务&lt;/h2&gt;
&lt;p&gt;我们都知道 Kubernetes 集群的客户端是无法直接访问 Pod 的 IP 地址的，因为 Pod 是处于 Kubernetes 内置的一个网络平面中。我们可以将 Kubernetes 内的服务使用 NodePort 或者 LoadBlancer 的方式暴露到集群以外。同时为了支持虚拟主机、隐藏和节省 IP 地址，可以使用 &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt; 来暴露 Kubernetes 中的服务。Kubernetes Ingress 原理如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;kubernetes-ingress.jpg&#34; alt=&#34;使用 Kubernetes Ingress 暴露服务&#34;&gt;&lt;/p&gt;
&lt;p&gt;简单的说，Ingress 就是从 Kubernetes 集群外访问集群的入口，将用户的 URL 请求转发到不同的服务上。Ingress 相当于 Nginx、Apache 等负载均衡方向代理服务器，其中还包括规则定义，即 URL 的路由信息，路由信息得的刷新由 &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-controllers&#34;&gt;Ingress controller&lt;/a&gt;来提供。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;networking.k8s.io/v1beta1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Ingress&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;annotations&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;kubernetes.io/ingress.class&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istio&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ingress&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;rules&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;host&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;httpbin.example.com&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;http&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;paths&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;path&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/status/*&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;backend&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;serviceName&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;httpbin&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;servicePort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的例子中的 &lt;code&gt;kubernetes.io/ingress.class: istio&lt;/code&gt; 注解表明该 Ingress 使用的 Istio Ingress Controller。&lt;/p&gt;
&lt;h2 id=&#34;使用-istio-gateway-暴露服务&#34;&gt;使用 Istio Gateway 暴露服务&lt;/h2&gt;
&lt;p&gt;我们都知道 Istio 是继承 Kubernetes 之后发展出来的一个流行的服务网格实现，它实现了 Kubernetes 没有的一些功能，请参考&lt;a href=&#34;https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/&#34;&gt;什么是 Istio？为什么 Kubernetes 需要 Istio？&lt;/a&gt;简要来说，正是因为 Istio 补足了 Kubernetes 对于云原生应用的流量管理、可观察性和安全方面的短板，使得流量管理变得对应用程序透明，使这部分功能从应用程序中转移到了平台层，成为了云原生基础设施。&lt;/p&gt;
&lt;p&gt;Istio 0.8 以前版本中使用 Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34;&gt;Ingress&lt;/a&gt; 来作为流量入口，其中使用 Envoy 作为 Ingress Controller。在 Istio 0.8 及以后的版本中，Istio 创建了 Gateway 对象。Gateway 和 VirtualService 用于表示 Istio Ingress 的配置模型，Istio Ingress 的缺省实现则采用了和 sidecar 相同的 Envoy 代理。通过该方式，Istio 控制面用一致的配置模型同时控制了入口网关和内部的 sidecar 代理。这些配置包括路由规则，策略检查、遥测收集以及其他服务管控功能。&lt;/p&gt;
&lt;p&gt;Istio Gateway 的功能与 Kubernetes Ingress 类似，它负责进出集群的南北流量。Istio Gateway 描述了一个负载均衡器，用于承载进出服务网格边缘的连接。该规范描述了一组开放端口和这些端口所使用的协议，以及用于负载均衡的 SNI 配置等。&lt;/p&gt;
&lt;p&gt;Istio Gateway 资源本身只能配置L4到L6的功能，例如暴露的端口、TLS 设置等；但 Gateway 可与 VirtualService 绑定，在VirtualService 中可以配置七层路由规则，例如按比例和版本的流量路由，故障注入，HTTP 重定向，HTTP 重写等所有Mesh内部支持的路由规则。&lt;/p&gt;
&lt;p&gt;下面是一个 Gateway 与 VirtualService 绑定的示例。拥有 &lt;code&gt;istio: ingressgateway&lt;/code&gt; 标签的 pod 将作为 Ingress Gateway 并路由对 &lt;code&gt;httpbin.example.com&lt;/code&gt; 虚拟主机的 80 端口的 HTTP 访问，这相当于给 Kubernetes 敞开了一个外部访问的入口。这与使用 Kubernetes Ingress 最大的区别就是，需要我们手动将VirtualService与Gateway 绑定，并指定 Gateway 所在的 pod。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;networking.istio.io/v1alpha3&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Gateway&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;httpbin-gateway&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;selector&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;istio&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ingressgateway&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;servers&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;port&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;number&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;http&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;protocol&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;HTTP&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;hosts&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;httpbin.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面这个 VirtualService 通过 &lt;code&gt;gateways&lt;/code&gt; 与上面的网关绑定在了一起，以接受来自该网关的流量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;networking.istio.io/v1alpha3&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;VirtualService&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;httpbin&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;hosts&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;httpbin.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;gateways&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;httpbin-gateway&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;http&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;match&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;uri&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;prefix&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/status&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;route&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;destination&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;port&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;number&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;host&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;httpbin&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;使用-api-网关暴露服务&#34;&gt;使用 API 网关暴露服务&lt;/h2&gt;
&lt;p&gt;API 网关是位于客户端和后端服务之间的 API 管理工具，一种将客户端接口与后端实现分离的方式，在微服务中得到了广泛的应用。当客户端发出请求时，API 网关会将其分解为多个请求，然后将它们路由到正确的位置，生成响应，并跟踪所有内容。&lt;/p&gt;
&lt;p&gt;API Gateway 是微服务架构体系中的一类型特殊服务，它是所有微服务的入口，它的职责是执行路由请求、协议转换、聚合数据、认证、限流、熔断等。大多数企业 API 都是通过 API 网关部署的。API 网关通常会处理跨 API 服务系统的常见任务，例如用户身份验证、速率限制和统计信息。&lt;/p&gt;
&lt;p&gt;在网格中可以有一个或多个 API Gateway。API 网关的职责有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请求路由和版本控制&lt;/li&gt;
&lt;li&gt;方便单体应用到微服务的过渡&lt;/li&gt;
&lt;li&gt;权限认证&lt;/li&gt;
&lt;li&gt;数据聚合：监控和计费&lt;/li&gt;
&lt;li&gt;协议转换&lt;/li&gt;
&lt;li&gt;消息和缓存&lt;/li&gt;
&lt;li&gt;安全和报警&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上很多基本功能比如路由和权限认证通过 Istio Gateway 也可以实现，只是在功能的丰富度和扩展性方面有些成熟的 API Gateway 可能更占优势，不过在 Istio mesh 中再引入 API Gateway 也可能带来一些弊端。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入了 API Gateway，需要考虑 API Gateway 本身的部署、运维、负载均衡等场景，增加了后端服务的复杂度&lt;/li&gt;
&lt;li&gt;API Gateway 中承载了大量的接口适配，导致难以维护&lt;/li&gt;
&lt;li&gt;对于部分场景，增加了一跳可能导致性能的降低&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在 Istio mesh 中你可以使用多种 Kubernetes Ingress Controller 来充当入口网关，当然你还可以直接使用 Istio 内置的 Istio 网关，对于策略控制、流量管理和用量监控可以直接通过 Istio 网关来完成，这样做的好处是通过 Istio 的控制平面来直接管理网关，而不需要再借助其他工具。但是对于 API 声明周期管理、复杂的计费、协议转换和认证等功能，传统的 API 网关可能更适合你。所以，你可以根据自己的需求来选择，也可以组合使用。&lt;/p&gt;
&lt;p&gt;目前有些传统的反向代理也在向 Service Mesh 方向发展，如 Nginx 构建了 &lt;a href=&#34;https://www.nginx.com/products/nginx-service-mesh/&#34;&gt;Nginx Service Mesh&lt;/a&gt;，Traefik 构建了 &lt;a href=&#34;https://traefik.io/traefik-mesh/&#34;&gt;Traefik Mesh&lt;/a&gt;。还有的 API 网关产品也向 Service Mesh 方向挺进，比如 Kong 发展出了 &lt;a href=&#34;https://kuma.io&#34;&gt;Kuma&lt;/a&gt;。在未来，我们会看到更多 API 网关、反向代理和服务网格的融合产品出现。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/evolving-kubernetes-networking-with-the-gateway-api/&#34;&gt;利用 Gateway API 发展 Kubernetes 网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/how-to-pick-gateway-for-service-mesh/&#34;&gt;如何为服务网格选择入口网关？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/service-mesh-and-api-gateway/&#34;&gt;Service Mesh 和 API Gateway 关系深度探讨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/using-traefik-ingress-controller-with-istio-service-mesh/&#34;&gt;在 Istio 服务网格中使用 Traefik Ingress Controller&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>服务网格之旅——使用 Kubernetes 和 Istio Service Mesh 构建混合云</title>
      <link>https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/</link>
      <pubDate>Mon, 12 Jul 2021 22:22:00 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/</guid>
      <description>
        
        
        &lt;p&gt;这篇文章将带你了解使用 Kubernetes 和 Istio Service Mesh 构建多集群及混合云的过程和需要考虑的问题。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;
&lt;p&gt;使用 Kubernetes 可以快速部署一个分布式环境，实现了云的互操作性，统一了云上的控制平面。并提供了 Service、Ingress 和 &lt;a href=&#34;https://kubernetes.io/blog/2021/04/22/evolving-kubernetes-networking-with-the-gateway-api/&#34;&gt;Gateway&lt;/a&gt; 等资源对象来处理应用程序的流量。如下图所示，Kubernetes 中默认使用 Service 做服务注册和发现，服务之间可以使用服务名称来访问。Kubernetes API Server 与集群内的每个节点上的 &lt;code&gt;kube-proxy&lt;/code&gt; 组件通信，为节点创建 iptables 规则，并将请求转发到其他 pod 上。&lt;/p&gt;
&lt;p&gt;假定现在客户端要访问 Kubernetes 中的服务，首先请求会发送到 Ingress/Gateway 上，然后根据 Ingress/Gateway 里的路由配置转发到后端服务上（图中是服务 A），接着服务 A 对服务 B 请求的流量转发轮询到服务 B 的实例上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gsgg6a11l1j31lu0u042s.jpg&#34; alt=&#34;Kubernetes&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-多集群管理&#34;&gt;Kubernetes 多集群管理&lt;/h2&gt;
&lt;p&gt;多集群管理最常见的使用场景包括服务流量负载均衡、隔离开发和生产环境、解耦数据处理和数据存储、跨云备份和灾难恢复、灵活分配计算资源、跨区域服务的低延迟访问以及避免厂商锁定等。一个企业内部往往有多个 Kubernetes 集群，由 MultiCluster SIG 开发的 KubeFed 实现 Kubernetes 集群联邦可以实现多集群管理的功能，这使得所有 Kubernetes 集群都通过同一个接口来管理。&lt;/p&gt;
&lt;p&gt;在使用集群联邦时需要解决以下几个通用问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配置需要联邦哪些集群&lt;/li&gt;
&lt;li&gt;需要在集群中传播的 API 资源&lt;/li&gt;
&lt;li&gt;配置 API 资源如何分配到不同的集群&lt;/li&gt;
&lt;li&gt;对集群中 DNS 记录注册以实现跨集群的服务发现&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是 KubeSphere 的多集群架构，也是最常用的一种 Kubernetes 多集群管理架构，其中 Host Cluster 作为控制平面，有两个成员集群，分别是 West 和 East。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gsgg7a2ojvj31aa0u0491.jpg&#34; alt=&#34;Multicluster&#34;&gt;&lt;/p&gt;
&lt;p&gt;Host 集群需要能够访问 Member 集群的 API Server，Member 集群之间的网络连通性没有要求。管理集群 Host Cluster 独立于其所管理的成员集群，Member Cluster 并不知道 Host Cluster 存在，这样做的好处是当控制平面发生故障时不会影响到成员集群，已经部署的负载仍然可以正常运行，不会受到影响。&lt;/p&gt;
&lt;p&gt;Host 集群同时承担着 API 入口的作用，由 Host Cluster 将对 Member 集群的资源请求转发到 Member 集群，这样做的目的是方便聚合，而且也利于做统一的权限认证。我们看到在 Host Cluster 中有联邦控制平面，其中的 Push Reconciler 会将联邦集群中身份、角色及角色绑定传播到所有成员集群中。&lt;/p&gt;
&lt;h2 id=&#34;istio&#34;&gt;Istio&lt;/h2&gt;
&lt;p&gt;当我们在 Kubernetes 中运行着多语言、多版本的微服务，并需要更细粒度的金丝雀发布和统一的安全策略管理，实现服务间的可观察性时，可以考虑使用 Istio 服务网格。Istio 通过向应用程序 Pod 中注入 sidecar proxy，缺省使用 IPTables 透明得拦截进出应用程序的所有流量，从而实现了应用层到集群中其他启用服务网格的服务的智能应用感知负载均衡，并绕过了初级的 kube-proxy 负载均衡。Istio 控制平面与 Kubernetes API Server 通信可以获取集群中所有注册的服务信息。&lt;/p&gt;
&lt;p&gt;下图展示了 Istio 的基本原理，其中所有节点属于同一个 Kubernetes 集群。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gsgg6sdrk2j32v60u0qbb.jpg&#34; alt=&#34;Istio Service Mesh&#34;&gt;&lt;/p&gt;
&lt;p&gt;你可能最终会有至少几个Kubernetes集群，每个集群都承载着微服务。Istio 的多集群部署根据网络隔离、主备情况存在多种&lt;a href=&#34;https://istio.io/latest/docs/setup/install/multicluster/&#34;&gt;部署模式&lt;/a&gt;，可以使用 Istio Operator 部署时通过声明来指定。集群中的这些微服务之间的通信可以通过服务网格来加强。在集群内部，Istio提供通用的通信模式，以提高弹性、安全性和可观察性。&lt;/p&gt;
&lt;p&gt;以上都是关于 Kubernetes 上的应用负载管理，但是对于虚拟机上遗留应用，如何在同一个平面中管理？如何管理多集群中的流量划分、网关和安全性呢？&lt;/p&gt;
&lt;h2 id=&#34;管理平面&#34;&gt;管理平面&lt;/h2&gt;
&lt;p&gt;在 Istio 之上再增加一层抽象，将网关、流量和安全分组管理，并将它们应用到不同的集群和命名空间上。下图展示的是 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt; 的多租户模型，利用 NGAC 来管理用户的访问权限，同时也有利于构建零信任网络。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gsgg8ndcajj31il0u00z9.jpg&#34; alt=&#34;Management Plane&#34;&gt;&lt;/p&gt;
&lt;p&gt;Istio 提供了工作负载识别，并由强大的 mTLS 加密保护。这种零信任模型比基于源 IP 等拓扑信息来信任工作负载更好。在 Istio 之上构建一个多集群管理的通用控制平面，然后再增加一个管理平面来管理多集群，提供多租户、管理配置、可观察性等功能。&lt;/p&gt;
&lt;p&gt;下图展示的是 Tetrate Service Bridge 的架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gsgg951mknj314g0u0dnf.jpg&#34; alt=&#34;Tetrate Service Bridge&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;使用 Kubernetes 实现了异构集群的互操作性，Istio 将容器化负载和虚拟机负载纳入到一个同一个控制平面内，统一管理集群内的流量、安全和可观察性。但是，随着集群数量、网络环境和用户权限的越发复杂，人们还需要在 Istio 的控制平面至上再构建一层管理平面来进行混合云管理。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>如何调试 Kubernetes 中的微服务 ——proxy、sidecar 还是 service mesh？</title>
      <link>https://jimmysong.io/blog/how-to-debug-microservices-in-kubernetes-with-proxy-sidecar-or-service-mesh/</link>
      <pubDate>Mon, 05 Jul 2021 22:22:00 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/how-to-debug-microservices-in-kubernetes-with-proxy-sidecar-or-service-mesh/</guid>
      <description>
        
        
        &lt;p&gt;Kubernetes 可以说是目前为止用来运行微服务的最佳载体，但是在调试 Kubernetes 环境中的微服务时的体验可能就没那么友好了。本文将带你了解如何调试 Kubernetes 中的微服务，介绍常用的工具，以及 Istio 的引入为微服务的调试带来的变革。&lt;/p&gt;
&lt;h2 id=&#34;调试微服务与传统单体应用有巨大的不同&#34;&gt;调试微服务与传统单体应用有巨大的不同&lt;/h2&gt;
&lt;p&gt;微服务的调试是一直长期困扰软件开发人员的问题，这在传统的单体应用中不存在，因为开发者可以利用 IDE 中的调试器，为应用程序增加断点、修改环境变量，单步执行等，这些都为软件调试提供了巨大帮助。随着 Kubernetes 的流行，微服务的调试就成了一个棘手的问题，其中相比传统单体应用的调试多了以下问题：&lt;/p&gt;
&lt;h3 id=&#34;多依赖&#34;&gt;多依赖&lt;/h3&gt;
&lt;p&gt;一个微服务往往依赖多个其他微服务，在调试某个微服务时，如何部署其他依赖服务以快速搭建一套最新的 stagging 环境？&lt;/p&gt;
&lt;h3 id=&#34;从本地机器访问&#34;&gt;从本地机器访问&lt;/h3&gt;
&lt;p&gt;微服务在开发者的本地电脑上运行时，通常无法直接访问到 Kubernetes 集群中的服务，如何像调试本地服务一样调试部署在 Kubernetes 集群中的微服务？&lt;/p&gt;
&lt;h3 id=&#34;开发效率低下&#34;&gt;开发效率低下&lt;/h3&gt;
&lt;p&gt;通常情况下，代码从更新到构建成镜像再推送到集群中需要一个漫长的过程，如何加快开发速度？&lt;/p&gt;
&lt;p&gt;我们一起来看下哪些工具能够解决以上问题。&lt;/p&gt;
&lt;h2 id=&#34;工具&#34;&gt;工具&lt;/h2&gt;
&lt;p&gt;调试 Kubernetes 中的微服务的主要解决方案有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Proxy：在 Kubernetes 集群和本地调试终端中部署一个代理，通过构建一个 VPN，使得本地应用可以直接访问到 Kubernetes 中的服务；&lt;/li&gt;
&lt;li&gt;Sidecar：替换原来应用容器的镜像为开发镜像，可以在这个容器中中对该服务进行调试，同时在要调试的微服务 pod 中注入一个 sidecar 作为辅助工具来同步代码；&lt;/li&gt;
&lt;li&gt;服务网格：要想了解应用的整体情况，就需要在所有微服务中注入 sidecar，这样你就可以获得一个监控全局状态的仪表板；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是实现以上解决方案的三个典型的开源项目，它们分别从不同的角度可以帮助你调试微服务。&lt;/p&gt;
&lt;h3 id=&#34;proxy-模式telepresence&#34;&gt;Proxy 模式：Telepresence&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.telepresence.io/&#34;&gt;Telesprence&lt;/a&gt; 本质上是一个本地代理，该代理将 Kubernetes 集群中的数据卷、环境变量、网络都代理到了本地。下图展示的是 Teleprence 的主要使用场景。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;telepresence.jpg&#34; alt=&#34;Proxy 模式：Telepresence&#34;&gt;&lt;/p&gt;
&lt;p&gt;用户需要在本地自主地执行 &lt;code&gt;telepresence&lt;/code&gt; 命令，它会自动将代理部署到 Kubernetes 中，有了该代理之后：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本地的服务就可以完整的访问到 Kubernetes 集群中的其他服务、环境变量、Secret、ConfigMap 等；&lt;/li&gt;
&lt;li&gt;集群中的服务还能直接访问到本地暴露出来的端点；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;但是这种方式仍然不够连贯，还需要用户在本地调试时运行多次命令，而且在某些网络环境下可能无法与 Kubernetes 集群建立 VPN 连接。&lt;/p&gt;
&lt;h3 id=&#34;sidecar-模式nocalhost&#34;&gt;Sidecar 模式：Nocalhost&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://nocalhost.dev/&#34;&gt;Nocalhost&lt;/a&gt; 是一个基于 Kubernetes 的云端开发环境。要想使用它，你只需要在你的 IDE——VS Code 中安装一个插件即可扩展 Kubernetes，并缩短开发反馈周期。通过为不同的用户创建不同的 namespace，并使用 ServiceAccount 绑定到不同用户角身上时，就可以实现开发环境隔离。同时，Nocalhost 还提供了 Web 控制台和 API，方便管理员来管理不同的开发环境。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;sidecar-nocalhost.jpg&#34; alt=&#34;Sidecar 模式：Nocalhost&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;测试&#34;&gt;测试&lt;/h4&gt;
&lt;p&gt;参考 &lt;a href=&#34;https://nocalhost.dev/getting-started.html&#34;&gt;Nocalhost 文档&lt;/a&gt;，我们在 macOS 上安装 Nocalhost，并使用 Minikube 来演示如何调试。&lt;/p&gt;
&lt;p&gt;执行下面的命令安装 Nocalhost 客户端并查看 &lt;code&gt;nhctl&lt;/code&gt; 命令行工具的版本。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;brew install nocalhost/repo/nocalhost

nhctl version
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们假设你机的 &lt;code&gt;kubeconfig&lt;/code&gt; 文件位于 &lt;code&gt;~/.kube/config&lt;/code&gt;（若不在此位置需要在下面的命令中使用 &lt;code&gt;--kubeconfig&lt;/code&gt; 手动指定） 并拥有 Kubernetes 集群的 admin 角色，执行下面的命令使用 Helm3 在 Kubernetes 上安装 Nocalhost 服务端。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;nhctl init demo -n nocalhost 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行下面的命令启动 Minikube 隧道并查看 Nocalhost web 端地址。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;minikube tunnel
kubectl get service nocalhost-web
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在浏览器中访问 &lt;code&gt;http://&amp;lt;EXTERNAL-IP&amp;gt;&lt;/code&gt; 即可，用户名/密码为：&lt;code&gt;admin@admin.com/123456&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;要想在 VS Code 中使用，你还想需要创建一个 ServiceAccount 并绑定 admin 角色，然后将该 ServiceAccount 作为 Kubeconfig 文件导出。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl create serviceaccount my-service-account
kubectl create rolebinding admin --clusterrole&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;admin --serviceaccount&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;default:my-service-account
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;只要你有一个 Kubernetes 集群，并有集群的 admin 权限，就可以参考 Nocalhost 的文档快速开始试用。在 VS Code 中使用 Nocalhost 插件时需要先为插件中配置 Kubernetes 集群。选择你刚导出的 Kubeconfig 文件或者直接复制文件中的内容粘贴到配置里。然后选择你需要测试的服务，并选择对应的 Dev Container，VS Code 会自动打开一个新的代码窗口。&lt;/p&gt;
&lt;p&gt;下面是以 Istio 官方提供的 &lt;a href=&#34;https://istio.io/latest/docs/examples/bookinfo/&#34;&gt;bookinfo 示例&lt;/a&gt;为例，你可以在本地 IDE 中打开克隆下来的代码，然后点击代码文件旁边的锤子即可进入开发模式。选择对应的 DevContainer，nocalhost 会自动向 pod 中注入一个开发容器 sidecar，并在终端中自动进入该容器，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;nocalhost-vs-code.jpg&#34; alt=&#34;Nocalhost VS code 界面&#34;&gt;&lt;/p&gt;
&lt;p&gt;在开发模式中，本地修改代码，无需重新构建镜像，远端开发环境实时生效，这样可以极大的加快开发速度。同时，Nocalhost 还提供了服务端，可用于开发环境和用户权限进行管理，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;nocalhost-web-admin.jpg&#34; alt=&#34;Nocalhost web 端&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;service-mesh-模式istio&#34;&gt;Service Mesh 模式：Istio&lt;/h3&gt;
&lt;p&gt;以上使用 proxy 和 sidecar 的方式，一次只能对一个服务进行调试，如果想要掌握服务的全局状况，比如获取的服务的指标，以及通过分布式追踪了解服务的依赖和调用流程，对服务的性能进行调试。这些&lt;a href=&#34;https://istio.io/latest/zh/docs/concepts/observability/&#34;&gt;可观察性&lt;/a&gt;的功能，需要为所有服务统一注入 sidecar 来实现。&lt;/p&gt;
&lt;p&gt;而且，当你的服务正处于从虚拟机迁移到 Kubernetes 的过程中时，使用 Istio 可以将虚拟机与 Kubernetes 纳入一个网络平面中（如下图所示），方便开发者调试和做渐进式的迁移。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio-service-mesh.jpg&#34; alt=&#34;Serivce Mesh 模式：Istio&#34;&gt;&lt;/p&gt;
&lt;p&gt;当然要获得这些好处也不是一点“代价”也不没有的，引入 Istio 后，你的 Kubernetes  service 需要遵守 Istio 的&lt;a href=&#34;https://istio.io/latest/zh/docs/ops/deployment/requirements/&#34;&gt;命名规范&lt;/a&gt;，学习使用 &lt;a href=&#34;https://istio.io/latest/docs/ops/diagnostic-tools/istioctl-analyze/&#34;&gt;Istioctl&lt;/a&gt; 命令行和日志的方式来调试微服务。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 &lt;code&gt;istioctl analyze&lt;/code&gt; 命令来调试集群中的微服务部署情况，可以使用 YAML 文件来检查某个命名空间或整个集群中的资源部署情况。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;istioctl proxy-config secret&lt;/code&gt;  来调试 service mesh 中的 pod 的 secret 被正确的加载并有效。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Istio 的配置信息在大型的集群部署中传播将会耗时更长并且可能有几秒钟的延迟时间，sidecar 的引入会给服务间调用带来一定延迟。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在应用微服务化和从虚拟机迁移到 Kubernetes 的过程中，开发者需要很多观念和习惯上的转变。通过 proxy 在本地跟 Kubernetes 间构建 VPN，可以方便开发者像调试本地服务一样调试 Kubernetes 中的服务。通过向 pod 中注入 sidecar，可以实现实时调试，加快开发进度。最后，Istio service mesh 真正实现了全局的可观察性，你还可以使用像 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt; 这样的工具来管理异构平台，帮助你渐渐地从单体应用过度到微服务。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 开源四周年回顾与展望</title>
      <link>https://jimmysong.io/blog/istio-4-year-birthday/</link>
      <pubDate>Mon, 24 May 2021 08:00:00 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-4-year-birthday/</guid>
      <description>
        
        
        &lt;p&gt;Istio 是由 &lt;a href=&#34;https://tetrate.io/&#34;&gt;Tetrate&lt;/a&gt; 创始人 Varun Talwar 和谷歌首席工程师 Louis Ryan 命名并在 2017 年 5 月 24 日开源。今天是 Istio 开源四周年，让我们一起来回顾一下 Istio 四年来的发展并展望一下它的未来。&lt;/p&gt;
&lt;h2 id=&#34;istio-的开源历史&#34;&gt;Istio 的开源历史&lt;/h2&gt;
&lt;p&gt;2017 年是 Kubernetes 结束容器编排之战的一年，Google 为了巩固在云原生领域的优势，并弥补 Kubernetes 在服务间流量管理方面的劣势，趁势开源了 Istio。下面是截止目前 Istio 历史上最重要的几次版本发布。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;日期&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2017-05-24&lt;/td&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;正式开源，该版本发布时仅一个命令行工具。确立了功能范围和 sidecar 部署模式，确立的 Envoy 作为默认 sidecar proxy 的地位。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017-10-10&lt;/td&gt;
&lt;td&gt;0.2&lt;/td&gt;
&lt;td&gt;支持多运行时环境，如虚拟机。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018-06-01&lt;/td&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;API 重构。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018-07-31&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;生产就绪，此后 Istio 团队被大规模重组。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019-03-19&lt;/td&gt;
&lt;td&gt;1.1&lt;/td&gt;
&lt;td&gt;企业就绪，支持多 Kubernetes 集群，性能优化。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-03-03&lt;/td&gt;
&lt;td&gt;1.5&lt;/td&gt;
&lt;td&gt;回归单体架构，支持 WebAssembly 扩展，使得 Istio 的生态更加强大。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-11-18&lt;/td&gt;
&lt;td&gt;1.8&lt;/td&gt;
&lt;td&gt;正式放弃 Mixer，进一步完善对虚拟机的支持。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Istio 开源后经过了一年时间的发展，在 1.0 发布的前两个月发布了 0.8 版本，这是对 API 的一次大规模重构。而在 2018 年 7 月底发布 1.0 时， Istio 达到了生产可用的临界点，此后 Google 对 Istio 团队进行了大规模重组，多家以 Istio 为基础的 Service Mesh &lt;a href=&#34;https://istio.io/latest/about/ecosystem/#providers&#34;&gt;创业公司&lt;/a&gt;诞生，可以说 2018 年是服务网格行业诞生的元年。&lt;/p&gt;
&lt;p&gt;2019年 3 月 Istio 1.1 发布，而这距离 1.0 发布已经过去了近 9 个月，这已经远远超出一个开源项目的平均发布周期。我们知道迭代和进化速度是基础软件的核心竞争力，此后 Istio 开始以每个季度一个版本的固定&lt;a href=&#34;https://istio.io/v1.7/about/release-cadence/&#34;&gt;发布节奏&lt;/a&gt;，并在 2019 年成为了 &lt;a href=&#34;https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors&#34;&gt;GitHub 增长最快的十大项目中排名第 4 名&lt;/a&gt;！&lt;/p&gt;
&lt;h2 id=&#34;istio-社区&#34;&gt;Istio 社区&lt;/h2&gt;
&lt;p&gt;Istio 开源四年来，已经在 GitHub 上收获了 2.7 万颗星，获得了大量的&lt;a href=&#34;https://istio.io/latest/about/case-studies/&#34;&gt;社区用户&lt;/a&gt;。下图是 &lt;a href=&#34;https://github.com/istio/istio&#34;&gt;Istio&lt;/a&gt; 的 GitHub star 数增长情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gqtm7n2hm1j31me0n2tag.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;2020 年 Istio 的项目管理开始走向成熟，治理方式也到了进化的阶段。2020 年，Istio 社区进行了第一次&lt;a href=&#34;https://istio.io/latest/blog/2020/steering-election-results/&#34;&gt;管委会选举&lt;/a&gt;，还把商标转让给了 &lt;a href=&#34;https://istio.io/latest/blog/2020/open-usage/&#34;&gt;Open Usage Commons&lt;/a&gt;。首届 &lt;a href=&#34;https://events.istio.io/istiocon-2021/&#34;&gt;IstioCon&lt;/a&gt; 在 2021 年 2 月份成功举办，几千人参加了线上会议。在中国也有大量的 Istio 社区用户，2021 年也会有线下面对面的 Istio 社区 meetup 在中国举办。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008i3skNly1gquicfqg14j31lw0smwl2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;根据 CNCF 2020 年调查，46% 的组织在生产中使用服务网格或计划在未来 12 个月内使用。Istio 是在生产中使用的最多的网格。&lt;/p&gt;
&lt;h2 id=&#34;未来&#34;&gt;未来&lt;/h2&gt;
&lt;p&gt;经过 4 年的发展，围绕 Istio 不仅形成了庞大的用户群，还诞生了多家 Istio 供应商，你可以在最近改版的 &lt;a href=&#34;https://istio.io&#34;&gt;Istio 的官网首页&lt;/a&gt;中看到。在最近几个版本中，Istio 已经将发展中心转移到了提升 Day 2 Operation 体验上来了。我们还希望看到更多的 Istio 的采纳路径建议、案例研究、学习资料、培训及认证（例如来自 Tetrate 的业界的第一个 &lt;a href=&#34;https://academy.tetrate.io/courses/certified-istio-administrator&#34;&gt;Istio 管理员认证&lt;/a&gt;），这些都将有利于 Istio 的推广和采用。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>什么是 Istio？为什么 Kubernetes 需要 Istio？</title>
      <link>https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/</link>
      <pubDate>Wed, 28 Apr 2021 09:06:14 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/</guid>
      <description>
        
        
        &lt;p&gt;Istio 是当前&lt;a href=&#34;https://www.cncf.io/blog/2020/03/04/2019-cncf-survey-results-are-here-deployments-are-growing-in-size-and-speed-as-cloud-native-adoption-becomes-mainstream/&#34;&gt;最流行的服务网格实现&lt;/a&gt;，它是在 Kubernetes 的基础上开发的，它跟 Kubernetes 在云原生应用的生态中拥有着不同的定位。本文不是直接为你介绍 Istio 具有哪些功能，而是先向你介绍 Istio 诞生的历史条件，然后带你从 Kubernetes 与 Istio 的分工开始，了解什么是 Istio。&lt;/p&gt;
&lt;p&gt;要想解释什么是 Istio，还得先了解 Istio 是在什么样的情况下出现的——即为什么会有 Istio？&lt;/p&gt;
&lt;p&gt;容器作为云原生应用的交付物，既解决了环境一致性的问题，又可以更细粒度的限制应用资源，但是随着微服务和 DevOps 的流行，容器作为微服务的载体得以广泛应用。2014 年，Google 开源了 Kubernetes，随后几年得到迅猛发展，在 2017 年奠定了容器编排调度标准的地位。Kubernetes 作为一种容器编排调度工具，解决了分布式应用程序的部署和调度问题。因为一台单机的资源有限，而互联网应用可能因为用户规模的急速扩张，或用户属性的不同在不同时间段会出现流量洪峰，因此对计算资源的弹性要求比较高。而一台单机显然无法满足一个如何规模庞大的应用，反之，对于一个规模很小的应用也没必要占用整台主机，那将导致巨大的浪费。&lt;/p&gt;
&lt;p&gt;简而言之，Kubernetes 定义服务的最终状态，并使系统自动地达到和维持在该状态。那么在应用部署完成后，如何管理服务上的流量呢？下面我们将看下 Kubernetes 中如何做服务管理，及在 Istio 中的变化。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中如何做服务管理&#34;&gt;Kubernetes 中如何做服务管理？&lt;/h2&gt;
&lt;p&gt;下图展示的是 Kubernetes 中的服务模型。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;service-model.jpg&#34; alt=&#34;Kubernetes 服务模型&#34;&gt;&lt;/p&gt;
&lt;p&gt;从上图中我们可以看出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同一个服务的的不同示例可能被调度到不同的节点上；&lt;/li&gt;
&lt;li&gt;Kubernetes 通过 Service 对象将一个服务的多个实例组合在了一起，统一对外服务；&lt;/li&gt;
&lt;li&gt;Kubernetes 在每个 node 中安装了 &lt;code&gt;kube-proxy&lt;/code&gt;  组件来转发流量，它拥有的简单的负载均衡功能；&lt;/li&gt;
&lt;li&gt;Kubernetes 集群外部流量可以通过 Ingress 进入集群中（Kubernetes 还有其他几种暴露服务的方式，如 NodePort、LoadBalancer 等）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes 是用于资源集约管理的工具。但在为应用分配好资源后，如何保证应用的健壮性、冗余性，如何实现更细粒度的流量划分（不是根据服务中实例个数来实现），如何保障服务的安全性，如何进行多集群管理等，这些问题 Kubernetes 都不能很好地解决。&lt;/p&gt;
&lt;p&gt;服务具有多个版本，需要迭代和上线，在新版发布的时候需要切分流量，实现金丝雀发布；同时我们应该假定服务是不可靠的，可能因为各种原因导致请求失败，需要面向失败来编程，如何监控应用程序的指标，了解每个请求的耗时和状态？Istio 的发起这们就想到了在每个 pod 中注入一个代理，将代理的配置通过一个控制平面集中分发，然后将从 pod 中应用容器发起的每个请求都劫持到 sidecar 代理中，然后转发，这样不就可以完美的解决以上问题了吗？Kubernetes 优秀的架构和可扩展性，例如 CRD，pod 内的部署模式，可以完美的解决大量 sidecar 的注入和管理问题，使得 Istio 的实现成为可能。&lt;/p&gt;
&lt;h2 id=&#34;istio-的基本原理&#34;&gt;Istio 的基本原理&lt;/h2&gt;
&lt;p&gt;下图是 Istio 中的服务模型，它既可以支持 Kubernetes 中的工作负载，又可以支持虚拟机。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio.jpg&#34; alt=&#34;Istio&#34;&gt;&lt;/p&gt;
&lt;p&gt;从图中我们可以看出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istiod 作为控制平面，将配置下发给所有的 sidecar proxy 和 gateway（为了美观，图中没有画 Istiod 及 sidecar 之间的连接）&lt;/li&gt;
&lt;li&gt;Istio 不再使用 &lt;code&gt;kube-proxy&lt;/code&gt; 组件做流量转发，而是依托在每个 pod 中注入的 sidecar proxy，所有的 proxy 组成了 Istio 的数据平面；&lt;/li&gt;
&lt;li&gt;应用程序管理员可以和管理 Kubernetes 中的工作负载一样，通过声明式 API 操作 Istio mesh 中流量的行为；&lt;/li&gt;
&lt;li&gt;Ingress 被 Gateway 资源所替代，Gateway 是一种特殊的 proxy，实际上也是复用的 Sidecar proxy；&lt;/li&gt;
&lt;li&gt;可以在虚拟机中安装 sidecar proxy，将虚拟机引入的 Istio mesh 中；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实际上在 Istio 之前，人们可以使用 SpringCloud、Netflix OSS 等，通过在应用程序中集成 SDK，编程的方式来管理应用程序中的流量。但是这通常会有编程语言限制，而且在 SDK 升级的时候，需要修改代码并重新上线应用，会增大人力负担。Istio 使得流量管理变得对应用程序透明，使这部分功能从应用程序中转移到了平台层，成为了云原生基础设施。&lt;/p&gt;
&lt;p&gt;正是因为 Istio 补足了 Kubernetes 对于云原生应用的流量管理、可观察性和安全方面的短板，在 2017 年由 Google、IBM 和 Lyft 共同发起的这个服务网格开源项目，并在三年来取得了长足的发展。关于 Istio 核心功能的介绍可以参考 &lt;a href=&#34;https://istio.io/latest/docs/concepts/what-is-istio/&#34;&gt;Istio 文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Service Mesh 相当于云原生时代的 TCP/IP，解决应用程序网络通信、安全及可见性问题；&lt;/li&gt;
&lt;li&gt;Istio 是目前最流行的 service mesh 实现，依托于 Kubernetes，但也可以扩展到虚拟机负载；&lt;/li&gt;
&lt;li&gt;Istio 的核心由控制平面和数据平面组成，Envoy 是默认的数据平面代理；&lt;/li&gt;
&lt;li&gt;Istio 作为云原生基础设施的网络层，对应用透明。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>为什么在使用了 Kubernetes 后你可能还需要 Istio？</title>
      <link>https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/</link>
      <pubDate>Wed, 07 Apr 2021 08:27:17 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/</guid>
      <description>
        
        
        &lt;p&gt;如果你听说过服务网格，并尝试过 &lt;a href=&#34;https://istio.io/&#34;&gt;Istio&lt;/a&gt;，你可能有以下问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为什么 Istio 要在 Kubernetes 上运行？&lt;/li&gt;
&lt;li&gt;Kubernetes 和服务网格在云原生应用架构中分别扮演什么角色？&lt;/li&gt;
&lt;li&gt;Istio 扩展了 Kubernetes 的哪些方面？它解决了哪些问题？&lt;/li&gt;
&lt;li&gt;Kubernetes、Envoy 和 Istio 之间是什么关系？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文将带大家了解 Kubernetes 和 Istio 的内部工作原理。此外，我会介绍 Kubernetes 中的负载均衡方法，并解释为什么有了 Kubernetes 后还需要 Istio。&lt;/p&gt;
&lt;p&gt;Kubernetes 本质上是通过声明式配置来实现应用生命周期管理，而服务网格本质上是提供应用间的流量、安全管理和可观察性。如果你已经使用 Kubernetes 搭建了一个稳定的应用平台，那么如何设置服务间调用的负载均衡和流量控制？是否有这样一个通用的工具或者说平台（非 SDK），可以实现？这就需要用到服务网格了。&lt;/p&gt;
&lt;p&gt;Envoy 引入了 xDS 协议，这个协议得到了各种开源软件的支持，比如 Istio、&lt;a href=&#34;https://mosn.io/&#34;&gt;MOSN&lt;/a&gt; 等。Envoy 将 xDS 贡献给服务网格或云原生基础设施。Envoy 本质上是一个现代版的代理，可以通过 API 进行配置，在此基础上衍生出许多不同的使用场景–比如 API Gateway、服务网格中的 sidecar 代理和边缘代理。&lt;/p&gt;
&lt;p&gt;本文包含以下内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kube-proxy 的作用描述。&lt;/li&gt;
&lt;li&gt;Kubernetes 在微服务管理方面的局限性。&lt;/li&gt;
&lt;li&gt;Istio 服务网格的功能介绍。&lt;/li&gt;
&lt;li&gt;Kubernetes、Envoy 和 Istio 服务网格中一些概念的比较。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-service-mesh&#34;&gt;Kubernetes vs Service Mesh&lt;/h2&gt;
&lt;p&gt;下图显示了 Kubernetes 中的服务访问关系和服务网格（每个 pod 模型一个 sidecar）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;008eGmZEly1gpb7knfo4dj31hk0redrz.jpg&#34; alt=&#34;Kubernetes vs Service Mesh&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;流量转发&#34;&gt;流量转发&lt;/h3&gt;
&lt;p&gt;Kubernetes 集群中的每个节点都部署了一个 kube-proxy 组件，该组件与 Kubernetes API Server 进行通信，获取集群中的服务信息，然后设置 iptables 规则，将服务请求直接发送到对应的 Endpoint（属于同一组服务的 pod）。&lt;/p&gt;
&lt;h3 id=&#34;服务发现&#34;&gt;服务发现&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;008eGmZEly1gpb7knwb79j30kq0fcjs9.jpg&#34; alt=&#34;Service Discovery&#34;&gt;&lt;/p&gt;
&lt;p&gt;Istio 可以跟踪 Kubernetes 中的服务注册，也可以在控制平面中通过平台适配器与其他服务发现系统对接；然后生成数据平面的配置（使用 CRD，这些配置存储在 etcd 中），数据平面的透明代理。数据平面的透明代理以 sidecar 容器的形式部署在每个应用服务的 pod 中，这些代理都需要请求控制平面同步代理配置。代理之所以 “透明”，是因为应用容器完全不知道代理的存在。过程中的 kube-proxy 组件也需要拦截流量，只不过 kube-proxy 拦截的是进出 Kubernetes 节点的流量–而 sidecar 代理拦截的是进出 pod 的流量。&lt;/p&gt;
&lt;h3 id=&#34;服务网格的劣势&#34;&gt;服务网格的劣势&lt;/h3&gt;
&lt;p&gt;由于 Kubernetes 的每个节点上都运行着很多 pod，所以在每个 pod 中放入原有的 kube-proxy 路由转发功能，会增加响应延迟–由于 sidecar 拦截流量时跳数更多，消耗更多的资源。为了对流量进行精细化管理，将增加一系列新的抽象功能。这将进一步增加用户的学习成本，但随着技术的普及，这种情况会慢慢得到缓解。&lt;/p&gt;
&lt;h3 id=&#34;服务网格的优势&#34;&gt;服务网格的优势&lt;/h3&gt;
&lt;p&gt;kube-proxy 的设置是全局的，无法对每个服务进行细粒度的控制，而 service mesh 通过 sidecar proxy 的方式将 Kubernetes 中的流量控制从服务层中抽离出来–可以实现更大的弹性。&lt;/p&gt;
&lt;h3 id=&#34;kube-proxy-的不足之处&#34;&gt;Kube-proxy 的不足之处&lt;/h3&gt;
&lt;p&gt;首先，如果转发的 pod 不能正常服务，它不会自动尝试其他 pod。每个 pod 都有一个健康检查机制，当一个 pod 出现健康问题时，kubelet 会重启 pod，kube-proxy 会删除相应的转发规则。另外，节点 Port 类型的服务不能添加 TLS 或更复杂的消息路由机制。&lt;/p&gt;
&lt;p&gt;Kube-proxy 实现了一个 Kubernetes 服务的多个 pod 实例之间的流量负载均衡，但如何对这些服务之间的流量进行精细化控制–比如将流量按百分比划分给不同的应用版本（这些应用版本都是同一个服务的一部分，但在不同的部署上），或者做金丝雀发布（灰度发布）和蓝绿发布？&lt;/p&gt;
&lt;p&gt;Kubernetes 社区给出了一个使用 Deployment 做&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments&#34;&gt;金丝雀发布&lt;/a&gt;的方法，本质上是通过修改 pod 的标签来给部署的服务分配不同的 pod。&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-ingress-vs-istio-gateway&#34;&gt;Kubernetes Ingress vs Istio Gateway&lt;/h3&gt;
&lt;p&gt;如上所述，kube-proxy 只能在 Kubernetes 集群内路由流量。Kubernetes 集群的 pod 位于 CNI 创建的网络中。Ingress 是在 Kubernetes 中创建的资源对象，用于集群外部的通信。它由位于 Kubernetes 边缘节点上的入口控制器驱动，负责管理南北向流量。Ingress 必须与各种 Ingress 控制器对接，比如 &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;nginx ingress 控制器&lt;/a&gt;和 &lt;a href=&#34;https://traefik.io/&#34;&gt;traefik&lt;/a&gt;。Ingress 只适用于 HTTP 流量，使用简单。它只能通过匹配有限的字段来路由流量——如服务、端口、HTTP 路径等。这使得它无法对 TCP 流量进行路由，如 MySQL、Redis 和各种 RPC。这就是为什么你会看到人们在 ingress 资源注释中写 Nginx 配置语言的原因（注：使用 Nginx Ingress Controller 可以通过 &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/&#34;&gt;配置 ConfigMap 和 Service 的方式&lt;/a&gt;来变通支持 TCP 和 UDP  流量转发）。直接路由南北流量的唯一通行方法是使用服务的 LoadBalancer 或 NodePort，前者需要云厂商支持，后者需要额外的端口管理。&lt;/p&gt;
&lt;p&gt;Istio Gateway 的功能与 Kubernetes Ingress 类似，它负责进出集群的南北流量。Istio Gateway 描述了一个负载均衡器，用于承载进出服务网格边缘的连接。该规范描述了一组开放端口和这些端口所使用的协议，以及用于负载均衡的 SNI 配置等。Gateway 是一个 CRD 扩展，它也重用了 sidecar 代理的功能；详细配置请参见 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/gateway/&#34;&gt;Istio 网站&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;envoy&#34;&gt;Envoy&lt;/h2&gt;
&lt;p&gt;Envoy 是 Istio 中默认的 sidecar 代理。Istio 基于 Enovy 的 xDS 协议扩展了其控制平面。在讨论 Envoy 的 xDS 协议之前，我们需要先熟悉 Envoy 的基本术语。下面是 Envoy 的架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-arch.jpg&#34; alt=&#34;Envoy 架构图&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;基础概念&#34;&gt;基础概念&lt;/h3&gt;
&lt;p&gt;以下是 Enovy 中你应该知道的基本术语。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下游。下游主机连接到 Envoy，发送请求，并接收响应，即发送请求的主机。&lt;/li&gt;
&lt;li&gt;上游：上游主机。上游主机接收来自 Envoy 的连接和请求，并返回响应；即接收请求的主机。&lt;/li&gt;
&lt;li&gt;Listener：监听器。监听器是一个命名的网络地址（如端口、UNIX 域套接字等）；下游客户端可以连接到这些监听器。Envoy 将一个或多个监听器暴露给下游主机进行连接。&lt;/li&gt;
&lt;li&gt;集群。集群是一组逻辑上相同的上游主机，Envoy 连接到它们。Envoy 通过服务发现来发现集群的成员。可以选择通过主动的健康检查来确定集群成员的健康状态。Envoy 通过负载均衡策略来决定集群中哪个成员的请求路由。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Envoy 中可以设置多个监听器，每个监听器可以设置一个过滤链（过滤链表），而且过滤链是可扩展的，这样我们可以更方便地操纵流量的行为–比如设置加密、私有 RPC 等。&lt;/p&gt;
&lt;p&gt;xDS 协议是由 Envoy 提出的，是 Istio 中默认的 sidecar 代理，但只要实现了 xDS 协议，理论上也可以作为 Istio 中的 sidecar 代理 —— 比如蚂蚁集团开源的 &lt;a href=&#34;https://mosn.io&#34;&gt;MOSN&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://cdn.thenewstack.io/media/2021/03/b800bf17-image3.png&#34;&gt;&lt;img src=&#34;008eGmZEly1gpb7kk7wk4j31060lqgqx.jpg&#34; alt=&#34;img&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Istio 是一个功能非常丰富的服务网格，包括以下功能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量管理。这是 Istio 最基本的功能。&lt;/li&gt;
&lt;li&gt;策略控制。实现访问控制系统、遥测采集、配额管理、计费等功能。&lt;/li&gt;
&lt;li&gt;可观察性。在 sidecar 代理中实现。&lt;/li&gt;
&lt;li&gt;安全认证。由 Citadel 组件进行密钥和证书管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;istio-中的流量管理&#34;&gt;Istio 中的流量管理&lt;/h2&gt;
&lt;p&gt;Istio 中定义了以下 CRD 来帮助用户进行流量管理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关。网关描述了一个运行在网络边缘的负载均衡器，用于接收传入或传出的 HTTP/TCP 连接。&lt;/li&gt;
&lt;li&gt;虚拟服务（VirtualService）。VirtualService 实际上是将 Kubernetes 服务连接到 Istio 网关。它还可以执行额外的操作，例如定义一组流量路由规则，以便在主机寻址时应用。&lt;/li&gt;
&lt;li&gt;DestinationRule。DestinationRule 定义的策略决定了流量被路由后的访问策略。简单来说，它定义了流量的路由方式。其中，这些策略可以定义为负载均衡配置、连接池大小和外部检测（用于识别和驱逐负载均衡池中不健康的主机）配置。&lt;/li&gt;
&lt;li&gt;EnvoyFilter。EnvoyFilter 对象描述了代理服务的过滤器，可以自定义 Istio Pilot 生成的代理配置。这种配置一般很少被主用户使用。&lt;/li&gt;
&lt;li&gt;ServiceEntry。默认情况下，Istio 服务 Mesh 中的服务无法发现 Mesh 之外的服务。ServiceEntry 可以在 Istio 内部的服务注册表中添加额外的条目，从而允许 Mesh 中自动发现的服务访问并路由到这些手动添加的服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;Kubernetes vs xDS vs Istio&lt;/h2&gt;
&lt;p&gt;在回顾了 Kubernetes 的 kube-proxy 组件、xDS 和 Istio 对流量管理的抽象后，现在我们仅从流量管理的角度来看看这三个组件 / 协议的比较（注意，三者并不完全等同）。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;xDS&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Istio service mesh&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;VirtualService&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;DestinationRule&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;EnvoyFilter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ingress&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;核心观点&#34;&gt;核心观点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 的本质是应用生命周期管理，具体来说就是部署和管理（伸缩、自动恢复、发布）。&lt;/li&gt;
&lt;li&gt;Kubernetes 为微服务提供了一个可扩展、高弹性的部署和管理平台。&lt;/li&gt;
&lt;li&gt;服务网格是基于透明代理，通过 sidecar 代理拦截服务之间的流量，然后通过控制平面配置管理它们的行为。&lt;/li&gt;
&lt;li&gt;服务网格将流量管理与 Kubernetes 解耦，不需要 kube-proxy 组件来支持服务网格内的流量；通过提供更接近微服务应用层的抽象来管理服务间的流量、安全性和可观察性。&lt;/li&gt;
&lt;li&gt;xDS 是服务网格的协议标准之一。&lt;/li&gt;
&lt;li&gt;服务网格是 Kubernetes 中服务的一个更高层次的抽象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;如果说 Kubernetes 管理的对象是一个 pod，那么服务网格管理的对象就是一个服务，所以用 Kubernetes 管理微服务，然后应用服务网格就可以了。如果你连服务都不想管理，那就用 &lt;a href=&#34;https://knative.dev/&#34;&gt;Knative&lt;/a&gt; 这样的无服务器平台，不过这是后话。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>使用 EKS-D 和 Istio 保证混合云环境一致性</title>
      <link>https://jimmysong.io/blog/eks-eksd-istio-hybrid-cloud/</link>
      <pubDate>Mon, 28 Dec 2020 14:18:40 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/eks-eksd-istio-hybrid-cloud/</guid>
      <description>
        
        
        &lt;p&gt;AWS 在 2020 年12 月举行的 re:Invent 大会上发布了 &lt;a href=&#34;https://distro.eks.amazonaws.com/&#34;&gt;EKS-D&lt;/a&gt;，此举旨在联合合作伙伴，开源 AWS 维护大规模 EKS 集群的经验，帮助用户实现混合云场景下 Kubernetes 的一致性的体验。本文将为你解析 EKS-D 的战略意义，说明它是如何与 Istio 共同保证混合云环境一致性的。&lt;/p&gt;
&lt;h2 id=&#34;什么是-eks-d&#34;&gt;什么是 EKS-D？&lt;/h2&gt;
&lt;p&gt;EKS-D 是 Amazon EKS 的一个发行版，可以运行在企业内部、云端或自己的系统上。EKS-D 保持与 Kubernetes 新版本同期发布。在不久的将来，将以 EKS Anywhere（EKS-A）为名，提供 EKS-D 的支持、打包产品和安装方法。&lt;/p&gt;
&lt;p&gt;下图展示了 AWS、EKS-D、 Kubernetes 及用户之间的关系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;0081Kckwly1gm3oyi69h3j31af0u0ju1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;EKS-D 对于 AWS、合作伙伴及用户来说具有不同的意义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;AWS：增加 AWS 的市场拥有率&lt;/li&gt;
&lt;li&gt;合作伙伴：整合 AWS 的渠道和客户资源以触达更多用户&lt;/li&gt;
&lt;li&gt;用户：保证了异构环境下的 Kubernetes 的一致性，简化运维&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如今企业要考虑选择哪个云供应商要考虑很多因素，同时，还有很多企业的 IT 难以跨入云，而是继续依赖究竟考验的传统 IT 架构以开展业务。&lt;/p&gt;
&lt;p&gt;在上云的时候客户希望在企业内部和云端获得一致的体验，以便进行迁移或实现混合云设置。不是所有应用都适合跨云迁移，为了合规、数据安全等种种原因，多集群、混合云的使用场景将很普遍。&lt;/p&gt;
&lt;h2 id=&#34;为什么使用多集群和混合云&#34;&gt;为什么使用多集群和混合云&lt;/h2&gt;
&lt;p&gt;我们在很多情况下或使用多集群、混合云等部署方式，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为了避免厂商锁定，便于应用跨集群迁移；&lt;/li&gt;
&lt;li&gt;为了实现应用的高可用；&lt;/li&gt;
&lt;li&gt;当一个集群的规模过大造成性能瓶颈时；&lt;/li&gt;
&lt;li&gt;为了合规和数据安全；&lt;/li&gt;
&lt;li&gt;为了就近部署，降低网络延迟，提高用户体验；&lt;/li&gt;
&lt;li&gt;为了进行一些测试；&lt;/li&gt;
&lt;li&gt;突发业务，需要集群扩容；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上情况经常发生，对集群的管理造成了挑战。Kubernetes 统一了容器编排的标准，随着其进一步普及，更有望成为云原生应用的底层 API。但是对于如何管理多集群和混合云环境中的 Kubernetes 集群，又为我们带来了新的挑战。&lt;/p&gt;
&lt;h2 id=&#34;使用-istio-service-mesh-管理混合云&#34;&gt;使用 Istio service mesh 管理混合云&lt;/h2&gt;
&lt;p&gt;Istio 服务网格作为云原生应用的网络基础设施层，可以同时管理 Kubernetes 及非容器负载，如&lt;a href=&#34;https://thenewstack.io/how-to-integrate-virtual-machines-into-istio-service-mesh/&#34;&gt;虚拟机&lt;/a&gt;。Istio 可以在&lt;a href=&#34;https://istio.io/latest/docs/setup/platform-setup/&#34;&gt;多种平台&lt;/a&gt;中部署，又支持多种&lt;a href=&#34;https://istio.io/latest/docs/ops/deployment/deployment-models/&#34;&gt;部署模式&lt;/a&gt;，兼具管理多集群和混合云的功能.在部署时需要充分考虑 Region、Zone 的分布、网络隔离、多租户、控制平面的高可用等因素。&lt;/p&gt;
&lt;p&gt;假如我们同时使用 EKS 和部署在私有数据中心中的 EKS-D，那么如何将两个集群使用一个统一的控制平面管理起来呢？如下图所示，cluster1 和 cluster2 分别表示部署在 EKS 和 EKS-D 的 Kubernetes 集群，这两个集群的网络是隔离的，现因为上文所说的适合使用混合云某个场景，现在为了将它们纳入同一个服务网格使用一个控制平面来管理，我们采用了 &lt;a href=&#34;https://istio.io/latest/docs/setup/install/multicluster/primary-remote_multi-network/&#34;&gt;Primary-Remote 多网络&lt;/a&gt;的部署模式。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;0081Kckwly1gm3oyiyq4fj315m0u0wi2.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;图示：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;图中黑色箭头表示控制平面内获取服务和端点配置的请求；&lt;/li&gt;
&lt;li&gt;图中蓝色箭头表示服务 A 访问服务 B 的路由；&lt;/li&gt;
&lt;li&gt;图中绿色箭头表示服务 A/B 向控制平面获取服务端点的路由；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;使用该模式部署 Istio 时，需要保证控制平面对 Kubernetes 的 API Server 的连接性，具体的安装过程请参考 &lt;a href=&#34;https://istio.io/latest/docs/setup/install/multicluster/primary-remote_multi-network/&#34;&gt;Istio 文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;EKS-D 保证了在混合云环境下 Kubernetes 集群的一致性，降低了集群的运维成本。Istio 固有的多集群感知能力，进一步从服务层面增强了用户体验的一致性，帮助我们将多集群中的服务纳入统一的控制平面管理。EKS-D 发布的时有众多的合作伙伴的响应，其中 Tetrate 作为 Istio service mesh 的解决方案供应商提供了 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge（TSB）&lt;/a&gt;在 EKS 和 EKS-D 上实现了跨工作负载的统一应用连接和安全性。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 对虚拟机支持史话</title>
      <link>https://jimmysong.io/blog/istio-vm-odysssey/</link>
      <pubDate>Fri, 25 Dec 2020 14:18:40 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-vm-odysssey/</guid>
      <description>
        
        
        &lt;p&gt;本文将为你介绍 Istio 历史上对虚拟机负载的支持情况，尤其是 Istio 1.8 中引入的智能 DNS 代理及 &lt;code&gt;WorkloadGroup&lt;/code&gt; 使得虚拟机与容器在资源抽象层面可以等同视之。我将为你展现一幅 Istio 支持虚拟机的波澜壮阔的奥德赛。&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;在我&lt;a href=&#34;https://thenewstack.io/how-to-integrate-virtual-machines-into-istio-service-mesh/&#34;&gt;之前的博客&lt;/a&gt;中谈到 Istio 1.7 如何支持虚拟机，但那时虚拟机仍然无法无缝的集成到 Istio 中，因为还需要做很多手动的操作。现在，Istio 1.8 新增了 WorkloadGroup 及&lt;a href=&#34;https://istio.io/latest/blog/2020/dns-proxy/&#34;&gt;智能 DNS 代理&lt;/a&gt;，这使得如虚拟机这样的非 Kubernetes 工作负载可以在 Istio 中成为像 Pod 一样的一等公民。&lt;/p&gt;
&lt;p&gt;不论有没有为虚拟机安装 sidecar，虚拟机通常情况下无法直接访问 Kubernetes 集群中的 DNS 服务器以解析 Kubernetes  服务的 Cluster IP 的（虽然你也许可以通过一些黑客的手段做到），这是在 Istio 中集成虚拟的最后一块短板，终于在 Istio 1.8 中完成了突破。&lt;/p&gt;
&lt;h2 id=&#34;为什么要支持虚拟机&#34;&gt;为什么要支持虚拟机？&lt;/h2&gt;
&lt;p&gt;在我们将应用在迁移到云原生架构，不断容器化的过程中，将经历三个阶段，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;0081Kckwly1gm0d6t775lj31s80k8go8.jpg&#34; alt=&#34;云原生应用的三个阶段&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;阶段一：应用全部部署在虚拟机上&lt;/li&gt;
&lt;li&gt;阶段二：应用既部署在虚拟机上也部署在容器里，正在从虚拟机向容器中迁移，并使用 Kubernetes 管理容器&lt;/li&gt;
&lt;li&gt;阶段三：所有的应用优先部署在容器里，使用 Kubernetes 管理容器，使用 Istio 管理应用间的通信&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上图仅是对以上三个阶段的最简化描述，实际上还会有多混合云、多机房、多集群等情况，且阶段三只是个理想化的阶段，容器和虚拟机将是长期共存的，但是容器化趋势不变。&lt;/p&gt;
&lt;p&gt;在阶段二中，人们通常会将新业务和少量应用率先实现容器化，并部署到 Kubernetes 中，在应用尚未完全实现容器化的时候，处于过度状态时会遇到很多问题，如何让应用与部署在虚拟机中的服务交互？虚拟机如何访问容器中的服务？在服务迁移的过程中如何保证稳定无缝？是否可以将容器和虚拟机纳入一个统一的控制平面来管理？Istio 从开源初期就考虑并着手解决这一问题。&lt;/p&gt;
&lt;h2 id=&#34;istio-支持虚拟机的历史&#34;&gt;Istio 支持虚拟机的历史&lt;/h2&gt;
&lt;p&gt;Istio 对于虚拟机的支持是个漫长的过程，堪称是一部奥德赛。&lt;/p&gt;
&lt;h3 id=&#34;istio-mesh-扩张&#34;&gt;Istio mesh 扩张&lt;/h3&gt;
&lt;p&gt;Istio 从 0.2 版本开始通过 &lt;a href=&#34;https://istio.io/v0.2/docs/setup/kubernetes/mesh-expansion.html&#34;&gt;Istio Mesh Expansion&lt;/a&gt; 将虚拟机加入的 Mesh 中，但是需要满足以下前提条件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;虚拟机必须可以通过 IP 地址直接访问到应用的 Pod，这就要求容器与 VM 之间通过 VPC 或者 VPN 建立扁平网络，虚拟机不需要访问 Cluster IP，直接对服务的 Endpoint 端点访问即可。&lt;/li&gt;
&lt;li&gt;虚拟机必须可以访问到 Istio 的控制平面服务（Pilot、Mixer、CA，现在已正整合为 Istiod），可以通过在 Istio Mesh 中部署负载均衡器将控制平面端点暴露给虚拟机。&lt;/li&gt;
&lt;li&gt;（可选）虚拟机可以访问到 Mesh 内部的（部署在 Kubernetes 中）的 DNS server。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;集成虚拟机的步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为 Istio 控制平面服务及 Kubernetes 集群的 DNS 服务创建 Internal 负载均衡器；&lt;/li&gt;
&lt;li&gt;生成 Istio Service CIDR、Service Account token、安全证书、Istio 控制平面服务的 IP（通过 Internal 负载均衡器暴露出来的 IP）的配置文件并发送给虚拟机；&lt;/li&gt;
&lt;li&gt;（可选）在虚拟机中安装、配置并启动 Istio 的组件、dnsmaq（用于DNS 发现），此时虚拟机可以使用   FQDN 访问 mesh 中的服务了，这一步是为了保证虚拟机可以正确解析出 mesh 中服务的 Cluster IP；&lt;/li&gt;
&lt;li&gt;若要在虚拟机中运行服务，需要配置 sidecar，新增需要拦截的 inbound 端口，然后重启 istio，还需要运行 istioctl 为服务注册&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示的从集成虚拟机到在 mesh 中访问虚拟机中服务的详细流程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;0081Kckwly1gm0d6rogojj30u00yhdil.jpg&#34; alt=&#34;图一：从集成虚拟机到在 mesh 中访问虚拟机中服务的详细流程&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DNS 被虚拟机中部署的 &lt;code&gt;dnsmasq&lt;/code&gt; 劫持，这使得它可以正确的获取 Istio 服务、Kubernetes 内置 DNS 的端点 IP；&lt;/li&gt;
&lt;li&gt;访问 Kubernetes 的内置 DNS 服务（该服务已通过 Internal 负载均衡器暴露到集群外，可以直接访问）；&lt;/li&gt;
&lt;li&gt;返回 &lt;code&gt;productpage.bookinfo.svc.cluster.local&lt;/code&gt; 被解析出来的 Cluster IP，注意该 IP 地址无法直接访问，但是如果无法被 DNS 解析的话将导致 VM 对该服务的请求失败；&lt;/li&gt;
&lt;li&gt;虚拟机对 mesh 中服务的访问被 sidecar proxy 劫持；&lt;/li&gt;
&lt;li&gt;因为 proxy 已连接 Istio 控制平面，可通过 xDS 查询到该服务的端点，因此流量将被转发到其中的一个端点。关于这一步的详细过程请参考 &lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/sidecar-traffic-route.html&#34;&gt;Istio Handbook 中的 sidecar 流量路由机制分析 一节&lt;/a&gt;；&lt;/li&gt;
&lt;li&gt;要想在 mesh 中访问 VM 中的服务，需要使用 &lt;code&gt;istioctl register&lt;/code&gt; 命令手动将 VM 中的服务添加到 mesh 中，这本质上是将 VM 中的服务，注册到 Kubernetes 中的 service 和 endpoint；&lt;/li&gt;
&lt;li&gt;mesh 中的服务可以使用 VM 注册的服务名称（FQDN，例如 &lt;code&gt;mysql.vm.svc.cluster.local&lt;/code&gt;）来访问；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上 Istio 对虚拟机支持的方式一直延续到 Istio 1.0，在 Istio 1.1 的时候引入了新的 API &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/service-entry/&#34;&gt;ServiceEntry&lt;/a&gt;，使用它可以在 Istio 的内部服务注册表中添加额外的条目，这样 mesh 中的服务就可以访问/路由到这些手动指定的服务了，不再需要运行 &lt;code&gt;istioctl register&lt;/code&gt; 命令，而且该命令在 Istio 1.9 中将被废弃。&lt;/p&gt;
&lt;p&gt;Istio 1.5 中增加了 &lt;code&gt;istioctl experimental add-to-mesh&lt;/code&gt; 命令，可以将虚拟机中的服务添加到 mesh 中，其功能与 &lt;code&gt;istioctl register&lt;/code&gt; 一样。&lt;/p&gt;
&lt;h3 id=&#34;新增资源抽象&#34;&gt;新增资源抽象&lt;/h3&gt;
&lt;p&gt;Istio 从 &lt;a href=&#34;https://istio.io/latest/news/releases/1.6.x/announcing-1.6/&#34;&gt;1.6 版本&lt;/a&gt;开始在&lt;a href=&#34;https://istio.io/latest/news/releases/1.6.x/announcing-1.6/change-notes/&#34;&gt;流量管理&lt;/a&gt;中引入了新的资源类型 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/workload-entry/&#34;&gt;WorkloadEntry&lt;/a&gt;，用以将虚拟机进行抽象，使得虚拟机在加入 mesh 后可以作为与 Kubernetes 中的 Pod 等同的负载，具备流量管理、安全管理、可视化等能力。通过 &lt;code&gt;WorkloadEntry&lt;/code&gt; 可以简化虚拟机的网格化配置过程。&lt;code&gt;WorkloadEntry&lt;/code&gt; 对象可以根据服务条目中指定的标签选择器选择多个工作负载条目和 Kubernetes pod。&lt;/p&gt;
&lt;p&gt;Istio 1.8 中增加了 &lt;a href=&#34;http://istio.io/latest/docs/reference/config/networking/workload-group/&#34;&gt;&lt;code&gt;WorkloadGroup&lt;/code&gt;&lt;/a&gt; 的资源对象，它提供了一个规范，可以同时包括虚拟机和 Kubernetes 工作负载，旨在模仿现有的用于 Kubernetes 工作负载的 sidecar 注入和部署规范模型来引导 Istio 代理。&lt;/p&gt;
&lt;p&gt;下面是虚拟机与 Kubernetes 中负载的资源抽象层级对比。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;对比项&lt;/th&gt;
&lt;th&gt;Kubernetes&lt;/th&gt;
&lt;th&gt;虚拟机&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;基础调度单位&lt;/td&gt;
&lt;td&gt;Pod&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;编排组合&lt;/td&gt;
&lt;td&gt;Deployment&lt;/td&gt;
&lt;td&gt;WorkloadGroup&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;服务注册与发现&lt;/td&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;从上面的图表中我们可以看到，对于虚拟机工作负载是可以与 Kubernetes 中的负载一一对对应的。&lt;/p&gt;
&lt;p&gt;此时看似一切都比较完美了，但是直接将 Kubernetes 集群中的 DNS server 暴露出来会带来很大的&lt;a href=&#34;https://blog.aquasec.com/dns-spoofing-kubernetes-clusters&#34;&gt;安全风险&lt;/a&gt;，因此我们一般手动将虚拟机需要访问的服务的域名和 Cluster IP 对写到本机的 &lt;code&gt;/etc/hosts&lt;/code&gt; 中，但是对于一个节点数量庞大的分布式集群来说，这种做法又有些不现实。&lt;/p&gt;
&lt;p&gt;通过配置虚拟机本地 &lt;code&gt;/etc/hosts&lt;/code&gt; 访问 mesh 内服务的流程，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;0081Kckwly1gm0d6qx2o0j30sq0v440v.jpg&#34; alt=&#34;图二：通过配置虚拟机本地 /etc/hosts 访问 mesh 内服务的流程&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将虚拟机中的服务注册到 mesh 中；&lt;/li&gt;
&lt;li&gt;将要访问的服务的域名、Cluster IP 对手动写入虚拟机本地的 &lt;code&gt;/etc/hosts&lt;/code&gt; 文件中；&lt;/li&gt;
&lt;li&gt;虚拟机获得访问服务的 Cluster IP；&lt;/li&gt;
&lt;li&gt;流量被 sidecar proxy 拦截并解析出要访问的服务的端点地址；&lt;/li&gt;
&lt;li&gt;访问服务的指定端点；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在 Kubernetes 中我们一般使用 Service 对象来实现服务的注册和发现，每个服务都有一个独立的 DNS 名称，应用程序可以使用服务名称来互相调用。我们可以使用 ServiceEntry 将虚拟机中的服务注册到 Istio 的服务注册表中，但是在 Kubernetes 集群中的 DNS server 无法对 mesh 外部暴露的情况下，虚拟机无法访问 Kubernetes 集群中的 DNS 服务以获取服务的 Cluster IP，从而导致虚拟机访问 mesh 中的服务失败。如果能在虚拟机中增加一个 sidecar 可以透明地拦截 DNS 请求，可获取 mesh 内所有服务的 ClusterIP，类似于图一中的 &lt;code&gt;dnsmasq&lt;/code&gt; 的角色，这样不就可以解决问题了吗？&lt;/p&gt;
&lt;h3 id=&#34;智能-dns-代理&#34;&gt;智能 DNS 代理&lt;/h3&gt;
&lt;p&gt;Istio 1.8 中引入了&lt;a href=&#34;https://cloudnative.to/blog/istio-dns-proxy/&#34;&gt;智能 DNS 代理&lt;/a&gt;，虚拟机访问 mesh 内服务无需再配置 &lt;code&gt;/ect/hosts&lt;/code&gt;，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;0081Kckwly1gm0d6sgfpxj30oi0rsjt5.jpg&#34; alt=&#34;图三：引入了智能 DNS 代理后虚拟机访问 mesh 内服务的流程&#34;&gt;&lt;/p&gt;
&lt;p&gt;DNS proxy 是用 Go 编写的 Istio sidecar 代理。Sidecar 上的 Istio agent 将附带一个由 Istiod 动态编程的缓存 DNS 代理。来自应用程序的 DNS 查询会被 pod 或 VM 中的 Istio 代理透明地拦截和服务，该代理会智能地响应 DNS 查询请求，可以实现虚拟机到服务网格的无缝多集群访问。&lt;/p&gt;
&lt;p&gt;至此，Istio 1.8 中引入的 WordloadGroup 及智能 DNS 代理，补足了 Istio 对虚拟机支持的最后一块短板，使得部署在虚拟机中的遗留应用可以跟 Kubernetes 中的 Pod 一样完全等同看待。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在这部 Istio 支持虚拟机的奥德赛中，我们可以看到：从最初的将 mesh 中的 DNS server 暴露给外部，在虚拟机中安装配置 &lt;code&gt;dnsmasq&lt;/code&gt;，到最后的使用智能 DNS 代理，并使用 &lt;code&gt;WorkloadEntry&lt;/code&gt;、&lt;code&gt;WorkloadGroup&lt;/code&gt; 和 &lt;code&gt;ServiceEntry&lt;/code&gt; 等资源抽象，逐步实现了虚拟机和 pod 的统一管理。本文仅仅是针对单集群的情况，在实际的生产中使用还远远不够，我们还需要处理安全、多集群、多租户等诸多问题，欢迎关注 Tetrate 的旗舰产品 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt; 了解更多关于 Istio 应用在生产上的最佳实践。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 1.8——用户至上的选择</title>
      <link>https://jimmysong.io/blog/istio-18-release/</link>
      <pubDate>Fri, 20 Nov 2020 08:34:40 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-18-release/</guid>
      <description>
        
        
        &lt;p&gt;今天 &lt;a href=&#34;https://istio.io/latest/news/releases/1.8.x/announcing-1.8/&#34;&gt;Istio 1.8&lt;/a&gt; 发布了，这是 Istio 在 2020 年发布的最后一个版本，按照 Istio 社区在&lt;a href=&#34;https://istio.io/latest/blog/2020/tradewinds-2020/&#34;&gt;今年初设定的目标&lt;/a&gt;继续推进，该版本主要有以下更新：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持使用 Helm 3 进行安装和升级&lt;/li&gt;
&lt;li&gt;正式移除了 Mixer&lt;/li&gt;
&lt;li&gt;新增了 Istio DNS proxy，透明地拦截应用程序的 DNS 查询，实现智能应答&lt;/li&gt;
&lt;li&gt;新增了 &lt;code&gt;WorkloadGroup&lt;/code&gt; 以简化对虚拟机的引入&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;WorkloadGroup &lt;/code&gt;是一个新的 API 对象，旨在与虚拟机等非 Kubernetes 工作负载一起使用，模仿现有的用于 Kubernetes 工作负载的 sidecar 注入和部署规范模型来引导 Istio 代理。&lt;/p&gt;
&lt;h2 id=&#34;安装与升级&#34;&gt;安装与升级&lt;/h2&gt;
&lt;p&gt;Istio 从 1.5 版本开始弃用了 Helm，使用 &lt;code&gt;istioctl manifest&lt;/code&gt; 方式安装，后来又改成了 &lt;code&gt;istioctl install&lt;/code&gt;，现在又重新回归了 Helm，Helm 作为 Kubernetes 环境下最常用的应用安装管理组件，此次回归也是倾听用户声音，优化安装体验的的反应吧，不过 Istio Operator 依然将是 Istio 安装的最终形式，从 1.8 版本开始 Istio 支持使用 &lt;a href=&#34;https://istio.io/latest/docs/setup/install/helm/&#34;&gt;Helm&lt;/a&gt; 进行 in-place 升级和 canary 升级。&lt;/p&gt;
&lt;h2 id=&#34;增强-istio-的易用性&#34;&gt;增强 Istio 的易用性&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;istioctl&lt;/code&gt; 命令行工具新的了 bug reporting 功能（&lt;code&gt;istioctl bug-report&lt;/code&gt;），可以用来收集调试信息和获取集群状态。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://istio.io/latest/blog/2020/addon-rework/&#34;&gt;安装 add-on&lt;/a&gt; 的方式变了，在 1.7 中已经不推荐使用 istioctl 来安装，在 1.8 中直接被移除了，这样有利于解决 add-on 落后于上游及难以维护的问题。&lt;/p&gt;
&lt;p&gt;正式移除了 Mixer，推荐使用 &lt;a href=&#34;https://istio.io/latest/blog/2020/wasm-announce/&#34;&gt;WebAssembly&lt;/a&gt; 通过扩展 Envoy 的方式来扩展 Istio，也推荐大家使用 &lt;a href=&#34;https://www.getenvoy.io/reference/getenvoy_extension_toolkit_reference/&#34;&gt;GetEnvoy Toolkit&lt;/a&gt; 来进行 Envoy 的扩展开发。&lt;/p&gt;
&lt;h2 id=&#34;对虚拟机的支持&#34;&gt;对虚拟机的支持&lt;/h2&gt;
&lt;p&gt;在我&lt;a href=&#34;https://thenewstack.io/how-to-integrate-virtual-machines-into-istio-service-mesh/&#34;&gt;之前的博客&lt;/a&gt;中谈到 Istio 1.7 如何支持虚拟机，在 Istio 1.8 中新增了&lt;a href=&#34;https://istio.io/latest/blog/2020/dns-proxy/&#34;&gt;智能 DNS 代理&lt;/a&gt;，它是由 Go 编写的 Istio sidecar 代理，sidecar 上的 Istio agent 将附带一个由 Istiod 动态编程的缓存 DNS 代理。来自应用程序的 DNS 查询会被 pod 或 VM 中的 Istio 代理透明地拦截和服务，该代理会智能地响应 DNS 查询请求，可以实现虚拟机到服务网格的无缝多集群访问。&lt;/p&gt;
&lt;p&gt;新增了 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/workload-group/&#34;&gt;WorkloadGroup&lt;/a&gt; ，它描述了工作负载实例的集合。提供了一个规范，工作负载实例可以用来引导它们的代理，包括元数据和身份。它只打算与虚拟机等非 Kubernetes 工作负载一起使用，旨在模仿现有的用于 Kubernetes 工作负载的sidecar注入和部署规范模型来引导 Istio 代理。&lt;/p&gt;
&lt;p&gt;在 &lt;a href=&#34;https://tetrate.io&#34;&gt;Tetrate&lt;/a&gt;，我们在客户的多集群部署中广泛使用这种机制，以使 sidecar 能够为暴露在网格中所有集群的入口网关的主机解析 DNS，并通过 mTLS 访问。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;总而言之，Istio 团队履行了&lt;a href=&#34;https://istio.io/latest/blog/2020/tradewinds-2020/&#34;&gt;年初的承诺&lt;/a&gt;，自 2018 年发布 1.1 版本发布起，保持了固定的发布节奏，每 3 个月发布一个版本，在性能、用户体验上持续优化，以满足 brownfiled 应用与 greenfield 应用在 Istio 上的无缝体验。我们期待 Istio 在 2021 年可以给我们带来更多惊喜。&lt;/p&gt;
&lt;p&gt;最后，感谢&lt;a href=&#34;https://github.com/malphi&#34;&gt;马若飞&lt;/a&gt;对本文的审阅。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>如何在 Istio Service Mesh 中集成虚拟机？</title>
      <link>https://jimmysong.io/blog/how-to-integrate-virtual-machines-into-istio-service-mesh/</link>
      <pubDate>Mon, 02 Nov 2020 16:43:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/how-to-integrate-virtual-machines-into-istio-service-mesh/</guid>
      <description>
        
        
        &lt;p&gt;Istio 是目前最流行的服务网格，用于连接、保护、控制和观察服务。当其 2017 年开源时，Kubernetes 已赢得容器编排之战，Istio 为了满足组织转向微服务的需求。虽然 Istio 声称支持异构环境，如 Nomad、Consul、Eureka、Cloud Foundry、Mesos 等，但实际上，它一直与 Kubernetes 合作得最好–它的服务发现就是基于 Kubernetes。&lt;/p&gt;
&lt;p&gt;Istio 在发展初期就因为一些问题而饱受诟病，比如组件数量多、安装和维护复杂、调试困难、由于引入了太多的新概念和对象（多达 50 个 CRD）而导致学习曲线陡峭，以及 Mixer 组件对性能的影响。但这些问题正在被 Istio 团队逐渐克服。从 2020 年初发布的&lt;a href=&#34;https://istio.io/latest/zh/blog/2020/tradewinds-2020/&#34;&gt;路线图&lt;/a&gt;中可以看出，Istio 已经取得了长足的进步。&lt;/p&gt;
&lt;p&gt;将基于虚拟机的工作负载更好地集成到服务网格中，是 Istio 团队今年的一大重点。Tetrate 还通过其产品 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34;&gt;Tetrate Service Bridge&lt;/a&gt; 提供了无缝的多云连接、安全性和可观察性，包括针对虚拟机的。本文将带您了解为什么 Istio 需要与虚拟机整合，以及如何整合。&lt;/p&gt;
&lt;h2 id=&#34;istio-为什么要支持虚拟机&#34;&gt;Istio 为什么要支持虚拟机？&lt;/h2&gt;
&lt;p&gt;虽然现在容器和 Kubernetes 已经被广泛使用，但仍然有很多部署在虚拟机上的服务和 Kubernetes 集群之外的 API 需要由 Istio mesh 来管理。如何将棕地环境与绿地环境统一管理，这是一个巨大的挑战。&lt;/p&gt;
&lt;h2 id=&#34;将虚拟机引入到网格中需要具备什么条件&#34;&gt;将虚拟机引入到网格中需要具备什么条件？&lt;/h2&gt;
&lt;p&gt;在介绍如何集成虚拟机之前，我先介绍一下将虚拟机添加到 Mesh 中需要什么条件。在支持虚拟机流量时，Istio 必须知道几件事：哪些虚拟机的服务要添加到 Mesh 中，以及如何访问虚拟机。每个虚拟机还需要一个身份，以便与服务网格的其他部分安全地通信。这些需求可以和 Kubernetes CRD 一起工作，也可以和 Consul 这样的完整的服务注册表一起工作。而基于服务账户的身份引导机制，为没有平台身份的虚拟机分配工作负载身份。对于有平台身份的虚拟机（如 EC2、GCP、Azure 等），Istio 正在进行这方面的工作，将平台身份与 Kubernetes 身份进行交换，方便设置 mTLS 通信。&lt;/p&gt;
&lt;h2 id=&#34;istio-如何支持虚拟机&#34;&gt;Istio 如何支持虚拟机？&lt;/h2&gt;
&lt;p&gt;Istio 对虚拟机的支持始于其服务注册表机制。Istio mesh 中的服务和实例信息来自 Istio 的服务注册表，到目前为止，Istio 的服务注册表只关注或跟踪 pod。在新的版本中，Istio 现在有资源类型来跟踪和观察虚拟机。网格内的 sidecar 无法观察和控制网格外服务的流量，因为它们没有任何信息。&lt;/p&gt;
&lt;p&gt;Istio 社区和 &lt;a href=&#34;https://www.tetrate.io/&#34;&gt;Tetrate&lt;/a&gt; 在 Istio 对虚拟机的支持上做了&lt;a href=&#34;https://www.tetrate.io/blog/istio-bringing-vms-into-the-mesh-with-cynthia-coan/&#34;&gt;很多工作&lt;/a&gt;。1.6 版本中增加了 WorkloadEntry，它允许你像描述 Kubernetes 中运行的主机一样描述虚拟机。在 1.7 版本中，该版本开始增加了通过令牌将虚拟机自动引导到 service mesh 中的基础，Istio 做了大量的工作。Istio 1.8 将首次推出另一个名为 WorkloadGroup 的抽象，它类似于 Kubernetes Deployment 对象 —— 但适用于虚拟机。&lt;/p&gt;
&lt;p&gt;下图显示了 Istio 如何在网格中对服务进行建模。最主要的信息来源来自于 Kubernetes 这样的平台服务注册表，或者 Consul 这样的系统。此外，ServiceEntry 作为用户定义的服务注册表，对虚拟机上的服务或组织外部的服务进行建模。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/0081Kckwly1gkc4ldbqzhj30p30ehwf5.jpg&#34; alt=&#34;Istio 中的服务注册发现模型&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;为什么不直接使用 ServiceEntry 引入虚拟机中的服务，却还要大费周折在虚拟机中安装 Istio？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 ServiceEntry，你可以让网格内部的服务发现和访问外部服务；此外，还可以管理这些外部服务的流量。结合 VirtualService，你还可以为相应的外部服务配置访问规则，比如请求超时、故障注入等，从而实现对指定外部服务的控制访问。 即便如此，它也只能控制客户端的流量，而不能控制引入的外部服务对其他服务的访问。也就是说，它不能控制作为调用发起者的服务的行为。在虚拟机中部署 sidecar，通过工作负载选择器引入虚拟机工作负载，可以像 Kubernetes 中的 pod 一样，对虚拟机进行无差别管理。&lt;/p&gt;
&lt;h2 id=&#34;demo&#34;&gt;Demo&lt;/h2&gt;
&lt;p&gt;在下面这个 demo 中我们将使在 GKE 中部署 Istio 并运行 bookinfo 示例，其中 ratings 服务的后端使用的是部署在虚拟机上的 MySQL，该示例可以在 &lt;a href=&#34;https://istio.io/latest/docs/examples/virtual-machines/bookinfo/&#34;&gt;Istio 官方文档&lt;/a&gt;中找到，我作出了部分改动，最终的流量路由如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://tva1.sinaimg.cn/large/0081Kckwly1gkc4lch5epj318g0avwfx.jpg&#34; alt=&#34;Bookinfo 示例中的流量示意图&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;安装流程&#34;&gt;安装流程&lt;/h3&gt;
&lt;p&gt;下面是示例的安装步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在 Google Cloud 中部署 Kubernetes 集群，Kubernetes 版本是 1.16.13；&lt;/li&gt;
&lt;li&gt;在 GKE 中安装 Istio 1.7.1；&lt;/li&gt;
&lt;li&gt;在 Google Cloud 中启动一台虚拟机并配置 Istio，将其加入到 Istio Mesh 中，这一步需要很多手动操作，生成证书、创建 token、配置 hosts 等；&lt;/li&gt;
&lt;li&gt;在 Istio Mesh 中部署 bookinfo 示例；&lt;/li&gt;
&lt;li&gt;在虚拟机中安装 MySQL；&lt;/li&gt;
&lt;li&gt;为虚拟机设置 VPC 防火箱规则；&lt;/li&gt;
&lt;li&gt;将虚拟机中的 MySQL 服务作为 ServiceEntry 引入到 Mesh 中并作为 rating 服务的后端；&lt;/li&gt;
&lt;li&gt;修改 MySQL 表中的数据，验证 bookinfo 中的 rating 相应的行为符合预期；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;未来方向&#34;&gt;未来方向&lt;/h2&gt;
&lt;p&gt;从 &lt;a href=&#34;https://istio.io/latest/docs/examples/virtual-machines/bookinfo/&#34;&gt;bookinfo&lt;/a&gt; 的演示中可以看出，在这个过程中涉及到的人工工作太多，很容易出错。在未来，Istio 会改进虚拟机测试的可操作性，根据平台身份自动引导，改进 DNS 支持和 istioctl 调试等。大家可以关注 &lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md&#34;&gt;Istio 环境工作组&lt;/a&gt;，了解更多关于虚拟机支持的细节。&lt;/p&gt;
&lt;h2 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/setup/install/virtual-machine/&#34;&gt;Virtual Machine Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/docs/examples/virtual-machines/single-network/&#34;&gt;Virtual Machines in Single-Network Meshes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/blog/istio-bringing-vms-into-the-mesh-with-cynthia-coan/&#34;&gt;Istio: Bringing VMs into the Mesh (with Cynthia Coan)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tetrate.io/blog/bridging-traditional-and-modern-workloads/&#34;&gt;Bridging Traditional and Modern Workloads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Service Mesh——后 Kubernetes 时代的微服务</title>
      <link>https://jimmysong.io/blog/service-mesh-the-microservices-in-post-kubernetes-era/</link>
      <pubDate>Wed, 01 Apr 2020 11:56:04 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/service-mesh-the-microservices-in-post-kubernetes-era/</guid>
      <description>
        
        
        &lt;p&gt;本文是以前所写内容的重新修订并收录于 ServiceMesher 社区的 &lt;a href=&#34;https://www.servicemesher.com/istio-handbook&#34;&gt;Istio Handbook&lt;/a&gt; 中，其他章节仍在编纂中。&lt;/p&gt;
&lt;p&gt;如果你刚听说 Service Mesh 不久，并试用过 &lt;a href=&#34;https://istio.io&#34;&gt;Istio&lt;/a&gt; 的话，那么你可能都会有下面几个疑问：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为什么 Istio 要运行在 Kubernetes 上呢？&lt;/li&gt;
&lt;li&gt;Kubernetes 和 Service Mesh 分别在云原生中扮演什么角色？&lt;/li&gt;
&lt;li&gt;Istio 扩展了 Kubernetes 的哪些方面？解决了哪些问题？&lt;/li&gt;
&lt;li&gt;Kubernetes、xDS 协议（&lt;a href=&#34;https://github.com/envoyproxy/envoy&#34;&gt;Envoy&lt;/a&gt;、&lt;a href=&#34;https://github.com/mosn/mosn&#34;&gt;MOSN&lt;/a&gt; 等）与 Istio 之间又是什么关系？&lt;/li&gt;
&lt;li&gt;到底该不该上 Service Mesh？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这一节我们将试图带您梳理清楚 Kubernetes、xDS 协议以及 Istio Service Mesh 之间的内在联系。此外，本节还将介绍 Kubernetes 中的负载均衡方式，xDS 协议对于 Service Mesh 的意义以及为什么说及时有了 Kubernetes 还需要 Istio。&lt;/p&gt;
&lt;p&gt;使用 Service Mesh 并不是说与 Kubernetes 决裂，而是水到渠成的事情。Kubernetes 的本质是通过声明式配置对应用进行生命周期管理，而 Service Mesh 的本质是提供应用间的流量和安全性管理以及可观察性。假如你已经使用 Kubernetes 构建了稳定的应用平台，那么如何设置服务间调用的负载均衡和流量控制？&lt;/p&gt;
&lt;p&gt;Envoy 创造的 xDS 协议被众多开源软件所支持，如 &lt;a href=&#34;https://github.com/istio/istio&#34;&gt;Istio&lt;/a&gt;、&lt;a href=&#34;https:/github.com/mosn/mosn&#34;&gt;MOSN&lt;/a&gt; 等。Envoy 对于 Service Mesh 或云原生来说最大的贡献就是定义了 xDS，Envoy 本质上是一个 proxy，是可通过 API 配置的现代版 proxy，基于它衍生出来很多不同的使用场景，如 API Gateway、Service Mesh 中的 Sidecar proxy 和边缘代理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;本节包含以下内容&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;说明 kube-proxy 的作用。&lt;/li&gt;
&lt;li&gt;Kubernetes 在微服务管理上的局限性。&lt;/li&gt;
&lt;li&gt;介绍 Istio Service Mesh 的功能。&lt;/li&gt;
&lt;li&gt;介绍 xDS 包含哪些内容。&lt;/li&gt;
&lt;li&gt;比较 Kubernetes、Envoy 和 Istio Service Mesh 中的一些概念。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;重要观点&#34;&gt;重要观点&lt;/h2&gt;
&lt;p&gt;如果你想要提前了解下文的所有内容，那么可以先阅读下面列出的本文中的一些主要观点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 的本质是应用的生命周期管理，具体来说就是部署和管理（扩缩容、自动恢复、发布）。&lt;/li&gt;
&lt;li&gt;Kubernetes 为微服务提供了可扩展、高弹性的部署和管理平台。&lt;/li&gt;
&lt;li&gt;Service Mesh 的基础是透明代理，通过 sidecar proxy 拦截到微服务间流量后再通过控制平面配置管理微服务的行为。&lt;/li&gt;
&lt;li&gt;Service Mesh 将流量管理从 Kubernetes 中解耦，Service Mesh 内部的流量无需 &lt;code&gt;kube-proxy&lt;/code&gt; 组件的支持，通过为更接近微服务应用层的抽象，管理服务间的流量、安全性和可观察性。&lt;/li&gt;
&lt;li&gt;xDS 定义了 Service Mesh 配置的协议标准。&lt;/li&gt;
&lt;li&gt;Service Mesh 是对 Kubernetes 中的 service 更上层的抽象，它的下一步是 serverless。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-service-mesh&#34;&gt;Kubernetes vs Service Mesh&lt;/h2&gt;
&lt;p&gt;下图展示的是 Kubernetes 与 Service Mesh 中的的服务访问关系（每个 pod 一个 sidecar 的模式）。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;kubernetes-vs-service-mesh.png&#34; alt=&#34;kubernetes 对比 service mesh&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;流量转发&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes 集群的每个节点都部署了一个 &lt;code&gt;kube-proxy&lt;/code&gt; 组件，该组件会与 Kubernetes API Server 通信，获取集群中的 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html&#34;&gt;service&lt;/a&gt; 信息，然后设置 iptables 规则，直接将对某个 service 的请求发送到对应的 Endpoint（属于同一组 service 的 pod）上。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务发现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio-service-registry.png&#34; alt=&#34;Service Mesh 中的服务注册&#34;&gt;&lt;/p&gt;
&lt;p&gt;Istio 可以沿用 Kubernetes 中的 service 做服务注册，还可以通过控制平面的平台适配器对接其他服务发现系统，然后生成数据平面的配置（使用 CRD 声明，保存在 etcd 中），数据平面的&lt;strong&gt;透明代理&lt;/strong&gt;（transparent proxy）以 sidecar 容器的形式部署在每个应用服务的 pod 中，这些 proxy 都需要请求控制平面来同步代理配置。之所以说是透明代理，是因为应用程序容器完全无感知代理的存在，该过程 kube-proxy 组件一样需要拦截流量，只不过 &lt;code&gt;kube-proxy&lt;/code&gt; 拦截的是进出 Kubernetes 节点的流量，而 sidecar proxy 拦截的是进出该 Pod 的流量，详见&lt;a href=&#34;https://jimmysong.io/blog/envoy-sidecar-routing-of-istio-service-mesh-deep-dive/&#34;&gt;理解 Istio Service Mesh 中 Envoy Sidecar 代理的路由转发&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service Mesh 的劣势&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为 Kubernetes 每个节点上都会运行众多的 Pod，将原先 &lt;code&gt;kube-proxy&lt;/code&gt; 方式的路由转发功能置于每个 pod 中，因为有 sidecar 拦截流量会多一次跳转时，增加响应延迟，同时大量的配置分发、配置同步，可能会影响应用性能。为了细粒度地进行流量管理，必将添加一系列新的抽象，从而会进一步增加用户的学习成本，但随着技术的普及，这样的情况会慢慢地得到缓解。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service Mesh 的优势&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kube-proxy&lt;/code&gt; 的设置都是全局生效的，无法对每个服务做细粒度的控制，而 Service Mesh 通过 sidecar proxy 的方式将 Kubernetes 中对流量的控制从 service 一层抽离出来，可以做更多的扩展。&lt;/p&gt;
&lt;h2 id=&#34;kube-proxy-组件&#34;&gt;kube-proxy 组件&lt;/h2&gt;
&lt;p&gt;在 Kubernetes 集群中，每个 Node 运行一个 &lt;code&gt;kube-proxy&lt;/code&gt; 进程。&lt;code&gt;kube-proxy&lt;/code&gt; 负责为 &lt;code&gt;Service&lt;/code&gt; 实现了一种 VIP（虚拟 IP）的形式。 在 Kubernetes v1.0 版本，代理完全在 userspace 实现。Kubernetes v1.1 版本新增了 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html#iptables-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F&#34;&gt;iptables 代理模式&lt;/a&gt;，但并不是默认的运行模式。从 Kubernetes v1.2 起，默认使用 iptables 代理。在 Kubernetes v1.8.0-beta.0 中，添加了 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html#ipvs-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F&#34;&gt;ipvs 代理模式&lt;/a&gt;。关于 kube-proxy 组件的更多介绍请参考 &lt;a href=&#34;https://cizixs.com/2017/03/30/kubernetes-introduction-service-and-kube-proxy/&#34;&gt;kubernetes 简介：service 和 kube-proxy 原理&lt;/a&gt; 和 &lt;a href=&#34;https://jishu.io/kubernetes/ipvs-loadbalancer-for-kubernetes/&#34;&gt;使用 IPVS 实现 Kubernetes 入口流量负载均衡&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;kube-proxy-的缺陷&#34;&gt;kube-proxy 的缺陷&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://cizixs.com/2017/03/30/kubernetes-introduction-service-and-kube-proxy/&#34;&gt;kube-proxy 的不足之处&lt;/a&gt;：&lt;/p&gt;
&lt;p&gt;首先，如果转发的 pod 不能正常提供服务，它不会自动尝试另一个 pod，每个 pod 都有一个健康检查的机制，当有 pod 健康状况有问题时，kubelet 会重启对应的 pod，kube-proxy 会删除对应的转发规则。另外，&lt;code&gt;nodePort&lt;/code&gt; 类型的服务也无法添加 TLS 或者更复杂的报文路由机制。&lt;/p&gt;
&lt;p&gt;Kube-proxy 实现了流量在 Kubernetes service 多个 pod 实例间的负载均衡，但是如何对这些 service 间的流量做细粒度的控制，比如按照百分比划分流量到不同的应用版本（这些应用都属于同一个 service，但位于不同的 deployment 上），做金丝雀发布（灰度发布）和蓝绿发布？Kubernetes 社区给出了 &lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments&#34;&gt;使用 Deployment 做金丝雀发布的方法&lt;/a&gt;，该方法本质上就是通过修改 pod 的 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/label.html&#34;&gt;label&lt;/a&gt; 来将不同的 pod 划归到 Deployment 的 Service 上。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-ingress-vs-istio-gateway&#34;&gt;Kubernetes Ingress vs Istio Gateway&lt;/h2&gt;
&lt;p&gt;上文说到 &lt;code&gt;kube-proxy&lt;/code&gt; 只能路由 Kubernetes 集群内部的流量，而我们知道 Kubernetes 集群的 Pod 位于 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/cni.html&#34;&gt;CNI&lt;/a&gt; 创建的网络中，集群外部是无法直接与其通信的，因此 Kubernetes 中创建了 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/ingress.html&#34;&gt;ingress&lt;/a&gt; 这个资源对象，它由位于 Kubernetes &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/edge-node-configuration.html&#34;&gt;边缘节点&lt;/a&gt;（这样的节点可以是很多个也可以是一组）的 Ingress controller 驱动，负责管理&lt;strong&gt;南北向流量&lt;/strong&gt;，Ingress 必须对接各种 Ingress Controller 才能使用，比如 &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;nginx ingress controller&lt;/a&gt;、&lt;a href=&#34;https://traefik.io/&#34;&gt;traefik&lt;/a&gt;。Ingress 只适用于 HTTP 流量，使用方式也很简单，只能对 service、port、HTTP 路径等有限字段匹配来路由流量，这导致它无法路由如 MySQL、Redis 和各种私有 RPC 等 TCP 流量。要想直接路由南北向的流量，只能使用 Service 的 LoadBalancer 或 NodePort，前者需要云厂商支持，后者需要进行额外的端口管理。有些 Ingress controller 支持暴露 TCP 和 UDP 服务，但是只能使用 Service 来暴露，Ingress 本身是不支持的，例如 &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/&#34;&gt;nginx ingress controller&lt;/a&gt;，服务暴露的端口是通过创建 ConfigMap 的方式来配置的。&lt;/p&gt;
&lt;p&gt;Istio Gateway 的功能与 Kubernetes Ingress 类似，都是负责集群的南北向流量。Istio &lt;code&gt;Gateway&lt;/code&gt; 描述的负载均衡器用于承载进出网格边缘的连接。该规范中描述了一系列开放端口和这些端口所使用的协议、负载均衡的 SNI 配置等内容。Gateway 是一种 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/crd.html&#34;&gt;CRD 扩展&lt;/a&gt;，它同时复用了 sidecar proxy 的能力，详细配置请参考 &lt;a href=&#34;https://istio.io/docs/reference/config/networking/gateway/&#34;&gt;Istio 官网&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;xds-协议&#34;&gt;xDS 协议&lt;/h2&gt;
&lt;p&gt;下面这张图大家在了解 Service Mesh 的时候可能都看到过，每个方块代表一个服务的实例，例如 Kubernetes 中的一个 Pod（其中包含了 sidecar proxy），xDS 协议控制了 Istio Service Mesh 中所有流量的具体行为，即将下图中的方块链接到了一起。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;service-mesh-schematic-diagram.png&#34; alt=&#34;Service Mesh 示意图&#34;&gt;&lt;/p&gt;
&lt;p&gt;xDS 协议是由 &lt;a href=&#34;https://envoyproxy.io/&#34;&gt;Envoy&lt;/a&gt; 提出的，在 Envoy v2 版本 API 中最原始的 xDS 协议指的是 CDS（Cluster Discovery Service）、EDS（Endpoint Discovery service）、LDS（Listener Discovery Service） 和 RDS（Route Discovery Service），后来在 v3 版本中又发展出了 Scoped Route Discovery Service（SRDS）、Virtual Host Discovery Service （VHDS）、Secret Discovery Service（SDS）、Runtime Discovery Service（RTDS）等，详见 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol&#34;&gt;xDS REST and gRPC protocol&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面我们以各有两个实例的 service，来看下 xDS 协议。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;xds-protocol.png&#34; alt=&#34;xDS 协议&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中的箭头不是流量进入 Proxy 后的路径或路由，也不是实际顺序，而是想象的一种 xDS 接口处理顺序，其实 xDS 之间也是有交叉引用的。&lt;/p&gt;
&lt;p&gt;支持 xDS 协议的代理通过查询文件或管理服务器来动态发现资源。概括地讲，对应的发现服务及其相应的 API 被称作 &lt;em&gt;xDS&lt;/em&gt;。Envoy 通过 &lt;strong&gt;订阅（subscription）&lt;/strong&gt; 的方式来获取资源，订阅方式有以下三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;文件订阅&lt;/strong&gt;：监控指定路径下的文件，发现动态资源的最简单方式就是将其保存于文件，并将路径配置在 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/core/config_source.proto#core-configsource&#34;&gt;ConfigSource&lt;/a&gt; 中的 &lt;code&gt;path&lt;/code&gt; 参数中。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;gRPC 流式订阅&lt;/strong&gt;：每个 xDS API 可以单独配置 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-v2/api/v2/core/config_source.proto#core-apiconfigsource&#34;&gt;&lt;code&gt;ApiConfigSource&lt;/code&gt;&lt;/a&gt;，指向对应的上游管理服务器的集群地址。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;轮询 REST-JSON 轮询订阅&lt;/strong&gt;：单个 xDS API 可对 REST 端点进行的同步（长）轮询。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上的 xDS 订阅方式详情请参考 &lt;a href=&#34;https://jimmysong.io/istio-handbook/concepts/envoy-xds-protocol.html&#34;&gt;xDS 协议解析&lt;/a&gt;。Istio 使用 gRPC 流式订阅的方式配置所有的数据平面的 sidecar proxy。&lt;/p&gt;
&lt;h3 id=&#34;xds-协议要点&#34;&gt;xDS 协议要点&lt;/h3&gt;
&lt;p&gt;最后总结下关于 xDS 协议的要点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;CDS、EDS、LDS、RDS 是最基础的 xDS 协议，它们可以分别独立更新。&lt;/li&gt;
&lt;li&gt;所有的发现服务（Discovery Service）可以连接不同的 Management Server，也就是说管理 xDS 的服务器可以是多个。&lt;/li&gt;
&lt;li&gt;Envoy 在原始 xDS 协议的基础上进行了一些列扩充，增加了 SDS（秘钥发现服务）、ADS（聚合发现服务）、HDS（健康发现服务）、MS（Metric 服务）、RLS（速率限制服务）等 API。&lt;/li&gt;
&lt;li&gt;为了保证数据一致性，若直接使用 xDS 原始 API 的话，需要保证这样的顺序更新：CDS &amp;ndash;&amp;gt; EDS &amp;ndash;&amp;gt; LDS &amp;ndash;&amp;gt; RDS，这是遵循电子工程中的&lt;strong&gt;先合后断&lt;/strong&gt;（Make-Before-Break）原则，即在断开原来的连接之前先建立好新的连接，应用在路由里就是为了防止设置了新的路由规则的时候却无法发现上游集群而导致流量被丢弃的情况，类似于电路里的断路。&lt;/li&gt;
&lt;li&gt;CDS 设置 Service Mesh 中有哪些服务。&lt;/li&gt;
&lt;li&gt;EDS 设置哪些实例（Endpoint）属于这些服务（Cluster）。&lt;/li&gt;
&lt;li&gt;LDS 设置实例上监听的端口以配置路由。&lt;/li&gt;
&lt;li&gt;RDS 最终服务间的路由关系，应该保证最后更新 RDS。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;envoy&#34;&gt;Envoy&lt;/h2&gt;
&lt;p&gt;Envoy 是 Istio Service Mesh 中默认的 Sidecar，Istio 在 Enovy 的基础上按照 Envoy 的 xDS 协议扩展了其控制平面，在讲到 Envoy xDS 协议之前我们还需要先熟悉下 Envoy 的基本术语。下面列举了 Envoy 里的基本术语及其数据结构解析，关于 Envoy 的详细介绍请参考 &lt;a href=&#34;http://cloudnative.to/envoy/&#34;&gt;Envoy 官方文档&lt;/a&gt;，至于 Envoy 在 Service Mesh（不仅限于 Istio） 中是如何作为转发代理工作的请参考网易云刘超的这篇&lt;a href=&#34;https://www.cnblogs.com/163yun/p/8962278.html&#34;&gt;深入解读 Service Mesh 背后的技术细节 &lt;/a&gt;以及&lt;a href=&#34;https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34;&gt;理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持&lt;/a&gt;，本文引用其中的一些观点，详细内容不再赘述。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-arch.png&#34; alt=&#34;Envoy proxy 架构图&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;基本术语&#34;&gt;基本术语&lt;/h3&gt;
&lt;p&gt;下面是您应该了解的 Enovy 里的基本术语：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Downstream（下游）&lt;/strong&gt;：下游主机连接到 Envoy，发送请求并接收响应，即发送请求的主机。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upstream（上游）&lt;/strong&gt;：上游主机接收来自 Envoy 的连接和请求，并返回响应，即接受请求的主机。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Listener（监听器）&lt;/strong&gt;：监听器是命名网地址（例如，端口、unix domain socket 等)，下游客户端可以连接这些监听器。Envoy 暴露一个或者多个监听器给下游主机连接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Cluster（集群）&lt;/strong&gt;：集群是指 Envoy 连接的一组逻辑相同的上游主机。Envoy 通过&lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/service_discovery.html#arch-overview-service-discovery&#34;&gt;服务发现&lt;/a&gt;来发现集群的成员。可以选择通过&lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/health_checking.html#arch-overview-health-checking&#34;&gt;主动健康检查&lt;/a&gt;来确定集群成员的健康状态。Envoy 通过&lt;a href=&#34;http://www.servicemesher.com/envoy/intro/arch_overview/load_balancing.html#arch-overview-load-balancing&#34;&gt;负载均衡策略&lt;/a&gt;决定将请求路由到集群的哪个成员。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Envoy 中可以设置多个 Listener，每个 Listener 中又可以设置 filter chain（过滤器链表），而且过滤器是可扩展的，这样就可以更方便我们操作流量的行为，例如设置加密、私有 RPC 等。&lt;/p&gt;
&lt;p&gt;xDS 协议是由 Envoy 提出的，现在是 Istio 中默认的 sidecar proxy，但只要实现 xDS 协议理论上都是可以作为 Istio 中的 sidecar proxy 的，例如蚂蚁集团开源的 &lt;a href=&#34;https://github.com/mosn/mosn&#34;&gt;MOSN&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;istio-service-mesh&#34;&gt;Istio Service Mesh&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;istio-mesh-arch.png&#34; alt=&#34;Istio service mesh 架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;Istio 是一个功能十分丰富的 Service Mesh，它包括如下功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量管理：这是 Istio 的最基本的功能。&lt;/li&gt;
&lt;li&gt;策略控制：通过 Mixer 组件和各种适配器来实现，实现访问控制系统、遥测捕获、配额管理和计费等。&lt;/li&gt;
&lt;li&gt;可观测性：在 sidecar proxy 中实现。&lt;/li&gt;
&lt;li&gt;安全认证：Citadel 组件做密钥和证书管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;istio-中的流量管理&#34;&gt;Istio 中的流量管理&lt;/h3&gt;
&lt;p&gt;Istio 中定义了如下的 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/custom-resource.html&#34;&gt;CRD&lt;/a&gt; 来帮助用户进行流量管理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Gateway&lt;/strong&gt;：&lt;a href=&#34;https://istio.io/docs/reference/config/networking/gateway/&#34;&gt;Gateway&lt;/a&gt; 描述了在网络边缘运行的负载均衡器，用于接收传入或传出的HTTP / TCP连接。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VirtualService&lt;/strong&gt;：&lt;a href=&#34;https://istio.io/docs/reference/config/networking/virtual-service/&#34;&gt;VirtualService&lt;/a&gt; 实际上将 Kubernetes 服务连接到 Istio Gateway。它还可以执行更多操作，例如定义一组流量路由规则，以便在主机被寻址时应用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DestinationRule&lt;/strong&gt;：&lt;a href=&#34;https://istio.io/zh/docs/reference/config/networking/destination-rule/&#34;&gt;&lt;code&gt;DestinationRule&lt;/code&gt;&lt;/a&gt; 所定义的策略，决定了经过路由处理之后的流量的访问策略。简单的说就是定义流量如何路由。这些策略中可以定义负载均衡配置、连接池尺寸以及外部检测（用于在负载均衡池中对不健康主机进行识别和驱逐）配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;EnvoyFilter&lt;/strong&gt;：&lt;a href=&#34;https://istio.io/docs/reference/config/networking/envoy-filter/&#34;&gt;&lt;code&gt;EnvoyFilter&lt;/code&gt;&lt;/a&gt; 对象描述了针对代理服务的过滤器，这些过滤器可以定制由 Istio Pilot 生成的代理配置。这个配置初级用户一般很少用到。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ServiceEntry&lt;/strong&gt;：默认情况下 Istio Service Mesh 中的服务是无法发现 Mesh 外的服务的，&lt;a href=&#34;https://istio.io/docs/reference/config/networking/service-entry/&#34;&gt;&lt;code&gt;ServiceEntry&lt;/code&gt;&lt;/a&gt; 能够在 Istio 内部的服务注册表中加入额外的条目，从而让网格中自动发现的服务能够访问和路由到这些手工加入的服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;Kubernetes vs xDS vs Istio&lt;/h2&gt;
&lt;p&gt;在阅读完上文对 Kubernetes 的 &lt;code&gt;kube-proxy&lt;/code&gt; 组件、xDS 和 Istio 中流量管理的抽象概念之后，下面将带您仅就流量管理方面比较下三者对应的组件/协议（注意，三者不可以完全等同）。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Kubernetes&lt;/th&gt;
&lt;th&gt;xDS&lt;/th&gt;
&lt;th&gt;Istio Service Mesh&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;VirtualService&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;DestinationRule&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;EnvoyFilter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ingress&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;如果说 Kubernetes 管理的对象是 Pod，那么 Service Mesh 中管理的对象就是一个个 Service，所以说使用 Kubernetes 管理微服务后再应用 Service Mesh 就是水到渠成了，如果连 Service 你也不想管了，那就用如 &lt;a href=&#34;https://github.com/knative/&#34;&gt;knative&lt;/a&gt; 这样的 serverless 平台，但这就是后话了。&lt;/p&gt;
&lt;p&gt;Envoy/MOSN 的功能也不只是做流量转发，以上概念只不过是 Istio 在 Kubernetes 之上新增一层抽象层中的冰山一角，但因为流量管理是服务网格最基础也是最重要的功能，所以这将成为本书的开始。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/163yun/p/8962278.html&#34;&gt;深入解读 Service Mesh 背后的技术细节 - cnblogs.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34;&gt;理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持 - jimmysong.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cizixs.com/2017/03/30/kubernetes-introduction-service-and-kube-proxy/&#34;&gt;kubernetes 简介：service 和 kube-proxy 原理 - cizixs.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jishu.io/kubernetes/ipvs-loadbalancer-for-kubernetes/&#34;&gt;使用 IPVS 实现 Kubernetes 入口流量负载均衡 - jishu.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/api-docs/xds_protocol&#34;&gt;xDS REST and gRPC protocol&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>云原生服务网格 Istio 图书</title>
      <link>https://jimmysong.io/blog/cloud-native-service-mesh-istio-book/</link>
      <pubDate>Sat, 03 Aug 2019 15:24:37 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/cloud-native-service-mesh-istio-book/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://item.jd.com/12538407.html&#34;&gt;《云原生服务网格 Istio：原理、实践、架构与源码解析（张超盟、章鑫、徐中虎、徐飞编著）》&lt;/a&gt;是 2019 年国内出版的第四本 Istio 相关图书，前三本分别是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://item.jd.com/12527008.html&#34;&gt;深入浅出Istio：Service Mesh快速入门与实践，崔秀龙 著&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://item.jd.com/12516473.html&#34;&gt;Service Mesh实战：用Istio软负载实现服务网格，周遥 著&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://item.jd.com/12601120.html&#34;&gt;Istio 入门与实战，毛广献 著&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在这四本书刚上市时我都获得了作者的赠书，这本书是由四位华为的同学编写，于 2019 年  7 月第一次印刷，全书共 24 章，606 页，售价 139 元。我是在 KubeCon China 2019 的上海大会现场张超盟亲手赠与我的，张超盟也是 2018 年&lt;a href=&#34;https://www.servicemesher.com/blog/service-mesh-meetup-shenzhen-20180825/&#34;&gt;第三届 Service Mesh Meetup&lt;/a&gt; 的讲师。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;006tNc79ly1g60ml3q3i4j30xc0m8wg2.jpg&#34; alt=&#34;右侧是云原生服务网格 Istio（华为云原生技术丛书）作者之一张超盟&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;本书结构&#34;&gt;本书结构&lt;/h2&gt;
&lt;p&gt;全书共分四个篇章，24 个章节，606 页，每个章节的页数占比统计如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;006tNc79ly1g5nsbm4pkej30u00uj0vw.jpg&#34; alt=&#34;云原生服务网格 Istio：原理、实践、架构与源码解析》图书章节页数占全书百分比-表格&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;006tNc79ly1g60mjr3lirj30v20u0q5g.jpg&#34; alt=&#34;《云原生服务网格 Istio：原理、实践、架构与源码解析》图书章节页数占全书百分比-饼图&#34;&gt;&lt;/p&gt;
&lt;p&gt;从统计结果中可以看出书中第 3 章（非侵入的流量治理）、第 14 章（司令官 Pilot）一共占全书的页数百分比为 24%，几乎占了四分之一的篇幅。&lt;/p&gt;
&lt;p&gt;这本书是目前（2019年08月15日）市面上能买到的最全的一本 Istio 相关的图书了，话说国外还一本 Istio 的书也出来，国内到现在都出了四本了，是不是有种墙外开花墙内香的感觉？&lt;/p&gt;
&lt;p&gt;建议大家结合 &lt;a href=&#34;https://istio.io&#34;&gt;Istio 官方文档&lt;/a&gt;一起来看这本书，Istio 版本更新虽然没有 Kubernetes 那么快，但是在本书发行一个多月后也要发布 1.2 版本了，欢迎大家&lt;a href=&#34;https://www.servicemesher.com&#34;&gt;加入 ServiceMesher 社区&lt;/a&gt;来学习 Istio！&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>理解 Istio Service Mesh 中 Envoy Sidecar 代理的路由转发</title>
      <link>https://jimmysong.io/blog/envoy-sidecar-routing-of-istio-service-mesh-deep-dive/</link>
      <pubDate>Wed, 26 Dec 2018 18:32:27 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/envoy-sidecar-routing-of-istio-service-mesh-deep-dive/</guid>
      <description>
        
        
        &lt;p&gt;本文以 Istio 官方的 &lt;a href=&#34;https://preliminary.istio.io/zh/docs/examples/bookinfo&#34;&gt;bookinfo 示例&lt;/a&gt;来讲解在进入 Pod 的流量被 iptables 转交给 Envoy sidecar 后，Envoy 是如何做路由转发的，详述了 Inbound 和 Outbound 处理过程。关于流量拦截的详细分析请参考&lt;a href=&#34;https://jimmysong.io/posts/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34;&gt;理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下面是 Istio 官方提供的 bookinfo 的请求流程图，假设 bookinfo 应用的所有服务中没有配置 DestinationRule。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;006tNbRwgy1fvlwjd3302j31bo0ro0x5.jpg&#34; alt=&#34;Bookinfo 示例&#34;&gt;&lt;/p&gt;
&lt;p&gt;下面是 Istio 自身组件与 Bookinfo 示例的连接关系图，我们可以看到所有的 HTTP 连接都在 9080 端口监听。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;006tNbRwly1fyitp0jsghj31o70u0x6p.jpg&#34; alt=&#34;Bookinfo 示例与 Istio 组件连接关系图&#34;&gt;&lt;/p&gt;
&lt;p&gt;可以在 &lt;a href=&#34;https://drive.google.com/open?id=19ed3_tkjf6RgGboxllMdt_Ytd5_cocib&#34;&gt;Google Drive&lt;/a&gt; 上下载原图。&lt;/p&gt;
&lt;h2 id=&#34;sidecar-注入及流量劫持步骤概述&#34;&gt;Sidecar 注入及流量劫持步骤概述&lt;/h2&gt;
&lt;p&gt;下面是从 Sidecar 注入、Pod 启动到 Sidecar proxy 拦截流量及 Envoy 处理路由的步骤概览。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Kubernetes 通过 Admission Controller 自动注入，或者用户使用 &lt;code&gt;istioctl&lt;/code&gt; 命令手动注入 sidecar 容器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; 应用 YAML 配置部署应用，此时 Kubernetes API server 接收到的服务创建配置文件中已经包含了 Init 容器及 sidecar proxy。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; 在 sidecar proxy 容器和应用容器启动之前，首先运行 Init 容器，Init 容器用于设置 iptables（Istio 中默认的流量拦截方式，还可以使用 BPF、IPVS 等方式） 将进入 pod 的流量劫持到 Envoy sidecar proxy。所有 TCP 流量（Envoy 目前只支持 TCP 流量）将被 sidecar 劫持，其他协议的流量将按原来的目的地请求。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt; 启动 Pod 中的 Envoy sidecar proxy 和应用程序容器。这一步的过程请参考&lt;a href=&#34;https://zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/#%E9%80%9A%E8%BF%87%E7%AE%A1%E7%90%86%E6%8E%A5%E5%8F%A3%E8%8E%B7%E5%8F%96%E5%AE%8C%E6%95%B4%E9%85%8D%E7%BD%AE&#34;&gt;通过管理接口获取完整配置&lt;/a&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Sidecar proxy 与应用容器的启动顺序问题&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;启动 sidecar proxy 和应用容器，究竟哪个容器先启动呢？正常情况是 Envoy Sidecar 和应用程序容器全部启动完成后再开始接收流量请求。但是我们无法预料哪个容器会先启动，那么容器启动顺序是否会对 Envoy 劫持流量有影响呢？答案是肯定的，不过分为以下两种情况。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;情况1：应用容器先启动，而 sidecar proxy 仍未就绪&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这种情况下，流量被 iptables 转移到 15001 端口，而 Pod 中没有监听该端口，TCP 链接就无法建立，请求失败。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;情况2：Sidecar 先启动，请求到达而应用程序仍未就绪&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这种情况下请求也肯定会失败，至于是在哪一步开始失败的，留给读者来思考。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;问题&lt;/strong&gt;：如果为 sidecar proxy 和应用程序容器添加&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/guide/configure-liveness-readiness-probes.html&#34;&gt;就绪和存活探针&lt;/a&gt;是否可以解决该问题呢？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5.&lt;/strong&gt; 不论是进入还是从 Pod 发出的 TCP 请求都会被 iptables 劫持，inbound 流量被劫持后经 Inbound Handler 处理后转交给应用程序容器处理，outbound 流量被 iptables 劫持后转交给 Outbound Handler 处理，并确定转发的 upstream 和 Endpoint。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;6.&lt;/strong&gt; Sidecar proxy 请求 Pilot 使用 xDS 协议同步 Envoy 配置，其中包括 LDS、EDS、CDS 等，不过为了保证更新的顺序，Envoy 会直接使用 ADS 向 Pilot 请求配置更新。&lt;/p&gt;
&lt;h2 id=&#34;envoy-如何处理路由转发&#34;&gt;Envoy 如何处理路由转发&lt;/h2&gt;
&lt;p&gt;下图展示的是 &lt;code&gt;productpage&lt;/code&gt; 服务请求访问 &lt;code&gt;http://reviews.default.svc.cluster.local:9080/&lt;/code&gt;，当流量进入 &lt;code&gt;reviews&lt;/code&gt; 服务内部时，&lt;code&gt;reviews&lt;/code&gt; 服务内部的 Envoy Sidecar 是如何做流量拦截和路由转发的。可以在 &lt;a href=&#34;https://drive.google.com/file/d/1n-h235tm8DnL_RqxTTA95rgGtrLkBsyr/view?usp=sharing&#34;&gt;Google Drive&lt;/a&gt; 上下载原图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-sidecar-traffic-interception-zh-20210818.png&#34; alt=&#34;Envoy sidecar 流量劫持与路由转发示意图&#34;&gt;&lt;/p&gt;
&lt;p&gt;第一步开始时，&lt;code&gt;productpage&lt;/code&gt; Pod 中的 Envoy sidecar 已经通过 EDS 选择出了要请求的 &lt;code&gt;reviews&lt;/code&gt; 服务的一个 Pod，知晓了其 IP 地址，发送 TCP 连接请求。&lt;/p&gt;
&lt;p&gt;Istio 官网中的 &lt;a href=&#34;https://preliminary.istio.io/zh/help/ops/traffic-management/proxy-cmd/#envoy-%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90&#34;&gt;Envoy 配置深度解析&lt;/a&gt;中是以发起 HTTP 请求的一方来详述 Envoy 做流量转发的过程，而本文中考虑的是接受 downstream 的流量的一方，它既要接收 downstream 发来的请求，自己还需要请求其他服务，例如 &lt;code&gt;reviews&lt;/code&gt; 服务中的 Pod 还需要请求 &lt;code&gt;ratings&lt;/code&gt; 服务。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reviews&lt;/code&gt; 服务有三个版本，每个版本有一个实例，三个版本中的 sidecar 工作步骤类似，下文只以 &lt;code&gt;reviews-v1-cb8655c75-b97zc&lt;/code&gt; 这一个 Pod 中的 Sidecar 流量转发步骤来说明。&lt;/p&gt;
&lt;h2 id=&#34;理解-inbound-handler&#34;&gt;理解 Inbound Handler&lt;/h2&gt;
&lt;p&gt;Inbound handler 的作用是将 iptables 拦截到的 downstream 的流量转交给 localhost，与 Pod 内的应用程序容器建立连接。&lt;/p&gt;
&lt;p&gt;查看下 &lt;code&gt;reviews-v1-cb8655c75-b97zc&lt;/code&gt; pod 中的 Listener。&lt;/p&gt;
&lt;p&gt;运行 &lt;code&gt;istioctl pc listener reviews-v1-cb8655c75-b97zc&lt;/code&gt; 查看该 Pod 中的具有哪些 Listener。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;ADDRESS            PORT      TYPE &lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;172.33.3.3         9080      HTTP &amp;lt;--- 接收所有 Inbound HTTP 流量，该地址即为当前 Pod 的 IP 地址&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.0.1         443       TCP  &amp;lt;--+&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.4.253       80        TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.4.253       8080      TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.109.182     443       TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.22.50       15011     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.22.50       853       TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.79.114      443       TCP     | &lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.143.179     15011     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.0.2         53        TCP     | 接收与 0.0.0.0_15001 监听器配对的 Outbound 非 HTTP 流量&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.22.50       443       TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.16.64       42422     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.127.202     16686     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.22.50       31400     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.22.50       8060      TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.169.13      14267     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.169.13      14268     TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.32.134      8443      TCP     |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;10.254.118.196     443       TCP  &amp;lt;--+&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            15004     HTTP &amp;lt;--+&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            8080      HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            15010     HTTP    | &lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            8088      HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            15031     HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            9090      HTTP    | &lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            9411      HTTP    | 接收与 0.0.0.0_15001 配对的 Outbound HTTP 流量&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            80        HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            15030     HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            9080      HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            9093      HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            3000      HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            8060      HTTP    |&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            9091      HTTP &amp;lt;--+    &lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;0.0.0.0            15001     TCP  &amp;lt;--- 接收所有经 iptables 拦截的 Inbound 和 Outbound 流量并转交给虚拟监听器处理&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当来自 &lt;code&gt;productpage&lt;/code&gt; 的流量抵达 &lt;code&gt;reviews&lt;/code&gt; Pod 的时候已经，downstream 必须明确知道 Pod 的 IP 地址为 &lt;code&gt;172.33.3.3&lt;/code&gt; 所以才会访问该 Pod，所以该请求是 &lt;code&gt;172.33.3.3:9080&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;virtual&lt;/code&gt; Listener&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从该 Pod 的 Listener 列表中可以看到，0.0.0.0:15001/TCP 的 Listener（其实际名字是 &lt;code&gt;virtual&lt;/code&gt;）监听所有的 Inbound 流量，下面是该 Listener 的详细配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;virtual&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;socketAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.0.0.0&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;15001&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterChains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;envoy.tcp_proxy&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;config&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;BlackHoleCluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;stat_prefix&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;BlackHoleCluster&amp;#34;&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;useOriginalDst&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;UseOriginalDst&lt;/strong&gt;：从配置中可以看出 &lt;code&gt;useOriginalDst&lt;/code&gt; 配置指定为 &lt;code&gt;true&lt;/code&gt;，这是一个布尔值，缺省为 false，使用 iptables 重定向连接时，proxy 接收的端口可能与&lt;a href=&#34;http://www.servicemesher.com/envoy/configuration/listener_filters/original_dst_filter.html&#34;&gt;原始目的地址&lt;/a&gt;的端口不一样，如此处 proxy 接收的端口为 15001，而原始目的地端口为 9080。当此标志设置为 true 时，Listener 将连接重定向到与原始目的地址关联的 Listener，此处为 &lt;code&gt;172.33.3.3:9080&lt;/code&gt;。如果没有与原始目的地址关联的 Listener，则连接由接收它的 Listener 处理，即该 &lt;code&gt;virtual&lt;/code&gt; Listener，经过 &lt;code&gt;envoy.tcp_proxy&lt;/code&gt; 过滤器处理转发给 &lt;code&gt;BlackHoleCluster&lt;/code&gt;，这个 Cluster 的作用正如它的名字，当 Envoy 找不到匹配的虚拟监听器时，就会将请求发送给它，并返回 404。这个将于下文提到的 Listener 中设置 &lt;code&gt;bindToPort&lt;/code&gt; 相呼应。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：该参数将被废弃，请使用&lt;a href=&#34;http://www.servicemesher.com/envoy/configuration/listener_filters/original_dst_filter.html&#34;&gt;原始目的地址&lt;/a&gt;的 Listener filter 替代。该参数的主要用途是：Envoy 通过监听 15001 端口将 iptables 拦截的流量经由其他 Listener 处理而不是直接转发出去，详情见 &lt;a href=&#34;https://zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/#virtual-listener&#34;&gt;Virtual Listener&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Listener 172.33.3.3_9080&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;上文说到进入 Inbound handler 的流量被 &lt;code&gt;virtual&lt;/code&gt; Listener 转移到 &lt;code&gt;172.33.3.3_9080&lt;/code&gt; Listener，我们在查看下该 Listener 配置。&lt;/p&gt;
&lt;p&gt;运行 &lt;code&gt;istioctl pc listener reviews-v1-cb8655c75-b97zc --address 172.33.3.3 --port 9080 -o json&lt;/code&gt; 查看。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;172.33.3.3_9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;socketAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;172.33.3.3&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;9080&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterChains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterChainMatch&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;transportProtocol&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;raw_buffer&amp;#34;&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;envoy.http_connection_manager&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;config&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                        &lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt; 
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;route_config&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||reviews.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;validate_clusters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;virtual_hosts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;domains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
                                    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|http|9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;routes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                            &lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
                                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;route&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||reviews.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;max_grpc_timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.000s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.000s&amp;#34;&lt;/span&gt;
                                            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;nt&#34;&gt;&amp;#34;use_remote_address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                        &lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
                    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;，&lt;/span&gt;
            &lt;span class=&#34;s2&#34;&gt;&amp;#34;deprecatedV1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;bindToPort&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterChainMatch&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;transportProtocol&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;tls&amp;#34;&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;tlsContext&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;bindToPort&lt;/strong&gt;：注意其中有一个 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/v1.6.0/api-v1/listeners/listeners&#34;&gt;&lt;code&gt;bindToPort&lt;/code&gt;&lt;/a&gt; 的配置，其值为 &lt;code&gt;false&lt;/code&gt;，该配置的缺省值为 &lt;code&gt;true&lt;/code&gt;，表示将 Listener 绑定到端口上，此处设置为 &lt;code&gt;false&lt;/code&gt; 则该 Listener 只能处理其他 Listener 转移过来的流量，即上文所说的 &lt;code&gt;virtual&lt;/code&gt; Listener，我们看其中的 filterChains.filters 中的 &lt;code&gt;envoy.http_connection_manager&lt;/code&gt; 配置部分：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;route_config&amp;#34;&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||reviews.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;validate_clusters&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;virtual_hosts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;domains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                        &lt;span class=&#34;s2&#34;&gt;&amp;#34;*&amp;#34;&lt;/span&gt;
                                    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|http|9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;routes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                                        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                            &lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
                                            &lt;span class=&#34;nt&#34;&gt;&amp;#34;route&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||reviews.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;max_grpc_timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.000s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                                                &lt;span class=&#34;nt&#34;&gt;&amp;#34;timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.000s&amp;#34;&lt;/span&gt;
                                            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                                    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
                            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
                        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该配置表示流量将转交给 Cluster &lt;code&gt;inbound|9080||reviews.default.svc.cluster.local&lt;/code&gt; 处理。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Cluster &lt;code&gt;inbound|9080||reviews.default.svc.cluster.local&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;运行 &lt;code&gt;istioctl pc cluster reviews-v1-cb8655c75-b97zc --fqdn reviews.default.svc.cluster.local --direction inbound -o json&lt;/code&gt; 查看该 Cluster 的配置如下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;inbound|9080||reviews.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;connectTimeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;1.000s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;hosts&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;socketAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;127.0.0.1&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                    &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;9080&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;nt&#34;&gt;&amp;#34;circuitBreakers&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;thresholds&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;可以看到该 Cluster 的 Endpoint 直接对应的就是 localhost，再经过 iptables 转发流量就被应用程序容器消费了。&lt;/p&gt;
&lt;h2 id=&#34;理解-outbound-handler&#34;&gt;理解 Outbound Handler&lt;/h2&gt;
&lt;p&gt;因为 &lt;code&gt;reviews&lt;/code&gt; 会向 &lt;code&gt;ratings&lt;/code&gt; 服务发送 HTTP 请求，请求的地址是：&lt;code&gt;http://ratings.default.svc.cluster.local:9080/&lt;/code&gt;，Outbound handler 的作用是将 iptables 拦截到的本地应用程序发出的流量，经由 Envoy 判断如何路由到 upstream。&lt;/p&gt;
&lt;p&gt;应用程序容器发出的请求为 Outbound 流量，被 iptables 劫持后转移给 Envoy  Outbound handler 处理，然后经过 &lt;code&gt;virtual&lt;/code&gt; Listener、&lt;code&gt;0.0.0.0_9080&lt;/code&gt; Listener，然后通过 Route 9080 找到 upstream 的 cluster，进而通过 EDS 找到 Endpoint 执行路由动作。这一部分可以参考 Istio 官网中的 &lt;a href=&#34;https://preliminary.istio.io/zh/help/ops/traffic-management/proxy-cmd/#envoy-%E9%85%8D%E7%BD%AE%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90&#34;&gt;Envoy 深度配置解析&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Route 9080&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;reviews&lt;/code&gt; 会请求 &lt;code&gt;ratings&lt;/code&gt; 服务，运行 &lt;code&gt;istioctl proxy-config routes reviews-v1-cb8655c75-b97zc --name 9080 -o json&lt;/code&gt; 查看 route 配置，因为 Envoy 会根据 HTTP header 中的 domains 来匹配 VirtualHost，所以下面只列举了 &lt;code&gt;ratings.default.svc.cluster.local:9080&lt;/code&gt; 这一个 VirtualHost。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;name&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;domains&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default:9080&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;10.254.234.130&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
        &lt;span class=&#34;s2&#34;&gt;&amp;#34;10.254.234.130:9080&amp;#34;&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;#34;routes&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;match&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;prefix&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;route&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;cluster&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;outbound|9080||ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;timeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.000s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;maxGrpcTimeout&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;0.000s&amp;#34;&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;decorator&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;operation&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;ratings.default.svc.cluster.local:9080/*&amp;#34;&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;perFilterConfig&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从该 Virtual Host 配置中可以看到将流量路由到 Cluster &lt;code&gt;outbound|9080||ratings.default.svc.cluster.local&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Endpoint &lt;code&gt;outbound|9080||ratings.default.svc.cluster.local&lt;/code&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Istio 1.1 以前版本不支持使用 &lt;code&gt;istioctl&lt;/code&gt; 命令直接查询 Cluster 的 Endpoint，可以使用查询 Pilot 的 debug 端点的方式折中。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; reviews-v1-cb8655c75-b97zc -c istio-proxy curl http://istio-pilot.istio-system.svc.cluster.local:9093/debug/edsz &amp;gt; endpoints.json
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;endpoints.json&lt;/code&gt; 文件中包含了所有 Cluster 的 Endpoint 信息，我们只选取其中的 &lt;code&gt;outbound|9080||ratings.default.svc.cluster.local&lt;/code&gt; Cluster 的结果如下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;clusterName&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;outbound|9080||ratings.default.svc.cluster.local&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
  &lt;span class=&#34;nt&#34;&gt;&amp;#34;endpoints&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;#34;locality&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;

      &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
      &lt;span class=&#34;nt&#34;&gt;&amp;#34;lbEndpoints&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
          &lt;span class=&#34;nt&#34;&gt;&amp;#34;endpoint&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
              &lt;span class=&#34;nt&#34;&gt;&amp;#34;socketAddress&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;address&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;172.33.100.2&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
                &lt;span class=&#34;nt&#34;&gt;&amp;#34;portValue&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;9080&lt;/span&gt;
              &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
          &lt;span class=&#34;nt&#34;&gt;&amp;#34;metadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
            &lt;span class=&#34;nt&#34;&gt;&amp;#34;filterMetadata&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
              &lt;span class=&#34;nt&#34;&gt;&amp;#34;istio&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
                  &lt;span class=&#34;nt&#34;&gt;&amp;#34;uid&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;kubernetes://ratings-v1-8558d4458d-ns6lk.default&amp;#34;&lt;/span&gt;
                &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
            &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
          &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
        &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
      &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
  &lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Endpoint 可以是一个或多个，Envoy 将根据一定规则选择适当的 Endpoint 来路由。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：Istio 1.1 将支持 &lt;code&gt;istioctl pc endpoint&lt;/code&gt; 命令来查询 Endpoint。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://preliminary.istio.io/zh/help/ops/traffic-management/proxy-cmd/&#34;&gt;调试 Envoy 和 Pilot - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/posts/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/&#34;&gt;理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持 - jimmysong.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhaohuabing.com/post/2018-09-25-istio-traffic-management-impl-intro/&#34;&gt;Istio流量管理实现机制深度解析 - zhaohuabing.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 中的服务和流量的抽象模型</title>
      <link>https://jimmysong.io/blog/istio-service-and-traffic-model/</link>
      <pubDate>Mon, 17 Dec 2018 21:37:35 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-service-and-traffic-model/</guid>
      <description>
        
        
        &lt;p&gt;本文介绍了 Istio 和 Kubernetes 中的一些服务和流量的抽象模型。虽然 Istio 一开始确定的抽象模型与对接的底层平台无关，但目前来看基本绑定 Kubernetes，本文仅以 Kubernetes 说明。另外在 &lt;a href=&#34;http://www.servicemesher.com&#34;&gt;ServiceMesher 社区&lt;/a&gt;中最近有很多关于 Istio、Envoy、Kubernetes 之中的服务模型关系的讨论，本文作为一个开篇说明，Kubernetes 和 Isito 之间有哪些共有的服务模型，Istio 在 Kubernetes 的服务模型之上又增加了什么。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;服务具有多个版本。&lt;/strong&gt; 在 CI/CD 过程中，同一个服务可能同时部署在多个环境中，如开发、生产和测试环境等，这些服务版本不一定具有不同的 API，可能只是一些小的更改导致的迭代版本。在 A/B 测试和灰度发布中经常遇到这种情况。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-与-istio-中共有的模型&#34;&gt;Kubernetes 与 Istio 中共有的模型&lt;/h2&gt;
&lt;p&gt;因为 Istio 基本就是绑定在 Kubernetes 上，下面是我们熟知的 Kubernetes 及 Istio 中共有的服务模型。&lt;/p&gt;
&lt;p&gt;Kubernetes 中 iptables 代理模式（另外还有 IPVS 模式）下的 service ，管理员可以在 kube-proxy 中配置简单的负载均衡，对整个 node 生效，无法配置到单个服务的负载均衡和其他微服务的高级功能，例如熔断、限流、追踪等，这些功能只能在应用中实现了，而在 Istio 的概念模型中完全去掉了 &lt;code&gt;kube-proxy&lt;/code&gt;  这个组件，将其分散到每个应用 Pod 中同时部署的 Envoy 中实现。&lt;/p&gt;
&lt;p&gt;下面列举的是 Kubernetes 和 Istio 中共有的模型。&lt;/p&gt;
&lt;h3 id=&#34;service&#34;&gt;Service&lt;/h3&gt;
&lt;p&gt;这实际上跟 Kubernetes 中的 service 概念是一致的，请参考 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html&#34;&gt;Kubernetes 中的 service&lt;/a&gt;。Istio 推出了比 service 更复杂的模型 &lt;code&gt;VirtualService&lt;/code&gt;，这不单纯是定义一个服务了，而是在服务之上定义了路由规则。&lt;/p&gt;
&lt;p&gt;每个服务都有一个完全限定的域名（FQDN），监听一个或多个端口。服务还可以有与其相关联的单个负载均衡器或虚拟 IP 地址。针对 FQDN 的 DNS 查询将解析为该负载均衡器或者虚拟 IP 的地址。&lt;/p&gt;
&lt;p&gt;例如 Kubernetes 中一个服务为 &lt;code&gt;foo.default.svc.cluster.local&lt;/code&gt; ，虚拟 IP /ClusterIP 是 10.0.1.1，监听的端口是 80 和 8080。&lt;/p&gt;
&lt;h3 id=&#34;endpoint&#34;&gt;Endpoint&lt;/h3&gt;
&lt;p&gt;这里指的是 Kubernetes 中的 endpoint，一个 endpoint 是实现了某服务的具体实例，一个服务可能有一个或者多个 Endpoint，表示为 IP 地址加端口，也可以为 DNS 名称加端口。&lt;/p&gt;
&lt;p&gt;其实到底哪些实例属于同一个 service，还是需要 通过 label 匹配来选择。&lt;/p&gt;
&lt;h3 id=&#34;label&#34;&gt;Label&lt;/h3&gt;
&lt;p&gt;服务的版本、对应的引用名称等是通过 label 来标记的，例如下面 Kubernetes 中一个应用的 YAML 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;extensions/v1beta1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Deployment&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ratings-v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;replicas&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;template&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;app&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ratings&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;containers&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;ratings&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istio/examples-bookinfo-ratings-v1&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1.8&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;imagePullPolicy&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;IfNotPresent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;containerPort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;9080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;version: v1&lt;/code&gt; 标记该服务是 v1 版本，&lt;code&gt;version&lt;/code&gt; 是一个约定俗称的标签，建议大家的服务上都带上该标签。&lt;/p&gt;
&lt;p&gt;当然服务的 label 可以设置任意多个，这样的好处是在做路由的时候可以根据标签匹配来做细粒度的流量划分。&lt;/p&gt;
&lt;h2 id=&#34;数据平面-envoy&#34;&gt;数据平面 Envoy&lt;/h2&gt;
&lt;p&gt;Envoy 是 Istio 中默认的 sidecar proxy，负责服务间的流量管控、认证与安全加密、可观察性等。&lt;/p&gt;
&lt;p&gt;下面是 Envoy 的架构图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-arch-20190114.png&#34; alt=&#34;Envoy架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;我再给大家介绍 Envoy 中的如下几个重要概念。&lt;/p&gt;
&lt;h3 id=&#34;cluster&#34;&gt;Cluster&lt;/h3&gt;
&lt;p&gt;集群（cluster）是 Envoy 连接到的一组逻辑上相似的上游主机。Envoy 通过&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/service_discovery#arch-overview-service-discovery&#34;&gt;服务发现&lt;/a&gt;发现集群中的成员。Envoy 可以通过&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/health_checking#arch-overview-health-checking&#34;&gt;主动运行状况检查&lt;/a&gt;来确定集群成员的健康状况。Envoy 如何将请求路由到集群成员由&lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/load_balancing#arch-overview-load-balancing&#34;&gt;负载均衡策略&lt;/a&gt;确定。&lt;/p&gt;
&lt;p&gt;这个与 Kubernetes 中的 Service 概念类似，只不过 Kubernetes 中的服务发现中并不包含健康状况检查，而是通过&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/guide/configure-liveness-readiness-probes.html&#34;&gt;配置 Pod 的 liveness 和 readiness 探针&lt;/a&gt;来实现，服务发现默认也是通过 DNS 来实现。&lt;/p&gt;
&lt;h3 id=&#34;listener&#34;&gt;Listener&lt;/h3&gt;
&lt;p&gt;监听器（listener）是可以由下游客户端连接的命名网络位置（例如，端口、unix域套接字等）。Envoy 公开一个或多个下游主机连接的侦听器。一般是每台主机运行一个 Envoy，使用单进程运行，但是每个进程中可以启动任意数量的 Listener（监听器），目前只监听 TCP，每个监听器都独立配置一定数量的（L3/L4）网络过滤器。Listenter 也可以通过 Listener Discovery Service（&lt;strong&gt;LDS&lt;/strong&gt;）动态获取。&lt;/p&gt;
&lt;h3 id=&#34;listener-filter&#34;&gt;Listener filter&lt;/h3&gt;
&lt;p&gt;Listener 使用 listener filter（监听器过滤器）来操作链接的元数据。它的作用是在不更改 Envoy 的核心功能的情况下添加更多的集成功能。Listener filter 的 API 相对简单，因为这些过滤器最终是在新接受的套接字上运行。在链中可以互相衔接以支持更复杂的场景，例如调用速率限制。Envoy 已经包含了多个监听器过滤器。&lt;/p&gt;
&lt;h2 id=&#34;istio-中增加的流量模型&#34;&gt;Istio 中增加的流量模型&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt;、&lt;code&gt;Gateway&lt;/code&gt;、&lt;code&gt;ServiceEntry&lt;/code&gt; 和 &lt;code&gt;EnvoyFilter&lt;/code&gt; 都是 Istio 中为流量管理所创建的 CRD，这些概念其实是做路由配置和流量管理的，而 Kubernetes 中的 service 只是用来做服务发现。Service Mesh 中真正的服务模型应该是 Envoy 的 &lt;a href=&#34;https://cloudnative.to/blog/envoy-xds-protocol/&#34;&gt;xDS 协议&lt;/a&gt;，其中包括了服务的流量治理，服务的端点是通过 EDS 来配置的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio-pilot.png&#34; alt=&#34;Istio pilot 架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是 Pilot 设计图，来自&lt;a href=&#34;https://github.com/istio/old_pilot_repo/blob/master/doc/design.md&#34;&gt;Istio Pilot design overview&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;routing&#34;&gt;Routing&lt;/h3&gt;
&lt;p&gt;Kubernetes 中的 service 是没有任何路由属性可以配置的，Istio 在设计之初就通过在同一个 Pod 中，在应用容器旁运行一个 sidecar proxy 来透明得实现细粒度的路由控制。&lt;/p&gt;
&lt;h3 id=&#34;virtualservice&#34;&gt;VirtualService&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;VirtualService&lt;/code&gt; 定义针对指定服务流量的路由规则。每个路由规则都针对特定协议的匹配规则。如果流量符合这些特征，就会根据规则发送到服务注册表中的目标服务（或者目标服务的子集或版本）。对于 A/B 测试和灰度发布等场景，通常需要使用划分 &lt;code&gt;subset&lt;/code&gt;，VirtualService 中根据 destination 中的 subset 配置来选择路由，但是这些 subset 究竟对应哪些服务示例，这就需要 &lt;code&gt;DestionationRule&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;destinationrule&#34;&gt;DestinationRule&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;DestinationRule&lt;/code&gt; 所定义的策略，决定了经过路由处理之后的流量的访问策略。这些策略中可以定义负载均衡配置、连接池尺寸以及外部检测（用于在负载均衡池中对不健康主机进行识别和驱逐）配置。&lt;/p&gt;
&lt;h3 id=&#34;gateway&#34;&gt;Gateway&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;Gateway&lt;/code&gt; 描述了一个负载均衡器，用于承载网格边缘的进入和发出连接。这一规范中描述了一系列开放端口，以及这些端口所使用的协议、负载均衡的 SNI 配置等内容。&lt;/p&gt;
&lt;p&gt;这个实际上就是定义服务网格的边缘路由。&lt;/p&gt;
&lt;h3 id=&#34;serviceentry&#34;&gt;ServiceEntry&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;ServiceEntry&lt;/code&gt; 能够在 Istio 内部的服务注册表中加入额外的条目，从而让网格中自动发现的服务能够访问和路由到这些手工加入的服务。&lt;code&gt;ServiceEntry&lt;/code&gt; 描述了服务的属性（DNS 名称、VIP、端口、协议以及端点）。这类服务可能是网格外的 API，或者是处于网格内部但却不存在于平台的服务注册表中的条目（例如需要和 Kubernetes 服务沟通的一组虚拟机服务）。&lt;/p&gt;
&lt;p&gt;如果没有配置 ServiceEntry 的话，Istio 实际上是无法发现服务网格外部的服务的。&lt;/p&gt;
&lt;h3 id=&#34;envoyfilter&#34;&gt;EnvoyFilter&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;EnvoyFilter&lt;/code&gt; 对象描述了针对代理服务的过滤器，这些过滤器可以定制由 Istio Pilot 生成的代理配置。这一功能一定要谨慎使用。错误的配置内容一旦完成传播，可能会令整个服务网格进入瘫痪状态。&lt;/p&gt;
&lt;p&gt;Envoy 中的 listener 可以配置多个 &lt;a href=&#34;https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/listener_filters&#34;&gt;filter&lt;/a&gt;，这也是一种通过 Istio 来扩展 Envoy 的机制。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/service.html&#34;&gt;Kubernetes 中的 service - jimmysong.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/old_pilot_repo/blob/master/doc/service-registry.md&#34;&gt;Istio services model - github.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io&#34;&gt;Istio 文档 - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持</title>
      <link>https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/</link>
      <pubDate>Tue, 11 Sep 2018 10:39:42 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/envoy-sidecar-injection-in-istio-service-mesh-deep-dive/</guid>
      <description>
        
        
        &lt;p&gt;本文最新更新于 2022 年 3 月 7 日。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;以往有很多文章讲解 Istio 是如何做 Sidecar 注入的，但是没有讲解注入之后 Sidecar 工作的细节。本文将带大家详细了解 Istio 是如何将 Envoy 作为 Sidecar 的方式注入到应用程序 Pod 中，及 Sidecar 是如何做劫持流量的。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在讲解 Istio 如何将 Envoy 代理注入到应用程序 Pod 中之前，我们需要先了解以下几个概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Sidecar 模式：容器应用模式之一，Service Mesh 架构的一种实现方式。&lt;/li&gt;
&lt;li&gt;Init 容器：Pod 中的一种专用的容器，在应用程序容器启动之前运行，用来包含一些应用镜像中不存在的实用工具或安装脚本。&lt;/li&gt;
&lt;li&gt;iptables：流量劫持是通过 iptables 转发实现的。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;查看目前 &lt;code&gt;reviews-v1-745ffc55b7-2l2lw&lt;/code&gt; Pod 中运行的容器：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n default get pod reviews-v1-745ffc55b7-2l2lw -o&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;{..spec.containers[*].name}&amp;#39;&lt;/span&gt;
reviews istio-proxy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;reviews&lt;/code&gt; 即应用容器，&lt;code&gt;istio-proxy&lt;/code&gt; 即 Envoy 代理的 sidecar 容器。另外该 Pod 中实际上还运行过一个 Init 容器，因为它执行结束就自动终止了，所以我们看不到该容器的存在。关注 &lt;code&gt;jsonpath&lt;/code&gt; 的用法请参考 &lt;a href=&#34;https://kubernetes.io/docs/reference/kubectl/jsonpath/&#34;&gt;JSONPath Support&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;sidecar-模式&#34;&gt;Sidecar 模式&lt;/h2&gt;
&lt;p&gt;在了解 Istio 使用 Sidecar 注入之前，需要先说明下什么是 Sidecar 模式。Sidecar 是容器应用模式的一种，也是在 Service Mesh 中发扬光大的一种模式，详见 &lt;a href=&#34;https://www.servicemesher.com/blog/service-mesh-architectures/&#34;&gt;Service Mesh 架构解析&lt;/a&gt;，其中详细描述了&lt;strong&gt;节点代理&lt;/strong&gt;和 &lt;strong&gt;Sidecar&lt;/strong&gt; 模式的服务网格架构。&lt;/p&gt;
&lt;p&gt;使用 Sidecar 模式部署服务网格时，无需在节点上运行代理（因此您不需要基础结构的协作），但是集群中将运行多个相同的 Sidecar 副本。从另一个角度看：我可以为一组微服务部署到一个服务网格中，你也可以部署一个有特定实现的服务网格。在 Sidecar 部署方式中，你会为每个应用的容器部署一个伴生容器。Sidecar 接管进出应用容器的所有流量。在 Kubernetes 的 Pod 中，在原有的应用容器旁边运行一个 Sidecar 容器，可以理解为两个容器共享存储、网络等资源，可以广义的将这个注入了 Sidecar 容器的 Pod 理解为一台主机，两个容器共享主机资源。&lt;/p&gt;
&lt;p&gt;下图展示的是 Service Mesh 的架构图，其中的位于每个 Pod 中的 proxy  组成了数据平面，而这些 proxy 正是以 sidecar 模式运行的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;istio-sidecar.jpg&#34; alt=&#34;Istio 架构&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：下文中所指的 Sidecar 都是指的 Envoy 代理容器。&lt;/p&gt;
&lt;h2 id=&#34;init-容器&#34;&gt;Init 容器&lt;/h2&gt;
&lt;p&gt;Init 容器是一种专用容器，它在应用程序容器启动之前运行，用来包含一些应用镜像中不存在的实用工具或安装脚本。&lt;/p&gt;
&lt;p&gt;一个 Pod 中可以指定多个 Init 容器，如果指定了多个，那么 Init 容器将会按顺序依次运行。只有当前面的 Init 容器必须运行成功后，才可以运行下一个 Init 容器。当所有的 Init 容器运行完成后，Kubernetes 才初始化 Pod 和运行应用容器。&lt;/p&gt;
&lt;p&gt;Init 容器使用 Linux Namespace，所以相对应用程序容器来说具有不同的文件系统视图。因此，它们能够具有访问 Secret 的权限，而应用程序容器则不能。&lt;/p&gt;
&lt;p&gt;在 Pod 启动过程中，Init 容器会按顺序在网络和数据卷初始化之后启动。每个容器必须在下一个容器启动之前成功退出。如果由于运行时或失败退出，将导致容器启动失败，它会根据 Pod 的 &lt;code&gt;restartPolicy&lt;/code&gt; 指定的策略进行重试。然而，如果 Pod 的 &lt;code&gt;restartPolicy&lt;/code&gt; 设置为 Always，Init 容器失败时会使用 &lt;code&gt;RestartPolicy&lt;/code&gt; 策略。&lt;/p&gt;
&lt;p&gt;在所有的 Init 容器没有成功之前，Pod 将不会变成 &lt;code&gt;Ready&lt;/code&gt; 状态。Init 容器的端口将不会在 Service 中进行聚集。 正在初始化中的 Pod 处于 &lt;code&gt;Pending&lt;/code&gt; 状态，但应该会将 &lt;code&gt;Initializing&lt;/code&gt; 状态设置为 true。Init 容器运行完成以后就会自动终止。&lt;/p&gt;
&lt;p&gt;关于 Init 容器的详细信息请参考 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/init-containers.html&#34;&gt;Init 容器 - Kubernetes 中文指南/云原生应用架构实践手册&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;sidecar-注入示例分析&#34;&gt;Sidecar 注入示例分析&lt;/h2&gt;
&lt;p&gt;本文我们将以 Istio 官方示例 &lt;code&gt;bookinfo&lt;/code&gt; 中 &lt;code&gt;reivews&lt;/code&gt; 服务为例，来接讲解 Sidecar 容器注入的额流程，每个注入了 Sidecar 的 Pod 中除了原先应用的应用本身的容器外，都会多出来这样两个容器：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;istio-init&lt;/code&gt;：用于给 Sidecar 容器即 Envoy 代理做初始化，设置 iptables 端口转发&lt;/li&gt;
&lt;li&gt;&lt;code&gt;istio-proxy&lt;/code&gt;：Envoy 代理容器，运行 Envoy 代理&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;接下来将分别解析下这两个容器。&lt;/p&gt;
&lt;h3 id=&#34;init-容器解析&#34;&gt;Init 容器解析&lt;/h3&gt;
&lt;p&gt;Istio 在 Pod 中注入的 Init 容器名为 &lt;code&gt;istio-init&lt;/code&gt;，如果你查看 &lt;code&gt;reviews&lt;/code&gt; Deployment 配置，你将看到其中 &lt;code&gt;initContaienrs&lt;/code&gt; 的启动参数：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;      initContainers:
        - name: istio-init
          image: docker.io/istio/proxyv2:1.13.1
          args:
            - istio-iptables
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-p&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;15001&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-z&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;15006&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-u&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;1337&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-m&amp;#39;&lt;/span&gt;
            - REDIRECT
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-i&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-x&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-b&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt;
            - &lt;span class=&#34;s1&#34;&gt;&amp;#39;-d&amp;#39;&lt;/span&gt;
            - 15090,15021,15020
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到 &lt;code&gt;istio-init&lt;/code&gt; 容器的入口是 &lt;code&gt;istio-iptables&lt;/code&gt; 命令，该命令是用于初始化路由表的。&lt;/p&gt;
&lt;h3 id=&#34;init-容器启动入口&#34;&gt;Init 容器启动入口&lt;/h3&gt;
&lt;p&gt;Init 容器的启动入口是 &lt;code&gt;/usr/local/bin/istio-iptable&lt;/code&gt; 命令，该命令的用法如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ istio-iptables -p PORT -u UID -g GID &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-m mode&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-b ports&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-d ports&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-i CIDR&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-x CIDR&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-h&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;
  -p: 指定重定向所有 TCP 流量的 Envoy 端口（默认为 &lt;span class=&#34;nv&#34;&gt;$ENVOY_PORT&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; 15001）
  -u: 指定未应用重定向的用户的 UID。通常，这是代理容器的 UID（默认为 &lt;span class=&#34;nv&#34;&gt;$ENVOY_USER&lt;/span&gt; 的 uid，istio_proxy 的 uid 或 1337）
  -g: 指定未应用重定向的用户的 GID。（与 -u param 相同的默认值）
  -m: 指定入站连接重定向到 Envoy 的模式，“REDIRECT” 或 “TPROXY”（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_INBOUND_INTERCEPTION_MODE&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
  -b: 逗号分隔的入站端口列表，其流量将重定向到 Envoy（可选）。使用通配符 “*” 表示重定向所有端口。为空时表示禁用所有入站重定向（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_INBOUND_PORTS&lt;/span&gt;）
  -d: 指定要从重定向到 Envoy 中排除（可选）的入站端口列表，以逗号格式分隔。使用通配符“*” 表示重定向所有入站流量（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_LOCAL_EXCLUDE_PORTS&lt;/span&gt;）
  -i: 指定重定向到 Envoy（可选）的 IP 地址范围，以逗号分隔的 CIDR 格式列表。使用通配符 “*” 表示重定向所有出站流量。空列表将禁用所有出站重定向（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_SERVICE_CIDR&lt;/span&gt;）
  -x: 指定将从重定向中排除的 IP 地址范围，以逗号分隔的 CIDR 格式列表。使用通配符 “*” 表示重定向所有出站流量（默认为 &lt;span class=&#34;nv&#34;&gt;$ISTIO_SERVICE_EXCLUDE_CIDR&lt;/span&gt;）。
  -z: 所有入站 TCP 流量重定向端口（默认为 &lt;span class=&#34;nv&#34;&gt;$INBOUND_CAPTURE_PORT&lt;/span&gt; 15006）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;关于该命令的详细代码请&lt;a href=&#34;https://github.com/istio/istio/blob/master/tools/istio-iptables/pkg/cmd/root.go&#34;&gt;查看 GitHub：&lt;code&gt;tools/istio-iptables/pkg/cmd/root.go&lt;/code&gt;&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;再参考 &lt;code&gt;istio-init&lt;/code&gt; 容器的启动参数，完整的启动命令如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ /usr/local/bin/istio-iptables -p &lt;span class=&#34;m&#34;&gt;15001&lt;/span&gt; -z &lt;span class=&#34;m&#34;&gt;15006&lt;/span&gt; -u &lt;span class=&#34;m&#34;&gt;1337&lt;/span&gt; -m REDIRECT -i &lt;span class=&#34;s1&#34;&gt;&amp;#39;*&amp;#39;&lt;/span&gt; -x &lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt; -b * -d &lt;span class=&#34;s2&#34;&gt;&amp;#34;15090,15201,15020&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该容器存在的意义就是让 Envoy 代理可以拦截所有的进出 Pod 的流量，即将入站流量重定向到 Sidecar，再拦截应用容器的出站流量经过 Sidecar 处理后再出站。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;命令解析&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这条启动命令的作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将应用容器的所有流量都转发到 Envoy 的 15006 端口。&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;istio-proxy&lt;/code&gt; 用户身份运行， UID 为 1337，即 Envoy 所处的用户空间，这也是 &lt;code&gt;istio-proxy&lt;/code&gt; 容器默认使用的用户，见 YAML 配置中的 &lt;code&gt;runAsUser&lt;/code&gt; 字段。&lt;/li&gt;
&lt;li&gt;使用默认的 &lt;code&gt;REDIRECT&lt;/code&gt; 模式来重定向流量。&lt;/li&gt;
&lt;li&gt;将所有出站流量都重定向到 Envoy 代理。&lt;/li&gt;
&lt;li&gt;将除了 15090、15201、15020 端口以外的所有端口的流量重定向到 Envoy 代理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;因为 Init 容器初始化完毕后就会自动终止，因为我们无法登陆到容器中查看 iptables 信息，但是 Init 容器初始化结果会保留到应用容器和 Sidecar 容器中。&lt;/p&gt;
&lt;h3 id=&#34;istio-proxy-容器解析&#34;&gt;istio-proxy 容器解析&lt;/h3&gt;
&lt;p&gt;为了查看 iptables 配置，我们需要登陆到 Sidecar 容器中使用 root 用户来查看，因为 &lt;code&gt;kubectl&lt;/code&gt; 无法使用特权模式来远程操作 docker 容器，所以我们需要登陆到 &lt;code&gt;reviews&lt;/code&gt; Pod 所在的主机上使用 &lt;code&gt;docker&lt;/code&gt; 命令登陆容器中查看。&lt;/p&gt;
&lt;p&gt;查看 &lt;code&gt;reviews&lt;/code&gt; Pod 所在的主机。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl -n default get pod -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;reviews -o wide
NAME                              READY     STATUS    RESTARTS   AGE       IP             NODE
reviews-v1-745ffc55b7-2l2lw   2/2       Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          1d        172.33.78.10   node3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;从输出结果中可以看到该 Pod 运行在 &lt;code&gt;node3&lt;/code&gt; 上，使用 &lt;code&gt;vagrant&lt;/code&gt; 命令登陆到 &lt;code&gt;node3&lt;/code&gt; 主机中并切换为 root 用户。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ vagrant ssh node3
$ sudo -i
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看 iptables 配置，列出 NAT（网络地址转换）表的所有规则，因为在 Init 容器启动的时候选择给  &lt;code&gt;istio-iptables.sh&lt;/code&gt; 传递的参数中指定将入站流量重定向到 Envoy 的模式为 “REDIRECT”，因此在 iptables 中将只有 NAT 表的规格配置，如果选择 &lt;code&gt;TPROXY&lt;/code&gt; 还会有 &lt;code&gt;mangle&lt;/code&gt; 表配置。&lt;code&gt;iptables&lt;/code&gt; 命令的详细用法请参考 &lt;a href=&#34;https://wangchujiang.com/linux-command/c/iptables.html&#34;&gt;iptables&lt;/a&gt;，规则配置请参考 &lt;a href=&#34;http://www.zsythink.net/archives/1517&#34;&gt;iptables 规则配置&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;理解-iptables&#34;&gt;理解 iptables&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;iptables&lt;/code&gt; 是 Linux 内核中的防火墙软件 netfilter 的管理工具，位于用户空间，同时也是 netfilter 的一部分。Netfilter 位于内核空间，不仅有网络地址转换的功能，也具备数据包内容修改、以及数据包过滤等防火墙功能。&lt;/p&gt;
&lt;p&gt;在了解 Init 容器初始化的 iptables 之前，我们先来了解下 iptables 和规则配置。&lt;/p&gt;
&lt;p&gt;下图展示了 iptables 调用链。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;iptables_packetflow.png&#34; alt=&#34;iptables 调用链&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;iptables-中的表&#34;&gt;iptables 中的表&lt;/h3&gt;
&lt;p&gt;Init 容器中使用的的 iptables 版本是 &lt;code&gt;v1.6.0&lt;/code&gt;，共包含 5 张表：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;raw&lt;/code&gt; 用于配置数据包，&lt;code&gt;raw&lt;/code&gt; 中的数据包不会被系统跟踪。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;filter&lt;/code&gt; 是用于存放所有与防火墙相关操作的默认表。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nat&lt;/code&gt; 用于 &lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation&#34;&gt;网络地址转换&lt;/a&gt;（例如：端口转发）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mangle&lt;/code&gt; 用于对特定数据包的修改（参考&lt;a href=&#34;https://en.wikipedia.org/wiki/Mangled_packet&#34;&gt;损坏数据包&lt;/a&gt;）。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;security&lt;/code&gt; 用于&lt;a href=&#34;https://wiki.archlinux.org/index.php/Security#Mandatory_access_control&#34;&gt;强制访问控制&lt;/a&gt; 网络规则。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：在本示例中只用到了 &lt;code&gt;nat&lt;/code&gt; 表。&lt;/p&gt;
&lt;p&gt;不同的表中的具有的链类型如下表所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;规则名称&lt;/th&gt;
&lt;th&gt;raw&lt;/th&gt;
&lt;th&gt;filter&lt;/th&gt;
&lt;th&gt;nat&lt;/th&gt;
&lt;th&gt;mangle&lt;/th&gt;
&lt;th&gt;security&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PREROUTING&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;INPUT&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;OUTPUT&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;POSTROUTING&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FORWARD&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;td&gt;✓&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;下图是 iptables 的调用链顺序。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;iptables-chains.jpg&#34; alt=&#34;iptables 调用链顺序&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;iptables-命令&#34;&gt;iptables 命令&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;iptables&lt;/code&gt; 命令的主要用途是修改这些表中的规则。&lt;code&gt;iptables&lt;/code&gt; 命令格式如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ iptables &lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-t 表名&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt; 命令选项［链名&lt;span class=&#34;o&#34;&gt;]&lt;/span&gt;［条件匹配］&lt;span class=&#34;o&#34;&gt;[&lt;/span&gt;-j 目标动作或跳转］
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Init 容器中的 &lt;code&gt;/istio-iptables.sh&lt;/code&gt; 启动入口脚本就是执行 iptables 初始化的。&lt;/p&gt;
&lt;h3 id=&#34;理解-iptables-规则&#34;&gt;理解 iptables 规则&lt;/h3&gt;
&lt;p&gt;查看 &lt;code&gt;istio-proxy&lt;/code&gt; 容器中的默认的 iptables 规则，默认查看的是 filter 表中的规则。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ iptables -L -v
Chain INPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT 350K packets, 63M bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

Chain FORWARD &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; packets, &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

Chain OUTPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT 18M packets, 1916M bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到三个默认的链，分别是 INPUT、FORWARD 和 OUTPUT，每个链中的第一行输出表示链名称（在本例中为INPUT/FORWARD/OUTPUT），后跟默认策略（ACCEPT）。&lt;/p&gt;
&lt;p&gt;每条链中都可以添加多条规则，规则是按照顺序从前到后执行的。我们来看下规则的表头定义。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;pkts&lt;/strong&gt;：处理过的匹配的报文数量&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;bytes&lt;/strong&gt;：累计处理的报文大小（字节数）&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;target&lt;/strong&gt;：如果报文与规则匹配，指定目标就会被执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;prot&lt;/strong&gt;：协议，例如 &lt;code&gt;tdp&lt;/code&gt;、&lt;code&gt;udp&lt;/code&gt;、&lt;code&gt;icmp&lt;/code&gt; 和 &lt;code&gt;all&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;opt&lt;/strong&gt;：很少使用，这一列用于显示 IP 选项。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;in&lt;/strong&gt;：入站网卡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;out&lt;/strong&gt;：出站网卡。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;source&lt;/strong&gt;：流量的源 IP 地址或子网，后者是 &lt;code&gt;anywhere&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;destination&lt;/strong&gt;：流量的目的地 IP 地址或子网，或者是 &lt;code&gt;anywhere&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还有一列没有表头，显示在最后，表示规则的选项，作为规则的扩展匹配条件，用来补充前面的几列中的配置。&lt;code&gt;prot&lt;/code&gt;、&lt;code&gt;opt&lt;/code&gt;、&lt;code&gt;in&lt;/code&gt;、&lt;code&gt;out&lt;/code&gt;、&lt;code&gt;source&lt;/code&gt; 和 &lt;code&gt;destination&lt;/code&gt; 和显示在 &lt;code&gt;destination&lt;/code&gt; 后面的没有表头的一列扩展条件共同组成匹配规则。当流量匹配这些规则后就会执行 &lt;code&gt;target&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;target 支持的类型&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;target&lt;/code&gt; 类型包括 ACCEPT&lt;code&gt;、REJECT&lt;/code&gt;、&lt;code&gt;DROP&lt;/code&gt;、&lt;code&gt;LOG&lt;/code&gt; 、&lt;code&gt;SNAT&lt;/code&gt;、&lt;code&gt;MASQUERADE&lt;/code&gt;、&lt;code&gt;DNAT&lt;/code&gt;、&lt;code&gt;REDIRECT&lt;/code&gt;、&lt;code&gt;RETURN&lt;/code&gt; 或者跳转到其他规则等。只要执行到某一条链中只有按照顺序有一条规则匹配后就可以确定报文的去向了，除了 &lt;code&gt;RETURN&lt;/code&gt; 类型，类似编程语言中的 &lt;code&gt;return&lt;/code&gt; 语句，返回到它的调用点，继续执行下一条规则。&lt;code&gt;target&lt;/code&gt; 支持的配置详解请参考 &lt;a href=&#34;http://www.zsythink.net/archives/1199&#34;&gt;iptables 详解（1）：iptables 概念&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;从输出结果中可以看到 Init 容器没有在 iptables 的默认链路中创建任何规则，而是创建了新的链路。&lt;/p&gt;
&lt;h2 id=&#34;查看-iptables-nat-表中注入的规则&#34;&gt;查看 iptables nat 表中注入的规则&lt;/h2&gt;
&lt;p&gt;Init 容器通过向 iptables nat 表中注入转发规则来劫持流量的，下图显示的是三个 reviews 服务示例中的某一个 Pod，其中有 init 容器、应用容器和 sidecar 容器，图中展示了 iptables 流量劫持的详细过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;envoy-sidecar-traffic-interception-zh-20210818.png&#34; alt=&#34;Envoy sidecar 流量劫持与路由转发示意图&#34;&gt;&lt;/p&gt;
&lt;p&gt;Init 容器启动时命令行参数中指定了 &lt;code&gt;REDIRECT&lt;/code&gt; 模式，因此只创建了 NAT 表规则，接下来我们查看下 NAT 表中创建的规则，这是全文中的&lt;strong&gt;重点部分&lt;/strong&gt;，前面讲了那么多都是为它做铺垫的。&lt;/p&gt;
&lt;h3 id=&#34;进入到-reviews-pod&#34;&gt;进入到 reviews pod&lt;/h3&gt;
&lt;p&gt;Reviews 服务有三个版本，我们进入到其中任意一个版本，例如 reviews-1，首先你需要搞清楚这个 pod 运行在哪个节点上，知道那个容器的具体 ID，然后使用 SSH 登录那个节点，使用 &lt;code&gt;ps&lt;/code&gt; 命令查看到那个容器的具体 IP，使用 &lt;code&gt;nsenter&lt;/code&gt; 命令进入该容器。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-sh&#34; data-lang=&#34;sh&#34;&gt;nsenter -t&lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;PID&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt; -n
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;为什么不直接使用 kubectl 进入容器？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Istio 向 pod 中自动注入的 sidecar 容器（名为 &lt;code&gt;istio-proxy&lt;/code&gt;）其中默认的用户是 &lt;code&gt;istio-proxy&lt;/code&gt;，该用户没有权限查看路由表规则，即当你在该容器中运行 &lt;code&gt;iptabes&lt;/code&gt; 命令时会得到 &lt;code&gt;iptables -t nat -L -v&lt;/code&gt; 这样的结果，而且你又没有 root 权限。对于 reviews 容器也是一样，默认用户的 UID 是 &lt;code&gt;1000&lt;/code&gt;，而且这个用户又没有名字，一样也无法切换为 root 用户，系统中默认没有安装 iptabels 命令。所以我们只能登录到 Pod 的宿主节点上，使用 &lt;code&gt;nsenter&lt;/code&gt; 命令进入容器内部。&lt;/p&gt;
&lt;h3 id=&#34;查看路由表&#34;&gt;查看路由表&lt;/h3&gt;
&lt;p&gt;下面是查看 nat 表中的规则，其中链的名字中包含 &lt;code&gt;ISTIO&lt;/code&gt; 前缀的是由 Init 容器注入的，规则匹配是根据下面显示的顺序来执行的，其中会有多次跳转。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 查看 NAT 表中规则配置的详细信息&lt;/span&gt;
$ iptables -t nat -L -v
&lt;span class=&#34;c1&#34;&gt;# PREROUTING 链：用于目标地址转换（DNAT），将所有入站 TCP 流量跳转到 ISTIO_INBOUND 链上&lt;/span&gt;
Chain PREROUTING &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; packets, &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;120&lt;/span&gt; ISTIO_INBOUND  tcp  --  any    any     anywhere             anywhere

&lt;span class=&#34;c1&#34;&gt;# INPUT 链：处理输入数据包，非 TCP 流量将继续 OUTPUT 链&lt;/span&gt;
Chain INPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; packets, &lt;span class=&#34;m&#34;&gt;120&lt;/span&gt; bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

&lt;span class=&#34;c1&#34;&gt;# OUTPUT 链：将所有出站数据包跳转到 ISTIO_OUTPUT 链上&lt;/span&gt;
Chain OUTPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;41146&lt;/span&gt; packets, 3845K bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
   &lt;span class=&#34;m&#34;&gt;93&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;5580&lt;/span&gt; ISTIO_OUTPUT  tcp  --  any    any     anywhere             anywhere

&lt;span class=&#34;c1&#34;&gt;# POSTROUTING 链：所有数据包流出网卡时都要先进入POSTROUTING 链，内核根据数据包目的地判断是否需要转发出去，我们看到此处未做任何处理&lt;/span&gt;
Chain POSTROUTING &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;policy ACCEPT &lt;span class=&#34;m&#34;&gt;41199&lt;/span&gt; packets, 3848K bytes&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination

&lt;span class=&#34;c1&#34;&gt;# ISTIO_INBOUND 链：将所有目的地为 9080 端口的入站流量重定向到 ISTIO_IN_REDIRECT 链上&lt;/span&gt;
Chain ISTIO_INBOUND &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;120&lt;/span&gt; ISTIO_IN_REDIRECT  tcp  --  any    any     anywhere             anywhere             tcp dpt:9080

&lt;span class=&#34;c1&#34;&gt;# ISTIO_IN_REDIRECT 链：将所有的入站流量跳转到本地的 15006 端口，至此成功的拦截了流量到 Envoy&lt;/span&gt; 
Chain ISTIO_IN_REDIRECT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;   &lt;span class=&#34;m&#34;&gt;120&lt;/span&gt; REDIRECT   tcp  --  any    any     anywhere             anywhere             redir ports &lt;span class=&#34;m&#34;&gt;15006&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# ISTIO_OUTPUT 链：选择需要重定向到 Envoy（即本地） 的出站流量，所有非 localhost 的流量全部转发到 ISTIO_REDIRECT。为了避免流量在该 Pod 中无限循环，所有到 istio-proxy 用户空间的流量都返回到它的调用点中的下一条规则，本例中即 OUTPUT 链，因为跳出 ISTIO_OUTPUT 规则之后就进入下一条链 POSTROUTING。如果目的地非 localhost 就跳转到 ISTIO_REDIRECT；如果流量是来自 istio-proxy 用户空间的，那么就跳出该链，返回它的调用链继续执行下一条规则（OUPT 的下一条规则，无需对流量进行处理）；所有的非 istio-proxy 用户空间的目的地是 localhost 的流量就跳转到 ISTIO_REDIRECT&lt;/span&gt;
Chain ISTIO_OUTPUT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; ISTIO_REDIRECT  all  --  any    lo      anywhere            !localhost
   &lt;span class=&#34;m&#34;&gt;40&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;2400&lt;/span&gt; RETURN     all  --  any    any     anywhere             anywhere             owner UID match istio-proxy
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    any     anywhere             anywhere             owner GID match istio-proxy	
    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;     &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt; RETURN     all  --  any    any     anywhere             localhost
   &lt;span class=&#34;m&#34;&gt;53&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3180&lt;/span&gt; ISTIO_REDIRECT  all  --  any    any     anywhere             anywhere

&lt;span class=&#34;c1&#34;&gt;# ISTIO_REDIRECT 链：将所有流量重定向到 Envoy（即本地） 的 15001 端口&lt;/span&gt;
Chain ISTIO_REDIRECT &lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; references&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
 pkts bytes target     prot opt in     out     &lt;span class=&#34;nb&#34;&gt;source&lt;/span&gt;               destination
   &lt;span class=&#34;m&#34;&gt;53&lt;/span&gt;  &lt;span class=&#34;m&#34;&gt;3180&lt;/span&gt; REDIRECT   tcp  --  any    any     anywhere             anywhere             redir ports &lt;span class=&#34;m&#34;&gt;15001&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;iptables&lt;/code&gt; 显示的链的顺序，即流量规则匹配的顺序。其中要特别注意 &lt;code&gt;ISTIO_OUTPUT&lt;/code&gt; 链中的规则配置。为了避免流量一直在 Pod 中无限循环，所有到 istio-proxy 用户空间的流量都返回到它的调用点中的下一条规则，本例中即 OUTPUT 链，因为跳出 &lt;code&gt;ISTIO_OUTPUT&lt;/code&gt; 规则之后就进入下一条链 &lt;code&gt;POSTROUTING&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ISTIO_OUTPUT&lt;/code&gt; 链规则匹配的详细过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果目的地非 localhost 就跳转到 ISTIO_REDIRECT 链&lt;/li&gt;
&lt;li&gt;所有来自 istio-proxy 用户空间的非 localhost 流量跳转到它的调用点 &lt;code&gt;OUTPUT&lt;/code&gt; 继续执行 &lt;code&gt;OUTPUT&lt;/code&gt; 链的下一条规则，因为 &lt;code&gt;OUTPUT&lt;/code&gt; 链中没有下一条规则了，所以会继续执行 &lt;code&gt;POSTROUTING&lt;/code&gt; 链然后跳出 iptables，直接访问目的地&lt;/li&gt;
&lt;li&gt;如果流量不是来自 istio-proxy 用户空间，又是对 localhost 的访问，那么就跳出 iptables，直接访问目的地&lt;/li&gt;
&lt;li&gt;其它所有情况都跳转到 &lt;code&gt;ISTIO_REDIRECT&lt;/code&gt; 链&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其实在最后这条规则前还可以增加 IP 地址过滤，让某些 IP 地址段不通过 Envoy 代理。&lt;/p&gt;
&lt;p&gt;以上 iptables 规则都是 Init 容器启动的时使用 &lt;a href=&#34;https://github.com/istio/istio/tree/master/tools/istio-iptables&#34;&gt;istio-iptables&lt;/a&gt; 命令生成的，详细过程可以查看该命令行程序。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/concepts/init-containers.html&#34;&gt;Init 容器 - Kubernetes 中文指南/云原生应用架构实践手册 - jimmysong.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/reference/kubectl/jsonpath/&#34;&gt;JSONPath Support - kubernetes.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wangchujiang.com/linux-command/c/iptables.html&#34;&gt;iptables 命令使用说明 - wangchujiang.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.digitalocean.com/community/tutorials/how-to-list-and-delete-iptables-firewall-rules&#34;&gt;How To List and Delete Iptables Firewall Rules - digitalocean.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/fhefh/archive/2011/04/04/2005249.html&#34;&gt;一句一句解说 iptables的详细中文手册 - cnblog.com&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Istio Service Mesh 教程</title>
      <link>https://jimmysong.io/blog/istio-tutorial/</link>
      <pubDate>Wed, 18 Apr 2018 23:20:47 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-tutorial/</guid>
      <description>
        
        
        &lt;p&gt;本文是 Istio 管理 Java 微服务的案例教程，使用的所有工具和软件全部基于开源方案，替换了 &lt;a href=&#34;https://github.com/redhat-developer-demos/istio-tutorial&#34;&gt;redhat-developer-demos/istio-tutorial&lt;/a&gt; 中的 minishift 环境，使用 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster&#34;&gt;kubernetes-vagrant-centos-cluster&lt;/a&gt; 替代，沿用了原有的微服务示例，使用 Zipkin 做分布式追踪而不是 Jaeger。&lt;/p&gt;
&lt;p&gt;本文中的代码和 YAML 文件见 &lt;a href=&#34;https://github.com/rootsongjc/istio-tutorial&#34;&gt;https://github.com/rootsongjc/istio-tutorial&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;准备环境&#34;&gt;准备环境&lt;/h2&gt;
&lt;p&gt;在进行本教程前需要先准备以下工具和环境。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;8G 以上内存&lt;/li&gt;
&lt;li&gt;Vagrant 2.0+&lt;/li&gt;
&lt;li&gt;Virtualbox 5.0 +&lt;/li&gt;
&lt;li&gt;提前下载 kubernetes1.9.1 的 release 压缩包&lt;/li&gt;
&lt;li&gt;docker 1.12+&lt;/li&gt;
&lt;li&gt;kubectl 1.9.1+&lt;/li&gt;
&lt;li&gt;maven 3.5.2+&lt;/li&gt;
&lt;li&gt;istioctl 0.7.1&lt;/li&gt;
&lt;li&gt;git&lt;/li&gt;
&lt;li&gt;curl、gzip、tar&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/johanhaleby/kubetail&#34;&gt;kubetail&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/JoeDog/siege&#34;&gt;siege&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;安装-kubernetes&#34;&gt;安装 Kubernetes&lt;/h2&gt;
&lt;p&gt;请参考 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster&#34;&gt;kubernetes-vagrant-centos-cluster&lt;/a&gt; 在本地启动拥有三个节点的 kubernetes 集群。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;git clone https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster.git
&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; kubernetes-vagrant-centos-cluster
vagrant up
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;安装-istio&#34;&gt;安装 Istio&lt;/h2&gt;
&lt;p&gt;在 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster&#34;&gt;kubernetes-vagrant-centos-cluster&lt;/a&gt; 中的包含 Istio 0.7.1 的安装 YAML 文件，运行下面的命令安装 Istio。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f addon/istio/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;运行示例&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -n default -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f yaml/istio-bookinfo/bookinfo.yaml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在您自己的本地主机的&lt;code&gt;/etc/hosts&lt;/code&gt;文件中增加如下配置项。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;172.17.8.102 grafana.istio.jimmysong.io&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;172.17.8.102 servicegraph.istio.jimmysong.io&lt;/span&gt;
&lt;span class=&#34;na&#34;&gt;172.17.8.102 zipkin.istio.jimmysong.io&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们可以通过下面的URL地址访问以上的服务。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Service&lt;/th&gt;
&lt;th&gt;URL&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;grafana&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://grafana.istio.jimmysong.io&#34;&gt;http://grafana.istio.jimmysong.io&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;servicegraph&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://servicegraph.istio.jimmysong.io/dotviz&#34;&gt;http://servicegraph.istio.jimmysong.io/dotviz&lt;/a&gt;，&lt;a href=&#34;http://servicegraph.istio.jimmysong.io/graph&#34;&gt;http://servicegraph.istio.jimmysong.io/graph&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;zipkin&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;http://zipkin.istio.jimmysong.io&#34;&gt;http://zipkin.istio.jimmysong.io&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;详细信息请参阅 &lt;a href=&#34;https://istio.io/docs/guides/bookinfo.html&#34;&gt;https://istio.io/docs/guides/bookinfo.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;部署示例应用&#34;&gt;部署示例应用&lt;/h2&gt;
&lt;p&gt;在打包成镜像部署到 kubernetes 集群上运行之前，我们先在本地运行所有示例。&lt;/p&gt;
&lt;p&gt;本教程中三个服务之间的依赖关系如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;customer → preference → recommendation&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;code&gt;customer&lt;/code&gt; 和 &lt;code&gt;preference&lt;/code&gt; 微服务是基于 Spring Boot 构建的，&lt;code&gt;recommendation&lt;/code&gt; 微服务是基于 &lt;a href=&#34;https://vertx.io&#34;&gt;vert.x&lt;/a&gt; 构建的。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;customer&lt;/code&gt; 和 &lt;code&gt;preference&lt;/code&gt; 微服务的 &lt;code&gt;pom.xml&lt;/code&gt; 文件中都引入了 OpenTracing 和 Jeager 的依赖。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-xml&#34; data-lang=&#34;xml&#34;&gt;&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
	&lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;io.opentracing.contrib&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
	&lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;opentracing-spring-cloud-starter&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
	&lt;span class=&#34;nt&#34;&gt;&amp;lt;version&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;0.1.7&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;dependency&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;
	&lt;span class=&#34;nt&#34;&gt;&amp;lt;groupId&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;com.uber.jaeger&lt;span class=&#34;nt&#34;&gt;&amp;lt;/groupId&amp;gt;&lt;/span&gt;
	&lt;span class=&#34;nt&#34;&gt;&amp;lt;artifactId&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;jaeger-tracerresolver&lt;span class=&#34;nt&#34;&gt;&amp;lt;/artifactId&amp;gt;&lt;/span&gt;
    &lt;span class=&#34;nt&#34;&gt;&amp;lt;version&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;&amp;gt;&lt;/span&gt;0.25.0&lt;span class=&#34;nt&#34;&gt;&amp;lt;/version&amp;gt;&lt;/span&gt;
&lt;span class=&#34;nt&#34;&gt;&amp;lt;/dependency&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;本地运行&#34;&gt;本地运行&lt;/h3&gt;
&lt;p&gt;我们首先在本地确定所有的微服务都可以正常运行，然后再打包镜像在 kubernetes 集群上运行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;启动 Jaeger&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;使用 docker 来运行 jagger。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker run -d &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  --rm &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -p5775:5775/udp &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -p6831:6831/udp &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -p6832:6832/udp &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -p16686:16686 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -p14268:14268 &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  jaegertracing/all-in-one:1.3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Jaeger UI 地址 http://localhost:16686&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Customer&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; customer/java/springboot
&lt;span class=&#34;nv&#34;&gt;JAEGER_SERVICE_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;customer mvn &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  spring-boot:run &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -Drun.arguments&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;--spring.config.location=src/main/resources/application-local.properties&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;服务访问地址： http://localhost:8280&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preference&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; preference/java/springboot
&lt;span class=&#34;nv&#34;&gt;JAEGER_SERVICE_NAME&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;preference mvn &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  spring-boot:run &lt;span class=&#34;se&#34;&gt;\
&lt;/span&gt;&lt;span class=&#34;se&#34;&gt;&lt;/span&gt;  -Drun.arguments&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;--spring.config.location=src/main/resources/application-local.properties&amp;#34;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;服务访问地址：http://localhost:8180&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Recommendation&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; recommendation/java/vertx
mvn vertx:run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;服务访问地址：http://localhost:8080&lt;/p&gt;
&lt;p&gt;所有服务都启动之后，此时访问 http://localhost:8280 将会看到如下输出。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;unknown&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;每访问一次最后的数字就会加 1。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Jaeger&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;此时访问 http://localhost:16686 将看到 Jaeger query UI，所有应用将 metrics 发送到 Jeager 中。&lt;/p&gt;
&lt;p&gt;可以在 Jaeger UI 中搜索 &lt;code&gt;customer&lt;/code&gt; 和 &lt;code&gt;preference&lt;/code&gt; service 的 trace 并查看每次请求的 tracing。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/jaeger-query-ui.png&#34; alt=&#34;Jaeger query UI&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;构建镜像&#34;&gt;构建镜像&lt;/h3&gt;
&lt;p&gt;在本地运行测试无误之后就可以构建镜像了。本教程中的容器镜像都是在 &lt;a href=&#34;https://hub.docker.com/r/fabric8/java-jboss-openjdk8-jdk/~/dockerfile/&#34;&gt;fabric8/java-jboss-openjdk8-jdk&lt;/a&gt; 的基础上构建的。只要将 Java 应用构建出 Jar 包然后放到 &lt;code&gt;/deployments&lt;/code&gt; 目录下基础镜像就可以自动帮我们运行，所以我们看到着几个应用的 &lt;code&gt;Dockerfile&lt;/code&gt; 文件中都没有执行入口，真正的执行入口是 &lt;a href=&#34;https://github.com/fabric8io-images/java/blob/master/images/jboss/openjdk8/jdk/run-java.sh&#34;&gt;run-java.sh&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Customer&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;构建 Customer 镜像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; customer/java/springboot
mvn clean package
docker build -t jimmysong/istio-tutorial-customer:v1 .
docker push jimmysong/istio-tutorial-customer:v1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;第一次构建和上传需要花费一点时间，下一次构建就会很快。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Preference&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;构建 Preference 镜像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; preference/java/springboot
mvn clean package
docker build -t jimmysong/istio-tutorial-preference:v1 .
docker push jimmysong/istio-tutorial-preference:v1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Recommendation&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;构建 Recommendation 镜像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; recommendation/java/vertx
mvn clean package
docker build -t jimmysong/istio-tutorial-recommendation:v1 .
docker push jimmysong/istio-tutorial-recommendation:v1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在三个 docker 镜像都构建完成了，我们检查一下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ docker images &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; grep istio-tutorial
REPOSITORY                                TAG                 IMAGE ID            CREATED             SIZE
jimmysong/istio-tutorial-recommendation   v1                  d31dd858c300        &lt;span class=&#34;m&#34;&gt;51&lt;/span&gt; seconds ago      443MB
jimmysong/istio-tutorial-preference       v1                  e5f0be361477        &lt;span class=&#34;m&#34;&gt;6&lt;/span&gt; minutes ago       459MB
jimmysong/istio-tutorial-customer         v1                  d9601692673e        &lt;span class=&#34;m&#34;&gt;13&lt;/span&gt; minutes ago      459MB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;部署到-kubernetes&#34;&gt;部署到 Kubernetes&lt;/h3&gt;
&lt;p&gt;使用下面的命令将以上服务部署到 kubernetes。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# create new namespace&lt;/span&gt;
kubectl create ns istio-tutorial

&lt;span class=&#34;c1&#34;&gt;# deploy recommendation&lt;/span&gt;
kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f recommendation/kubernetes/Deployment.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-tutorial
kubectl apply -f recommendation/kubernetes/Service.yml

&lt;span class=&#34;c1&#34;&gt;# deploy preferrence&lt;/span&gt;
kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f preference/kubernetes/Deployment.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-tutorial
kubectl apply -f preference/kubernetes/Service.yml

&lt;span class=&#34;c1&#34;&gt;# deploy customer&lt;/span&gt;
kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f customer/kubernetes/Deployment.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-tutorial
kubectl apply -f customer/kubernetes/Service.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;**注意：**&lt;code&gt;preference&lt;/code&gt; 和 &lt;code&gt;customer&lt;/code&gt; 应用启动速度比较慢，我们将 livenessProb 配置中的 &lt;code&gt;initialDelaySeconds&lt;/code&gt; 设置为 &lt;strong&gt;20&lt;/strong&gt; 秒。&lt;/p&gt;
&lt;p&gt;查看 Pod 启动状态：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl get pod -w -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;增加-ingress-配置&#34;&gt;增加 Ingress 配置&lt;/h3&gt;
&lt;p&gt;为了在 kubernetes 集群外部访问 customer 服务，我们需要增加 ingress 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f ingress/ingress.yaml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;修改本地的 &lt;code&gt;/etc/hosts&lt;/code&gt; 文件，增加一条配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;172.17.8.102 customer.istio-tutorial.jimmysong.io&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在访问 &lt;a href=&#34;http://customer.istio-tutorial.jimmysong.io&#34;&gt;http://customer.istio-tutorial.jimmysong.io&lt;/a&gt; 将看到如下输出：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;gt; preference =&amp;gt; recommendation v1 from &amp;#39;6fc97476f8-m2ntp&amp;#39;: 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;批量访问该地址。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;./bin/poll_customer.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;访问 &lt;a href=&#34;http://servicegraph.istio.jimmysong.io/dotviz&#34;&gt;http://servicegraph.istio.jimmysong.io/dotviz&lt;/a&gt; 查看服务的分布式追踪和依赖关系。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/istio-tutorial-zipkin-trace.png&#34; alt=&#34;分布式追踪&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/istio-tutorial-zipkin-dependency.png&#34; alt=&#34;依赖关系&#34;&gt;&lt;/p&gt;
&lt;p&gt;访问 &lt;a href=&#34;http://servicegraph.istio.jimmysong.io/dotviz&#34;&gt;http://servicegraph.istio.jimmysong.io/dotviz&lt;/a&gt; 查看服务间的关系图和 QPS。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/istio-tutorial-serivcegraph-dotviz.png&#34; alt=&#34;服务关系图和QPS&#34;&gt;&lt;/p&gt;
&lt;p&gt;访问 &lt;a href=&#34;http://grafana.istio.jimmysong.io&#34;&gt;http://grafana.istio.jimmysong.io&lt;/a&gt; 查看 Service Mesh 的监控信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/istio-tutorial-grafana.png&#34; alt=&#34;Grafana 监控&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;istio-使用示例&#34;&gt;Istio 使用示例&lt;/h2&gt;
&lt;p&gt;为了试用 Istio 中的各种功能，我们需要为应用构建多个版本，我们为 recommendation 构建 v2 版本的镜像，看看如何使用 Istio 控制微服务的流量。&lt;/p&gt;
&lt;h3 id=&#34;构建-recommendationv2&#34;&gt;构建 recommendation:v2&lt;/h3&gt;
&lt;p&gt;我们将构建新版的 &lt;code&gt;recommendation&lt;/code&gt; 服务的镜像，并观察 &lt;code&gt;customer&lt;/code&gt; 对不同版本的 &lt;code&gt;recommendataion&lt;/code&gt; 服务的访问频率。&lt;/p&gt;
&lt;p&gt;修改 &lt;code&gt;recommendation/java/vertx/src/main/java/com/redhat/developer/demos/recommendation/RecommendationVerticle.java&lt;/code&gt; 程序中代码。&lt;/p&gt;
&lt;p&gt;将 &lt;code&gt;private static final String RESPONSE_STRING_FORMAT = &amp;quot;recommendation v1 from &#39;%s&#39;: %d\n&amp;quot;;&lt;/code&gt; 修改为 &lt;code&gt;private static final String RESPONSE_STRING_FORMAT = &amp;quot;recommendation v2 from &#39;%s&#39;: %d\n&amp;quot;;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;并构建 &lt;code&gt;recommendation:v2&lt;/code&gt; 镜像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; recommendation/java/vertx
mvn clean package
docker build -t jimmysong/istio-tutorial-recommendation:v2 .
docker push jimmysong/istio-tutorial-recommendation:v2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将应用部署到 kubernetes。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# deploy recommendation&lt;/span&gt;
kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f recommendation/kubernetes/Deployment-v2.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在再访问 &lt;code&gt;customer&lt;/code&gt; 服务，将看到如下输出：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3581&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3582&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3583&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;4&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们可以看到 v1 和 v2 版本的 &lt;code&gt;recommendation&lt;/code&gt; 服务会被间隔访问到。&lt;/p&gt;
&lt;p&gt;我们再将 v2 版本的 &lt;code&gt;recommendation&lt;/code&gt; 实例数设置成 2 个。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl scale --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; deployment/recommendation-v2 -n istio-tutorial
kubectl get pod -w -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;观察 &lt;code&gt;recommendation-v2&lt;/code&gt; Pod 达到两个之后再访问 &lt;code&gt;customer&lt;/code&gt; 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-j9fgj&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;71&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3651&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-j9fgj&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;72&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3652&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-j9fgj&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;73&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3653&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;观察输出中 v1 和 v2 版本 &lt;code&gt;recommendation&lt;/code&gt; 的访问频率。&lt;/p&gt;
&lt;p&gt;将 &lt;code&gt;recommendataion&lt;/code&gt; 服务的实例数恢复为 1。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl scale --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; deployment/recommendation-v2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;修改-istio-routerules&#34;&gt;修改 Istio RouteRules&lt;/h3&gt;
&lt;p&gt;以下所有路有规则都是针对 &lt;code&gt;recommendation&lt;/code&gt; 服务，并在 repo 的根目录下执行。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;将所有流量打给 v2&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;下面将演示如何动态的划分不同版本服务间的流量，将所有的流量都打到 &lt;code&gt;recommendation:v2&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v2.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在再访问 &lt;code&gt;customer&lt;/code&gt; 服务将看到所有的流量都会打到 &lt;code&gt;recommendation:v2&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;删除 RouteRules 后再访问 &lt;code&gt;customer&lt;/code&gt; 服务将看到又恢复了 v1 和 v2 版本的 &lt;code&gt;recommendation&lt;/code&gt; 服务的间隔访问。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-default
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;切分流量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;将 90% 的流量给 v1，10% 的流量给 v2。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v1_and_v2.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行&lt;code&gt;bin/poll_customer.sh&lt;/code&gt; 观察访问情况。&lt;/p&gt;
&lt;p&gt;要想动态切分流量只要修改 RouteRules 中的 &lt;code&gt;weight&lt;/code&gt; 配置即可。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;config.istio.io/v1alpha2&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;RouteRule&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;recommendation-v1-v2&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;destination&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;namespace&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;istio-tutorial&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;recommendation&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;precedence&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;route&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;weight&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;90&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v2&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;weight&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为 RouteRule 有优先级，为了继续后面的实验，在验证完成后删除该 RouteRule。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-v1-v2 -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;故障注入&#34;&gt;故障注入&lt;/h3&gt;
&lt;p&gt;有时候我们为了增强系统的健壮性，需要对系统做混沌工程，故意注入故障，并保障服务可以自动处理这些故障。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注入 HTTP 503 错误&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-503.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;有 50% 的几率报 503 错误。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;135&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; fault filter abort
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3860&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; fault filter abort
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; fault filter abort
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;136&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;3861&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; fault filter abort
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; fault filter abort
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;77b9f6cc68-5xs27&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;137&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; fault filter abort
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;清理 RouteRule。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-503 -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;增加延迟&#34;&gt;增加延迟&lt;/h3&gt;
&lt;p&gt;增加服务的访问延迟。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-delay.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;会有 50% 的几率访问 &lt;code&gt;recommendation&lt;/code&gt; 服务有 7 秒的延迟。百分比和延迟时间可以在 RouteRule 中配置。&lt;/p&gt;
&lt;p&gt;清理 RouteRule。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-delay -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;重试&#34;&gt;重试&lt;/h3&gt;
&lt;p&gt;让服务不是直接失败，而是增加重试机制。&lt;/p&gt;
&lt;p&gt;我们下面将同时应用两条 RouteRule，让访问 &lt;code&gt;recommendation&lt;/code&gt; 服务时有 50% 的几率出现 503 错误，并在出现错误的时候尝试访问 v2 版本，超时时间为 2 秒。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v2_503.yml -n istio-tutorial
istioctl create -f istiofiles/route-rule-recommendation-v2_retry.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行 &lt;code&gt;bin/poll_customer.sh&lt;/code&gt; 我们看到一开始有些 503 错误，然后所有的流量都流向了 v2。&lt;/p&gt;
&lt;p&gt;清理 RouteRules。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-v2-retry -n istio-tutorial
istioctl delete routerule recommendation-v2-503 -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;超时&#34;&gt;超时&lt;/h3&gt;
&lt;p&gt;设置超时时间，只有服务访问超时才认定服务访问失败。&lt;/p&gt;
&lt;p&gt;取消注释 &lt;code&gt;recommendation/java/vertx/src/main/java/com/redhat/developer/demos/recommendation/RecommendationVerticle.java&lt;/code&gt; 中的下面一行，增加超时时间为 3 秒。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-java&#34; data-lang=&#34;java&#34;&gt;&lt;span class=&#34;n&#34;&gt;router&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;get&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;na&#34;&gt;handler&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;this&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;重新生成镜像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; recommendation/java/vertx
mvn clean package
docker build -t jimmysong/istio-tutorial-recommendation:v2 .
docker push jimmysong/istio-tutorial-recommendation:v2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;重新部署到 kubernetes。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl delete -f recommendation/kubernetes/Deployment-v2.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因为我们重新构建的镜像使用了同样的名字和 tag，而之前在 &lt;code&gt;Deployment-v2.yml&lt;/code&gt; 中配置的镜像拉取策略是 &lt;code&gt;IfNotPresent&lt;/code&gt;，这样的话即使我们构建了新的镜像也无法应用到集群上，因此将镜像拉取策略改成 &lt;code&gt;Always&lt;/code&gt; 确保每次启动 Pod 的时候都会拉取镜像。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f recommendation/kubernetes/Deployment-v2.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;启用超时 RouteRules。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-timeout.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;访问 &lt;code&gt;customer&lt;/code&gt; 服务将看到如下输出：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;504&lt;/span&gt; upstream request timeout
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;4002&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;504&lt;/span&gt; upstream request timeout
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;4003&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;504&lt;/span&gt; upstream request timeout
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;4004&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;清理 RouteRules。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-timeout -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;基于-user-agent-的智能路由金丝雀发布&#34;&gt;基于 user-agent 的智能路由（金丝雀发布）&lt;/h3&gt;
&lt;p&gt;User-agent 是一个字符串，其中包含了浏览器的信息，访问 &lt;a href=&#34;https://www.whoishostingthis.com/tools/user-agent&#34;&gt;https://www.whoishostingthis.com/tools/user-agent&lt;/a&gt; 获取你的 user-agent。&lt;/p&gt;
&lt;p&gt;我的 user-agent 是：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将所有的流量打到 v1。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v1.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将使用 Safari 浏览器访问的流量打到 v2。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-safari-recommendation-v2.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;谁用 Safari 或者 Chrome（Chrome 浏览器的 user-agent 中也包含 Safari 字段）访问 &lt;a href=&#34;http://customer.istio-tutorial.jimmysong.io/&#34;&gt;http://customer.istio-tutorial.jimmysong.io/&lt;/a&gt; 在经过 3 秒钟（我们在前面重新编译 v2 镜像，设置了 3 秒超时时间）后将看到访问 v2 的输出。&lt;/p&gt;
&lt;p&gt;或者使用 curl 访问。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;curl -A Safari http://customer.istio-tutorial.jimmysong.io/
curl -A Firefox http://customer.istio-tutorial.jimmysong.io/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;观察返回的结果。&lt;/p&gt;
&lt;p&gt;将移动端用户的流量导到 v2。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-mobile-recommendation-v2.yml -n istio-tutorial

curl -A &lt;span class=&#34;s2&#34;&gt;&amp;#34;Mozilla/5.0 (iPhone; U; CPU iPhone OS 4(KHTML, like Gecko) Version/5.0.2 Mobile/8J2 Safari/6533.18.5&amp;#34;&lt;/span&gt; http://customer.istio-tutorial.jimmysong.io/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;观察输出的结果。&lt;/p&gt;
&lt;p&gt;清理 RouteRules。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-mobile -n istio-tutorial
istioctl delete routerule recommendation-safari -n istio-tutorial
istioctl delete routerule recommendation-default -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;镜像流量&#34;&gt;镜像流量&lt;/h3&gt;
&lt;p&gt;确保当前至少运行了两个版本的 &lt;code&gt;recommendation&lt;/code&gt; 服务，并且没有 RouteRule。&lt;/p&gt;
&lt;p&gt;注：可以使用 &lt;code&gt;istioctl get routerule&lt;/code&gt; 获取 RouteRule。&lt;/p&gt;
&lt;p&gt;设置流量镜像，将所有 v1 的流量都被镜像到 v2。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v1-mirror-v2.yml -n istio-tutorial
bin/poll_customer.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看 recommendation-v2 的日志。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl logs -f &lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt;oc get pods&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;grep recommendation-v2&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;awk &lt;span class=&#34;s1&#34;&gt;&amp;#39;{ print $1 }&amp;#39;&lt;/span&gt;&lt;span class=&#34;sb&#34;&gt;`&lt;/span&gt; -c recommendation
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;访问控制&#34;&gt;访问控制&lt;/h3&gt;
&lt;p&gt;Istio 可以设置服务访问的黑白名单，如果没有权限的话会返回 HTTP 404 Not Found。&lt;/p&gt;
&lt;h4 id=&#34;白名单&#34;&gt;白名单&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/acl-whitelist.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;此时访问 &lt;code&gt;customer&lt;/code&gt; 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;404&lt;/span&gt; NOT_FOUND:preferencewhitelist.listchecker.istio-tutorial:customer is not whitelisted
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;重置环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete -f istiofiles/acl-whitelist.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;黑名单&#34;&gt;黑名单&lt;/h4&gt;
&lt;p&gt;设置黑名单，所有位于黑名单中的流量将获得 403 Forbidden 返回码。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/acl-blacklist.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;此时访问 &lt;code&gt;customer&lt;/code&gt; 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;403&lt;/span&gt; PERMISSION_DENIED:denycustomerhandler.denier.istio-tutorial:Not allowed
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;重置环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete -f istiofiles/acl-blacklist.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;负载均衡&#34;&gt;负载均衡&lt;/h3&gt;
&lt;p&gt;Kubernetes 中默认的负载均衡策略是 round-robin，当然我们可以使用 Istio 把它修改成 random。&lt;/p&gt;
&lt;p&gt;增加 v1 的实例数。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl scale deployment recommendation-v1 --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;持续访问 &lt;code&gt;customer&lt;/code&gt; 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;bin/poll_customer.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;保持前台输出，观察流量的行为。&lt;/p&gt;
&lt;p&gt;应用负载均衡策略。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/recommendation_lb_policy_app.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;观察一段时间流量的行为后，重置环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete -f istiofiles/recommendation_lb_policy_app.yml -n istio-tutorial
kubectl scale deployment recommendation-v1 --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;速率限制&#34;&gt;速率限制&lt;/h3&gt;
&lt;p&gt;暂时不可用&lt;/p&gt;
&lt;h3 id=&#34;断路器&#34;&gt;断路器&lt;/h3&gt;
&lt;p&gt;当达到最大连接数和最大挂起请求数时快速失败。&lt;/p&gt;
&lt;p&gt;将流量在 v1 和 v2 之间均分。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v1_and_v2_50_50.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;未开启断路器的时候启动负载测试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ siege -r &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; -c &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; -v customer.istio-tutorial.jimmysong.io
New configuration template added to /Users/jimmysong/.siege
Run siege -C to view the current settings in that file
** SIEGE 4.0.4
** Preparing &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; concurrent users &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; battle.
The server is now under siege...
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.10 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.12 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.13 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.13 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.13 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.17 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.12 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.14 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.15 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.15 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.17 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.17 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.20 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.20 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.05 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.12 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.15 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.25 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.26 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.14 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.58 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     6.15 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     6.16 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.03 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     6.06 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     6.04 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.11 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.09 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     6.15 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     6.71 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     3.52 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
^C
Lifting the server siege...
Transactions:		          &lt;span class=&#34;m&#34;&gt;31&lt;/span&gt; hits
Availability:		      100.00 %
Elapsed time:		        7.99 secs
Data transferred:	        0.00 MB
Response time:		        2.99 secs
Transaction rate:	        3.88 trans/sec
Throughput:		        0.00 MB/sec
Concurrency:		       11.60
Successful transactions:          &lt;span class=&#34;m&#34;&gt;31&lt;/span&gt;
Failed transactions:	           &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;
Longest transaction:	        6.71
Shortest transaction:	        0.05
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;所有的请求都成功了，但是性能很差，因为 v2 版本设置了 3 秒的超时时间。&lt;/p&gt;
&lt;p&gt;我们启用下断路器。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/recommendation_cb_policy_version_v2.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;重新测试一下。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ siege -r &lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; -c &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; -v customer.istio-tutorial.jimmysong.io
** SIEGE 4.0.4
** Preparing &lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; concurrent users &lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; battle.
The server is now under siege...
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.07 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.07 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.07 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.12 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.12 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.16 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.16 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.21 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.21 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.24 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.24 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.14 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.29 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.13 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.18 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.13 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.11 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.39 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.24 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.44 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.43 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.44 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.40 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.47 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.42 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.42 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.06 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.07 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.15 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.12 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.57 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.18 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.52 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.65 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.42 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.09 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.43 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;     0.04 secs:      &lt;span class=&#34;m&#34;&gt;92&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     4.15 secs:      &lt;span class=&#34;m&#34;&gt;74&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /
HTTP/1.1 &lt;span class=&#34;m&#34;&gt;200&lt;/span&gt;     0.01 secs:      &lt;span class=&#34;m&#34;&gt;75&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; GET  /

Transactions:		          &lt;span class=&#34;m&#34;&gt;19&lt;/span&gt; hits
Availability:		       47.50 %
Elapsed time:		        4.16 secs
Data transferred:	        0.00 MB
Response time:		        0.72 secs
Transaction rate:	        4.57 trans/sec
Throughput:		        0.00 MB/sec
Concurrency:		        3.31
Successful transactions:          &lt;span class=&#34;m&#34;&gt;19&lt;/span&gt;
Failed transactions:	          &lt;span class=&#34;m&#34;&gt;21&lt;/span&gt;
Longest transaction:	        4.15
Shortest transaction:	        0.01
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们可以看到在启用了断路器后各项性能都有提高。&lt;/p&gt;
&lt;p&gt;清理配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete routerule recommendation-v1-v2 -n istio-tutorial
istioctl delete -f istiofiles/recommendation_cb_policy_version_v2.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;pool-ejection&#34;&gt;Pool Ejection&lt;/h3&gt;
&lt;p&gt;所谓的 Pool Ejection 就是当某些实例出现错误（如返回 5xx 错误码）临时将该实例弹出一段时间后（窗口期，可配置），然后再将其加入到负载均衡池中。我们的例子中配置的窗口期是 15 秒。&lt;/p&gt;
&lt;p&gt;将 v1 和 v2 的流量均分。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/route-rule-recommendation-v1_and_v2_50_50.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;增加 v2 的实例个数。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl scale deployment recommendation-v2 --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;2&lt;/span&gt; -n istio-tutorial
kubectl get pods -w
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;等待所有的 Pod 的状态都启动完成。&lt;/p&gt;
&lt;p&gt;现在到 v2 的容器中操作。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; recommendation-v2-785465d9cd-225ms -c recommendation /bin/bash
$ curl localhost:8080/misbehave
Following requests to &lt;span class=&#34;s1&#34;&gt;&amp;#39;/&amp;#39;&lt;/span&gt; will &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; a &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;增加 Pool Ejection 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/recommendation_cb_policy_pool_ejection.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;此时再访问 &lt;code&gt;customer&lt;/code&gt; 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;$ bin/poll_customer.sh
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;10505&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;785465d9cd-225ms&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;2407&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;10506&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;785465d9cd-225ms&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;2408&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;10507&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;10508&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v1 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;6fc97476f8-m2ntp&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;10509&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;m&#34;&gt;503&lt;/span&gt; recommendation misbehavior from &lt;span class=&#34;s1&#34;&gt;&amp;#39;785465d9cd-ldc6j&amp;#39;&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;785465d9cd-225ms&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;2409&lt;/span&gt;
&lt;span class=&#34;nv&#34;&gt;customer&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; &lt;span class=&#34;nv&#34;&gt;preference&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&amp;gt; recommendation v2 from &lt;span class=&#34;s1&#34;&gt;&amp;#39;785465d9cd-225ms&amp;#39;&lt;/span&gt;: &lt;span class=&#34;m&#34;&gt;2410&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们看到窗口期生效了，当出现 503 错误后至少 15 秒后才会出现第二次。&lt;/p&gt;
&lt;p&gt;即使有了负载均衡池弹出策略对于系统的弹性来说依然还不够，如果你的服务有多个可用实例，可以将&lt;strong&gt;断路器&lt;/strong&gt;、&lt;strong&gt;重试&lt;/strong&gt;、&lt;strong&gt;Pool Ejection&lt;/strong&gt; 等策略组合起来使用。&lt;/p&gt;
&lt;p&gt;例如在以上的 Pool Ejection 的基础上增加重试策略。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl replace -f istiofiles/route-rule-recommendation-v1_and_v2_retry.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在再访问 &lt;code&gt;customer&lt;/code&gt; 服务就看不到 503 错误了。&lt;/p&gt;
&lt;p&gt;清理配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl scale deployment recommendation-v2 --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; -n istio-tutorial
istioctl delete routerule recommendation-v1-v2 -n istio-tutorial
istioctl delete -f istiofiles/recommendation_cb_policy_pool_ejection.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;egress&#34;&gt;Egress&lt;/h3&gt;
&lt;p&gt;Egress 是用来配置 Istio serivce mesh 中的服务对外部服务的访问策略。&lt;/p&gt;
&lt;p&gt;具体配置请参考 &lt;a href=&#34;http://istio.doczh.cn/docs/tasks/traffic-management/egress.html&#34;&gt;控制 Egress 流量&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;以下示例还有问题，无法正常工作。&lt;/p&gt;
&lt;p&gt;构建示例镜像 egresshttpbin。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; egress/egresshttpbin/
mvn clean package
docker build -t jimmysong/istio-tutorial-egresshttpbin:v1 .
docker push jimmysong/istio-tutorial-egresshttpbin:v1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;部署到 Kubernetes。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f egress/egresshttpbin/src/main/kubernetes/Deployment.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-toturial
kubectl create -f egress/egresshttpbin/src/main/kubernetes/Service.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了在 kubernetes 集群外部访问到该服务，修改增加 ingress 配置并修改本地的&lt;code&gt;/etc/hosts&lt;/code&gt; 文件，我们在前面已经完成了，此处不再赘述。&lt;/p&gt;
&lt;p&gt;构建示例镜像 egressgithub。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; egress/egressgithub
mvn clean package
docker build -t jimmysong/istio-tutorial-egressgithub:v1 .
docker push jimmysong/istio-tutorial-egressgithub:v1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;部署到 Kubernetes。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f egress/egressgithub/src/main/kubernetes/Deployment.yml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; -n istio-tutorial
kubectl create -f egress/egressgithub/src/main/kubernetes/Service.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;增加 Egress 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/egress_httpbin.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;到 egresshttpbin 容器中测试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -it &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;oc get pods -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.items[*].metadata.name}&amp;#34;&lt;/span&gt; -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;egresshttpbin,version&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;v1&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c egresshttpbin /bin/bash

curl localhost:8080

curl httpbin.org/user-agent

curl httpbin.org/headers

&lt;span class=&#34;nb&#34;&gt;exit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;增加对 &lt;a href=&#34;https://jimmysong.io&#34;&gt;jimmysong.io&lt;/a&gt; 的 egress 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;cat &lt;span class=&#34;s&#34;&gt;&amp;lt;&amp;lt;EOF | istioctl create -f -
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;apiVersion: config.istio.io/v1alpha2
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;kind: EgressRule
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;metadata:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  name: jimmysong-egress-rule
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  namespace: istio-tutorial
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;spec:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  destination:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    service: jimmysong.io
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;  ports:
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;    - port: 443
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;      protocol: https
&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;EOF&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;增加 Egress 配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl create -f istiofiles/egress_github.yml -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;到 egressgithub 容器中测试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -it &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;oc get pods -o &lt;span class=&#34;nv&#34;&gt;jsonpath&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;{.items[*].metadata.name}&amp;#34;&lt;/span&gt; -l &lt;span class=&#34;nv&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;egressgithub,version&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;v1&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c egressgithub /bin/bash

curl http://jimmysong:443

&lt;span class=&#34;nb&#34;&gt;exit&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;清理环境。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;istioctl delete egressrule httpbin-egress-rule jimmysong-egress-rule github-egress-rule -n istio-tutorial
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/redhat-developer-demos/istio-tutorial&#34;&gt;https://github.com/redhat-developer-demos/istio-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.redhat.com/books/introducing-istio-service-mesh-microservices/&#34;&gt;Book - Introducing Istio Service Mesh for Microservices&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Istio 社区介绍与社区参与注意事项</title>
      <link>https://jimmysong.io/blog/istio-community-tips/</link>
      <pubDate>Sat, 14 Apr 2018 18:34:40 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/istio-community-tips/</guid>
      <description>
        
        
        &lt;p&gt;本文讲述了参与 Istio 社区和进行 Istio 开发时需要注意的事项。&lt;/p&gt;
&lt;h3 id=&#34;工作组&#34;&gt;工作组&lt;/h3&gt;
&lt;p&gt;绝大多数复杂的开源项目都是以工作组的方式组织的，要想为 Istio 社区做贡献可以加入到以下的工作组（Working Group）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#api-management&#34;&gt;API Management&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#config&#34;&gt;Config&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#environments&#34;&gt;Environments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#networking&#34;&gt;Networking&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#performance-and-scalability&#34;&gt;Performance &amp;amp; Scalability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#policies-and-telemetry&#34;&gt;Policies &amp;amp; Telemetry&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#security&#34;&gt;Security&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUPS.md#test-and-release&#34;&gt;Test &amp;amp; Release&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;代码规范&#34;&gt;代码规范&lt;/h3&gt;
&lt;p&gt;Istio 的代码规范沿用 &lt;a href=&#34;https://github.com/cncf/foundation/blob/master/code-of-conduct.md&#34;&gt;CNCF 社区的代码规范&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;开发指南&#34;&gt;开发指南&lt;/h3&gt;
&lt;p&gt;进行 Istio 开发之前需要做下面几件事情：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配置基础环境，如 Kubernetes&lt;/li&gt;
&lt;li&gt;配置代码库、下载依赖和测试&lt;/li&gt;
&lt;li&gt;配置 CircleCI 集成环境&lt;/li&gt;
&lt;li&gt;编写参考文档&lt;/li&gt;
&lt;li&gt;Git workflow 配置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详见 &lt;a href=&#34;https://github.com/istio/istio/wiki/Dev-Guide&#34;&gt;Dev Guide wiki&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;设计文档&#34;&gt;设计文档&lt;/h3&gt;
&lt;p&gt;所有的设计文档都保存在 &lt;a href=&#34;https://drive.google.com/drive/u/0/folders/0AIS5p3eW9BCtUk9PVA&#34;&gt;Google Drive&lt;/a&gt; 中，其中包括以下资源：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Technical Oversight Committee：ToC管理的文档&lt;/li&gt;
&lt;li&gt;Misc：一些杂项&lt;/li&gt;
&lt;li&gt;Working Groups：最重要的部分，各个工作组相关的设计文档&lt;/li&gt;
&lt;li&gt;Presentations：Istio 相关的演讲幻灯片，从这些文稿中可以快速了解 Istio&lt;/li&gt;
&lt;li&gt;Logo：Istio logo&lt;/li&gt;
&lt;li&gt;Eng：社区相关的维护文档&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;社区角色划分&#34;&gt;社区角色划分&lt;/h3&gt;
&lt;p&gt;根据对开发者和要求和贡献程度的不同，Istio 社区中包含以下角色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md#collaborator&#34;&gt;Collaborator&lt;/a&gt;：非正式贡献者，偶尔贡献，任何人都可以成为该角色&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md#member&#34;&gt;Member&lt;/a&gt;：正式贡献者，经常贡献，必须有2个已有的 member 提名&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md#approver&#34;&gt;Approver&lt;/a&gt;：老手，可以批准 member 的贡献&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md#lead&#34;&gt;Lead&lt;/a&gt;：管理功能、项目和提议，必须由 &lt;a href=&#34;https://github.com/istio/community/blob/master/WORKING-GROUP-PROCESSES.md&#34;&gt;ToC&lt;/a&gt; 提名&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md#administrator&#34;&gt;Administrator&lt;/a&gt;：管理员，管理和控制权限，必须由 ToC 提名&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md#vendor&#34;&gt;Vendor&lt;/a&gt;：贡献 Istio 项目的扩展&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详见 &lt;a href=&#34;https://github.com/istio/community/blob/master/ROLES.md&#34;&gt;Istio Community Roles&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;各种功能的状态&#34;&gt;各种功能的状态&lt;/h3&gt;
&lt;p&gt;Istio 中的所有 feature 根据&lt;strong&gt;是否生产可用&lt;/strong&gt;、&lt;strong&gt;API兼容性&lt;/strong&gt;、&lt;strong&gt;性能&lt;/strong&gt;、&lt;strong&gt;维护策略&lt;/strong&gt;分为三种状态：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alpha：仅仅可以作为 demo，无法生产上使用，也没有性能保证，随时都可能不维护&lt;/li&gt;
&lt;li&gt;Beta：可以在生产上使用了，也有版本化的 API 但是无法保证性能，保证三个月的维护&lt;/li&gt;
&lt;li&gt;Stable：可以上生产而且还能保证性能，API 向后兼容，保证一年的维护&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Istio 的 feature 分为四大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量管理：各种协议的支持、路由规则配置、Ingress TLS 等&lt;/li&gt;
&lt;li&gt;可观察性：监控、日志、分布式追踪、服务依赖拓扑&lt;/li&gt;
&lt;li&gt;安全性：各种 checker 和安全性配置&lt;/li&gt;
&lt;li&gt;Core：核心功能&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;功能划分与各种功能的状态详情请见：&lt;a href=&#34;https://istio.io/latest/about/feature-stages/&#34;&gt;https://istio.io/latest/about/feature-stages/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;云原生社区-istio-讨论组&#34;&gt;云原生社区 Istio 讨论组&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://cloudnative.to&#34;&gt;云原生社区&lt;/a&gt;专门成立里 Istio SIG（微信讨论群），将原来 ServiceMesher 中关注 Istio 的人群专门集中到一个讨论组中，其中包含了百度、阿里巴巴、腾讯、网易、Tetrate、Intel、字节跳动等公司的服务网格专家及众多的终端用户，欢迎大家&lt;a href=&#34;https://i.cloudnative.to/istio&#34;&gt;申请加入群聊&lt;/a&gt;。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>适用于kubernetes的应用开发部署流程同时集成Istio service mesh</title>
      <link>https://jimmysong.io/blog/creating-cloud-native-app-with-kubernetes/</link>
      <pubDate>Mon, 26 Mar 2018 22:48:44 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/creating-cloud-native-app-with-kubernetes/</guid>
      <description>
        
        
        &lt;p&gt;本文讲解了如何开发容器化应用，并使用Wercker持续集成工具构建docker镜像上传到docker镜像仓库中，然后在本地使用&lt;code&gt;docker-compose&lt;/code&gt;测试后，再使用&lt;code&gt;kompose&lt;/code&gt;自动生成kubernetes的yaml文件，再将注入Envoy sidecar容器，集成Istio service mesh中的详细过程。&lt;/p&gt;
&lt;p&gt;当我们有了一个kubernetes集群后，如何在上面开发和部署应用，应该遵循怎样的流程？本次分享将向您展示如何使用go语言开发和部署一个kubernetes native应用，使用wercker进行持续集成与持续发布，我将以一个很简单的前后端访问，获取伪造数据并展示的例子来说明。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：本文部分内容曾是我2017年9月14日在DockOne社区分享的内容，本文同时归档到&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34;&gt;kubernetes-handbook&lt;/a&gt;中。&lt;/p&gt;
&lt;p&gt;整个过程如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/how-to-use-kubernetes-with-istio.jpg&#34; alt=&#34;流程图&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;主要内容&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;服务API的定义&lt;/li&gt;
&lt;li&gt;使用Go语言开发kubernetes原生应用&lt;/li&gt;
&lt;li&gt;使用wercker做持续构建与发布&lt;/li&gt;
&lt;li&gt;使用traefik和VIP做边缘节点提供外部访问路由&lt;/li&gt;
&lt;li&gt;集成Istio Service Mesh&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;环境声明&#34;&gt;环境声明&lt;/h2&gt;
&lt;p&gt;首先声明下我们使用的集群环境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker1.12.5&lt;/li&gt;
&lt;li&gt;flannel network host-gw&lt;/li&gt;
&lt;li&gt;kubernetes 1.6.0+&lt;/li&gt;
&lt;li&gt;TLS enabled&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;详细的部署文档和更多资料请参考 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook&#34;&gt;kubernetes-handbook&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;应用示例&#34;&gt;应用示例&lt;/h2&gt;
&lt;p&gt;我们的这两个示例仅仅是为了演示，开发部署一个伪造的 metric 并显示在 web 页面上，包括两个service：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-test&#34;&gt;k8s-app-monitor-test&lt;/a&gt;：生成模拟的监控数据，发送http请求，获取json返回值&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-agent&#34;&gt;K8s-app-monitor-agent&lt;/a&gt;：获取监控数据并绘图，访问浏览器获取图表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个镜像可以直接从docker hub上下载&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;jimmysong/k8s-app-monitor-test:latest&lt;/li&gt;
&lt;li&gt;jimmysong/k8s-app-monitor-agent:latest&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;定义api&#34;&gt;定义API&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-test&#34;&gt;API文档&lt;/a&gt; 中的&lt;code&gt;api.html&lt;/code&gt;文件，该文档在API blueprint中定义，使用&lt;a href=&#34;https://github.com/danielgtaylor/aglio&#34;&gt;aglio&lt;/a&gt; 生成，打开后如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;k8s-app-monitor-test-api-doc.jpg&#34; alt=&#34;API文档&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;关于服务发现&#34;&gt;关于服务发现&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;K8s-app-monitor-agent&lt;/code&gt;服务需要访问&lt;code&gt;k8s-app-monitor-test&lt;/code&gt;服务，这就涉及到服务发现的问题，我们在代码中直接写死了要访问的服务的内网DNS地址（kubedns中的地址，即&lt;code&gt;k8s-app-monitor-test.default.svc.cluster.local&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;我们知道Kubernetes在启动Pod的时候为容器注入环境变量，这些环境变量在所有的 namespace 中共享（环境变量是不断追加的，新启动的Pod中将拥有老的Pod中所有的环境变量，而老的Pod中的环境变量不变）。但是既然使用这些环境变量就已经可以访问到对应的service，那么获取应用的地址信息，究竟是使用变量呢？还是直接使用DNS解析来发现？&lt;/p&gt;
&lt;p&gt;答案是使用DNS，详细说明见&lt;a href=&#34;http://jimmysong.io/posts/exploring-kubernetes-env-with-docker/&#34;&gt;Kubernetes中的服务发现与Docker容器间的环境变量传递源码探究&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;持续集成&#34;&gt;持续集成&lt;/h2&gt;
&lt;p&gt;开源项目的构建离不开CI工具，你可能经常会在很多GitHub的开源项目首页上看到这样的东西：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;wercker-budget.jpg&#34; alt=&#34;wercker status badge&#34;&gt;&lt;/p&gt;
&lt;p&gt;这些图标都是CI工具提供的，可以直观的看到当前的构建状态，例如wercker中可以在&lt;code&gt;Application&lt;/code&gt;-&lt;code&gt;magpie&lt;/code&gt;-&lt;code&gt;options&lt;/code&gt;中看到：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;wercker-status-budge-setting.jpg&#34; alt=&#34;wercker status badge设置&#34;&gt;&lt;/p&gt;
&lt;p&gt;将文本框中的代码复制到你的项目的&lt;code&gt;README&lt;/code&gt;文件中，就可以在项目主页上看到这样的标志了。&lt;/p&gt;
&lt;p&gt;现在市面上有很多流行的CI/CD工具和DevOps工具有很多，这些工具提高了软件开发的效率，增加了开发人员的幸福感。这些工具有：&lt;/p&gt;
&lt;p&gt;适用于GitHub上的开源项目，可以直接使用GitHub账户登陆，对于公开项目可以直接使用：&lt;a href=&#34;https://travis-ci.org/&#34;&gt;Travis-ci&lt;/a&gt;、&lt;a href=&#34;https://circleci.com/&#34;&gt;CircleCI&lt;/a&gt;、&lt;a href=&#34;http://www.wercker.com/&#34;&gt;Wercker&lt;/a&gt;。从目前GitHub上开源项目的使用情况来看，Travis-ci的使用率更高一些。&lt;/p&gt;
&lt;p&gt;适用于企业级的：&lt;a href=&#34;https://jenkins.io/&#34;&gt;Jenkins&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;不仅包括CI/CD功能的DevOps平台：&lt;a href=&#34;https://www.jfrog.com/&#34;&gt;JFrog&lt;/a&gt;、&lt;a href=&#34;https://spinnaker.io/&#34;&gt;Spinnaker&lt;/a&gt;、&lt;a href=&#34;https://fabric8.io/&#34;&gt;Fabric8&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;wercker简介&#34;&gt;Wercker简介&lt;/h4&gt;
&lt;p&gt;Wercker是一家为现代云服务提供容器化应用及微服务的快速开发、部署工具的初创企业，成立于2012年，总部位于荷兰阿姆斯特丹。其以容器为中心的平台可以对微服务和应用的开发进行自动化。开发者通过利用其命令行工具能够生成容器到桌面，然后自动生成应用并部署到各种云平台上面。其支持的平台包括Heroku、AWS以及Rackspace等。&lt;/p&gt;
&lt;p&gt;Wercker于2016年获得450万美元A轮融资，此轮融资由Inkef Capital领投，Notion Capital跟投，融资所得将用于商业版产品的开发。此轮融资过后其总融资额为750万美元。&lt;/p&gt;
&lt;p&gt;Wercker于2017年4月被Oracle甲骨文于收购。&lt;/p&gt;
&lt;h4 id=&#34;如何使用&#34;&gt;如何使用&lt;/h4&gt;
&lt;p&gt;通过Wercker搭建CI环境只需经过三个基本步骤。&lt;/p&gt;
&lt;p&gt;1．在Wercker网站中创建一个应用程序。&lt;/p&gt;
&lt;p&gt;2．将wercker.yml添加到应用程序的代码库中。&lt;/p&gt;
&lt;p&gt;3．选择打包和部署构建的位置。&lt;/p&gt;
&lt;p&gt;可以使用GitHub帐号直接登录&lt;a href=&#34;http://www.wercker.com/&#34;&gt;Wercker&lt;/a&gt;，整个创建应用CI的流程一共3步。&lt;/p&gt;
&lt;p&gt;一旦拥有了账户，那么只需简单地点击位于顶部的&lt;strong&gt;应用程序&lt;/strong&gt;菜单，然后选择&lt;strong&gt;创建&lt;/strong&gt;选项即可。如果系统提示是否要创建组织或应用程序，请选择&lt;strong&gt;应用程序&lt;/strong&gt;。Wercker组织允许多个Wercker用户之间进行协作，而无须提供信用卡。下图为设置新应用程序的向导页面。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;wercker-create-application.jpg&#34; alt=&#34;向导页面&#34;&gt;&lt;/p&gt;
&lt;p&gt;选择了GitHub中的repo之后，第二步配置访问权限，最后一步Wercker会尝试生成一个wercker.yml文件（后面会讨论）。不过至少对于Go应用程序来说，这个配置很少会满足要求，所以我们总是需要创建自己的Wercker配置文件。&lt;/p&gt;
&lt;h4 id=&#34;创建wercker配置文件werckeryaml&#34;&gt;创建Wercker配置文件Wercker.yaml&lt;/h4&gt;
&lt;p&gt;Wercker配置文件是一个YAML文件，该文件必须在GitHub repo的最顶层目录，该文件主要包含三个部分，对应可用的三个主要管道。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dev&lt;/strong&gt;：定义了开发管道的步骤列表。与所有管道一样，可以选定一个&lt;strong&gt;box&lt;/strong&gt;用于构建，也可以全局指定一个box应用于所有管道。box可以是Wercker内置的预制Docker镜像之一，也可以是Docker Hub托管的任何Docker镜像。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Build&lt;/strong&gt;：定义了在Wercker构建期间要执行的步骤和脚本的列表。与许多其他服务（如Jenkins和TeamCity）不同，构建步骤位于代码库的配置文件中，而不是隐藏在服务配置里。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deploy&lt;/strong&gt;：在这里可以定义构建的部署方式和位置。&lt;/p&gt;
&lt;p&gt;Wercker中还有&lt;strong&gt;工作流&lt;/strong&gt;的概念，通过使用分支、条件构建、多个部署目标和其他高级功能扩展了管道的功能，这些高级功能读着可以自己在wercker的网站中探索。&lt;/p&gt;
&lt;p&gt;因为我使用wercker自动构建，构建完成后自动打包成docker镜像并上传到docker hub中（需要先在docker hub中创建repo），如何使用 wercker 做持续构建与发布，并集成docker hub插件请参考：&lt;a href=&#34;https://jimmysong.io/posts/continuous-integration-with-wercker/&#34;&gt;wercker构建&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;K8s-app-monitor-agent的wercker配置文件如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;box&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;golang&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;build&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;steps&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;setup-go-workspace&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;script&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;go&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;get&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;code&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;|
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;cd $WERCKER_SOURCE_DIR&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;go&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;version&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;go&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;get&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-u&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;github.com/Masterminds/glide&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;export&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;PATH=$WERCKER_SOURCE_DIR/bin&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;$PATH&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;glide&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;install&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# Build the project&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;script&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;go&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;build&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;code&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;|
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;go build&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;script&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;copy&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;files&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;to&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;wercker&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;output&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;code&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;|
&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;         &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt; &lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;cp -R ./ ${WERCKER_OUTPUT_DIR}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;deploy&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;steps&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;internal/docker-push&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;username&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;$USERNAME&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;password&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;$PASSWORD&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;cmd&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/pipeline/source/k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;port&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;3000&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;tag&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;latest&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;       &lt;/span&gt;repository&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;jimmysong/k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;其中的&lt;code&gt;$USERNAME&lt;/code&gt;和&lt;code&gt;$PASSWORD&lt;/code&gt;是docker hub的用户名和密码，这些是作为wercker构建时候的环境变量，在wercker的web端进行配置的。&lt;/p&gt;
&lt;p&gt;此文件包含两个管道：build和deploy。在开发流程中，我们使用Wercker和Docker创建一个干净的Docker镜像，然后将它push到Docker Hub中。Wercker包含一个叫做&lt;code&gt;Internal/docker-push&lt;/code&gt;的deploy plugin，可以将构建好的docker镜像push到镜像仓库中，默认是Docker Hub，也可以配置成私有镜像仓库。&lt;/p&gt;
&lt;p&gt;box键的值是golang。这意味着我们使用的是一个基础的Docker镜像，它已经安装了Go环境。这一点至关重要，因为执行Wercker构建的基准Docker镜像需要包含应用程序所需的构建工具。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://app.wercker.com/jimmysong/k8s-app-monitor-agent&#34;&gt;查看详细构建流程&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;当然你还可以使用其他的CI工具，因为wercker的插件比较方便，可以直接构建成docker镜像上传到docker hub中，比较方便，所以我选择了wercker，作为个人项目和开源项目的话可以选择它，企业内部建议选择Jenkins。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;生成了如下两个docker镜像：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;jimmysong/k8s-app-monitor-test:latest&lt;/li&gt;
&lt;li&gt;jimmysong/k8s-app-monitor-agent:latest&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;本地测试&#34;&gt;本地测试&lt;/h2&gt;
&lt;p&gt;在将服务发布到线上之前，我们可以先使用&lt;code&gt;docker-compose&lt;/code&gt;在本地测试一下，这两个应用的&lt;code&gt;docker-compose.yaml&lt;/code&gt;文件如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;version&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;services&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;jimmysong/k8s-app-monitor-agent&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;234d51c&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;container_name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;depends_on&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-test&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8888&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8888&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;environment&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;SERVICE_NAME=k8s-app-monitor-test&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;k8s-app-monitor-test&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;jimmysong/k8s-app-monitor-test&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;9c935dd&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;container_name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;monitor-test&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;3000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;执行下面的命令运行测试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;docker-compose up
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在浏览器中访问&lt;a href=&#34;http://localhost:8888/k8s-app-monitor-test&#34;&gt;http://localhost:8888/k8s-app-monitor-test&lt;/a&gt;就可以看到监控页面。&lt;/p&gt;
&lt;h2 id=&#34;启动服务&#34;&gt;启动服务&lt;/h2&gt;
&lt;p&gt;所有的kubernetes应用启动所用的yaml配置文件都保存在那两个GitHub仓库的&lt;code&gt;manifest.yaml&lt;/code&gt;文件中。&lt;/p&gt;
&lt;p&gt;比如&lt;code&gt;k8s-app-monitor-agent&lt;/code&gt;的&lt;code&gt;manifest.yaml&lt;/code&gt;文件如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;extensions/v1beta1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Deployment&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;namespace&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;default&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;replicas&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;template&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;k8s-app&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;containers&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;image&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;jimmysong/k8s-app-monitor-agent&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;latest&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;imagePullPolicy&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Always&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;app&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;containerPort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;env&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;APP_PORT&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;value&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;3000&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;SERVICE_NAME&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;value&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;k8s-app-monitor-test&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;---&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;v1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Service&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;labels&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;k8s-svc&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;ports&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;port&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;protocol&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;TCP&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;http&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;selector&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;k8s-app&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意其中的&lt;code&gt;env&lt;/code&gt;，包括了两个环境变量（注意：环境变量名称必须为大写字母）：&lt;code&gt;APP_PORT&lt;/code&gt;和&lt;code&gt;SERVICE_NAME&lt;/code&gt;，这两个环境变量，在 &lt;code&gt;main.go&lt;/code&gt;的代码中我们可以看到：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;drawChart&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;res&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ResponseWriter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;req&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Request&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;port&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Getenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;APP_PORT&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;service&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Getenv&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;SERVICE_NAME&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;port&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;3000&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;==&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;service&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;localhost&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果程序启动的时候找不到该环境变量，将会使用程序内置的默认值，当然我们不该将服务地址写死在程序内部，而应该是可配置的，在kubernetes中最佳配置方式是环境变量或者ConfigMap。&lt;/p&gt;
&lt;p&gt;分别在两个GitHub目录下执行&lt;code&gt;kubectl create -f manifest.yaml&lt;/code&gt;即可启动服务。&lt;/p&gt;
&lt;h2 id=&#34;边缘节点配置&#34;&gt;边缘节点配置&lt;/h2&gt;
&lt;p&gt;边缘节点架构图&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;kubernetes-edge-node-architecture.png&#34; alt=&#34;边缘节点架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;选择Kubernetes的三个node作为边缘节点，并安装keepalived，上图展示了边缘节点的配置，同时展示了向Kubernetes中添加服务的过程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边缘节点定义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;首先解释下什么叫边缘节点（Edge Node），所谓的边缘节点即集群内部用来向集群外暴露服务能力的节点，集群外部的服务通过该节点来调用集群内部的服务，边缘节点是集群内外交流的一个Endpoint。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;边缘节点要考虑两个问题&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;边缘节点的高可用，不能有单点故障，否则整个kubernetes集群的外部访问将不可用&lt;/li&gt;
&lt;li&gt;对外的一致暴露端口，即只能有一个外网访问IP和端口&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了满足边缘节点的以上需求，我们使用&lt;a href=&#34;http://www.keepalived.org/&#34;&gt;keepalived&lt;/a&gt;来实现。&lt;/p&gt;
&lt;p&gt;在Kubernetes中添加了service的同时，在DNS中增加一个记录，这条记录需要跟ingress中的&lt;code&gt;host&lt;/code&gt;字段相同，IP地址即VIP的地址，本示例中是&lt;code&gt;172.20.0.119&lt;/code&gt;，这样集群外部就可以通过service的DNS名称来访问服务了。&lt;/p&gt;
&lt;p&gt;参考&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook/blob/master/practice/edge-node-configuration.md&#34;&gt;详细操作步骤和配置&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;发布&#34;&gt;发布&lt;/h2&gt;
&lt;p&gt;所有的kubernetes应用启动所用的yaml配置文件都保存在那两个GitHub仓库的&lt;code&gt;manifest.yaml&lt;/code&gt;文件中。也可以使用&lt;a href=&#34;https://github.com/kubernetes/kompose&#34;&gt;kompose&lt;/a&gt;这个工具，可以将&lt;em&gt;docker-compose&lt;/em&gt;的YAML文件转换成kubernetes规格的YAML文件。&lt;/p&gt;
&lt;p&gt;分别在两个GitHub目录下执行&lt;code&gt;kubectl create -f manifest.yaml&lt;/code&gt;即可启动服务。也可以直接在&lt;em&gt;k8s-app-monitor-agent&lt;/em&gt;代码库的&lt;code&gt;k8s&lt;/code&gt;目录下执行&lt;code&gt;kubectl apply -f kompose&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在以上YAML文件中有包含了Ingress配置，是为了将&lt;em&gt;k8s-app-monitor-agent&lt;/em&gt;服务暴露给集群外部访问。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方式一&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;服务启动后需要更新ingress配置，在&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/manifests/traefik-ingress/ingress.yaml&#34;&gt;ingress.yaml&lt;/a&gt;文件中增加以下几行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;host&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent.jimmysong.io&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;http&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;paths&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;path&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;backend&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;serviceName&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;servicePort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8888&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;保存后，然后执行&lt;code&gt;kubectl replace -f ingress.yaml&lt;/code&gt;即可刷新ingress。&lt;/p&gt;
&lt;p&gt;修改本机的&lt;code&gt;/etc/hosts&lt;/code&gt;文件，在其中加入以下一行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;na&#34;&gt;172.20.0.119 k8s-app-monitor-agent.jimmysong.io&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当然你也可以将该域名加入到内网的DNS中，为了简单起见我使用hosts。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;方式二&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;或者不修改已有的Ingress，而是为该队外暴露的服务单独创建一个Ingress，如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;apiVersion&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;extensions/v1beta1&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;kind&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;Ingress&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;metadata&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;name&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent-ingress&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;annotations&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;kubernetes.io/ingress.class&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;treafik&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;spec&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;rules&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;host&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent.jimmysong.io&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;http&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;paths&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;-&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;path&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;/&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;backend&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;serviceName&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;k8s-app-monitor-agent&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;servicePort&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8888&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;详见&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/edge-node-configuration.html&#34;&gt;边缘节点配置&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;集成istio-service-mesh&#34;&gt;集成Istio service mesh&lt;/h2&gt;
&lt;p&gt;上一步中我们生成了kubernetes可读取的应用的YAML配置文件，我们可以将所有的YAML配置和并到同一个YAML文件中假如文件名为&lt;code&gt;k8s-app-monitor-istio-all-in-one.yaml&lt;/code&gt;，如果要将其集成到Istio service mesh，只需要执行下面的命令。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;kubectl apply -n default -f &amp;lt;&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;istioctl kube-inject -f k8s-app-monitor-istio-all-in-one.yaml&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样就会在每个Pod中注入一个sidecar容器。&lt;/p&gt;
&lt;h2 id=&#34;验证&#34;&gt;验证&lt;/h2&gt;
&lt;p&gt;如果您使用的是Traefik ingress来暴露的服务，那么在浏览器中访问&lt;a href=&#34;http://k8s-app-monitor-agent.jimmysong.io/k8s-app-monitor-agent&#34;&gt;http://k8s-app-monitor-agent.jimmysong.io/k8s-app-monitor-agent&lt;/a&gt;，可以看到如下的画面，每次刷新页面将看到新的柱状图。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/k8s-app-monitor-agent.jpg&#34; alt=&#34;图表&#34;&gt;&lt;/p&gt;
&lt;p&gt;使用&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-vagrant-centos-cluster&#34;&gt;kubernetes-vagrant-centos-cluster&lt;/a&gt;来部署的kubernetes集群，该应用集成了Istio service mesh后可以通过&lt;a href=&#34;http://172.17.8.101:32000/k8s-app-monitor-agent&#34;&gt;http://172.17.8.101:32000/k8s-app-monitor-agent&lt;/a&gt;来访问。&lt;/p&gt;
&lt;p&gt;在对&lt;code&gt;k8s-app-monitor-agent&lt;/code&gt;服务进行了N此访问之后，再访问&lt;a href=&#34;http://grafana.istio.jimmysong.io/&#34;&gt;http://grafana.istio.jimmysong.io&lt;/a&gt;可以看到Service Mesh的监控信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/k8s-app-monitor-istio-grafana.png&#34; alt=&#34;Grafana页面&#34;&gt;&lt;/p&gt;
&lt;p&gt;访问&lt;a href=&#34;http://servicegraph.istio.jimmysong.io/dotviz&#34;&gt;http://servicegraph.istio.jimmysong.io/dotviz&lt;/a&gt;可以看到服务的依赖和QPS信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/k8s-app-monitor-istio-servicegraph-dotviz.png&#34; alt=&#34;servicegraph页面&#34;&gt;&lt;/p&gt;
&lt;p&gt;访问&lt;a href=&#34;http://zipkin.istio.jimmysong.io/&#34;&gt;http://zipkin.istio.jimmysong.io&lt;/a&gt;可以选择查看&lt;code&gt;k8s-app-monitor-agent&lt;/code&gt;应用的追踪信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://jimmysong.io/kubernetes-handbook/images/k8s-app-monitor-istio-zipkin.png&#34; alt=&#34;Zipkin页面&#34;&gt;&lt;/p&gt;
&lt;p&gt;至此从代码提交到上线到Kubernetes集群上并集成Istio service mesh的过程就全部完成了。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;本文首发于2017年9月14日，更新于2018年3月26日。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/posts/deploy-applications-in-kubernetes/&#34;&gt;适用于Kubernetes的应用开发与部署流程详解&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://app.wercker.com/jimmysong/k8s-app-monitor-agent/&#34;&gt;示例的项目代码服务器端&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-agent&#34;&gt;示例项目代码前端&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/&#34;&gt;kubernetes-handbok&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook/blob/master/practice/edge-node-configuration.md&#34;&gt;边缘节点配置&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>为什么我们需要Istio？</title>
      <link>https://jimmysong.io/blog/why-do-we-need-istio/</link>
      <pubDate>Mon, 19 Mar 2018 23:43:33 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/why-do-we-need-istio/</guid>
      <description>
        
        
        &lt;p&gt;本文译自&lt;a href=&#34;https://medium.com/google-cloud/istio-why-do-i-need-it-18d122838ee3&#34;&gt;Istio Why do I need it?&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我最近没有多少时间去玩k8s，并承认Istio到底给k8s带来了什么方面有点迷失了。这是否会增加更多的运营开销？它是否简化了我们通常需要做的事情？这些问题都浮现在我的脑海里。&lt;/p&gt;
&lt;p&gt;（我怀疑在发布了这些内容之后，我的团队中比我更懂k8s的人可能会想找我谈谈&amp;hellip;&amp;hellip;虽然我讲会跟团队中的成员辩论，但那将是我最喜欢的对话）&lt;/p&gt;
&lt;p&gt;那么Istio究竟是什么？&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://istio.io/&#34;&gt;Istio网站&lt;/a&gt;上说：&lt;/p&gt;
&lt;p&gt;Istio带给你：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HTTP、gRPC、WebSocket和TCP流量的自动负载均衡。&lt;/li&gt;
&lt;li&gt;通过丰富的路由规则、重试、故障转移和故障注入对流量行为进行细粒度控制。&lt;/li&gt;
&lt;li&gt;支持访问控制、速率限制和配额的可拔插策略层和配置API。&lt;/li&gt;
&lt;li&gt;自动指标、日志和集群内所有流量的跟踪，包括集群入口和出口。&lt;/li&gt;
&lt;li&gt;通过集群中的服务之间的强身份断言来实现服务间的身份验证。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过在整个环境中部署一个特殊的sidecar代理（辅助容器），您可以将Istio支持添加到服务中（这给我留下了深刻的印象，如果您想做到这一点，请参阅后面的内容）。安装了sidecar代理之后，（微）服务之间的所有网络通信都通过这个代理。此外，所有的网络通信都是使用Istio的控制平面功能进行配置和管理的。&lt;/p&gt;
&lt;p&gt;Istio是&lt;strong&gt;Service Mesh（服务网格）&lt;/strong&gt;。我认为的service mesh定义就是“它是一个专用的基础设施层，使得服务间的通信安全、高效和可靠”&lt;/p&gt;
&lt;p&gt;然而，如果像我一样，你从&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html&#34;&gt;概念文档&lt;/a&gt;开始看的话，上面有这样的内容：“术语&lt;strong&gt;service mesh&lt;/strong&gt;通常用于描述组成这些应用程序的微服务网络以及它们之间的交互。随着服务网格的大小和复杂程度不断增加，可能会变得难以理解和管理。可能出现包括服务发现、负载平衡、故障恢复、度量和监控，以及更复杂的需求，如A/B测试、金丝雀发布、速率限制、访问控制和端到端身份验证。Istio提供了一个完整的解决方案，通过对整个服务网格提供行为分析和操作控制来满足微服务应用程序的各种需求。“&lt;/p&gt;
&lt;p&gt;读完之后你可能会像我一样困惑！最后在网上查了一圈关于什么是服务网格之后，我终于搞明白了。我最后使用的可能是一个在所有搜索到的样本里一个非代表性的共识，但这是一个合理的选择。不过有个细节确实了，就是如何将它与k8s等编排工具分开。Istio需要跟k8s一起使用，没有k8s或其他容器编排工具的它就不存在了吗？它没有做编排，实际上它的是为解决管理基于微服务的解决方案中网络和操作复杂性而设计的。它涵盖的范围就像k8s一样！现在我真的需要继续这个帖子了。。。&lt;/p&gt;
&lt;p&gt;所以我知道Istio是什么，给我们带来了什么，但它实际上解决了什么挑战呢？&lt;/p&gt;
&lt;p&gt;从&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/overview.html&#34;&gt;为什么使用Istio页面&lt;/a&gt;中可以看出，它在服务网络中统一提供了许多关键功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量管理&lt;/li&gt;
&lt;li&gt;可观察性&lt;/li&gt;
&lt;li&gt;强制策略&lt;/li&gt;
&lt;li&gt;服务身份标识和安全&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于我来说，要真正理解Istio的价值，所以我使用了&lt;a href=&#34;https://codelabs.developers.google.com/codelabs/cloud-hello-istio/#0&#34;&gt;codelab&lt;/a&gt;。编写code lab的人真是太棒了！&lt;/p&gt;
&lt;p&gt;Code lab向我介绍了Istio控制平面的四个主要组件：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Pilot&lt;/strong&gt;：处理代理sidecar的配置和编程。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Mixer&lt;/strong&gt;：为您的流量处理决策并收集遥测数据。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ingress&lt;/strong&gt;：处理来自群集外部的传入请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CA&lt;/strong&gt;：证书颁发机构。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;查看&lt;a href=&#34;https://istio.io/docs/concepts/what-is-istio/#architecture&#34;&gt;Istio架构概念&lt;/a&gt;页面了解这些组件如何协同工作的。&lt;/p&gt;
&lt;p&gt;Code lab提供了&lt;a href=&#34;https://istio.io/docs/concepts/traffic-management/rules-configuration.html#route-rules&#34;&gt;路由规则&lt;/a&gt;——流量管理部分&lt;/p&gt;
&lt;p&gt;我还尝试了&lt;a href=&#34;https://istio.io/docs/tasks/&#34;&gt;Istio.io&lt;/a&gt;中的一些task，因为我需要了解它如何处理那些领域的工作。&lt;/p&gt;
&lt;p&gt;提示：如果您在完成codelab时也决定在四处看看，那么请将您的群集与应用程序一起启动并运行。无论如何，你会再次使用它。&lt;/p&gt;
&lt;p&gt;所以我对它如何解决这些问题有了一个基本的了解，但是如果我使用像GKE这样的托管K8s（好吧，你知道我会选那个不是吗？）使用Istio是否合适？&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：是的，这里有更多的细节，但我主要想弄明白为什么需要使用Istio。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;集群最终用户/开发人员访问&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;GKE结合使用&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/iam-integration&#34;&gt;IAM&lt;/a&gt;和RBAC，是的，这里面有很多东西需要你了解。&lt;/p&gt;
&lt;p&gt;要为您的集群用户授予比Cloud IAM更细粒度的权限，您可以使用namespace和RBAC来限制对特定pod的访问或排除对secret的访问。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://istio.io/docs/concepts/security/rbac.html&#34;&gt;Istio RBAC&lt;/a&gt;介绍了两个侧重于服务的角色&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ServiceRole&lt;/strong&gt;定义用于访问网格中的服务的角色。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ServiceRoleBinding&lt;/strong&gt;将角色授予主题（例如用户、组、服务）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;它们是k8s中的CustomResourceDefinition（CRD）对象。但您仍然需要了解IAM。&lt;/p&gt;
&lt;h4 id=&#34;服务身份标识&#34;&gt;服务身份标识&lt;/h4&gt;
&lt;p&gt;GKE可以使用service account来管理&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/tutorials/authenticating-to-cloud-platform&#34;&gt;GKE上运行的应用程序&lt;/a&gt;可以使用哪些GCP服务。这些service accout的密钥使用secret存储。Pod中运行的进程的身份标识是由&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/&#34;&gt;k8s service account&lt;/a&gt;与RBAC一起决定的。Istio使用&lt;a href=&#34;https://istio.io/docs/concepts/security/mutual-tls.html&#34;&gt;istio-auth&lt;/a&gt;，它使用双向TLS提供强大的服务间和最终用户身份验证，内置身份和凭证管理。Istio-auth使用Kubernetes service account。&lt;/p&gt;
&lt;p&gt;Istio不提供任何使用GCP service account帮助。这还很早，但是它正在制定未来发展计划的路线图。&lt;/p&gt;
&lt;p&gt;Istio-auth很好，计划中的增强功能将值得等待。我对安全的复杂性感到厌烦，因为这不可避免地导致配置错误，所以我希望它与service account类型之间进行更加无缝的对齐！&lt;/p&gt;
&lt;h4 id=&#34;网络控制&#34;&gt;网络控制&lt;/h4&gt;
&lt;p&gt;GKE（用于k8s版本1.7.6 +）使用&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/network-policy&#34;&gt;k8s网络策略&lt;/a&gt;来管理哪些Pod可以和服务通信。这是相对简单的配置。 Istio也有网络策略，但他们不是你知道和喜欢的K8s策略，为什么会有这样的区别呢？ &lt;a href=&#34;https://istio.io/blog/2017/0.1-using-network-policy.html&#34;&gt;这篇文章&lt;/a&gt;很好地解释了这一点，所以我不会在这里重述，但是这个表格总结了不同之处以及为什么会有这样的不同。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;项目&lt;/th&gt;
&lt;th&gt;Istio策略&lt;/th&gt;
&lt;th&gt;网络策略&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;层&lt;/td&gt;
&lt;td&gt;Service（7层）&lt;/td&gt;
&lt;td&gt;Network（3、4层）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;实现&lt;/td&gt;
&lt;td&gt;Userspace&lt;/td&gt;
&lt;td&gt;Kernel&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;控制点&lt;/td&gt;
&lt;td&gt;Pod&lt;/td&gt;
&lt;td&gt;Node&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Istio使用envoy作为sidecar代理。Envoy在OSI模型的应用层运行，所以在第7层。我的这篇博客将为你详细解释。&lt;/p&gt;
&lt;p&gt;您需要两种策略类型，这是纵深防御的方法。&lt;/p&gt;
&lt;h4 id=&#34;多个集群&#34;&gt;多个集群&lt;/h4&gt;
&lt;p&gt;Istio有个非常酷的功能是&lt;a href=&#34;https://istio.io/docs/concepts/policy-and-control/mixer.html#adapters&#34;&gt;mixer适配器&lt;/a&gt;。简而言之，它可以从底层后端进行抽象以提供核心功能，例如日志记录、监控、配额、ACL检查等。它公开了一个一致的API，与使用的后端无关。就像GCS公开了一个API，无论您使用什么存储类别！&lt;/p&gt;
&lt;p&gt;我认为&lt;a href=&#34;https://istio.io/blog/2017/adapter-model.html&#34;&gt;mixer适配器模型&lt;/a&gt;博客文章中的这张图片解释了mixer适配器中的全部要点。&lt;/p&gt;
&lt;p&gt;有一个&lt;a href=&#34;https://istio.io/docs/guides/integrating-vms.html&#34;&gt;早期demo&lt;/a&gt;，我认为它是istio最有用的特性之一，它实际上使用虚拟机来承载codelab中使用的评分dbase MySQL数据库，并将其作为GKE集群所属网格的一部分。使用一个网格来管理它们！&lt;/p&gt;
&lt;h4 id=&#34;流量管理&#34;&gt;流量管理&lt;/h4&gt;
&lt;p&gt;如果你使用了codelab，你会看到使用istio来引导使用路由规则的流量是多么容易。使用K8s，您还可以使用金丝雀部署进行流量管理，并以类似于istio的方式将一定比例的流量引导至您的应用的一个版本，但Istio在这种情况下更灵活，方法是允许您设置细粒度流量百分比并控制流量使用code lab中的其他标准。&lt;/p&gt;
&lt;h4 id=&#34;服务发现&#34;&gt;服务发现&lt;/h4&gt;
&lt;p&gt;服务注册在k8s中完成。Istio抽象出底层的服务发现机制，并将其转换为envoy sidecar可消费的标准格式。&lt;/p&gt;
&lt;h4 id=&#34;审计记录和监控&#34;&gt;审计记录和监控&lt;/h4&gt;
&lt;p&gt;如果是超出GKE提供的标准日志记录的话，可以将GKE与&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/logging&#34;&gt;StackDriver日志记录&lt;/a&gt;集成来收集，在持久化存储中存储&lt;code&gt;容器日志&lt;/code&gt;、&lt;code&gt;系统日志&lt;/code&gt;和关于群集中的活动的&lt;code&gt;事件&lt;/code&gt;，例如Pod的调度。还可以与&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/monitoring&#34;&gt;StackDriver Monitoring&lt;/a&gt;集成以收集系统度量指标（度量群集的基础设施，例如CPU或内存使用情况）和自定义指标（特定于应用程序的指标）。&lt;/p&gt;
&lt;p&gt;Istio利用prometheus与grafana一起作为仪表板进行记录和监控。我喜欢&lt;a href=&#34;https://istio.io/docs/tasks/telemetry/servicegraph.html&#34;&gt;service graph配置&lt;/a&gt;，它可以为您提供service mesh的图形表示。你也可以用kibana和fluentd来配合Elasticsearch使用。&lt;/p&gt;
&lt;h4 id=&#34;那么我需要istio吗&#34;&gt;那么我需要Istio吗？&lt;/h4&gt;
&lt;p&gt;Istio的流量管理非常棒，mixer适配器模型可以轻松管理覆盖多个群集和虚拟机的网格。我喜欢Istio是因为它可以让你进中精力思考服务，而不是那么多的pod和节点，并不是说你不必担心这些，而是只关注服务就好了！&lt;/p&gt;
&lt;p&gt;如果你需要管理一个分布式集群，那么Istio应该在你的选择列表里。如果您需要在流量管理方面有比k8s提供的更多的灵活性的化那么Istio也很值得关注。&lt;/p&gt;
&lt;p&gt;如果你有足够的资源来处理处于发展早期的事物，那么尽早理解Istio是值得的。如果你已经在使用k8s的话那么istio的学习曲线将很低。&lt;/p&gt;
&lt;p&gt;记住它是一个建立在上层的东西，所以你仍然需要在k8s层做些事情，比如配置k8s网络策略来补充istio网络策略。&lt;/p&gt;
&lt;p&gt;Istio还处于发展的早期阶段，所以它不会做你期望的所有事情，但我们希望它会。你将无法避免的在提供商API和Istio之间来回调用才能完成一个完整的工作，所以它不是你希望的那种一站式解决方案。&lt;/p&gt;
&lt;p&gt;Dashboard是可视化网格配置的一种很好的方式，因为编写YAML会让人很快疲惫！是的，您可以设置仪表板上的控制面板来可视化度量指标，但我希望看到它与StackDriver集成。&lt;/p&gt;
&lt;p&gt;因此，在总体了解Istio之后，我实际上很喜欢它所承诺的内容。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>什么是Service Mesh（服务网格）？</title>
      <link>https://jimmysong.io/blog/what-is-a-service-mesh/</link>
      <pubDate>Wed, 20 Sep 2017 21:56:04 +0800</pubDate>
      
      <guid>https://jimmysong.io/blog/what-is-a-service-mesh/</guid>
      <description>
        
        
        &lt;p&gt;Service Mesh 又译作 “服务网格”，作为服务间通信的基础设施层。Buoyant 公司的 CEO Willian Morgan 在他的这篇文章 &lt;a href=&#34;https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/&#34;&gt;WHAT’S A Service Mesh? AND WHY DO I NEED ONE?&lt;/a&gt; 中解释了什么是 Service Mesh，为什么云原生应用需要 Service Mesh。&lt;/p&gt;
&lt;p&gt;下面是 &lt;a href=&#34;https://twitter.com/wm&#34;&gt;Willian Morgan&lt;/a&gt; 对 Service Mesh 的解释。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Service Mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the Service Mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;翻译成中文是：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;服务网格（Service Mesh）是处理服务间通信的基础设施层。它负责构成现代云原生应用程序的复杂服务拓扑来可靠地交付请求。在实践中，Service Mesh 通常以轻量级网络代理阵列的形式实现，这些代理与应用程序代码部署在一起，对应用程序来说无需感知代理的存在。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;service-mesh的特点&#34;&gt;Service Mesh的特点&lt;/h2&gt;
&lt;p&gt;Service Mesh 有如下几个特点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序间通信的中间层&lt;/li&gt;
&lt;li&gt;轻量级网络代理&lt;/li&gt;
&lt;li&gt;应用程序无感知&lt;/li&gt;
&lt;li&gt;解耦应用程序的重试/超时、监控、追踪和服务发现&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前两款流行的 Service Mesh 开源软件 &lt;a href=&#34;https://istio.io&#34;&gt;Istio&lt;/a&gt; 和 &lt;a href=&#34;https://linkerd.io&#34;&gt;Linkerd&lt;/a&gt; 都可以直接在 Kubernetes 中集成，其中 Linkerd 已经成为 CNCF 中的项目。&lt;/p&gt;
&lt;h2 id=&#34;理解-service-mesh&#34;&gt;理解 Service Mesh&lt;/h2&gt;
&lt;p&gt;如果用一句话来解释什么是 Service Mesh，可以将它比作是应用程序或者说微服务间的 TCP/IP，负责服务之间的网络调用、限流、熔断和监控。对于编写应用程序来说一般无须关心 TCP/IP 这一层（比如通过 HTTP 协议的 RESTful 应用），同样使用 Service Mesh 也就无须关心服务之间的那些原本通过服务框架实现的事情，比如 Spring Cloud、Netflix OSS 和其他中间件，现在只要交给 Service Mesh 就可以了。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://philcalcado.com/&#34;&gt;Phil Calçado&lt;/a&gt; 在他的这篇博客 &lt;a href=&#34;http://philcalcado.com/2017/08/03/pattern_service_mesh.html&#34;&gt;Pattern: Service Mesh&lt;/a&gt; 中详细解释了 Service Mesh 的来龙去脉：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;从最原始的主机之间直接使用网线相连&lt;/li&gt;
&lt;li&gt;网络层的出现&lt;/li&gt;
&lt;li&gt;集成到应用程序内部的控制流&lt;/li&gt;
&lt;li&gt;分解到应用程序外部的控制流&lt;/li&gt;
&lt;li&gt;应用程序的中集成服务发现和断路器&lt;/li&gt;
&lt;li&gt;出现了专门用于服务发现和断路器的软件包/库，如 &lt;a href=&#34;https://finagle.github.io/&#34;&gt;Twitter 的 Finagle&lt;/a&gt; 和 &lt;a href=&#34;https://code.facebook.com/posts/1503205539947302&#34;&gt;Facebook  的 Proxygen&lt;/a&gt;，这时候还是集成在应用程序内部&lt;/li&gt;
&lt;li&gt;出现了专门用于服务发现和断路器的开源软件，如 &lt;a href=&#34;http://netflix.github.io/&#34;&gt;Netflix OSS&lt;/a&gt;、Airbnb 的 &lt;a href=&#34;https://github.com/airbnb/synapse&#34;&gt;synapse&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/airbnb/nerve&#34;&gt;nerve&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;最后作为微服务的中间层 Service Mesh 出现&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Service Mesh 的架构如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;service-mesh-arch.png&#34; alt=&#34;Service Mesh 架构图&#34;&gt;&lt;/p&gt;
&lt;p&gt;图片来自：&lt;a href=&#34;http://philcalcado.com/2017/08/03/pattern_service_mesh.html&#34;&gt;Pattern: Service Mesh&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Service Mesh 作为 sidecar 运行，对应用程序来说是透明，所有应用程序间的流量都会通过它，所以对应用程序流量的控制都可以在 serivce mesh 中实现。&lt;/p&gt;
&lt;h2 id=&#34;service-mesh如何工作&#34;&gt;Service Mesh如何工作？&lt;/h2&gt;
&lt;p&gt;下面以 Istio 为例讲解 Service Mesh 如何工作，后续文章将会详解 Istio 如何在 Kubernetes 中工作。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Sidecar（Istio 中使用 &lt;a href=&#34;https://envoyproxy.io&#34;&gt;Envoy&lt;/a&gt; 作为 sidecar 代理）将服务请求路由到目的地址，根据请求中的参数判断是到生产环境、测试环境还是 staging 环境中的服务（服务可能同时部署在这三个环境中），是路由到本地环境还是公有云环境？所有的这些路由信息可以动态配置，可以是全局配置也可以为某些服务单独配置。这些配置是由服务网格的控制平面推送给各个 sidecar 的，&lt;/li&gt;
&lt;li&gt;当 sidecar 确认了目的地址后，将流量发送到相应服务发现端点，在 Kubernetes 中是 service，然后 service 会将服务转发给后端的实例。&lt;/li&gt;
&lt;li&gt;Sidecar 根据它观测到最近请求的延迟时间，选择出所有应用程序的实例中响应最快的实例。&lt;/li&gt;
&lt;li&gt;Sidecar 将请求发送给该实例，同时记录响应类型和延迟数据。&lt;/li&gt;
&lt;li&gt;如果该实例挂了、不响应了或者进程不工作了，sidecar 会将把请求发送到其他实例上重试。&lt;/li&gt;
&lt;li&gt;如果该实例持续返回 error，sidecar 会将该实例从负载均衡池中移除，稍后再周期性得重试。&lt;/li&gt;
&lt;li&gt;如果请求的截止时间已过，sidecar 主动标记该请求为失败，而不是再次尝试添加负载。&lt;/li&gt;
&lt;li&gt;SIdecar 以 metric 和分布式追踪的形式捕获上述行为的各个方面，这些追踪信息将发送到集中 metric 系统。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;为何使用-service-mesh&#34;&gt;为何使用 Service Mesh？&lt;/h2&gt;
&lt;p&gt;Service Mesh 并没有给我们带来新功能，它是用于解决其他工具已经解决过的问题，只不过这次是在以 Kubernetes 为基础的云原生生态环境下的实现。&lt;/p&gt;
&lt;p&gt;在传统的 MVC 三层 Web 应用程序架构下，服务之间的通讯并不复杂，在应用程序内部自己管理即可，但是在现今的复杂的大型网站情况下，单体应用被分解为众多的微服务，服务之间的依赖和通讯十分复杂，出现了 twitter 开发的 &lt;a href=&#34;https://twitter.github.io/finagle/&#34;&gt;Finagle&lt;/a&gt;、Netflix 开发的 &lt;a href=&#34;https://github.com/Netflix/Hystrix&#34;&gt;Hystrix&lt;/a&gt; 和 Google 的 Stubby 这样的 “胖客户端” 库，这些就是早期的 Service Mesh，但是它们都仅适用于特定的环境和特定的开发语言，并不能作为平台级的 Service Mesh 支持。&lt;/p&gt;
&lt;p&gt;在 Cloud Native 架构下，容器的使用赋予了异构应用程序更多的可能性，Kubernetes 增强了应用的横向扩容能力，用户可以快速的编排出复杂环境、复杂依赖关系的应用程序，同时开发者又无须过分关心应用程序的监控、扩展性、服务发现和分布式追踪这些繁琐的事情，进而专注于程序开发，赋予开发者更多的创造性。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://buoyant.io/2017/04/25/whats-a-service-mesh-and-why-do-i-need-one/&#34;&gt;What&#39;s a Service Mesh? And why do I need one?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://redmonk.com/jgovernor/2017/05/31/so-what-even-is-a-service-mesh-hot-take-on-istio-and-linkerd&#34;&gt;So what even is a Service Mesh? Hot take on Istio and Linkerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/attest-engineering/linkerd-a-service-mesh-for-aws-ecs-937f201f847a&#34;&gt;linkerd: A Service Mesh for AWS ECS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/blog/istio-service-mesh-for-microservices.html&#34;&gt;Introducing Istio: A robust Service Mesh for microservices&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://blog.christianposta.com/microservices/application-network-functions-with-esbs-api-management-and-now-service-mesh/&#34;&gt;Application Network Functions With ESBs, API Management, and Now.. Service Mesh?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://philcalcado.com/2017/08/03/pattern_service_mesh.html&#34;&gt;Pattern: Service Mesh&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://envoyproxy.io&#34;&gt;Envoy 官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/&#34;&gt;Istio 官方文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/&#34;&gt;Istio Handbook - Istio 服务网格进阶实战&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
