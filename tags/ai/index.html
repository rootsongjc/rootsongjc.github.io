<!DOCTYPE html>
<html lang="zh"><head>
  <meta charset="utf-8">
  
  <title>AI - Jimmy Song</title>
  

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  <meta name="description" content="宋净超的博客">
  <meta name="author" content="Jimmy Song">
  <meta name="generator" content="Hugo 0.136.0">

  <!-- CSS plugins -->
  
  
    
    
      
    
  
    
    
      
    
  
    
    
      
    
  
    
    
      
    
  
    
    
      
    
  
  
  <link rel="preload" href="/css/combined.7ac6b2864cb09c5595ac8ca79f8ca0db6c69a657edac885ba2c2412080d68da0.css" as="style">
  <link rel="stylesheet" href="/css/combined.7ac6b2864cb09c5595ac8ca79f8ca0db6c69a657edac885ba2c2412080d68da0.css" media="screen">
  

  <!-- Main Stylesheet -->
  
  <link rel="preload" href="/scss/style.min.f6911c0ac7d2b5b69c3f2d9f2a2b3b496b5da0608580347fdb4dc11ef74f3ec5.css" as="style">
  <link rel="stylesheet" href="/scss/style.min.f6911c0ac7d2b5b69c3f2d9f2a2b3b496b5da0608580347fdb4dc11ef74f3ec5.css" media="screen">

  <!-- Bigger picture css -->
  
  <link rel="stylesheet" href="/plugins/bigger-picture/bigger-picture.min.css" media="print" onload="this.media='all'">
  <!--Favicon generate by https://realfavicongenerator.net-->
  <link rel="icon" href="/favicon.png" type="image/png">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes="200x200" href="/images/favicon.png" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">

  <link href='/opensearchdescription.xml' rel='search' title='Content search' type='application/opensearchdescription+xml'/>

  <!--Twitter card-->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:site" content="jimmysong.io" />
  <meta name="twitter:creator" content="@jimmysongio" />
  <meta property="og:url" content="https://jimmysong.io/tags/ai/" />
  <meta property="og:title" content="AI | Jimmy Song" />
  <meta property="twitter:title" content="AI | Jimmy Song" />

  
  <meta property="og:description" content="宋净超的博客" />
  <meta property="twitter:description" content="宋净超的博客" />

  
  <meta property="og:image" content="https://jimmysong.io/images/banner/default.jpg" />
  <meta property="twitter:image" content="https://jimmysong.io/images/banner/default.jpg" />

  
  
</head>
<body>
<header class="fixed-top header">
  
  
  <button onclick="topFunction()" id="backTopBtn" title="Go to top"><i class="fa fa-arrow-circle-up" aria-hidden="true"></i></button>
  
  <div class="navigation w-100 ">
    <div class="container-xl">
      <nav class="navbar navbar-expand-lg navbar-light p-0">
        <a class="navbar-brand" href="/">
            
            <b>JIMMY SONG</b>
            
        </a>
        <button class="navbar-toggler rounded-0" type="button" data-toggle="collapse" data-target="#navigation"
          aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse text-center" id="navigation">
          <ul class="navbar-nav ml-auto">
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/blog">博客</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/book">资料</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/tags">标签</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/notice">公告</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/contact">联系</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/about">关于</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/community/">社区</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="https://space.bilibili.com/515485124" target="_blank" rel="noopener">视频 <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i></a>
              
            </li>
            
            

          
          
          <li class="nav-item">
            
            
            
              
              
                
                
                
                  
                    
                    <a class="nav-link" href="/en/tags/ai/">English</a>
                    
                  
                
              
              
              
                
                  
                    
                    
                  
                
                
                
              
          </li>
          
          
          <!-- search -->
           <button type="button" class="search-btn js-search" id="searchOpen" aria-label="Search">
              <div class="search-container d-flex justify-content-center">
              <span class="search-content">
                  <i class="fa fa-search"></i>
                  <span>搜索</span>
              </span>
              <span class="search-shortcuts d-none d-sm-block">
                  <kbd class="cmd-key">⌘</kbd>
                  <kbd class="k-key">K</kbd>
              </span>
              </div>
          </button>
          
          </ul>
        </div>
      </nav>
    </div>
  </div>
</header>


            <aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between">
        <div class="col-6 search-title">
          <p>站内搜索</p> 
        </div>
        <div class="col-6 col-search-close">
          <div class="js-search" aria-label="关闭"><i class="fa-solid fa-circle-xmark text-muted" aria-hidden="true"></i></div>
        </div>
      </div>

      <div id="search-box">
        <i class="fa-solid fa-magnifying-glass" id="search-icon" aria-hidden="true"></i>
        <input name="q" id="search-query" placeholder="请输入搜索词" autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control" aria-label="请输入搜索词">
        
        <div class="mt-4">
          <span>搜索类型: </span>
          <span>
            <input type="radio" id="all" name="search_type" value="all" checked>
            <label for="all">所有</label>
            
              <input type="radio" id="blog" name="search_type" value="blog">
              <label for="blog">原创</label>
              <input type="radio" id="trans" name="search_type" value="trans">
              <label for="trans">译文</label>
            
            <input type="radio" id="book" name="search_type" value="book">
            <label for="book">资料</label>
            <input type="radio" id="notice" name="search_type" value="notice">
            <label for="notice">公告</label>
          </span>
        </div>
      </div>
      
    </section>
    <section class="section-search-results">
      <div id="search-results-count" class="search-results-count"></div>
      <div id="search-hits">
        
      </div>
    </section>
  </div>
</aside>

        
        
            

<section class="bg-cover page-title-section overlay" style="background-image: url('/images/backgrounds/circle.svg'),url('/images/backgrounds/page-title.webp');background-size: cover;">
    <div class="container-xl">
        <div class="row">
            <div class="col-12">
                <p class="h1">
                    AI
                </p>
                <p class="page-description">
                    
                </p>
                
            </div>
        </div>
    </div>
</section>

        


<section class="section-sm book-list-section bg-gray">
  <div class="container-xl">
    <div class="row">
      <div class="col-lg-8 order-2 order-lg-1">
        <div class="row">
          
          
          
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/ai-ppt-to-hugo/">如何使用通义千问 AI 生成 PPT 并发布到个人网站</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2024/11/26</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/%e5%b7%a5%e5%85%b7"> 
             工具
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('如何使用通义千问 AI 生成 PPT 并发布到个人网站', '使用通义千问 AI 快速生成 PPT，并通过 Canva 调整后嵌入 Hugo 网站，展示高效方法。', '\n以下是使用通义千问 AI 快速生成 PPT 并将其发布到个人网站的简单流程：\n\n{{\u003cslide src=\u0022https:\/\/www.canva.cn\/design\/DAGXkFFIYXY\/d7XYxuZkK1Mcpz3Qrb2bfw\/view\u0022\u003e}}\n\n注：PPT 内容由通义 AI 生成，访问 [tongyi.ai 智能](https:\/\/tongyi.aliyun.com\/aippt)生成更多 PPT\n\n## 使用通义千问生成 PPT\n\n- **工具地址**：[通义千问 AI PPT](https:\/\/tongyi.aliyun.com\/aippt)\n- **登录方式**：\n    - 使用淘宝账号和手机号验证码登录。\n- **功能亮点**：\n    1. **主题生成**：输入一个主题，AI 可以自动生成 PPT 内容（适合简单场景）。\n    2. **长文生成**：支持最多 **10 万字**的文本解析，适合将报告或博客生成 PPT。\n    3. **模板个性化**：支持选择多种模板，生成的 PPT 可以导出为 **pptx 格式**。\n- **使用体验**：\n    - 我尝试用自己的博客生成了一份 PPT，AI 自动整理了章节和配图，效果还不错，模板选择提升了个性化展示的效果。\n\n## 导入 Canva 进行调整\n\n- **工具地址**：[Canva.cn](https:\/\/www.canva.cn\/)\n- **调整方法**：\n    1. 将从通义千问生成的 **pptx 文件**导入 Canva。\n    2. 根据需要调整 **排版布局**，补充和调整一些内容。\n    3. 完成调整后，在 Canva 中选择导出为 **嵌入式网页**，生成一个可分享的链接。\n\n## 将 PPT 发布到个人网站\n\n- **工具**：Hugo\n- **操作步骤**：\n    1. 在 Hugo 博客中，使用以下 Shortcode 嵌入 Canva 的分享链接：\n\n        \u0060\u0060\u0060html\n        \u003cslide src=\u0022https:\/\/www.canva.cn\/design\/DAGXjo0P9w0\/view\u0022\u003e\n        \u0060\u0060\u0060\n\n    2. 保存后部署网站，即可在博客中直接展示 PPT。\n\n## 使用场景\n\n博客嵌入 PPT 的适用场景可以涵盖以下几个方面：\n\n1. 提炼长内容的梗概；\n2. 简化多图内容的存储与排版；\n3. 展示数据与图表；\n4. 教程与演示文档；\n5. 总结与复盘；\n6. 对外分享和推广。\n\n## 总结\n\n通过 **通义千问 AI PPT** 和 **Canva** 的结合，可以快速生成并发布高质量的 PPT 到个人网站。这种方法尤其适合将博客内容快速转化为视觉化演示，既省时又高效。\n\n如果需要更多样式和交互，可以进一步自定义 Canva 的模板，满足更高的个性化需求。\n', '\/blog\/ai-ppt-to-hugo\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">使用通义千问 AI 快速生成 PPT，并通过 Canva 调整后嵌入 Hugo 网站，展示高效方法。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/building-a-generative-ai-platform/">[译] 构建生成式人工智能平台：从基础知识到高级实现策略指南</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2024/07/26</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/ai"> 
             AI
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://huyenchip.com/2024/07/25/genai-platform.html" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('构建生成式人工智能平台：从基础知识到高级实现策略指南', '探索构建生成式人工智能平台的关键组件与实现策略，从基础架构到高级功能，提供全面的指导和深入分析。', '\n在研究了各公司部署生成式人工智能应用程序的方式后，我注意到他们的平台之间有许多相似之处。本文概述了生成式人工智能平台的常见组件、其功能及其实现方式。我尽量保持架构的通用性，但某些应用可能会有所不同。以下是整体架构的外观。\n\n![生成式 AI 平台概览](1-genai-platform.webp)\n\n这是一个相当复杂的系统。本文将从最简单的架构开始，逐步添加更多组件。在最简单的形式中，你的应用程序接收一个查询并将其发送到模型。模型生成响应，该响应被返回给用户。没有防护措施、没有增强上下文，也没有优化。**模型 API**框指的是第三方 API（例如 OpenAI、Google、Anthropic）和自托管 API。\n\n![生成式 AI 平台概览](2.webp)\n\n从这里开始，你可以根据需要添加更多组件。本文讨论的顺序是常见的，尽管你不需要完全按照相同的顺序操作。如果你的系统运行良好，可以跳过某个组件。开发过程中的每一步都需要进行评估。\n\n1. 通过让模型访问外部数据源和信息收集工具，增强模型的上下文输入。\n2. 设置防护措施，以保护你的系统和用户。\n3. 添加模型路由器和网关，以支持复杂的管道并增加更多安全性。\n4. 通过缓存优化延迟和成本。\n5. 添加复杂逻辑和写操作，以最大化系统的功能。\n\n可观察性和编排是平台的两个重要组件。我们将在本文末尾讨论它们。\n\n**» 本文不涉及的内容 «**\n\n_本文重点讨论部署 AI 应用程序的总体架构。它讨论构建这些组件时需要哪些组件和考虑因素。它不涉及如何构建 AI 应用程序，因此不讨论模型评估、应用程序评估、提示工程、微调、数据注释指南或用于 RAG 的分块策略。所有这些主题都包含在我即将出版的书籍 [AI Engineering](https:\/\/learning.oreilly.com\/library\/view\/ai-engineering\/9781098166298\/) 中。_\n\n## 第一步：增强上下文\n\n平台的初步扩展通常涉及添加机制，允许系统用必要的信息增强每个查询。收集相关信息称为上下文构建。\n\n许多查询需要上下文来回答。上下文中的相关信息越多，模型就越少依赖其内部知识，这可能因其训练数据和训练方法而不可靠。研究表明，访问上下文中的相关信息可以帮助模型生成更详细的回应，同时减少幻觉 ([Lewis et al.](https:\/\/arxiv.org\/abs\/2005.11401), 2020)。\n\n例如，给定查询“Acme 的精美打印机 A300 是否能打印 100 页每秒？”，如果给出了精美打印机 A300 的规格，模型将能够更好地响应。（感谢 Chetan Tekur 举的例子）\n\n上下文构建对于基础模型来说等同于传统 ML 模型的特征工程。它们的目的相同：为模型提供处理输入所需的信息。\n\n在上下文中学习，从上下文中学习，是一种连续学习的形式。它使模型能够持续地整合新信息以做出决策，防止其过时。例如，一个在上周数据上训练的模型，除非将新信息包含在其上下文中，否则无法回答有关本周的问题。通过使用最新信息更新模型的上下文，例如精美打印机 A300 的最新规格，模型保持最新状态，并可以回应超出其截止日期的查询。\n\n### RAGs\n\n上下文构建的最著名模式是 RAG，检索增强生成。RAG 由两个组件组成：一个生成器（例如语言模型）和一个检索器，后者从外部来源检索相关信息。\n\n![生成式 AI 平台概览](3-rag.webp)\n\n检索不仅限于 RAG。它是搜索引擎、推荐系统、日志分析等的支柱。许多为传统检索系统开发的检索算法可以用于 RAG。\n\n外部记忆源通常包含非结构化数据，如备忘录、合同、新闻更新等。它们可以统称为_文档_。一个文档可以有 10 个标记，也可以有 100 万个标记。简单地检索整个文档可能会导致你的上下文长度过长。RAG 通常要求将文档分割成_可管理的块_，这可以根据模型的最大上下文长度和应用程序的延迟要求确定。要了解更多有关分块和最佳块大小的信息，请参见 [Pinecone](https:\/\/www.pinecone.io\/learn\/chunking-strategies\/)、[Langchain](https:\/\/js.langchain.com\/v0.1\/docs\/modules\/data_connection\/document_transformers\/)、[Llamaindex](https:\/\/docs.llamaindex.ai\/en\/stable\/optimizing\/production_rag\/) 和 [Greg Kamradt](https:\/\/www.youtube.com\/watch?v=8OJC21T2SL4) 的教程。\n\n一旦外部记忆源的数据被加载并分块后，检索主要通过以下两种方式执行：\n\n1. **基于术语的检索**  \n   这可以简单到像关键字搜索。例如，对于查询“transformer”，检索包含此关键词的所有文档。更复杂的算法包括 BM25（利用 TF-IDF）和 Elasticsearch（利用倒排索引）。基于术语的检索通常用于文本数据，但它也适用于包含文本元数据（如标题、标签、字幕、评论等）的图像和视频。\n\n2. **基于嵌入的检索**（也称为向量搜索）  \n   你将数据块转换为嵌入向量，使用嵌入模型如 [BERT](https:\/\/arxiv.org\/abs\/1810.04805)，[sentence-transformers](https:\/\/github.com\/UKPLab\/sentence-transformers)，以及 OpenAI 或 Google 提供的专有嵌入模型。根据查询，检索与查询嵌入最接近的数据，这一过程由向量搜索算法确定。\n\n   向量搜索通常被视为最近邻搜索，使用近似最近邻 (ANN) 算法，如 [FAISS](https:\/\/arxiv.org\/abs\/1702.08734)（Facebook AI 相似性搜索），Google 的 [ScaNN](https:\/\/research.google.blog\/announcing-scann-efficient-vector-similarity-search\/)，Spotify 的 [ANNOY](https:\/\/github.com\/spotify\/annoy)，和 [hnswlib](https:\/\/github.com\/nmslib\/hnswlib)（[层次化可导航小世界](https:\/\/arxiv.org\/abs\/1603.09320)）。[ANN-benchmarks 网站](https:\/\/ann-benchmarks.com\/) 在多个数据集上比较了不同 ANN 算法，考虑了索引和查询之间的权衡。\n\n   - **召回率**：算法找到的最近邻居的比例。\n   - **每秒查询数 (QPS)**：算法每秒可以处理的查询数。这对高流量应用至关重要。\n   - **构建时间**：构建索引所需的时间。这个指标特别重要，尤其是如果你需要频繁更新你的索引（例如因为你的数据发生了变化）。\n   - **索引大小**：算法创建的索引的大小，这对评估其可扩展性和存储需求至关重要。\n\n   这种方法不仅适用于文本文档，还适用于图像、视频、音频和代码。许多团队甚至尝试总结 SQL 表和数据框，然后使用这些总结来生成检索用的嵌入。\n\n基于术语的检索比基于嵌入的检索快得多、成本也更低。它可以开箱即用，是一个吸引人的起点。BM25 和 Elasticsearch 在行业中得到了广泛使用，为更复杂的检索系统提供了强大的基线。尽管基于嵌入的检索在计算上开销较大，但随着时间的推移可以显著改进，以超越基于术语的检索。\n\n生产检索系统通常结合了几种方法。结合基于术语的检索和基于嵌入的检索被称为 _混合搜索_。\n\n一个常见的模式是顺序的。首先，一个便宜、精度较低的检索器，如基于术语的系统，获取候选项。然后，一个更精确但更昂贵的机制，如 k-最近邻，找到这些候选中的最佳选项。第二步也称为重排。\n\n例如，给定术语“transformer”，你可以检索所有包含单词 transformer 的文档，无论它们是关于电器设备、神经结构还是电影。然后你使用向量搜索，在这些文档中找到与你的 transformer 查询实际相关的文档。\n\n上下文重排与传统的搜索重排不同，因为项目的确切位置不那么重要。在搜索中，排名（例如第一或第五）至关重要。在上下文重排中，文档的顺序仍然重要，因为它影响模型如何处理它们。模型可能更好地理解上下文开始和结束时的文档，正如论文 [Lost in the middle](https:\/\/arxiv.org\/abs\/2307.03172) (Liu et al., 2023) 所示。然而，只要文档被包含在内，其顺序的影响就比在搜索排名中的影响要小。\n\n另一种模式是集成。记住，检索器通过对查询的相关性评分对文档进行排名。你使用多个检索器同时获取候选项，然后将这些不同的排名结合起来生成最终的排名。\n\n### 带表格数据的 RAGs\n\n外部数据源也可以是结构化的，如数据框或 SQL 表。从 SQL 表检索数据与从非结构化文档检索数据有显著不同。系统的工作流程如下：\n\n1. **文本到 SQL**：根据用户查询和表结构，确定需要什么 SQL 查询。\n2. **SQL 执行**：执行 SQL 查询。\n3. **生成**：根据 SQL 结果和原始用户查询生成响应。\n\n![生成式 AI 平台概览](4-rag-with-tabular-data.webp)\n\n对于文本到 SQL 步骤，如果有很多可用的表格，其架构不能全部适应模型上下文，你可能需要一个中间步骤来预测每个查询使用哪些表格。文本到 SQL 可以由生成最终响应的同一模型或许多专门的文本到 SQL 模型完成。\n\n### 具有代理能力的 RAGs\n\n互联网是一个重要的数据来源。像 Google 或 Bing API 这样的网络搜索工具可以使模型访问丰富、最新的资源，以收集每个查询的相关信息。例如，给定查询“今年谁赢得了奥斯卡？”，系统会搜索有关最新奥斯卡的信息，并使用这些信息为用户生成最终响应。\n\n基于术语的检索、基于嵌入的检索、SQL 执行和网络搜索是模型可以采取的行动，以增强其上下文。你可以将每个动作视为模型可以调用的函数。可以整合外部动作的工作流程也被称为 _具有代理能力_。其架构如下所示。\n\n![生成式 AI 平台概览](5-agentic-rag.webp)\n\n**» 动作与工具 «**\n\n一个工具允许一个或多个动作。例如，一个人员搜索工具可能允许两个动作：按姓名搜索和按电子邮件搜索。然而，差别很小，所以很多人将 _动作_ 和 _工具_ 混为一谈。\n\n**» 只读动作与写入动作 «**\n\n从外部源检索信息但不改变其状态的动作是只读动作。赋予模型写入动作，例如更新表中的值，使模型能够执行更多任务，但也带来了更多风险，稍后将进行讨论。\n\n### 查询重写\n\n通常，需要重写用户查询以增加获取正确信息的可能性。考虑以下对话。\n\n\u0060\u0060\u0060\n用户：John Doe 上次从我们这里购买东西是什么时候？\nAI：John 最后一次从我们这里购买是两周前，即 2030 年 1 月 3 日购买的 Fruity Fedora 帽。\n用户：那 Emily Doe 呢？\n\u0060\u0060\u0060\n\n最后一个问题，“那 Emily Doe 呢？”是模糊的。如果你逐字使用这个查询来检索文档，你可能会得到无关的结果。你需要重写这个查询，以反映用户实际在询问什么。新查询应该本身就有意义。最后一个问题应该被重写为“Emily Doe 上次从我们这里购买东西是什么时候？”\n\n查询重写通常使用其他 AI 模型完成，使用类似于“给定以下对话，重写最后一个用户输入以反映用户实际在询问什么”的提示。\n\n![生成式 AI 平台概览](6-query-rewriting.webp)\n\n查询重写可能会变得复杂，特别是如果你需要进行身份解析或纳入其他知识。如果用户问“他的妻子怎么样？”，你首先需要查询你的数据库来找出他的妻子是谁。如果你没有这个信息，重写模型应该承认这个查询是无法解决的，而不是臆造一个名字，导致错误的答案。\n\n## 第二步：设置防护栏\n\n防护栏有助于减少 AI 风险，保护的不仅是用户，还有开发者。在存在失败潜力的地方应设置防护栏。本文讨论两种类型的防护栏：输入防护和输出防护。\n\n### 输入防护\n\n输入防护通常用于防范两种风险：将私人信息泄露给外部 API，以及执行可能危及系统的不良提示（模型越狱）。\n\n#### 向外部 API 泄露私人信息\n\n当需要将数据发送到组织外部时，使用外部模型 API 会特别有这种风险。例如，员工可能会将公司的秘密或用户的私人信息复制到提示中，并发送到托管模型的位置。\n\n没有万无一失的方法来消除使用第三方 API 时的潜在泄露。然而，你可以通过防护栏来减轻这些风险。你可以使用许多可用的工具之一来自动检测敏感数据。要检测的敏感数据由你指定。常见的敏感数据类别包括：\n\n- 个人信息（身份证号、电话号码、银行账户）。\n- 人脸。\n- 与公司的知识产权或特权信息相关的特定关键词和短语。\n\n许多敏感数据检测工具使用 AI 来识别潜在的敏感信息，例如判断一个字符串是否像一个有效的家庭地址。如果发现一个查询包含敏感信息，你有两个选择：阻止整个查询或从中移除敏感信息。例如，你可以使用占位符 \\[PHONE NUMBER\\] 来掩盖用户的电话号码。如果生成的响应包含此占位符，请使用 PII 可逆字典将此占位符映射回原始信息，以便你可以取消屏蔽它，如下图所示。\n\n![生成式 AI 平台概览](7-reversible-pii-mapping.webp)\n\n#### 模型越狱\n\n试图越狱 AI 模型，让它们说出或做出不良行为，已经成为一种在线运动。尽管有些人可能觉得让 ChatGPT 发表争议性言论很有趣，但如果你的客户支持聊天机器人，带有你的品牌和标志做同样的事情就没那么有趣了。这对于有权访问工具的 AI 系统尤其危险。想象一下，如果用户找到一种方法让你的系统执行一个会破坏你的数据的 SQL 查询。\n\n为了对抗这一点，你应该首先在你的系统上设置防护栏，以便不会自动执行任何有害的操作。例如，没有人工批准，不得执行可以插入、删除或更新数据的 SQL 查询。这种增加的安全性的缺点是它可能会减慢你的系统。\n\n为了防止你的应用程序发表不应该发表的离谱言论，你可以为你的应用程序定义范围外的话题。例如，如果你的应用程序是一个客户支持聊天机器人，它不应该回答政治或社会问题。一个简单的方法是过滤掉包含通常与争议话题相关的预定义短语的输入，如“移民”或“反疫苗”。更复杂的算法使用 AI 来分类输入是否关于预定义的受限话题之一。\n\n如果你的系统中有害提示很少，你可以使用异常检测算法来识别不寻常的提示。\n\n#### 故障管理\n\nAI 模型是概率性的，这意味着如果你再次尝试一个查询，你可能会得到不同的响应。许多故障可以通过基本的重试逻辑来缓解。例如，如果响应为空，尝试再次查询 X 次或直到你得到一个非空响应。同样，如果响应格式错误，再试一次直到模型生成一个格式正确的响应。\n\n然而，这种重试策略可能会增加额外的延迟和成本。一次重试意味着 API 调用次数翻倍。如果在失败后进行重试，用户体验的延迟将会加倍。为了减少延迟，你可以并行进行调用。例如，对于每个查询，不是等待第一个查询失败后再重试，而是同时向模型发送两次查询，获取两个响应，并选择较好的一个。这会增加冗余的 API 调用次数，但保持延迟在可管理的范围内。\n\n处理棘手查询时常常需要人类介入。例如，如果查询包含特定关键短语，你可以将查询转给人工操作员。有些团队使用专门的模型（可能是内部训练的）来决定何时将对话转交给人类。例如，有一个团队在他们的情感分析模型检测到用户开始生气时，会将对话转给人工操作员。另一个团队在一定的对话轮数后转交对话，以防用户陷入无限循环。\n\n### 防护栏权衡\n\n**可靠性与延迟的权衡**：虽然承认防护栏的重要性，但一些团队告诉我延迟更为重要。他们决定不实施防护栏，因为这会显著增加应用的延迟。然而，这些团队属于少数。大多数团队发现增加的风险比增加的延迟更为昂贵。\n\n输出防护栏可能在流式完成模式中不太有效。默认情况下，整个响应在显示给用户之前生成，这可能需要很长时间。在流式完成模式中，新的令牌在生成时即时传输给用户，减少了用户等待看到响应的时间。缺点是，很难评估部分响应，因此不安全的响应可能在系统防护栏判定应该阻止之前被传输给用户。\n\n**自托管与第三方 API 的权衡**：自托管模型意味着你不必将数据发送给第三方，减少了输入防护栏的需求。然而，这也意味着你必须自己实施所有必要的防护栏，而不是依赖第三方服务提供的防护栏。\n\n我们的平台现在看起来是这样的。防护栏可以是独立工具或模型网关的一部分，稍后将进行讨论。如果使用，评分器通常被归类在模型 API 下，因为评分器通常也是 AI 模型。用于评分的模型通常比用于生成的模型小且快。\n\n![生成式 AI 平台概览](8-guardrails.webp)\n\n## 第三步：添加模型路由器和网关\n\n随着应用变得越来越复杂并涉及更多模型，出现了两种类型的工具以帮助你处理多个模型：路由器和网关。\n\n### 路由器\n\n应用程序可以使用不同的模型来响应不同类型的查询。对不同的查询有不同的解决方案有几个好处。首先，这允许你拥有专门的解决方案，如一个专门处理技术故障的模型，另一个专门处理订阅的模型。专门的模型可能比通用模型表现更好。其次，这可以帮助你节省成本。你可以将简单的查询路由到更便宜的模型，而不是所有查询都路由到昂贵的模型。\n\n路由器通常包括**意图分类器**，用于预测用户试图做什么。根据预测的意图，将查询路由到合适的解决方案。例如，对于客户支持聊天机器人，如果意图是：\n\n- 重置密码 -\u003e 将用户路由到关于密码重置的页面。\n- 纠正账单错误 -\u003e 将用户路由到人工操作员。\n- 排查技术问题 -\u003e 将查询路由到为排查故障而微调的模型。\n\n意图分类器还可以帮助你的系统避免超出范围的对话。例如，你可以有一个意图分类器来预测查询是否超出范围。如果查询被认为是不适当的（例如，如果用户询问你在即将到来的选举中会投票给谁），聊天机器人可以礼貌地拒绝参与，使用一个标准回复（“作为一个聊天机器人，我没有投票的能力。如果你有关于我们产品的问题，我很乐意帮助。”）而不浪费一个 API 调用。\n\n如果你的系统有权访问多个动作，路由器可以包括一个**下一步动作预测器**来帮助系统决定下一步采取什么动作。一个有效的动作是如果查询含糊不清，要求澄清。例如，对于查询“Freezing”，系统可能会问，“你是想冻结你的账户还是在谈论天气？”或者简单地说，“对不起，请你详细说明一下。”\n\n意图分类器和下一步动作预测器可以是通用模型或专门的分类模型。专门的分类模型通常比通用模型小且快，允许你的系统使用多个这样的模型，而不会引入显著的额外延迟和成本。\n\n当将查询路由到具有不同上下文限制的模型时，可能需要相应地调整查询的上下文。考虑一个设定为使用 4K 上下文限制的模型的 1,000 令牌查询。然后系统采取一个动作，例如网络搜索，带回 8,000 令牌的上下文。你可以截断查询的上下文以适应最初的模型，或者将查询路由到具有更大上下文限制的模型。\n\n### 网关\n\n模型网关是一个中间层，允许你的组织以统一且安全的方式与不同模型进行交互。模型网关的基本功能是使开发者能够以相同的方式访问不同的模型——无论是自托管模型还是商业 API（如 OpenAI 或 Google）背后的模型。模型网关简化了代码的维护。如果模型 API 发生变化，你只需要更新模型网关，而不是更新所有使用该模型 API 的应用程序。\n\n模型网关是**访问控制和成本管理**。与其将组织的令牌分发给每个需要访问 OpenAI API 的人，不如只允许他们通过模型网关访问，这样可以创建一个集中和受控的访问点。网关还可以实施细粒度的访问控制，指定哪些用户或应用程序应该访问哪个模型。此外，网关还可以监控和限制 API 调用的使用，有效防止滥用和管理成本。\n\n模型网关还可以用来实施回退策略，以克服速率限制或 API 失败（后者不幸很常见）。当主要 API 不可用时，网关可以将请求路由到备用模型，短暂等待后重试，或以其他优雅的方式处理失败。这确保了你的应用程序可以平稳运行，不受中断。\n\n由于请求和响应已经通过网关，这是实施其他功能（如负载平衡、日志记录和分析）的好地方。一些网关服务甚至提供缓存和防护栏。\n\n鉴于网关的实施相对简单，市面上有许多现成的网关。示例包括 Portkey 的[网关](https:\/\/github.com\/Portkey-AI\/gateway)，[MLflow AI Gateway](https:\/\/mlflow.org\/docs\/latest\/llms\/gateway\/index.html)，WealthSimple 的[llm-gateway](https:\/\/github.com\/wealthsimple\/llm-gateway)，[TrueFoundry](https:\/\/docs.truefoundry.com\/docs\/ai-gateway)，[Kong](https:\/\/konghq.com\/products\/kong-ai-gateway)，和 [Cloudflare](https:\/\/developers.cloudflare.com\/ai-gateway\/)。\n\n随着网关和路由器的添加，我们的平台变得更加令人兴奋。与评分一样，路由也在模型网关中进行。用于路由的模型通常比用于生成的模型小且快。\n\n![生成式 AI 平台概览](10-model-gateway.webp)\n\n## 第四步：通过缓存减少延迟\n\n当我与我的朋友 Eugene Yan 分享这篇帖子时，他说缓存可能是 AI 平台中最被低估的组件。缓存可以显著减少应用程序的延迟和成本。\n\n缓存技术也可以在训练期间使用，但由于这篇帖子是关于部署的，我将重点讨论用于推理的缓存。一些常见的推理缓存技术包括提示缓存、精确缓存和语义缓存。提示缓存通常由你使用的推理 API 实现。在评估推理库时，了解它支持哪种缓存机制是有帮助的。\n\n_用于注意力机制的 KV 缓存超出了本讨论的范围。_\n\n### 提示缓存\n\n许多应用中的提示存在重叠的文本段。例如，所有查询可以共享相同的系统提示。提示缓存存储这些重叠段以便重用，因此你只需要处理一次。对于有长系统提示的应用，提示缓存可以显著减少延迟和成本。如果你的系统提示是 1000 个令牌，而你的应用今天生成了 100 万个模型 API 调用，提示缓存将每天为你节省大约 10 亿个重复输入令牌的处理！然而，这并不是完全免费的。与 KV 缓存一样，提示缓存的大小可能相当大，需要显著的工程努力。\n\n提示缓存还适用于涉及长文档的查询。例如，如果许多用户查询与同一长文档（如一本书或代码库）相关，这个长文档可以被缓存以便跨查询重用。\n\n自从 2023 年 11 月 [Gim et al.](https:\/\/arxiv.org\/pdf\/2311.04934) 引入以来，提示缓存已经被纳入模型 API。Google 宣布将在 2024 年 6 月提供名为 [context cache](https:\/\/ai.google.dev\/gemini-api\/docs\/caching) 的功能。缓存的输入令牌与常规输入令牌相比可获得 75% 的折扣，但你需要为缓存存储支付额外费用（编写时为每小时 1 美元\/100 万令牌）。考虑到提示缓存的明显好处，我不会感到惊讶如果它变得和 KV 缓存一样流行。\n\n而 llama.cpp 也有 [prompt cache](https:\/\/github.com\/ggerganov\/llama.cpp\/blob\/master\/examples\/main\/README.md#prompt-caching)，但它似乎只缓存整个提示，并且仅适用于同一聊天会话中的查询。其文档有限，但从阅读代码的情况来看，在一次长对话中，它会缓存之前的消息并只处理最新的消息。\n\n### 精确缓存\n\n如果提示缓存和 KV 缓存是基础模型独有的，那么精确缓存则更为通用和直接。你的系统存储处理过的项目以便稍后在请求确切项目时重用。例如，如果用户要求模型总结一个产品，系统会检查缓存中是否有该产品的总结。如果有，就获取这个总结。如果没有，就总结该产品并缓存总结。\n\n精确缓存也用于基于嵌入的检索，以避免重复的向量搜索。如果传入的查询已经在向量搜索缓存中，就获取缓存的搜索结果。如果没有，就为这个查询执行向量搜索并缓存结果。\n\n缓存对于需要多个步骤（例如思维链）和\/或耗时操作（例如检索、SQL 执行或网络搜索）的查询特别有吸引力。\n\n精确缓存可以使用内存存储来实现快速检索。然而，由于内存存储有限，也可以使用数据库如 PostgreSQL、Redis 或分层存储来平衡速度和存储容量。拥有一个逐出政策对于管理缓存大小和维护性能至关重要。常见的逐出政策包括最近最少使用（LRU）、最少频繁使用（LFU）和先进先出（FIFO）。\n\n缓存一个查询多长时间取决于这个查询被再次调用的可能性有多大。特定于用户的查询，如“我的最近订单的状态如何”，不太可能被其他用户重用，因此不应该被缓存。同样，缓存时间敏感的查询，如“天气如何？”也没有多大意义。有些团队训练一个小型分类器来预测是否应该缓存一个查询。\n\n### 语义缓存\n\n与精确缓存不同，语义缓存不要求传入查询与任何缓存的查询完全相同。语义缓存允许重用相似的查询。想象一下，一个用户问“越南的首都是什么？”模型生成答案“河内”。后来，另一个用户问“越南的首都**_城市_**是什么？”这是同一个问题，但增加了“城市”这个词。语义缓存的思想是系统可以重用答案“河内”，而不是从头计算新查询。\n\n语义缓存只有在你有可靠的方式确定两个查询在语义上是否相似时才有效。一种常见的方法是基于嵌入的相似性，具体操作如下：\n\n1. 对每个查询生成其嵌入，使用嵌入模型。\n2. 使用向量搜索找到与当前查询嵌入最接近的缓存嵌入。假设这个相似度得分是 X。\n3. 如果 X 小于你设置的相似度阈值，认为缓存的查询与当前查询相同，并返回缓存结果。如果不是，处理这个当前查询并将其与其嵌入和结果一起缓存。\n\n这种方法需要一个向量数据库来存储缓存查询的嵌入。\n\n与其他缓存技术相比，语义缓存的价值更为可疑，因为它的许多组件容易失败。其成功依赖于高质量的嵌入、功能性的向量搜索和可靠的相似度度量。设置正确的相似度阈值也可能很棘手，需要大量的试验和错误。如果系统错误地将传入查询视为与另一个查询相似，从缓存中获取的响应将是错误的。\n\n此外，语义缓存可能耗时且计算密集，因为它涉及向量搜索。这种向量搜索的速度和成本取决于你的缓存嵌入数据库的大小。\n\n如果缓存命中率很高，即大部分查询可以通过利用缓存结果有效地回答，那么语义缓存可能仍然值得。然而，在纳入语义缓存的复杂性之前，请确保评估与之相关的效率、成本和性能风险。\n\n## 可观测性\n\n虽然我将可观测性单独分为一节，但它应该从平台构建之初就被整合进去，而不是事后才加入。对于所有规模的项目，可观测性都至关重要，其重要性随着系统复杂性的增加而增加。\n\n### 指标\n\n讨论监控时，大多数人会想到指标。你想追踪的指标取决于你希望了解系统的哪些方面，这是特定于应用程序的。一般而言，有两类指标你可能会追踪：模型指标和系统指标。\n\n系统指标反映了你整个系统的状态。常见的系统指标包括吞吐量、内存使用情况、硬件利用率和服务可用性\/运行时间。本帖将重点介绍模型指标。\n\n模型指标评估你的模型性能，如准确性、毒性和幻觉率。应用程序流程中的不同步骤也有自己的指标。例如，在 RAG 应用中，检索质量常用上下文相关性和上下文精确度来评估。向量数据库的评估可以通过它存储数据所需的存储空间和查询数据所需的时间来进行。\n\n### 日志\n\n关于日志，我的哲学很简单：记录一切。记录系统配置、查询、输出和中间输出。记录组件开始、结束、崩溃等事件。录制日志时，请确保为其标记和 ID，以帮助你了解日志来自系统中的哪里。\n\n记录所有内容意味着你拥有的日志量可能会迅速增长。许多用于自动日志分析和日志异常检测的工具都是由 AI 驱动的。\n\n虽然手工处理日志是不可能的，但每天手工检查你的生产数据，了解用户如何使用你的应用程序是有用的。Shankar 等人（2024）发现，随着开发者与更多数据的互动，他们对什么构成良好和不良输出的看法发生了变化，使他们能够重写他们的提示以增加良好响应的机会，并更新他们的评估流程以捕捉不良响应。\n\n### 跟踪\n\n跟踪是详细记录请求通过各种系统组件和服务的执行路径。在 AI 应用中，跟踪揭示了从用户发送查询到返回最终响应的整个过程，包括系统采取的动作、检索的文档以及发送给模型的最终提示。它还应显示每个步骤所需的时间及其相关成本（如果可测量）。例如，这是 [Langsmith](https:\/\/blog.langchain.dev\/announcing-langsmith\/) 跟踪的可视化表示。\n\n![生成式 AI 平台概览](15-traces.webp)\n\n理想情况下，你应该能够逐步追踪每个查询在系统中的转换。如果查询失败，你应该能够确定出错的确切步骤：是处理不当、检索的上下文不相关，还是模型生成了错误的响应。\n\n## AI 流水线编排\n\nAI 应用可以变得相当复杂，涉及多个模型、从多个数据库检索数据，并使用多种工具。编排器帮助你指定如何将这些不同组件组合（链接）在一起，创建端到端的应用流程。\n\n在高层次上，编排器分两步工作：组件定义和链接（也称为流水线）。\n\n1. **组件定义**  \n   你需要告诉编排器你的系统使用哪些组件，如模型（包括用于生成、路由和评分的模型）、系统可以从中检索数据的数据库以及系统可以采取的操作。与模型网关的直接集成可以简化模型引入，一些编排工具也想成为网关。许多编排器还支持与评估和监控工具的集成。\n\n2. **链接（或流水线）**  \n   你告诉编排器你的系统从接收用户查询到完成任务的步骤顺序。简而言之，链接就是函数组合。以下是流水线的一个示例。\n\n   1. 处理原始查询。\n   2. 根据处理后的查询检索相关数据。\n   3. 将原始查询和检索到的数据组合起来，创建模型预期格式的提示。\n   4. 模型根据提示生成响应。\n   5. 评估响应。\n   6. 如果响应被认为是好的，返回给用户。如果不是，将查询路由到人工操作员。\n\n   编排器负责在步骤之间传递数据，并可以提供工具来确保当前步骤的输出符合下一步骤的预期格式。\n\n设计流程时，尤其对于有严格延迟要求的应用，尽可能并行处理各个步骤。例如，如果你有一个路由组件（决定将查询发送到哪里）和一个 PII 移除组件，它们可以同时进行。\n\n有许多 AI 编排工具，包括 [LangChain](https:\/\/github.com\/langchain-ai\/langchain), [LlamaIndex](https:\/\/github.com\/run-llama\/llama_index), [Flowise](https:\/\/github.com\/FlowiseAI\/Flowise), [Langflow](https:\/\/github.com\/langflow-ai\/langflow), 和 [Haystack](https:\/\/github.com\/deepset-ai\/haystack)。每个工具都有自己的 API，所以我不会在这里展示实际代码。\n\n虽然在开始一个项目时直接使用编排工具很诱人，但首先应该在没有工具的情况下开始构建应用。任何外部工具都会带来额外的复杂性。编排器可能会抽象掉系统工作的关键细节，使系统难以理解和调试。\n\n随着应用开发过程的深入，你可能会发现编排器能让你的工作更轻松。在评估编排器时需要考虑三个方面：\n\n1. **集成和扩展性**  \n   评估编排器是否支持你已经使用或可能在未来采用的组件。例如，如果你想使用 Llama 模型，检查编排器是否支持它。鉴于存在许多模型、数据库和框架，编排器不可能支持所有内容。因此，你还需要考虑编排器的扩展性。如果它不支持特定组件，更改难度如何？\n\n2. **支持复杂流水线**  \n   随着应用复杂性的增加，你可能需要管理涉及多个步骤和条件逻辑的复杂流水线。支持高级功能如分支、并行处理和错误处理的编排器将帮助你有效管理这些复杂性。\n\n3. **易用性、性能和可扩展性**  \n   考虑编排器的用户友好性。寻找直观的 API、全面的文档和强大的社区支持，这些可以显著降低你和你团队的学习曲线。避免使用会启动隐藏 API 调用或引入应用延迟的编排器。此外，确保编排器可以随着应用、开发者和流量的增长有效扩展。\n\n## 结论\n\n这篇文章从基础架构开始，逐步添加组件来应对日益增长的应用复杂性。每次添加都带来了自己的好处和挑战，需要仔细考虑和实施。\n\n虽然组件的分离对于保持系统的模块化和可维护性很重要，但这种分离是流动的。组件之间有许多重叠。例如，模型网关可以与防护栏共享功能。缓存可以在不同的组件中实施，如在向量搜索和推理服务中。\n\n这篇文章比我预期的要长，但仍有许多细节我没有能够进一步探讨，尤其是在可观测性、上下文构建、复杂逻辑、缓存和防护栏方面。我将在即将出版的书籍《AI 工程》中更深入地探讨这些组件。\n\n这篇文章也没有讨论如何服务模型，假设大多数人将使用第三方 API 提供的模型。《AI 工程》还将专门介绍推理和模型优化。\n\n## 参考文献和致谢\n\n特别感谢 [Luke Metz](https:\/\/x.com\/luke_metz), [Alex Li](https:\/\/www.linkedin.com\/in\/findalexli\/), [Chetan Tekur](https:\/\/www.linkedin.com\/in\/chetantekur\/), [Kittipat “Bot” Kampa](https:\/\/www.linkedin.com\/in\/kittipat-bot-kampa-1b1965\/), [Hien Luu](https:\/\/www.linkedin.com\/in\/hienluu\/), 和 [Denys Linkov](https:\/\/www.linkedin.com\/in\/denyslinkov\/) 对本文早期版本的反馈。他们的见解极大地改善了内容。任何剩余的错误都是我的。\n\n我阅读了许多公司分享的案例研究，了解它们如何采用生成式 AI，以下是我最喜欢的一些。\n\n- [构建生成式 AI 产品的思考](https:\/\/www.linkedin.com\/blog\/engineering\/generative-ai\/musings-on-building-a-generative-ai-product?_l=en_US) (LinkedIn, 2024)\n- [我们是如何在 Pinterest 构建 Text-to-SQL 的](https:\/\/medium.com\/pinterest-engineering\/how-we-built-text-to-sql-at-pinterest-30bad30dabff) (Pinterest, 2024)\n- [从想法到现实：通过生成式 AI 提升我们的客户支持](https:\/\/medium.com\/vimeo-engineering-blog\/from-idea-to-reality-elevating-our-customer-support-through-generative-ai-101a2c5ea680) (Vimeo, 2023)\n- [深入探究世界上最智能的电子邮件 AI](https:\/\/www.shortwave.com\/blog\/deep-dive-into-worlds-smartest-email-ai\/) (Shortwave, 2023)\n- [LLM-powered 数据实体分类的大规模实施](https:\/\/engineering.grab.com\/llm-powered-data-classification) (Grab, 2023)\n- [从预测到生成 - 如何加速 Uber 的 AI 之旅](https:\/\/www.uber.com\/blog\/from-predictive-to-generative-ai\/) (Uber, 2024)\n', '\/trans\/building-a-generative-ai-platform\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">探索构建生成式人工智能平台的关键组件与实现策略，从基础架构到高级功能，提供全面的指导和深入分析。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/sapwned-sap-ai-vulnerabilities-ai-security/">[译] SAPwned：SAP AI 漏洞暴露客户云环境和私有 AI 工件</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2024/07/18</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/istio"> 
             Istio
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://www.wiz.io/blog/sapwned-sap-ai-vulnerabilities-ai-security" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('SAPwned：SAP AI 漏洞暴露客户云环境和私有 AI 工件', '本文通过研究 SAP AI Core，揭示了多个安全漏洞，这些漏洞可能允许攻击者访问客户数据和内部工件。', '\n## AI 是否存在隔离问题？\n\n在过去的几个月里，我们 Wiz 研究团队对多个 AI 服务提供商进行了广泛的租户隔离研究。我们认为这些服务更容易受到租户隔离漏洞的影响，因为它们允许用户运行 AI 模型和应用程序，这等同于执行任意代码。随着 AI 基础设施越来越成为许多商业环境的标配，这些攻击的影响正变得越来越重要。\n\n我们将在即将举行的 Black Hat 会议上展示这个研究项目的发现，在我们的会议“隔离还是幻觉？为乐趣和权重黑客攻击 AI 基础设施提供商”。\n\n在这个项目的最新一期中，我们研究了 SAP 的 AI 产品，恰当地命名为“SAP AI Core”。这是我们系列中的第三份报告，继我们对 Hugging Face 和 Replicate 平台的研究之后。本博客将探索漏洞链并详细介绍我们的发现，称为“SAPwned”，同时也将观察到确保管理 AI 平台安全的潜在影响和更广泛的启示。\n\n## 执行摘要\n\nAI 训练过程需要访问大量敏感客户数据，这使 AI 训练服务成为攻击者的诱人目标。SAP AI Core 提供与 HANA 及其他云服务的集成，通过云访问密钥访问客户的内部数据。这些凭据非常敏感，我们的研究目标是确定潜在的恶意行为者是否能够访问这些客户秘密。\n\n我们对 SAP AI Core 的研究始于使用 SAP 的基础设施执行合法的 AI 训练程序。通过执行任意代码，我们能够横向移动并接管服务——获取客户的私有文件以及客户云环境的凭据：AWS、Azure、SAP HANA Cloud 等。我们发现的漏洞可能允许攻击者访问客户数据并污染内部工件——蔓延到相关服务和其他客户环境。\n\n具体来说，我们获得的访问权限允许我们：\n\n- 在 SAP 的内部容器注册表上读取和修改 Docker 镜像\n\n- 在 Google 容器注册表上读取和修改 SAP 的 Docker 镜像\n\n- 在 SAP 的内部 Artifactory 服务器上读取和修改工件\n\n- 获得 SAP AI Core 的 Kubernetes 集群的集群管理员权限\n\n- 访问客户的云凭证和私有 AI 工件\n\n![我们研究发现的逐步插图](f1.png)\n\n我们发现这些问题的根本原因是攻击者可以运行恶意 AI 模型和训练程序，这本质上是代码。在审查了几个主要 AI 服务之后，我们认为行业必须改进其在运行 AI 模型时的隔离和沙箱标准。\n\n所有漏洞已报告给 SAP 的安全团队，并由 SAP 修复，如其网站所确认。我们感谢他们的合作。没有客户数据受到泄露。\n\n## 介绍：研究开始\n\nSAP AI Core 是一项服务，允许用户以可扩展和管理的方式在 SAP 的庞大云资源上开发、训练和运行 AI 服务。类似于其他云提供商（和 AI 基础设施提供商），客户的代码在 SAP 的共享环境中运行——构成跨租户访问的风险。\n\n我们的研究始于作为 SAP 客户，基本权限允许我们创建 AI 项目。因此，我们首先在 SAP AI Core 上创建了一个常规 AI 应用程序。SAP 的平台允许我们提供一个 Argo Workflow 文件，该文件反过来生成了一个根据我们的配置的新 Kubernetes Pod。\n\n![SAP AI Core 上的 Argo 工作流配置示例](f2.png)\n\n这允许我们在 Pod 中按设计运行我们自己的任意代码——不需要任何漏洞。然而，我们的环境受到了相当大的限制。我们很快意识到，我们的 Pod 的网络访问非常有限，这是由 Istio 代理 sidecar 强制执行的——因此，扫描内部网络对我们来说不是一个选项。至少现在不是。\n\n## Bug #1: 通过 1337 的力量绕过网络限制\n\n我们首先尝试的是为我们的 Pod 配置“有趣”的权限。然而，SAP 的准入控制器阻止了我们尝试的所有危险安全选项——例如，以\u0060root\u0060身份运行我们的容器。\n\n尽管如此，我们发现准入控制器未能阻止两种有趣的配置。\n\n第一个是\u0060shareProcessNamespace\u0060，它允许我们与我们的 sidecar 容器共享进程命名空间。由于我们的 sidecar 是 Istio 代理，我们获得了对 Istio 的配置的访问权限，包括对集群的集中式 Istiod 服务器的访问令牌。\n\n![通过我们的 sidecar 容器访问 Istio 令牌](f3.png)\n\n另一个是\u0060runAsUser\u0060（和\u0060runAsGroup\u0060）。虽然我们不能成为 root，但所有其他 UID 都是允许的——包括 Istio 的 UID，讽刺的是，这个 UID 是\u00601337\u0060（是的，真的）。我们将我们的 UID 设置为 1337，并成功地以 Istio 用户的身份运行。由于 Istio 本身是[从 Istio 的 iptables 规则中排除的](https:\/\/istio.io\/latest\/docs\/reference\/config\/analysis\/ist0144\/)——我们现在运行时没有任何流量限制！\n\n![发送请求到内部网络——在 UID 1337 之前和之后](f4.png)\n\n我们摆脱了流量束缚，开始扫描我们 Pod 的内部网络。使用我们的 Istio 令牌，我们能够从 Istiod 服务器读取配置并了解内部环境——这引导我们进行了以下发现。\n\n## Bug #2: Loki 泄露 AWS 令牌\n\n我们在集群中找到了一个 Grafana Loki 的实例，因此我们请求了\u0060\/config\u0060端点以查看 Loki 的配置。API 响应了完整的配置，包括 Loki 用来访问 S3 的 AWS 密钥：\n\n![来自 SAP 的 Loki 服务器的配置摘录](f5.png)\n\n这些密钥授予访问 Loki 的 S3 存储桶的权限，其中包含 AI Core 服务（SAP 称其不敏感）和客户 Pods 的大量日志。\n\n![Loki 的 S3 存储桶中的部分文件列表](f6.png)\n\n## Bug #3: 未经身份验证的 EFS 共享暴露用户文件\n\n在内部网络中，我们发现了 6 个 AWS Elastic File System（EFS）实例，监听端口 2049。EFS 实例的一个[常见问题](https:\/\/youtu.be\/HcNmkCRXFdE)是它们默认配置为公共的——这意味着只要您可以访问其 NFS 端口，就不需要凭据即可查看或编辑文件。这些实例也不例外，我们使用简单的开源 NFS 工具，可以自由访问共享的内容。\n\n列出这些 EFS 实例上存储的文件，揭示了大量 AI 数据，包括代码和训练数据集，按客户 ID 分类：\n\n![](f7.png)\n\n![两个 EFS 共享的部分文件列表；每个文件夹代表一个不同的客户 ID](f8.png)\n\n## Bug #4: 未经身份验证的 Helm 服务器危及内部 Docker 注册表和 Artifactory\n\n我们在网络上最有趣的发现是一个名为 Tiller 的服务，这是 Helm 包管理器的服务器组件（版本 2）。\n\n与 Tiller 的通信是通过其 gRPC 接口在端口 44134 进行的，该端口默认是未经身份验证的。\n\n在我们的内部网络上查询这个服务器，揭示了对 SAP 的 Docker 注册表以及其 Artifactory 服务器的高权限密钥：\n\n![通过 Helm 服务器查询暴露的容器注册表和 Artifactory 凭据](f9.png)\n\n使用这些密钥的读取权限，潜在的攻击者可以读取内部图像和构建，提取商业秘密，可能还包括客户数据。\n\n使用这些密钥的写权限，攻击者可以篡改图像和构建，对 SAP AI Core 服务进行供应链攻击。\n\n## Bug #5: 未经身份验证的 Helm 服务器危及 K8s 集群，暴露 Google 访问令牌和客户秘密\n\nHelm 服务器暴露了读写操作。尽管读取权限暴露了敏感的秘密（如上所示），但服务器的写权限允许完全接管集群。\n\nTiller 的\u0060install\u0060命令接受一个 Helm 包并将其部署到 K8s 集群。我们创建了一个恶意 Helm 包，生成了一个具有\u0060cluster-admin\u0060权限的新 Pod，并运行了安装命令。\n\n现在我们在集群上运行具有完全权限！\n\n![通过 Helm 获得的 K8s 权限的部分列表](f10.png)\n\n使用这种访问级别，攻击者可以直接访问其他客户的 Pods 并窃取敏感数据，如模型、数据集和代码。这种访问还允许攻击者干扰客户的 Pods，污染 AI 数据并操纵模型的推理。\n\n此外，这种访问级别还将允许我们查看客户自己的秘密——甚至超出 SAP AI Core 范围的秘密。例如，我们的 AI Core 账户包含了我们的 AWS 账户（用于 S3 数据访问）、我们的 SAP HANA 账户（用于 Data Lake 访问）和我们的 Docker Hub 账户（用于拉取我们的镜像）的秘密。使用我们新获得的访问级别，我们查询了这些秘密，并设法以纯文本形式访问它们所有：\n\n![使用我们的 K8s 权限访问客户秘密](f11.png)\n\n同样的查询还揭示了一个名为\u0060sap-docker-registry-secret\u0060的 SAP 访问 Google 容器注册表的密钥。我们已经确认这个密钥授予了读写权限——进一步扩大了潜在供应链攻击的范围。\n\n## 启示\n\n我们对 SAP AI Core 的研究表明，深度防御的重要性。我们面临的主要安全障碍是 Istio 阻止我们的流量到达内部网络。一旦我们能够绕过这个障碍，我们就获得了对几个内部资产的访问权限，这些资产不需要任何其他身份验证——这意味着内部网络被视为可信的。加固这些内部服务本可以将这次攻击的影响降至最低，将其从完全服务接管降级为轻微的安全事件。\n\n符合我们之前与 K8s 相关的漏洞，这项研究还展示了在管理服务中使用 K8s 的租户隔离陷阱。控制平面（服务逻辑）和数据平面（客户计算）之间的关键分离受到了 K8s 架构的影响，该架构通过 API、身份、共享计算和软件分段网络允许它们之间的逻辑连接。\n\n此外，这项研究表明，AI R\u0026D 过程引入的独特挑战。AI 培训本质上需要运行任意代码；因此，应该有适当的保护措施，确保不受信任的代码与内部资产和其他租户正确分离。\n\n## 披露时间线\n\n-   **2024 年 1 月 25 日** – Wiz 研究报告安全发现给 SAP\n\n-   **2024 年 1 月 27 日** – SAP 回复并分配了一个案件编号\n\n-   **2024 年 2 月 16 日** – SAP 修复了第一个漏洞并旋转了相关的秘密\n\n-   **2024 年 2 月 28 日** – Wiz 研究绕过补丁使用 2 个新漏洞，报告给 SAP\n\n-   **2024 年 5 月 15 日** – SAP 部署修复了所有报告的漏洞\n\n-   **2024 年 7 月 17 日** – 公开披露\n\n## 保持联系！\n\n嗨，我们是 Wiz 研究团队的 Hillai Ben-Sasson（[@hillai](https:\/\/twitter.com\/hillai)），Shir Tamari（[@shirtamari](https:\/\/twitter.com\/shirtamari)），Nir Ohfeld（[@nirohfeld](https:\/\/twitter.com\/nirohfeld)），Sagi Tzadik（[@sagitz_](https:\/\/twitter.com\/sagitz_)) 和 Ronen Shustin（[@ronenshh](https:\/\/twitter.com\/ronenshh)）。我们是一群资深白帽黑客，我们的目标是让云成为每个人更安全的地方。我们主要关注在云中找到新的攻击向量并揭露云供应商的隔离问题。\n\n我们很想听听您的意见！欢迎通过 Twitter 或电子邮件与我们联系：[research@wiz.io](mailto:research@wiz.io)。\n', '\/trans\/sapwned-sap-ai-vulnerabilities-ai-security\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文通过研究 SAP AI Core，揭示了多个安全漏洞，这些漏洞可能允许攻击者访问客户数据和内部工件。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/">[译] 了解 Llama 3：迄今最强大的免费开源大模型从概念到使用</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2024/07/01</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/ai"> 
             AI
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://www.unite.ai/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage/" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('了解 Llama 3：迄今最强大的免费开源大模型从概念到使用', '探索 Llama 3：Meta 推出的创新开源 LLM，介绍其架构、训练和实践应用，助力 AI 开发者。', '\nMeta 公司最近发布了 [Llama 3](https:\/\/ai.meta.com\/blog\/meta-llama-3\/)，这是其最新一代尖端开源大型语言模型（LLM）。基于其前身的基础之上，Llama 3 旨在提升 Llama 2 作为与 ChatGPT 竞争的重要开源产品的能力，如文章 [Llama 2: 深入探索开源挑战者 ChatGPT](https:\/\/www.unite.ai\/llama-2-a-deep-dive-into-the-open-source-challenger-to-chatgpt\/) 中全面回顾的那样。\n\n在本文中，我们将讨论 Llama 3 背后的核心概念，探索其创新架构和训练过程，并提供关于如何负责任地访问、使用和部署这一开创性模型的实际指导。无论你是研究人员、开发者还是 AI 爱好者，这篇文章都将为你提供利用 Llama 3 为你的项目和应用赋能的知识和资源。\n\n## Llama 的演变：从 Llama 2 到 Llama 3\n\nMeta 的 CEO，Mark Zuckerberg，在 [Threads.net](https:\/\/www.threads.net\/@zuck\/post\/C56MFEKxl-x) 上宣布了 Llama 3 的首次亮相，这是 Meta AI 开发的最新 AI 模型。这个尖端模型现在已开源，旨在提升 Meta 的各种产品，包括 Messenger 和 Instagram。Zuckerberg 强调，Llama 3 使 Meta AI 成为最先进的[免费可用的 AI 助手](https:\/\/about.fb.com\/news\/2024\/04\/meta-ai-assistant-built-with-llama-3\/)。\n\n在我们讨论 Llama 3 的具体细节之前，让我们简要回顾一下它的前身，Llama 2。Llama 2 于 2022 年推出，是开源 LLM 领域的一个重要里程碑，提供了一个强大而高效的模型，可以在消费者硬件上运行。\n\n然而，尽管 Llama 2 取得了显著的成就，但它也有其局限性。用户报告了一些问题，如错误拒绝（模型拒绝回答无害的提示）、有限的帮助性，以及在推理和代码生成等领域的改进空间。\n\n进入 Llama 3：Meta 对这些挑战和社区的反馈做出了回应。通过 Llama 3，Meta 设定了与当今市场上顶级专有模型相媲美的最佳开源模型的目标，同时也优先考虑了负责任的开发和部署实践。\n\n## Llama 3：架构和训练\n\nLlama 3 的一项关键创新是其分词器，特点是显著扩展的词汇表，**128,256 个 token**（从 Llama 2 的 32,000 个增加）。这更大的词汇表允许更有效的文本编码，无论是输入还是输出，可能导致更强的多语言能力和整体性能的提升。\n\nLlama 3 还采用了**分组查询注意力**（GQA），这是一种提高可扩展性的有效表示技术，有助于模型更有效地处理更长的上下文。**8B** 版本的 Llama 3 使用了 GQA，而**8B** 和 **70B** 模型都可以处理长达 **8,192 个 token**的序列。\n\n### 训练数据和扩展\n\n用于 Llama 3 的训练数据是其性能提升的关键因素。Meta 精心策划了一个包含超过 **15 万亿** token 的庞大数据集，来自公开可获得的在线来源，是用于 Llama 2 的数据集的七倍。这个数据集还包括了超过 5% 的高质量非英语数据，涵盖了 **30 多种语言**，为未来的多语言应用做准备。\n\n为了确保数据质量，Meta 采用了先进的过滤技术，包括启发式过滤器、NSFW 过滤器、语义去重和训练在 Llama 2 上预测数据质量的文本分类器。团队还进行了广泛的实验，以确定预训练的最佳数据来源组合，确保 Llama 3 在广泛的用例上表现良好，包括琐事、STEM、编码和历史知识。\n\n放大预训练是 Llama 3 开发的另一个关键方面。Meta 开发了缩放法则，使他们能够在实际训练之前预测其最大模型在关键任务上的性能，如代码生成。这些信息指导了关于数据组合和计算分配的决策，最终导致了更有效和有效的培训。\n\nLlama 3 最大的模型是在两个定制构建的 24,000 GPU 集群上训练的，利用数据并行、模型并行和流水线并行技术的组合。Meta 的先进训练堆栈自动化了错误检测、处理和维护，最大化了 GPU 的运行时间，使训练效率比 Llama 2 提高了大约三倍。\n\n### 指令微调和性能\n\n为了充分发挥 Llama 3 在聊天和对话应用中的潜力，Meta 创新了其指令微调方法。其方法结合了**监督微调**（SFT）、拒绝抽样、**近端政策优化**（PPO）和**直接偏好优化**（DPO）。\n\nSFT 中使用的提示质量和在 PPO 和 DPO 中使用的偏好排名在对齐模型的性能中起着关键作用。Meta 的团队精心策划了这些数据，并对由人类注释者提供的注释进行了多轮质量保证。\n\n通过 PPO 和 DPO 对偏好排名进行训练还显著提高了 Llama 3 在推理和编码任务上的性能。Meta 发现，即使模型在直接回答推理问题时遇到困难，它仍然可能产生正确的推理迹象。通过偏好排名的训练，模型学会了如何从这些迹象中选择正确的答案。\n\n![对比结果](f2.jpg)\n\n成果显而易见：Llama 3 在常见的行业基准测试中表现优于许多可用的开源聊天模型，为 LLM 的 8B 和 70B 参数级别建立了新的最佳性能。\n\n![](f3.png)\n\n## 负责任的开发和安全考虑\n\n在追求尖端性能的同时，Meta 也优先考虑了负责任的开发和部署实践，用于 Llama 3。该公司采用了系统级方法，将 Llama 3 模型视为更广泛生态系统的一部分，使开发者能够设计和定制模型以满足其特定用例和安全要求。\n\n![](f4.png)\n\nMeta 进行了广泛的红队演习，执行了对抗评估，并实施了安全缓解技术，以降低其指令调优模型中的残余风险。然而，该公司承认可能仍会存在残余风险，并建议开发者在其特定用例的背景下评估这些风险。\n\n为支持负责任的部署，Meta 更新了其负责任使用指南，为开发者提供了一个全面的资源，以实施模型和系统级安全最佳实践，用于他们的应用。该指南涵盖了内容审查、风险评估和使用安全工具（如 Llama Guard 2 和 Code Shield）等主题。\n\nLlama Guard 2，基于 MLCommons 分类法构建，旨在对 LLM 输入（提示）和响应进行分类，检测可能被视为不安全或有害的内容。CyberSecEval 2 在其前身的基础上增加了措施，以防止模型的代码解释器被滥用、攻击性网络安全能力和对提示注入攻击的易感性。\n\nCode Shield 是 Llama 3 新推出的一个介绍，增加了推断时间的不安全代码过滤，减轻了不安全代码建议、代码解释器滥用和安全命令执行等风险。\n\n## 访问和使用 Llama 3\n\n随着 Meta AI 的 Llama 3 发布，已推出了几种开源工具，可在各种操作系统上进行本地部署，包括 Mac、Windows 和 Linux。本节详细介绍了三个值得注意的工具：Ollama、Open WebUI 和 LM Studio，每个工具都提供了利用 Llama 3 功能的独特功能。\n\n**Ollama**：适用于 Mac、Linux 和 Windows，[Ollama](https:\/\/ollama.com\/download) 简化了在个人计算机上操作 Llama 3 和其他大型语言模型的过程，即使是那些硬件较弱的设备也是如此。它包括一个包管理器，便于模型管理，并支持跨平台的下载和运行模型的命令。\n\n**Open WebUI with Docker**：这个工具提供了一个用户友好的、基于 [Docker](https:\/\/docs.docker.com\/desktop\/) 的界面，兼容 Mac、Linux 和 Windows。它与 Ollama 注册表中的模型无缝集成，允许用户在本地 Web 界面内部署和交互，例如 Llama 3。\n\n**LM Studio**：面向 Mac、Linux 和 Windows 的用户，[LM Studio](https:\/\/lmstudio.ai\/) 支持一系列模型，基于 llama.cpp 项目构建。它提供了一个聊天界面，便于直接与各种模型进行交互，包括 Llama 3 8B Instruct 模型。\n\n这些工具确保用户可以在个人设备上高效利用 Llama 3，满足技术技能和需求的不同范围。每个平台都提供了设置和模型交互的分步过程，使先进的人工智能更加易于开发者和爱好者接触。\n\n## 大规模部署 Llama 3\n\n除了直接提供模型权重外，Meta 还与各种云提供商、模型 API 服务和硬件平台合作，实现 Llama 3 的无缝部署。\n\nLlama 3 的一大优势是其改进的 token 效率，这要归功于新的分词器。基准测试显示，与 Llama 2 相比，Llama 3 需要的 token 减少了 **15%**，从而实现了更快、更经济的推断。\n\nGrouped Query Attention (GQA) 的整合在 Llama 3 的 8B 版本中有助于保持与 Llama 2 的 7B 版本相当的推断效率，尽管参数数量增加了。\n\n为简化部署流程，Meta 提供了 Llama Recipes 代码库，其中包含开源代码和微调、部署、模型评估等示例。这个代码库为开发者提供了一个宝贵的资源，帮助他们利用 Llama 3 的能力来应用到他们的应用中。\n\n对于那些有兴趣探索 Llama 3 性能的人来说，Meta 已经将其最新模型整合到 Meta AI 中，这是一个以 Llama 3 技术构建的领先人工智能助手。用户可以通过各种 Meta 应用程序，如 Facebook、Instagram、WhatsApp、Messenger 和 Web 与 Meta AI 进行交互，以完成任务、学习、创造和与他们关心的事物建立联系。\n\n## Llama 3 接下来会怎样？\n\n尽管 8B 和 70B 模型标志着 Llama 3 发布的开始，但 Meta 对这款开创性 LLM 的未来有雄心勃勃的计划。\n\n在未来几个月，我们可以期待看到新功能的引入，包括多模态（能够处理和生成不同数据模态，如图像和视频）、多语言支持（支持多种语言）和更长的上下文窗口，以提高在需要广泛上下文的任务上的性能。\n\n此外，Meta 计划发布更大的模型大小，包括目前正在训练中的超过 4000 亿参数的模型，这些模型在性能和能力方面展现出了有前途的趋势。\n\n为了进一步推进该领域的发展，Meta 还将发布关于 Llama 3 的详细研究论文，与广泛的 AI 社区分享其发现和见解。\n\n作为即将推出的内容的预览，Meta 分享了一些其最大 LLM 模型在各种基准上的早期性能快照。尽管这些结果是基于早期检查点的，并且可能会发生变化，但它们提供了一个激动人心的展望，展示了 Llama 3 的未来潜力。\n\n## 结论\n\nLlama 3 代表了开源大型语言模型演变的一个重要里程碑，推动了性能、能力和负责任开发实践的边界。凭借其创新架构、庞大的训练数据集和尖端的微调技术，Llama 3 为 LLM 的 8B 和 70B 参数级别建立了新的最佳性能基准。\n\n然而，Llama 3 不仅仅是一个强大的语言模型；它还体现了 Meta 致力于培养一个开放和负责任的 AI 生态系统的承诺。通过提供全面的资源、安全工具和最佳实践，Meta 授权开发者充分利用 Llama 3 的潜力，同时确保根据其特定用例和受众的需求实现负责任的部署。\n\n随着 Llama 3 之旅的继续，随着新的能力、模型大小和研究发现的出现，AI 社区热切期待从这款开创性 LLM 中涌现出的创新应用和突破。\n\n无论你是一名推动自然语言处理边界的研究人员、一名构建下一代智能应用的开发者还是对最新进展感到好奇的 AI 爱好者，Llama 3 都承诺成为你工具箱中的强大工具，开启新的大门并解锁一系列可能性。\n', '\/trans\/everything-you-need-to-know-about-llama-3-most-powerful-open-source-model-yet-concepts-to-usage\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">探索 Llama 3：Meta 推出的创新开源 LLM，介绍其架构、训练和实践应用，助力 AI 开发者。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/cloud-native-ai-whitepaper/">深入解读 CNCF 推出的云原生 AI 白皮书</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2024/04/16</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/%e4%ba%91%e5%8e%9f%e7%94%9f"> 
             云原生
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('深入解读 CNCF 推出的云原生 AI 白皮书', 'KubeCon EU 2024 期间 CNCF 推出首份云原生 AI 白皮书，本文是对该白皮书内容的深入解读。', '\n2024 年 3 月，在 KubeCon EU 期间，云原生计算基金会（CNCF）发布了首份关于云原生人工智能（CNAI）的详细[白皮书](https:\/\/www.cncf.io\/reports\/cloud-native-artificial-intelligence-whitepaper\/)。这份报告详尽地探讨了将云原生技术与人工智能融合的当前状态、面临的挑战、以及未来的发展方向。本文将对这份白皮书的核心内容进行深入解读。\n\n## 什么是云原生 AI？\n\n云原生 AI 指的是利用云原生技术原则来构建和部署人工智能应用和工作负载的方法。这包括利用微服务、容器化、声明式 API 和持续集成\/持续部署（CI\/CD）等云原生技术来增强 AI 应用的可扩展性、可复用性和可操作性。\n\n下图展示了云原生 AI 的架构，图片根据该白皮书重新绘制。\n\n![云原生 AI 架构](cloud-native-ai.svg)\n\n## 云原生 AI 与云原生技术之间的关系\n\n云原生技术提供了一个灵活、可扩展的平台，使得开发和运行 AI 应用变得更加高效。通过容器化和微服务架构，开发人员可以快速迭代和部署 AI 模型，同时保证系统的高可用性和可扩展性。Kubernetes 和其他云原生工具提供了必要的支持，例如资源调度、自动扩缩容和服务发现等。\n\n白皮书中给出了两个例子说明云原生 AI 与云原生技术的关系，即在云原生基础架构上运行 AI：\n\n- [Hugging Face Collaborates with Microsoft to launch Hugging Face Model Catalog on Azure](https:\/\/huggingface.co\/blog\/hugging-face-endpoints-on-azure)\n- [OpenAI Scaling Kubernetes to 7,500 nodes](https:\/\/openai.com\/research\/scaling-kubernetes-to-7500-nodes)\n\n## 云原生 AI 的挑战\n\n尽管云原生技术为 AI 应用提供了坚实的基础，但在将 AI 工作负载与云原生平台整合时，仍然存在一些挑战。这些挑战包括数据准备的复杂性、模型训练的资源需求、以及在多租户环境中保持模型的安全性和隔离性。此外，云原生环境中的资源管理和调度对于大规模 AI 应用尤其关键，需要进一步优化以支持高效的模型训练和推理。\n\n## 云原生 AI 的发展路径\n\n白皮书中提出了几条云原生 AI 的发展路径，包括改进资源调度算法以更好地支持 AI 负载、开发新的服务网格技术以提高 AI 应用的性能和安全性，以及通过开源项目和社区合作来推动云原生 AI 技术的创新和标准化。\n\n## 云原生 AI 技术景观图\n\n云原生 AI 涉及到多种技术，从容器和微服务到服务网格和无服务器计算。Kubernetes 是部署和管理 AI 应用的关键平台，而 Istio、Envoy 等服务网格技术则提供了强大的流量管理和安全功能。此外，Prometheus 和 Grafana 等监控工具对于维护 AI 应用的性能和可靠性至关重要。\n\n下面是白皮书中给出的云原生 AI 景观图。\n\n### General Orchestration\n\n- Kubernetes\n- Volcano\n- Armada\n- Kuberay\n- Nvidia NeMo\n- Yunikorn\n- Kueue\n- Flame\n\n### Distributed Training\n\n- Kubeflow Training Operator\n- Pytorch DDP\n- TensorFlow Distributed\n- Open MPI\n- DeepSpeed\n- Megatron\n- Horovod\n- Apla\n- ...\n\n### ML Serving\n- Kserve\n- Seldon\n- VLLM\n- TGT\n- Skypilot\n- ...\n\n### CI\/CD - Delivery\n- Kubeflow Pipelines\n- Mlflow\n- TFX\n- BentoML\n- MLRun\n- ...\n\n### Data Science\n- Jupyter\n- Kubeflow Notebooks\n- PyTorch\n- TensorFlow\n- Apache Zeppelin\n- ...\n\n### Workload Observability\n- Prometheus\n- Influxdb\n- Grafana\n- Weights and Biases (wandb)\n- OpenTelemetry\n- ...\n\n### AutoML\n- Hyperopt\n- Optuna\n- Kubeflow Katib\n- NNI\n- ...\n\n### Governance \u0026 Policy\n- Kyverno\n- Kyverno-JSON\n- OPA\/Gatekeeper\n- StackRox Minder\n- ...\n\n### Data Architecture\n- ClickHouse\n- Apache Pinot\n- Apache Druid\n- Cassandra\n- ScyllaDB\n- Hadoop HDFS\n- Apache HBase\n- Presto\n- Trino\n- Apache Spark\n- Apache Flink\n- Kafka\n- Pulsar\n- Fluid\n- Memcached\n- Redis\n- Alluxio\n- Apache Superset\n- ...\n\n### Vector Databases\n- Milvus\n- Chroma\n- Weaviate\n- Quadrant\n- Pinecone\n- Extensions\n  - Redis\n  - Postgres SQL\n  - ElasticSearch\n- ...\n\n### Model\/LLM Observability\n- Trulens\n- Langfuse\n- Deepchecks\n- OpenLLMetry\n- ...\n\n## 总结\n\n最后，笔者梳理了以下关键观点：\n\n- **开源社区的推动作用**：白皮书明确指出开源社区对云原生 AI 进步的推动作用，其中包括通过开源项目和广泛的合作来加速创新和降低成本。\n\n- **云原生技术的重要性**：云原生 AI 是按照云原生原则构建和部署的，突出了可重复性和可扩展性的重要性。云原生技术为 AI 应用提供了高效的开发和运行环境，特别是在资源调度和服务可伸缩性方面。\n\n- **存在的挑战**：尽管云原生 AI 带来了诸多优势，但在数据准备、模型训练资源需求以及模型安全性和隔离性方面，仍面临不少挑战。\n\n- **未来发展方向**：白皮书提出的发展路径包括优化资源调度算法以支持 AI 负载，开发新的服务网格技术以提升性能和安全性，以及利用开源项目和社区合作进一步促进技术创新和标准化。\n\n- **关键技术组件**：云原生 AI 涉及的关键技术包括容器、微服务、服务网格和无服务器计算等，其中 Kubernetes 扮演着 AI 应用部署和管理的中心角色，Istio 和 Envoy 等服务网格技术提供了必要的流量管理和安全保障。\n\n有关详情，请下载 [云原生 AI 白皮书](https:\/\/www.cncf.io\/reports\/cloud-native-artificial-intelligence-whitepaper\/)。\n', '\/blog\/cloud-native-ai-whitepaper\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">KubeCon EU 2024 期间 CNCF 推出首份云原生 AI 白皮书，本文是对该白皮书内容的深入解读。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/7-best-practices-for-developers-getting-started-with-genai/">[译] 给初学生成式 AI（GenAI）的开发人员的 7 条最佳实践</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/12/20</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/ai"> 
             AI
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://thenewstack.io/7-best-practices-for-developers-getting-started-with-genai/" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('给初学生成式 AI（GenAI）的开发人员的 7 条最佳实践', '这篇文章分享了七个步骤，帮助开发者掌握生成式 AI 的基本概念和技能。', '## 编者按\n\n编辑评论：这是一篇非常有价值的文章，向开发者展示了生成式 AI 的潜力和应用。生成式 AI 是一种利用大型语言模型来生成和转换文本的技术，它可以帮助开发者解决一些复杂的问题，如代码生成，文档编写，内容创作等。生成式 AI 也是一种云原生的技术，它需要大量的计算资源和数据，以及高效的部署和管理方式。文章提供了一些实用的工具和平台，如 GitHub Copilot，Bard，ChatGPT 等，让开发者可以轻松地尝试和使用生成式 AI。文章还给出了一些注意事项和建议，如保护数据隐私，验证输出质量，避免滥用等，让开发者可以负责任地使用生成式 AI。我认为这篇文章是一个很好的入门指南，让开发者可以了解和利用生成式 AI 来打造创新的云原生应用。\n\n---\n\n## 正文\n\n通过一点经验，你可以使用 GenAI 解决一些相当困难的问题，就像学习任何新技术一样，最好的方法就是动手实践。\n\n随着可访问的生成式人工智能进入主流，以及由此产生的通过简单语言转化整个人类知识的能力，每个企业都在竭力将人工智能整合到其技术体系中。对于开发人员来说，压力很大，但也有着令人兴奋的无限可能性。\n\n如果你有一些经验，你可以使用 GenAI 解决一些相当困难的问题，就像学习自 HTML 诞生以来的每一项新技术一样。让我们看看你可以采取的七个步骤，以开始建立 GenAI 的基础，并最终逐步发展成一个完全运作、可扩展的应用程序。\n\n## 1. 玩转现有的 GenAI 工具\n\n入门 GenAI 的最佳方法是实践，而且门槛非常低。市场上现在有许多免费选项，比如 Bard、ChatGPT、Bing 和 Anthropic，有很多可以学习的选择。\n\n尝试使用 GenAI 工具和代码生成解决方案进行实验（并鼓励你的团队进行实验），例如[GitHub Copilot](https:\/\/github.com\/features\/copilot)，它集成到每个流行的 IDE 中，充当一对程序员。Copilot 提供程序员建议，帮助解决代码问题，并生成整个函数，使学习和适应GenAI变得更快更容易。\n\n当你首次使用这些现成的工具时，要小心使用专有或敏感的公司数据，即使只是提供给工具一个提示也要小心。Gen AI 供应商可能会存储并使用你的数据用于将来的训练运行，这是公司数据政策和信息安全协议的重大违规行为。确保你及时直接地向你的团队传达这一黄金规则。\n\n## 2. 了解从 GenAI 中可以获得什么\n\n一旦你开始尝试 GenAI，你将很快了解到不同提示会产生什么类型的输出。大多数 GenAI 工具可以生成各种格式的文本，包括：\n\n- **生成**新的故事、想法、文章或任意长度的文本。\n- **转换**现有文本为不同格式，如 JSON、Markdown 或 CSV。\n- **翻译**文本成不同语言。\n- 以聊天的方式**对话**来回。\n- **审查**文本以展示特定元素。\n- 将长篇内容**汇总**以获取洞察。\n- **分析**文本的情感。\n\n任何人都可以生成这些类型的生成文本结果，无需编程技能。只需键入提示，文本就会产生。然而，大型语言模型（LLM）经过的培训越多，即它摄取的语言碎片越多，随着时间的推移，它在生成、更改和分析文本方面就会变得更加准确。\n\n## 3. 学习提示工程\n\n部署 GenAI 的良好方法之一是掌握编写提示的技巧，这既是一门艺术又是一门科学。虽然提示工程师是一个实际的职位描述，但它也是任何希望提高他们使用 AI 的人的好绰号。优秀的提示工程师知道如何开发、完善和优化文本提示，以获得最佳结果并提高整个 AI 系统的性能。\n\n提示工程不需要特定的学位或背景，但从事这项工作的人需要擅长清晰解释事物。这是重要的，因为所有可用的 LLM 都是无状态的，这意味着没有长期记忆，每次交互只存在于小会话中。\n\n在提示工程中，以下三个因素变得重要：\n\n1. **上下文**：你提出的问题、聊天历史记录和你设置的参数。\n2. **知识**：LLM 已经接受的培训内容以及你通过提示提供的新信息的结合。\n3. **形式**：你期望以何种方式生成信息的语气。\n\n上下文、知识和形式的结合塑造了 GenAI 的大量知识存储成为你希望获得的响应类型。\n\n## 4. 探索其他 GenAI 提示方法\n\n到目前为止，我们一直在谈论零-shot 提示，这基本上意味着提出一个带有一些上下文的问题。如果你从这种方法中没有得到期望的结果，还有四种提示 GenAI 的方法。\n\n1. **单次提示**：提供你正在寻找的输出类型的示例。如果你想要特定类型的格式，例如[标题]和[4 个要点]，这将特别有用。\n2. **少量提示**：这类似于单次提示，但你会提供三到五个示例而不仅仅是一个。\n3. **“让我们一步一步地思考”**：这种技巧对 LLM 和对人都同样有效。如果你有一个包含多个部分的复杂问题，请在末尾输入此短语，等待 LLM 分解问题。\n4. **思路链提示**：对于涉及复杂算术或其他推理任务的问题，思路链提示会指示工具“展示其工作方式”并解释其如何得出答案。以下是可能的示例：\n\n![](f1.png)\n\n## 5. 查看其他 GenAI 工作示例\n\n一旦你熟悉了 GenAI 工具并了解如何编写出色的提示，[请查看 OpenAI 发布的一些示例](https:\/\/github.com\/openai\/openai-cookbook\/tree\/main\/examples)，了解其他人正在做什么以及可能的其他可能性。随着你的实验，你将更加熟悉聊天界面，并学会如何对其进行微调，以便熟练地缩小响应范围，甚至将响应转换为 CSV 文件或其他类型的表格。\n\n考虑如何将你的 GenAI 知识应用于你的业务，以简化困难或重复性任务，生成创意并使信息易于让更广泛的受众访问。你可以想象出哪些新的用例？以前不可能的东西现在成为可能了吗？\n\n## 6. 集成第三方 GenAI 工具和 API\n\n考虑使用 ChatGPT、Bard 和 Claude 2 等 API 通过 API 使用 LLMs 的角色。这些工具都提供了强大的 API，并有支持文档，因此入门门槛很低。大多数这些 API 是基于使用量的，因此更容易玩弄。\n\n通常情况下，通过语义搜索和由向量数据库支持的嵌入来将自定义或私有数据集成到 LLM 提示中，你还可以集成自定义或私有数据。通常称为 RAG（检索增强生成）。\n\n分解这两个术语：\n\n- **语义搜索**：使用词嵌入比较查询的含义与其索引中文档的含义，即使没有完全匹配的单词也能获得更相关的结果。\n- **嵌入**：将对象（如单词、句子或整个文档）的数值表示转化为多维空间。这使得评估不同实体之间的关系成为可能。\n\n以下是这可能看起来的一个示例：\n\n![](f2.png)\n\n这幅图展示了“猫”和“狗”的概念比它们与“人”或“蜘蛛”的概念更接近，“车辆汽车”则是最远的，是概念中最不相关的。（[这里有更多关于如何使用语义搜索和嵌入的信息](https:\/\/www.confluent.io\/blog\/chatgpt-and-streaming-data-for-real-time-generative-ai\/#connecting-knowledge-base-to-gpt)。）\n\n## 7. 从头开始训练自己的模型\n\n这最后的建议实际上不太像建议，更像是一个“可选的下一步”。训练自己的 GenAI 模型并不适合每个人，但如果你：\n\n- 拥有独特而有价值的知识库。\n- 想要执行商业 LLM 无法完成的某些任务。\n- 发现商业 LLM 的推理成本在商业上没有意义。\n- 有特定的安全要求，需要托管自己的 LLM 数据，并且不愿通过第三方 API 传递数据。\n\n训练自己的模型的一种方法是使用开源模型，例如 Llama 2、Mosaic MPT-7B、Falcon 或 Vicuna，其中许多还提供了商业使用许可证。这些通常根据它们具有的参数数量进行标记：7B、13B、40B 等。 “B”代表模型的参数数目，以及它可以处理和存储的信息量。数字越高，模型就越复杂和复杂，但训练和运行成本也越高。如果你的用例不复杂，并且如果你计划在性能相当强大的现代笔记本电脑上运行模型，那么具有较低参数的模型是开始的最佳且最经济的方法。\n\n中大型组织可能会选择从头开始构建和训练一个 LLM 模型。这是一条非常昂贵、资源密集且耗时的 AI 之路。你需要难以招聘的技术人才，并具备长时间迭代的机会，因此对大多数组织来说，这条路线不现实。\n\n### 微调 LLM\n\n一些组织选择中间路径：微调基本开源 LLM 以实现模型预训练能力之外的特定功能。如果你希望以你品牌独特的声音创建虚拟助手或基于真实客户购买构建的推荐系统，那么这是一个很好的选择。这些模型会随着你纳入排名靠前的用户交互而不断地训练自己。事实上，[Open AI 报告](https:\/\/voicebot.ai\/2023\/08\/23\/openai-brings-fine-tuning-to-gpt-3-5-turbo-and-gpt-4\/)，使用此模型，可以将提示长度缩短多达 90%，同时保持性能不变。此外，Open AI 的商业 API 的最新增强功能使其与驱动 ChatGPT 和 Bing AI 的模型一样强大和易于访问。\n', '\/trans\/7-best-practices-for-developers-getting-started-with-genai\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">这篇文章分享了七个步骤，帮助开发者掌握生成式 AI 的基本概念和技能。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/can-chatgpt-save-collective-kubernetes-troubleshooting/">[译] Kubernetes 故障排除智慧的演变</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/09/10</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/kubernetes"> 
             Kubernetes
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://thenewstack.io/can-chatgpt-save-collective-kubernetes-troubleshooting/" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Kubernetes 故障排除智慧的演变', '本文讨论了在 Kubernetes 故障排除中的两种路径：一种是增强操作员的分析工作，通过自动化和简化对故障排除知识的访问来提供帮助；另一种是将操作员从故障排除中排除，通过使用 AI\/ML 模型和可观测性数据来自动化故障修复。同时强调了数据的重要性，以及继续共享故障排除经验和建立对可观测性的一致认识的必要性。', '摘要：本文讨论了在 Kubernetes 故障排除中的两种路径：一种是增强操作员的分析工作，通过自动化和简化对故障排除知识的访问来提供帮助；另一种是将操作员从故障排除中排除，通过使用 AI\/ML 模型和可观测性数据来自动化故障修复。同时强调了数据的重要性，以及继续共享故障排除经验和建立对可观测性的一致认识的必要性。\n\n---\n\n本文译自：https:\/\/thenewstack.io\/can-chatgpt-save-collective-kubernetes-troubleshooting\/\n\n数十年前，系统管理员们开始在互联网上分享他们每天面临的技术问题。他们进行了长时间、充满活力且富有价值的讨论，探讨如何调查和解决问题的根本原因，然后详细说明最终对他们有效的解决方案。\n\n这股洪流从未停歇，只是改变了流向。如今，这些讨论仍在 Stack Overflow、Reddit 以及企业工程博客上进行。每一次讨论都是对全球 IT 系统故障排除经验的宝贵贡献。\n\n[Kubernetes](https:\/\/roadmap.sh\/kubernetes)也从根本上改变了这种流向。与几十年来困扰系统管理员和 IT 人员的虚拟机（VM）和单体应用程序相比，[微服务架构](https:\/\/thenewstack.io\/microservices\/)要复杂得多。由于 Kubernetes 缺乏数据持久性，往往无法对规模化的 K8s 错误进行本地重现。即使能够捕获，观测数据也会在多个平台上分散，而资源和依赖关系的相互关联关系也难以捕捉。\n\n现在，凭直觉并不一定足够。您需要知道如何调试集群以获得下一步的线索。\n\n这种复杂性意味着公开的故障排除讨论比以往任何时候都更为重要，但现在我们开始看到这股宝贵的洪流不是被重定向，而是完全被堵住了。你在谷歌上看到了这一点。任何与 Kubernetes 相关问题的搜索都会出现一半以上的付费广告和至少一页 SEO 驱动的文章，这些文章缺乏技术深度。[Stack Overflow](https:\/\/thenewstack.io\/stack-overflow-adds-ai-will-the-community-respond\/) 正在失去其作为技术人员首选问答资源的主导地位，Reddit 在过去几年中也陷入了争议。\n\n现在，每个 Kubernetes 的 DevOps 平台都在建立最后一个堤坝：将您的故障排除知识集中在其平台上，并用[人工智能（AI）和机器学习（ML）](https:\/\/thenewstack.io\/70-percent-of-developers-using-or-will-use-ai-says-stack-overflow-survey\/)取而代之，直到整个堆栈对于甚至是最有经验的云原生工程师来说都成为一个黑盒。当发生这种情况时，您失去了逐个探测、排除故障和修复系统的能力。这种趋势将曾经是众包故障排除技能洪流变成了过去所能提供的仅仅是一滴水。\n\n当我们依赖于平台时，故障排除技术的集体智慧就会消失。\n\n## 故障排除智慧的传承\n\n起初，系统管理员依靠实体书籍进行技术文档和整体最佳实践的实施。随着互联网在 80 年代和 90 年代的普及，这些人通常通过[Usenet](https:\/\/today.duke.edu\/2010\/05\/usenet.html)与同行进行交流，并在像 comp.lang.* 这样的新闻组中提出工作中的技术问题，这类新闻组类似于我们今天所知的论坛的简化版本。\n\n随着互联网的普及迅速，并几乎完全改变了故障排除智慧的洪流。工程师和管理员们不再聚集在新闻组中，而是涌向包括 Experts Exchange 在内的数千个论坛，该论坛于 1996 年上线。在积累了大量的问题和答案之后，Experts Exchange 团队将所有答案都放在了每年 250 美元的付费墙后面，这使得无数宝贵的讨论无法公开获取，最终导致了该网站的影响力下降。\n\n[Stack Overflow 随后出现](https:\/\/www.joelonsoftware.com\/2018\/04\/06\/the-stack-overflow-age\/)，再次向公众开放了这些讨论，并通过声望点数对讨论进行游戏化，这些声望点数可以通过提供见解和解决方案来获得。其他用户随后对“最佳”解决方案进行投票和验证，这有助于其他搜索者快速找到答案。Stack Overflow 的游戏化、自我管理和社区使其成为了洪流式故障排除知识的唯一渠道。\n\n但是，就像其他时代一样，没有什么好事能永远持续下去。近 10 年来，人们一直在预测[“Stack Overflow 的衰落”](https:\/\/johnslegers.medium.com\/the-decline-of-stack-overflow-7cb69faa575d)，并指出由于其具有攻击性的性质和由拥有最多声望点数的人进行管理的结构，它“讨厌新用户”。虽然 Stack Overflow 的影响力和流行度确实下降了，但 Reddit 的开发\/工程专注的 subreddit 填补了这个空白，它仍然是公开可访问的故障排除知识的最大存储库。\n\n特别是对于 Kubernetes 和云原生社区来说，这仍然是一个重要的资源，因为它们仍然在经历重大的增长阵痛。而这是一种宝贵的资源，因为如果您认为现在的 Kubernetes 已经很复杂了...\n\n## Kubernetes 的复杂性问题\n\n在一篇关于“直观调试”失败的精彩文章中，软件交付顾问 Pete Hodgson 认为，构建和交付软件的现代架构（如 Kubernetes 和微服务）比以往任何时候都更加复杂。他写道：“对于我们大多数人来说，为服务器命名为希腊神话角色，并通过 ssh 进入服务器运行\u0060tail\u0060和\u0060top\u0060的日子已经一去不复返了。”但是，“这种转变是有代价的……传统的理解和故障排除生产环境的方法在这个新世界中已经行不通了。”\n\n![Cynefin 模型](cynfin.jpg)\n\n*Cynefin 模型。来源：维基百科*\n\nHodgson 使用[Cynefin 模型](https:\/\/en.wikipedia.org\/wiki\/Cynefin_framework)来说明软件架构过去是复杂的，因为有足够的经验，人们可以理解故障排除和解决方案之间的因果关系。\n\n他认为，分布式微服务架构是复杂的，即使经验丰富的人对根本原因以及如何进行故障排除也只有“有限的直觉”。他们必须花更多时间通过可观测性数据提出问题和回答问题，最终假设可能出错的原因。\n\n如果我们同意 Hodgson 的前提 - Kubernetes 本质上是复杂的，并且在响应之前需要花费更多的时间分析问题，那么与 Kubernetes 一起工作的工程师学会了哪些问题最重要，然后用可观测性数据回答，以进行最佳的下一步行动，似乎是至关重要的。\n\n这正是新一代以 AI 驱动的故障排除平台所提供的智慧。\n\n## Kubernetes 故障排除的两种路径\n\n多年来，像 OpenAI 这样的公司一直在根据 Stack Overflow、Reddit 等公开数据进行抓取和训练模型，这意味着这些 AI 模型可以访问大量的系统和应用知识，包括 Kubernetes。还有一些人意识到组织的可观测性数据是训练 AI\/ML 模型分析新场景的宝贵资源。\n\n他们都在问同一个问题：我们如何利用关于 Kubernetes 的现有数据来简化搜索最佳解决方案的过程？他们正在构建的产品采取非常不同的路径。\n\n### 第一种：增强操作员的分析工作\n\n这些工具自动化和简化对公开在线发布的大量故障排除知识的访问。它们不会取代进行适当故障排除或[根本原因分析](https:\/\/aws.amazon.com\/opensearch-service\/resources\/root-cause-analysis\/)（RCA）所需的人类直觉和创造力，而是有条不紊地自动化操作员查找相关信息的方式。\n\n例如，如果一个刚接触 Kubernetes 的开发人员在运行\u0060kubectl get pods\u0060时发现\u0060CrashLoopBackOff\u0060状态导致他们无法部署应用程序，他们可以查询一个 AI 驱动的工具以获得建议，比如运行\u0060kubectl describe $POD\u0060或\u0060kubectl logs $POD\u0060。这些步骤可能会进一步引导开发人员使用\u0060kubectl describe $DEPLOYMENT\u0060来调查相关的部署情况。\n\n在[Botkube](https:\/\/botkube.io\/)，我们对使用 AI 在大量故障排除智慧的基础上自动化这个来回查询的概念非常感兴趣。用户应该能够直接在 Slack 中提问，如“我如何排除这个无法正常工作的服务？”并收到 ChatGPT 撰写的回答。在一次公司范围的黑客马拉松活动中，我们着手实施这一概念，为我们的协作故障排除平台构建了一个新的插件。\n\n通过[Doctor](https:\/\/botkube.io\/blog\/use-chatgpt-to-troubleshoot-kubernetes-errors-with-botkubes-doctor)，您可以利用大量的故障排除知识，通过 Botkube 作为您的 Kubernetes 集群和消息\/协作平台之间的桥梁，无需在 Stack Overflow 或 Google 搜索广告中漫游，这对于新手 Kubernetes 开发人员和操作员特别有用。\n\n该插件还通过生成一个带有**获取帮助**按钮的 Slack 消息进一步自动化，用于任何错误或异常，然后查询 ChatGPT 以获取可行的解决方案和下一步操作。您甚至可以将 Doctor 插件的结果导入其他操作或集成，以简化您主动使用现有广泛的 Kubernetes 故障排除知识来更直观地调试和感知问题的方式。\n\n### 第二种：将操作员从故障排除中排除\n\n这些工具不关心公开知识的泛滥。如果它们可以基于实际的可观测性数据训练通用的 AI\/ML 模型，然后根据您的特定架构进行微调，它们可以试图完全剔除人为操作员在根本原因分析和故障修复中的作用。\n\n[Causely](https:\/\/www.causely.io\/platform\/causely-for-kubernetes-applications\/)就是这样一家初创公司，他们并不回避使用 AI 来“消除人为故障排除”的愿景。该平台连接到您现有的可观测性数据，并处理它们以微调因果关系模型，理论上可直接进行修复步骤 - 无需探测或使用\u0060kubectl\u0060。\n\n如果说有时候有一个 Kubernetes 神灵听起来很诱人，那我可能会撒谎，但我对像 Causely 这样的工具夺走运维工作并不担心。我担心的是在 Causely 引领的未来中，我们宝贵的故障排除知识会发生什么。\n\n### 这两种路径之间的差距：数据\n\n我不是在为“人工智能将取代所有 DevOps 工作”发表言论。我们已经读过太多这样的末日场景，适用于每个小众和行业。我更关心这两种路径之间的差距：用于训练和回答问题或呈现结果的数据是什么？\n\n第一种路径通常使用现有的公开数据。尽管有关 AI 公司爬取这些站点进行训练数据的担忧-Reddit 和 Twitter，但这些数据的开放性仍然提供了一个激励循环，以保持开发人员和工程师继续在 Reddit、Stack Overflow 和其他平台上共享知识的持续泛滥。\n\n云原生社区通常也倾向于共享技术知识，认同共享技术知识和一个“涨潮（Kubernetes 故障排除技巧的涨潮）抬高所有船（压力巨大的 Kubernetes 工程师）”的想法。\n\n第二条路径看起来更为暗淡。随着以 AI 驱动的 DevOps 平台的兴起，越来越多的故障排除知识被锁定在这些仪表板和驱动平台的专有 AI 模型中。我们都同意，Kubernetes 基础架构将继续变得更加复杂，而不是更简单，这意味着随着时间的推移，我们对节点、Pod 和容器之间发生的情况的理解将变得更少。\n\n当我们停止互相分析问题和感知解决方案时，我们变得依赖于平台。这对每个人来说都是一条失败的道路，除了平台之外。\n\n### 我们如何不失去（或失去得更少）？\n\n我们能做的最好的事情是继续在线上发布关于我们在 Kubernetes 和其他领域的故障排除经验的惊人内容，比如“[关于故障排除 Kubernetes 部署的视觉指南](https:\/\/learnk8s.io\/troubleshooting-deployments)”；通过游戏化创造教育性应用程序，比如[SadServers](https:\/\/sadservers.com\/)；在故障排除系统时采取我们最喜欢的第一步，比如“[为什么在排除未知机器问题时我通常首先运行‘w’](https:\/\/rachelbythebay.com\/w\/2018\/03\/26\/w\/)”；并进行详细的事后分析，详细描述了探测、感知和应对潜在灾难性情况的压力故事，比如[2023 年 7 月的 Tarsnap 故障](https:\/\/mail.tarsnap.com\/tarsnap-announce\/msg00050.html)。\n\n我们还可以超越技术解决方案，比如讨论我们如何在紧张的故障排除场景中管理和支持同事，或者在组织范围内建立对可观测性的一致认识。\n\n尽管它们目前面临困境，但 Stack Overflow 和 Reddit 将继续是讨论故障排除和寻求答案的可靠渠道。如果它们最终与 Usenet 和 Experts Exchange 齐名，它们可能会被其他可公开获得的替代品所取代。\n\n无论何时何地以何种方式发生，我希望您能加入我们在 Botkube 和全新的 Doctor 插件中，为在 Kubernetes 中协作解决复杂问题构建新的渠道。\n\n无论 AI 驱动的 DevOps 平台是否继续基于抓取的公共 Kubernetes 数据训练新模型，只要我们不自愿地将好奇心、冒险精神和解决问题的能力全部放入这些黑匣子中，就会始终有一条新路径，让宝贵的故障排除知识源源不断地流动。\n', '\/trans\/can-chatgpt-save-collective-kubernetes-troubleshooting\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文讨论了在 Kubernetes 故障排除中的两种路径：一种是增强操作员的分析工作，通过自动化和简化对故障排除知识的访问来提供帮助；另一种是将操作员从故障排除中排除，通过使用 AI/ML 模型和可观测性数据来自动化故障修复。同时强调了数据的重要性，以及继续共享故障排除经验和建立对可观测性的一致认识的必要性。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/is-it-too-early-to-leverage-ai-for-webassembly/">[译] 将 AI 应用于 WebAssembly 还为时过早吗？</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/09/07</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/%e5%85%b6%e4%bb%96"> 
             其他
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://thenewstack.io/is-it-too-early-to-leverage-ai-for-webassembly/" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('将 AI 应用于 WebAssembly 还为时过早吗？', 'Fermyon Technologies 认为，将 AI 应用于 WebAssembly 并不为时过早。', '\n摘要：Fermyon Technologies 认为，将 AI 应用于 WebAssembly 并不为时过早。WebAssembly 为在服务器上运行推理提供了坚实的基础，而且在许多不同的环境中，如浏览器和物联网设备等，通过将这些工作负载移动到终端用户设备上，可以消除延迟并避免将数据发送到集中式服务器，同时能够在边缘发现的多种异构设备上运行。Fermyon Serverless AI 通过提供超过 100 倍于其他按需 AI 基础设施服务的亚秒冷启动时间来解决了企业级 AI 应用程序成本高的问题。这是一种共生关系。\n\n---\n\n人工智能及其在 IT、软件开发和运营方面的应用刚开始发挥作用，预示着人类角色将如何在近期和长期内演变，特别是在较小的规模上，WebAssembly 代表着一种正在引起重大关注的技术，同时证明了其可行性，但成功的商业模型尚未实现，主要是由于最终端点的缺乏标准化。与此同时，至少有一家供应商 Fermyon 认为，在这个阶段应用 AI 于 WebAssembly 并不为时过早。\n\n那么，AI 如何潜在地帮助 Wasm 的开发和采用，这是否为时过早？正如 VMware CTO 办公室的高级工程师 Angel M De Miguel Meana 所指出的那样，自从 ChatGPT 推出以来，AI 生态系统已经发生了巨大的变化，WebAssembly 为在服务器上运行推理提供了坚实的基础，而且在许多不同的环境中，如浏览器和物联网设备等，通过将这些工作负载移动到终端用户设备上，可以消除延迟并避免将数据发送到集中式服务器，同时能够在边缘发现的多种异构设备上运行。由于 Wasm 生态系统仍在兴起，因此在早期阶段集成 AI 将有助于推动新的和现有的与 AI 相关的标准。这是一种共生关系。\n\n## 完美的匹配\n\nFermyon Technologies 的联合创始人兼首席执行官 Matt Butcher 告诉 The New Stack：“我们成立 Fermyon 的目标是打造下一代无服务器平台。AI 显然是这一下一代的一部分。在我们的行业中，我们经常看到革命性的技术一起成长：Java 和 Web、云和微服务、Docker 和 Kubernetes。WebAssembly 和 AI 是一对完美的组合。我看到它们一起成长（并变老）。”\n\n“烘焙”AI 模型，如 LLM（大型语言模型）或转换器，到 WebAssembly 运行时中，是加速采用 WebAssembly 的逻辑下一步，Enterprise Management Associates (EMA) 的分析师 Torsten Volk 告诉 The New Stack。与调用诸如通过 API 的数据库服务类似，编译 WebAssembly 应用程序（二进制文件）可以将其 API 请求发送到 WebAssembly 运行时，该运行时将该调用中继到 AI 模型并将模型响应返回给发起者，Volk 说。\n\n“一旦我们有一个提供开发人员一个标准 API 的通用组件模型（CCM），访问数据库、AI 模型、GPU、消息传递、身份验证等，这些 API 请求将变得非常强大。CCM 将让开发人员编写相同的代码，在数据中心、云甚至边缘位置的任何类型的服务器上与 AI 模型（例如 GPT 或 Llama）进行通信，只要该服务器拥有足够的硬件资源可用，”Volk 说。“这一切都归结为关键问题，即产业参与者何时会就 CCM 达成一致。同时，WebAssembly 云（如 Fermyon）可以利用 WebAssembly 使 AI 模型在其自己的云基础设施中具有可移植性和可扩展性，无需 CCM，并将一些节省成本传递给客户。”\n\n## 解决问题\n\n同时，Fermyon 认为，在这个阶段应用 AI 于 WebAssembly 并不为时过早。正如 Butcher 所指出的那样，负责在 LLM（如 LLaMA2）上构建和运行企业 AI 应用程序的开发人员面临着 100 倍计算成本的挑战，即每小时 32 美元及以上的 GPU 访问费用。或者，他们可以使用按需服务，但是启动时间却非常慢。这使得以实惠的方式提供企业级 AI 应用程序变得不切实际。\n\nFermyon Serverless AI 通过提供超过 100 倍于其他按需 AI 基础设施服务的亚秒冷启动时间来解决了这个问题，Butcher 说。这一“突破”得益于驱动 Fermyon Cloud 的服务器 WebAssembly 技术，该技术被架构为亚毫秒冷启动和高容量时间分片的计算实例，已被证明可以将计算密度提高 30 倍。“将此运行时配置文件扩展到 GPU 将使 Fermyon Cloud 成为最快的 AI 推理基础设施服务，”Butcher 说。\n\nVolk 说，这样的推理服务“非常有趣”，因为典型的 WebAssembly 应用程序仅包含几兆字节，而 AI 模型的大小要大得多。这意味着它们不会像传统的 WebAssembly 应用程序那样启动得那么快。“我认为 Fermyon 已经想出了如何使用时间分片为 WebAssembly 应用程序提供 GPU 访问的方法，以便所有这些应用程序都可以通过其 WebAssembly 运行时保留一些时间片来获取所需的 GPU 资源”，Volk 说。“这意味着很多应用程序可以共享一小部分昂贵的 GPU，以按需为其用户提供服务。这有点像分时共享，但不需要强制参加午餐时间的演示。”\n\n使用 Spin 入门。\n\n!https:\/\/prod-files-secure.s3.us-west-2.amazonaws.com\/86575c70-5cc9-4b3e-bee7-d1bb14ba20e3\/6bf78916-e34c-4051-86a7-52145cdc372a\/4a27b287-capture-decran-2023-09-05-192118.png\n\n那么，用户如何与 Serverless AI 交互？Fermyon 的 Serverless AI 没有 REST API 或外部服务，它仅构建在 Fermyon 的 Spin 本地和 Fermyon Cloud 中，Butcher 解释说。“在您的代码的任何位置，您都可以将提示传递到 Serverless AI 并获得响应。在这个第一个测试版中，我们包括 LLaMa2 的聊天模型和最近宣布的 Code Llama 代码生成模型，”Butcher 说。“因此，无论您是在总结文本、实现自己的聊天机器人还是编写后端代码生成器，Serverless AI 都可以满足您的需求。我们的目标是使 AI 变得简单，使开发人员可以立即开始利用它来构建新的令人瞩目的无服务器应用程序。”\n\n## 重要意义\n\n使用 WebAssembly 来运行工作负载，可以使用 Fermyon Serverless AI 将“GPU 的一小部分”分配给用户应用程序，以“及时”执行 AI 操作，Fermyon CTO 和联合创始人 Radu Matei 在一篇博客文章中写道。 “当操作完成时，我们将该 GPU 的一小部分分配给队列中的另一个应用程序，”Matei 写道。“由于 Fermyon Cloud 中的启动时间为毫秒级，因此我们可以在分配给 GPU 的用户应用程序之间快速切换。如果所有 GPU 分数都在忙于计算数据，我们将在下一个可用的应用程序之前将传入的应用程序排队。”\n\n这有两个重大的影响，Matei 写道。首先，用户不必等待虚拟机或容器启动并附加到 GPU 上。此外，“我们可以实现更高的资源利用率和效率，”Matei 写道。\n\nFermyon 传达的 Serverless AI 的具体特点包括：\n\n- 这是一款开发人员工具和托管服务，专为使用开源 LLM 进行 AI 推理的无服务器应用程序而设计。\n- 由于我们的核心 WebAssembly 技术，我们的冷启动时间比竞争对手快 100 倍，从几分钟缩短到不到一秒。这使我们能够在相同的时间内（并且使用相同的硬件）执行数百个应用程序（二进制文件），而今天的服务用于运行一个。\n- 我们为使用 Spin 构建和运行 AI 应用程序提供了本地开发体验，然后将其部署到 Fermyon Cloud 中，以高性能的方式以其他解决方案的一小部分成本提供服务。\n- Fermyon Cloud 使用 AI 级别的 GPU 处理每个请求。由于我们的快速启动和高效的时间共享，我们可以在数百个应用程序之间共享单个 GPU。\n- 我们正在推出免费的私人测试版。\n\n## 大希望\n\n然而，在 Wasm 和 AI 同时达到潜力之前，还有很长的路要走。在 WasmCon 2023 上，Second State 的 CEO 兼联合创始人 Michael Yuan 和 Wasm 的运行时项目以及 WasmEdge 的讨论了一些正在进行的工作。他在与 De Miguel Meana 的谈话中涵盖了这个话题，“开始使用 AI 和 WebAssembly”在 WasmCon 2023 上。\n\n“在这个领域（AI 和 Wasm）需要做很多生态系统工作。例如，仅拥有推理是不够的，”Yuan 说。“现在的百万美元问题是，当您拥有图像和文本时，如何将其转换为一系列数字，然后在推理之后如何将这些数字转换回可用的格式？”\n\n预处理和后处理是 Python 今天最大的优势之一，这得益于为这些任务提供的众多库，Yuan 说。将这些预处理和后处理函数合并到 Rust 函数中将是有益的，但需要社区更多的努力来支持其他模块。“这个生态系统有很大的增长潜力，”Yuan 说。\n', '\/trans\/is-it-too-early-to-leverage-ai-for-webassembly\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">Fermyon Technologies 认为，将 AI 应用于 WebAssembly 并不为时过早。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/chatgpt-chrome-extensions/">免费的 ChatGPT 浏览器插件工具推荐 | 亲测有效</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/04/26</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/ai"> 
             AI
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('免费的 ChatGPT 浏览器插件工具推荐 | 亲测有效', '本文整理了一些可以帮助你高效使用 ChatGPT 的浏览器插件，经过本人实测有效，推荐大家。', '\nChatGPT 是一个强大的工具，可以根据提示生成文本响应。然而，使用浏览器版本可能会很繁琐和耗时。幸运的是，有几个浏览器扩展可以帮助您更有效地使用 ChatGPT。在本文中，我们将讨论几个我个人测试并推荐的最有用的 ChatGPT 浏览器扩展。这些插件都是完全免费的，不存在订阅或者后期收费选项，大家可以放心使用。\n\n下图展示了安装了插件的 Chrome 浏览器中的 ChatGPT 页面。\n\n![安装了 Chrome 插件的 ChatGPT 页面](chrome.jpg)\n\n## ChatGPT Prompt Genius\n\nGitHub:\u003chttps:\/\/github.com\/benf2004\/ChatGPT-Prompt-Genius\u003e\n\n这个项目是一个多功能的 ChatGPT 浏览器扩展，它可以帮助你发现、分享、导入和使用最好的 ChatGPT 提示。你也可以把你的聊天记录保存在本地，方便以后查看和参考。你可以使用扩展的提示模板功能，轻松地找到并添加提示到你的收藏。你可以在 ChatGPT 页面上搜索、分类和选择提示，找到有创意和有用的方式使用 ChatGPT。还可以添加一些主题，比如短信、温馨的壁炉和黑客。\n\n## ChatGPT for Google\n\n在搜索引擎结果中同时显示 ChatGPT 的回答，功能点如下：\n\n- 支持所有主流的搜索引擎\n- 在获得搜索结果后可直接开始聊天\n- 支持 OpenAI 官方 API\n- 从插件弹窗里快速使用 ChatGPT\n- 支持 Markdown 渲染\n- 支持代码高亮\n- 支持深色模式\n- 可自定义 ChatGPT 触发模式\n\n你可以在 [Chrome 网上应用商店](https:\/\/chrome.google.com\/webstore\/detail\/chatgpt-for-google\/jgjaeacdkonaoafenlfkkkmbaopkbilf) 下载。\n\n## KeepChatGPT\n\nGitHub:\u003chttps:\/\/github.com\/xcanwin\/KeepChatGPT\u003e\n\n让我们在使用 ChatGPT 过程中更高效、更顺畅，完美解决 ChatGPT 网络错误，不再频繁地刷新网页，足足省去 10 个多余的步骤。还可以取消后台监管审计。\n\n解决了这几类报错：\n\n1. NetworkError when attempting to fetch resource.\n2. Something went wrong. If this issue persists please contact us through our help center at help.openai.com .\n3. This content may violate our content policy.\n4. Conversation not found.\n\n## TalkBerry\n\n这个 Chrome 扩展的主要内容是让你可以用语音和 ChatGPT 交流，而不需要打字。它的功能有：\n\n- 选择你想要聊天的语言，支持多种语言。\n- 点击麦克风按钮，开始对话，ChatGPT 会用语音回复你。\n- 用语音命令控制 ChatGPT，比如说“停止”或“继续”。\n- 在设置菜单中调整语音识别和文本转语音的选项。\n\n这个扩展可以让你更方便地使用 ChatGPT，也可以帮助你学习外语或提高口语能力。它是一个免费和开源的项目，你可以在 Chrome 网上应用商店 下载。\n\n需要注意的是，你无法关闭用语音朗读，除非你卸载掉该扩展。\n\n## WebChatGPT\n\n这个免费的扩展程序将相关的网络结果添加到您对 ChatGPT 的提示中，以获得更准确和最新的对话。\n\n- 为您的查询获取网络结果\n- 从任何 URL 中提取网页文本\n- 添加和使用提示模板\n- 使用 Duckduckgo bangs 从数千个网站中获取搜索结果\n\n当你不想使用时，也可以在 ChatGPT 页面上随时关闭它。你可以在 [Chrome 网上应用商店](https:\/\/chrome.google.com\/webstore\/detail\/webchatgpt-chatgpt-with-i\/lpfemeioodjbpieminkklglpmhlngfcn?hl=zh-CN) 下载该扩展。\n\n## 总结\n\n这几个 ChatGPT 浏览器扩展可以帮助您更有效地使用 ChatGPT。无论您需要更便捷的界面、带有有用功能的侧边栏，都有一款扩展可以帮助。我建议尝试每个扩展，以确定哪个最适合您的需求。有了这些工具，您可以改善您的 ChatGPT 体验，快速轻松地生成高质量的文本响应。以后再发现其他更好的插件，笔者会在本文中更新，也欢迎读者朋友们有推荐的插件可以在评论中留言。\n', '\/blog\/chatgpt-chrome-extensions\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文整理了一些可以帮助你高效使用 ChatGPT 的浏览器插件，经过本人实测有效，推荐大家。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/hello-google-bard/">体验过 Google Bard 之后我有些话要说</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/03/27</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/ai"> 
             AI
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('体验过 Google Bard 之后我有些话要说', '这篇文章介绍了 Google Bard，它是一个由 Google 开发的生成式 AI 工具，可以与用户合作，帮助他们更有效地思考和创造。文章还比较了 Bing Chat、OpenAI ChatGPT 和 Google Bard 的不同，以及它们对同一个问题的回答。笔者认为必应聊天的回答最好。', '\n上周我申请加入 Google Bard waitlist，没想到这么快今天就收到了试用邀请，比起其他的生成式 AI 聊天工具申请试用要几个周甚至几个月才能通过要快的多。\n\n## Google Bard 简介\n\nGoogle Bard 是一个早期的实验性项目，它让你可以和生成式 AI 合作。它是由一个大型语言模型（LLM）驱动的，具体来说是 LaMDA 的一个轻量化和优化版本。你可以用 Google Bard 来提高你的效率，加速你的想法，激发你的好奇心。你可以向 Google Bard 提出各种问题，它会尝试给你有用的回答和建议。例如，你可以问 Google Bard 如何达到今年读更多书的目标，如何用简单的语言解释量子物理，或者如何为一篇博客文章写一个大纲。\n\nGoogle Bard 目前仅对英国和美国用户开放，且只支持英文。你可以在[这里](https:\/\/bard.google.com\/)申请加入 Google Bard 体验的 Waitlist。在申请通过之后你会收到一封告知邮件如图 1 所示，然后就可以去 [bard.google.com](https:\/\/bard.google.com\/) 体验了。\n\n![图 1：Google Bard 体验资格通过邮件](bard-email.jpg)\n\nGoogle Bard 的用户界面如图 2 所示。\n\n![图 2：Google Bard 的用户界面](bard-ui.jpg)\n\n## 测试：马云去哪了？\n\n下面我就同一个问题向 ChatGPT、必应聊天、Google Bard 提问——”Where is Jack Ma now?“，它们的回答如图 3 所示。\n\n![图 3：“马云去哪了？”在三种工具中的回答对比](chatgpt-vs-bing-vs-bard.jpg)\n\n你觉得哪个回答更好呢？我觉得是必应聊天。\n\n## Google Bard vs Bing Chat vs ChatGPT\n\n前段时间我也体验了新必应的聊天，见[体验新必应——聊天式的搜索引擎辅助工具](\/blog\/new-bing-chat\/)。\n\n正好使用生成式 AI 工具已经有好多个月了，三样工具我都用过了，我在下表中简单比较一下它们。\n\n| 技术        | 开发者 | 应用场景                               | 主要功能                                               | 特色                                                         | 缺点                                                         |\n| ----------- | ------ | -------------------------------------- | ------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| Google Bard | Google | 帮助用户更有效地思考和创造             | 回答问题和提供建议                                     | 同时提供三个回答供用户选择                                   | 界面体验一般，缺乏个性                                       |\n| Bing Chat   | 微软   | 提供聊天交互式服务，聊天式搜索         | 回答常见问题，帮助预订机票或查找餐厅                   | 增加了引用来源，使得回答更可信；可检索互联网上的实时数据；提供联想问题可供用户追问 | 缺乏个性，数据来源不够广泛                                   |\n| ChatGPT     | OpenAI | 聊天交互、问题回答、文本摘要等多个领域 | 应用广泛，包括自然语言处理、信息检索、机器翻译、编程等 | 简单直接，更加人性化，提供开发者 API                         | 时常胡言乱语，数据只更新到 2021 年；服务不稳定，免费账户需要经常刷新才能使用 |\n\n## 总结\n\n这篇文章介绍了 Google Bard，它是一个由 Google 开发的生成式 AI 工具，可以与用户合作，帮助他们更有效地思考和创造。文章还比较了 Bing Chat、OpenAI ChatGPT 和 Google Bard 的不同，以及它们对同一个问题的回答。笔者认为必应聊天的回答最好。\n', '\/blog\/hello-google-bard\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">这篇文章介绍了 Google Bard，它是一个由 Google 开发的生成式 AI 工具，可以与用户合作，帮助他们更有效地思考和创造。文章还比较了 Bing Chat、OpenAI ChatGPT 和 Google Bard 的不同，以及它们对同一个问题的回答。笔者认为必应聊天的回答最好。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
          <div class="col-12">
 
 
 
 
 
 
 
 
 
 
 
 <nav aria-label="Page navigation">
   <ul class="pagination justify-content-center">
     
     
     
     
     
     
       
       
       
         
       
       
       
         <li class="page-item page-item active ">
           <a href="/tags/ai/" class="page-link">
             1
           </a>
         </li>
       
     
       
       
       
         
       
       
       
         <li class="page-item">
           <a href="/tags/ai/page/2/" class="page-link">
             2
           </a>
         </li>
       
     
     
     
     <li class="page-item">
       <a href="/tags/ai/page/2/" class="page-link">
         »
       </a>
     </li>
     
     
     
     <li class="page-item">
       <a class="page-link" href="/tags/ai/page/2/">
         »»
       </a>
     </li>
     
   </ul>
 </nav>
 
</div>

        </div>
      </div>
      <!-- sidebar -->
      <aside class="col-lg-4 order-1 order-lg-2 d-none d-sm-block">
          <div class="sidebar">
          <!-- categories -->
<div class="blog-categories mb-4">
  <p class="sidebar-title">
      专栏
  </p>
  
  
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
  
  <div class="bg-gray">
      
        <a href="/categories/istio" class="sidebar-item">
            <span>Istio</span>
            <span>(80)</span>
        </a>
      
        <a href="/categories/service-mesh" class="sidebar-item">
            <span>Service Mesh</span>
            <span>(42)</span>
        </a>
      
        <a href="/categories/kubernetes" class="sidebar-item">
            <span>Kubernetes</span>
            <span>(25)</span>
        </a>
      
        <a href="/categories/%e9%9a%8f%e7%ac%94" class="sidebar-item">
            <span>随笔</span>
            <span>(22)</span>
        </a>
      
        <a href="/categories/%e5%85%b6%e4%bb%96" class="sidebar-item">
            <span>其他</span>
            <span>(19)</span>
        </a>
      
        <a href="/categories/envoy" class="sidebar-item">
            <span>Envoy</span>
            <span>(17)</span>
        </a>
      
        <a href="/categories/%e4%b8%9a%e6%80%81" class="sidebar-item">
            <span>业态</span>
            <span>(17)</span>
        </a>
      
        <a href="/categories/%e4%ba%91%e5%8e%9f%e7%94%9f" class="sidebar-item">
            <span>云原生</span>
            <span>(14)</span>
        </a>
      
        <a href="/categories/ai" class="sidebar-item">
            <span>AI</span>
            <span>(9)</span>
        </a>
      
        <a href="/categories/%e5%ae%89%e5%85%a8" class="sidebar-item">
            <span>安全</span>
            <span>(9)</span>
        </a>
      
        <a href="/categories/%e5%bc%80%e6%ba%90" class="sidebar-item">
            <span>开源</span>
            <span>(9)</span>
        </a>
      
        <a href="/categories/%e6%97%85%e8%a1%8c" class="sidebar-item">
            <span>旅行</span>
            <span>(8)</span>
        </a>
      
        <a href="/categories/%e5%8f%af%e8%a7%82%e6%b5%8b%e6%80%a7" class="sidebar-item">
            <span>可观测性</span>
            <span>(5)</span>
        </a>
      
        <a href="/categories/%e5%b7%a5%e5%85%b7" class="sidebar-item">
            <span>工具</span>
            <span>(5)</span>
        </a>
  </div>
</div>

<div class="blog-categories mb-4">
  <p class="sidebar-title">
      资料
  </p>
  
  
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
  
  <div class="bg-gray">
      
        <a href="/categories/%e5%87%ba%e7%89%88%e7%89%a9" class="sidebar-item">
            <span>出版物</span>
            <span>(8)</span>
        </a>
      
        <a href="/categories/%e7%bf%bb%e8%af%91%e7%94%b5%e5%ad%90%e4%b9%a6" class="sidebar-item">
            <span>翻译电子书</span>
            <span>(8)</span>
        </a>
      
        <a href="/categories/%e7%bf%bb%e8%af%91%e6%96%87%e6%a1%a3" class="sidebar-item">
            <span>翻译文档</span>
            <span>(7)</span>
        </a>
      
        <a href="/categories/%e7%bf%bb%e8%af%91%e5%9b%be%e4%b9%a6" class="sidebar-item">
            <span>翻译图书</span>
            <span>(6)</span>
        </a>
      
        <a href="/categories/%e5%8e%9f%e5%88%9b%e5%9b%be%e4%b9%a6" class="sidebar-item">
            <span>原创图书</span>
            <span>(2)</span>
        </a>
      
        <a href="/categories/%e6%95%99%e7%a8%8b%e6%89%8b%e5%86%8c" class="sidebar-item">
            <span>教程手册</span>
            <span>(2)</span>
        </a>
  </div>
</div>





          </div>
      </aside>
      <!-- /sidebar -->
    </div>
  </div>
</section>




<footer>
  
  <div class="footer bg-footer section-sm border-bottom overlay ">
    <div class="container-xl">
      <div class="row">
        <div class="col col-xl-4 d-sm-none mb-2 mb-lg-0 d-xl-block d-none">
          
          <p class="h3 text-white mb-4 text-uppercase">联系</p>
          
          <ul class="list-unstyled">
            
            
            <li class="mb-4 text-color">微信公众号</li>
            
            
            <li class="mb-4"><img src="/images/servicemesher-wechat.webp" width="118px" height="118px" alt="footer image"></li>
            
            
            
          
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">博客</p>
          <ul class="list-unstyled">
            
            <li class="mb-3"><a class="text-color" href="/blog/migrate-to-istio-telemetry-api/">从 MeshConfig 迁移到 Istio Telemetry API：提升网格观测性和灵活性</a></li>
            
            <li class="mb-3"><a class="text-color" href="/blog/south-korea-trip/">韩国旅行回忆：首尔、釜山与仁川的真实体验</a></li>
            
            <li class="mb-3"><a class="text-color" href="/blog/istio-sidecar-vs-ambient-network-cost-performance/">Istio sidecar 和 ambient 模式的网络成本对比</a></li>
            
          </ul>
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">链接</p>
          <ul class="list-unstyled">
            
            <li class="mb-3">
              <a class="text-color" href="https://istio.io/latest/zh/" target="_blank" rel="noopener noreferrer">
                  Istio 服务网格
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://tetrate.io/?jimmysong" target="_blank" rel="noopener noreferrer">
                  Tetrate 公司
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://space.bilibili.com/515485124" target="_blank" rel="noopener noreferrer">
                  云原生学院|Bilibili
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="/awesome-cloud-native/" target="_blank" rel="noopener noreferrer">
                  云原生开源项目大全
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://cloudnative.to" target="_blank" rel="noopener noreferrer">
                  云原生社区（中国）
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
          </ul>
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">教程</p>
          <ul class="list-unstyled">
            
            <li class="mb-3">
              <a class="text-color" href="https://academy.tetrate.io/courses/envoy-fundamentals-zh" target="_blank" rel="noopener noreferrer">
                  Envoy 基础教程
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://academy.tetrate.io/courses/istio-fundamentals-zh" target="_blank" rel="noopener noreferrer">
                  Istio 基础教程
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="/book/kubernetes-handbook/" >
                  Kubernetes 基础教程
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="/book/envoy-made-simple/" >
                  简明 Envoy 教程
                  
              </a>
            </li>
            
          </ul>
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">通知</p>
          <ul class="list-unstyled">
            
            <li class="mb-3"><a class="text-color" href="/notice/nist-sp-800-233-service-mesh-proxy-models/">资料分享：云原生应用服务网格代理模型的威胁分析指南</a></li>
            
            <li class="mb-3"><a class="text-color" href="/notice/kubecon-china-2024-panel/">KubeCon China 2024（香港）</a></li>
            
            <li class="mb-3"><a class="text-color" href="/notice/website-revamp-notice/">网站改版通知</a></li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>

  
  <div class="copyright py-4 bg-footer overlay">
    <div class="container-xl">
      <div class="row">
        <div class="col-sm-6 text-sm-left text-center">
          <p class="mb-0 text-color">© 2017-2024 Jimmy Song 保留所有权利</p>
        </div>
        <div class="col-sm-6 text-sm-right text-center">
          <ul class="list-inline">
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="https://twitter.com/jimmysongio" target="_blank" title="Social link" rel="noopener noreferrer">
                    <i class="fa-brands fa-x-twitter text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="/contact/" >
                    <i class="fa-brands fa-weixin text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="https://github.com/rootsongjc" target="_blank" title="Social link" rel="noopener noreferrer">
                    <i class="fa-brands fa-github text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="https://linkedin.com/in/jimmysongio" target="_blank" title="Social link" rel="noopener noreferrer">
                    <i class="fa-brands fa-linkedin text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="mailto:rootsongjc@gmail.com" >
                    <i class="fa-solid fa-envelope text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="/blog/index.xml" >
                    <i class="fa-solid fa-rss text-white"></i>
              </a>
            </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>


<!-- JS Plugins -->

<script src="/plugins/popper/popper.min.js"></script>

<script src="/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/plugins/slick/slick.min.js"></script>

<script src="/plugins/filterizr/jquery.filterizr.min.js"></script>

<script src="/plugins/search/fuse.min.js"></script>

<script src="/plugins/search/mark.js"></script>

<script src="/plugins/hex_md5/hex_md5.js"></script>

<script src="/plugins/anchor/anchor.min.js"></script>

<script src="/plugins/tocbot/tocbot.min.js"></script>

<script src="/plugins/bigger-picture/bigger-picture.min.js"></script>


<!-- Main Script -->

<script src="/js/script.min.f94c22b1d478bfc9e2e0a7d954429e47b7e6d36edd423758482e04154ae1842e.js"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-ESY906ZWZ0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-ESY906ZWZ0');
</script>


<!-- Baidu analysis -->
<meta name="baidu-site-verification" content="g8IYR9SNLF" />










<script src="https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js"></script>










<script src="/js/wowchemy-search.min.7a37268e7bbe4a9160c2e4c33b749816.js" type="module"></script>
<script id="search-hit-fuse-template" type="text/x-template">
  <div class="search-hit" id="summary-{{key}}">
    <div class="search-hit-content border-bottom">
      <div class="search-hit-name">
        <div class='search-hit-link'><a href="{{relpermalink}}">{{title}}</a></div>
        <div class="search-hit-metadata d-flex">
            <span class="mr-1"><i class="fa-regular fa-calendar mr-1"></i>{{date}}</span>
            <span class="mr-1"><i class="fa-regular fa-folder-open mr-1"></i>{{section}}</span>
            <span class="d-sm-block d-none"><i class="fa-solid fa-link mr-1"></i>{{relpermalink}}</span>
        </div>
        <div class="search-hit-description">{{snippet}}</div>
      </div>
    </div>
  </div>
</script>



    </body>
</html>
