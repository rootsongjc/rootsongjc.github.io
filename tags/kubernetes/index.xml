<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy Song – Kubernetes</title>
    <link>https://jimmysong.io/tags/kubernetes/</link>
    <description>Recent content in Kubernetes on Jimmy Song</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <managingEditor>rootsongjc@gmail.com (Jimmy Song)</managingEditor>
    <webMaster>rootsongjc@gmail.com (Jimmy Song)</webMaster>
    <lastBuildDate>Thu, 22 Aug 2024 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="https://jimmysong.io/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    
    
      
         
        
                                                         
                                                         
                           
    <item>
      <title>如何实现无 Pod 的 Kubernetes 和 Istio 部署</title>
      <link>https://jimmysong.io/trans/podless-kubernetes-istio/</link>
      <pubDate>Tue, 30 Jul 2024 10:58:54 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/podless-kubernetes-istio/</guid>
      <description>
        
        
        &lt;p&gt;Kubernetes 经常被批评（有些不公平）操作起来过于复杂，促使大多数人依赖托管服务。然而，&lt;a href=&#34;https://k3s.io/&#34; title=&#34;&amp;lt;code&amp;gt;k3s&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;k3s&lt;/code&gt;&lt;/a&gt; 某种程度上颠覆了这一点，将完整的 Kubernetes 发行版打包成一个二进制文件。这非常方便，特别是在物联网等小型环境中运行时；虽然隔离组件对非常大规模、先进的部署有好处，但对较小的环境来说，操作微服务可能只是一种负担——这正是 &lt;a href=&#34;https://blog.christianposta.com/microservices/istio-as-an-example-of-when-not-to-do-microservices/&#34; title=&#34;Istio 多年前选择重构为更单体架构的原因&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 多年前选择重构为更单体架构的原因&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;然而，它还是没有那么“精简”。在一个空集群中运行 &lt;code&gt;k3d cluster create test&lt;/code&gt; 后，我们会在集群中看到各种 pod：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl get pods --all-namespaces
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAMESPACE     NAME                                      READY   STATUS     RESTARTS  AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   local-path-provisioner-6c86858495-gc9jq   1/1     Running    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;         2m18s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   coredns-6799fbcd5-pdf4b                   1/1     Running    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;         2m18s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   helm-install-traefik-crd-cp9s2            0/1     Completed  &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;         2m18s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   helm-install-traefik-pch7c                0/1     Completed  &lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;         2m18s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   traefik-f4564c4f4-q4lkj                   1/1     Running    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;         2m8s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   metrics-server-54fd9b65b-d69w6            1/1     Running    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;         2m18s
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-system   svclb-traefik-58c5bb65-sq54b              2/2     Running    &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;         2m8s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/k3d-io/k3d/&#34; title=&#34;&amp;lt;code&amp;gt;k3d&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;k3d&lt;/code&gt;&lt;/a&gt; 是一个方便的工具，可以在 Docker 内部部署 &lt;code&gt;k3s&lt;/code&gt;，便于测试。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是怎么回事？我们的“单二进制 Kubernetes”怎么变成了 6 个不同的容器？&lt;/p&gt;
&lt;p&gt;虽然 k3s 将许多组件（&lt;code&gt;kube-proxy&lt;/code&gt;、&lt;code&gt;flannel&lt;/code&gt;、&lt;code&gt;containerd&lt;/code&gt;、&lt;code&gt;kubelet&lt;/code&gt; 等）嵌入到一个二进制文件中，但其他组件则作为标准 pod 在集群中运行。&lt;/p&gt;
&lt;p&gt;此外，一旦我们部署了我们最喜欢的 &lt;a href=&#34;https://istio.io/&#34; title=&#34;服务网格&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;服务网格&lt;/a&gt;，我们将会有更多的 pod，使我们离没有 pod 的目标更远。&lt;/p&gt;
&lt;h2 id=&#34;没有-pod-的-kubernetes&#34;&gt;没有 pod 的 Kubernetes？&lt;/h2&gt;
&lt;p&gt;那么问题是——我们能否通过进一步推进 &lt;code&gt;k3s&lt;/code&gt; 的理念，将完整的集群功能嵌入到一个二进制文件中，来获得一个功能齐全的 Kubernetes 和 Istio 部署？&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;警告&lt;/strong&gt;：这些是实验性概念；绝不要在生产环境中尝试！&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先，我们可以直接去除一些不必要的组件，如 &lt;code&gt;servicelb&lt;/code&gt;（负载均衡服务需要）、&lt;code&gt;traefik&lt;/code&gt;（Ingress 需要）、&lt;code&gt;local-storage&lt;/code&gt;（PVC 需要）和 &lt;code&gt;metrics-server&lt;/code&gt;（&lt;code&gt;kubectl top&lt;/code&gt; 需要）。&lt;/p&gt;
&lt;p&gt;这就剩下 &lt;code&gt;coredns&lt;/code&gt; 和 Istio。&lt;/p&gt;
&lt;p&gt;如果我们追求极简，我们肯定会希望使用 Istio 的 &lt;a href=&#34;https://istio.io/latest/docs/ops/ambient/getting-started/&#34; title=&#34;ambient mode&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ambient mode&lt;/a&gt;，它完全不需要 sidecar。幸运的是，它开箱即用并且有完整的 &lt;a href=&#34;https://istio.io/latest/docs/ops/configuration/traffic-management/dns-proxy/&#34; title=&#34;DNS 支持&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DNS 支持&lt;/a&gt;。这让我们可以去掉 &lt;code&gt;coredns&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;这样一来，如果我们能运行 Istio ambient，就可以去掉 &lt;code&gt;kube-system&lt;/code&gt; 中的所有内容。这相对简单；难点在于不为 Istio 添加更多的 pod。&lt;/p&gt;
&lt;h2 id=&#34;嵌入-istio&#34;&gt;嵌入 Istio&lt;/h2&gt;
&lt;p&gt;通过 &lt;code&gt;k3s&lt;/code&gt; 的一个分支，我修改了它，使 Istio 本身嵌入到 &lt;code&gt;k3s&lt;/code&gt; 中。&lt;code&gt;k3s&lt;/code&gt; 可以作为服务器和/或代理运行。通常你会有 1 个服务器，每个其他节点作为代理运行。&lt;/p&gt;
&lt;p&gt;在 &lt;code&gt;server&lt;/code&gt; 上，我们希望运行 &lt;code&gt;Istiod&lt;/code&gt;（Istio 的控制平面）。在代理上，我们希望运行 &lt;code&gt;istio-cni&lt;/code&gt;（每个节点的控制平面）和 &lt;code&gt;ztunnel&lt;/code&gt;（每个节点的数据平面）。&lt;/p&gt;
&lt;p&gt;这三个组件都可以直接嵌入到 &lt;code&gt;k3s&lt;/code&gt; 中，只需一些工作！&lt;/p&gt;
&lt;p&gt;使用这个自定义构建，我们可以通过一些自定义配置启动一个新的 &lt;code&gt;k3d&lt;/code&gt; 集群，禁用我们不再需要的组件：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k3d.io/v1alpha5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Simple&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;podless&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;agents&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;options&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k3d&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;60s&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;disableLoadbalancer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;disableRollback&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k3s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;extraArgs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;arg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--&lt;span class=&#34;l&#34;&gt;disable-cloud-controller&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeFilters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;server:*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;arg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--&lt;span class=&#34;l&#34;&gt;disable-kube-proxy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeFilters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;server:*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;arg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--&lt;span class=&#34;l&#34;&gt;disable-network-policy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeFilters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;server:*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;arg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--&lt;span class=&#34;l&#34;&gt;disable-helm-controller&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeFilters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;server:*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;arg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;--&lt;span class=&#34;l&#34;&gt;disable=coredns,servicelb,traefik,local-storage,metrics-server&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodeFilters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;server:*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里我们禁用了上面看到的所有 pod，包括一些额外的。&lt;/p&gt;
&lt;p&gt;一个显著的例子是 &lt;code&gt;kube-proxy&lt;/code&gt;。像其他一些项目一样（如 &lt;a href=&#34;https://docs.cilium.io/en/stable/network/kubernetes/kubeproxy-free/&#34; title=&#34;Cilium&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cilium&lt;/a&gt;），Istio 的 &lt;code&gt;ztunnel&lt;/code&gt; 可以有效地替代大多数用例中的 &lt;code&gt;kube-proxy&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;无-pod-的服务网格&#34;&gt;无 pod 的服务网格&lt;/h2&gt;
&lt;p&gt;所有配置就绪后，我们的集群是什么样子？&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ kubectl get pods --all-namespaces
No resources found
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;到目前为止一切顺利&amp;hellip;.当然，什么都不运行很容易；真正的挑战是保持集群的功能。&lt;/p&gt;
&lt;p&gt;让我们部署一些应用程序 pod。再次强调，这些是集群中的唯一 pod：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ kubectl get pods --all-namespaces
NAMESPACE   NAME                     READY   STATUS    RESTARTS   AGE
default     shell-5fff89ccf5-98kgg   1/1     Running   0          19s
default     echo-66d88ff694-9qprp    1/1     Running   0          14s
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;然后我们可以发送流量：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ kubectl exec deploy/shell -- curl -s echo
RequestHeader=Accept:*/*
RequestHeader=User-Agent:curl/8.5.0
Hostname=echo-66d88ff694-9qprp
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;流量完全正常，包括服务流量（以前由 &lt;code&gt;kube-proxy&lt;/code&gt; 处理）和 DNS（以前由 &lt;code&gt;coredns&lt;/code&gt; 处理）。现在这些全部由 &lt;code&gt;ztunnel&lt;/code&gt; 处理，并且所有内容都通过安全的 mTLS 传输。&lt;/p&gt;
&lt;p&gt;除了 mTLS 加密，我们还可以基于 mTLS 身份应用策略。同样，这些都由 &lt;code&gt;ztunnel&lt;/code&gt; 执行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;security.istio.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AuthorizationPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;allow-default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;action&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ALLOW&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;echo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;source&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;cluster.local/ns/default/sa/shell&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;现在 &lt;code&gt;default&lt;/code&gt; 命名空间的流量被允许，但其他流量不被允许。我们可以通过从 &lt;code&gt;shell&lt;/code&gt; 发送流量以及我在 &lt;code&gt;other&lt;/code&gt; 命名空间中部署的新测试工作负载来验证这一点：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; deploy/shell -- curl -s &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;RequestHeader&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Accept:*/*
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;RequestHeader&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;User-Agent:curl/8.5.0
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nv&#34;&gt;Hostname&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;echo-66d88ff694-9qprp
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; deploy/shell -n other -- curl -s &lt;span class=&#34;nb&#34;&gt;echo&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nb&#34;&gt;command&lt;/span&gt; terminated with &lt;span class=&#34;nb&#34;&gt;exit&lt;/span&gt; code &lt;span class=&#34;m&#34;&gt;56&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;正如预期的那样，我们的其他应用程序被拒绝了！&lt;/p&gt;
&lt;p&gt;此外，如果我们愿意，我们可以将流量升级通过完整的 HTTP 代理（&lt;a href=&#34;https://istio.io/latest/docs/ops/ambient/architecture/&#34; title=&#34;&amp;amp;ldquo;waypoint&amp;amp;rdquo;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;waypoint&amp;rdquo;&lt;/a&gt;）：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ istioctl x waypoint apply --enroll-namespace
waypoint default/waypoint applied

$ kubectl get pods
NAME                        READY   STATUS    RESTARTS   AGE
echo-66d88ff694-czd65       1/1     Running  

 0          93m
shell-56bd5dbdbf-f4gh9      1/1     Running   0          93m
waypoint-7cd4dc789f-2s7z2   1/1     Running   0          41s

$ kubectl exec deploy/shell -- curl -s echo
RequestHeader=Accept:*/*
RequestHeader=User-Agent:curl/8.5.0
RequestHeader=X-Request-Id:18d72190-9caa-4162-8bc5-4c11518d7568
Hostname=echo-66d88ff694-czd65
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;现在我们的 waypoint 已经部署，所有到命名空间的流量会自动转发到它，在那里可以执行完整的 HTTP 策略。这里，我们可以看到 &lt;code&gt;X-Request-Id&lt;/code&gt; 被添加到我们的请求中，但我们还可以获得 &lt;a href=&#34;https://istio.io/latest/blog/2021/zero-config-istio/&#34; title=&#34;自动配置的其他功能&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自动配置的其他功能&lt;/a&gt;，以及更多 &lt;a href=&#34;https://istio.io/latest/docs/tasks/&#34; title=&#34;我们可以配置的内容&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我们可以配置的内容&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;最终，我们能够部署一个完整的 Kubernetes 集群和服务网格，所有基础设施组件嵌入到一个隐藏的节点二进制文件中——集群功能不需要 pod。&lt;/p&gt;
&lt;p&gt;这实际操作起来是否实用？不太实用。然而，这确实表明 Kubernetes/Istio 被认为过于臃肿和复杂的看法并不完全准确。&lt;/p&gt;
&lt;p&gt;它真的比典型的集群更简单吗？某种程度上是的……我们确实替换了两个组件（&lt;code&gt;kube-proxy&lt;/code&gt; 和 &lt;code&gt;coredns&lt;/code&gt;），但其余的我们基本上只是隐藏和打包。这显然不如完全替换有意义，但也不错。话虽如此，隐藏东西对 &lt;a href=&#34;https://twitter.com/wm/status/1577081662848241664&#34; title=&#34;社交媒体参与度&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;社交媒体参与度&lt;/a&gt; 有好处，而 &lt;code&gt;k3s&lt;/code&gt; 通过有效地隐藏和打包取得了巨大成功，因此显然提供了一些实实在在的好处。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>无需 Kubernetes 测试 Kubernetes 网络实现</title>
      <link>https://jimmysong.io/trans/ztunnel-testing/</link>
      <pubDate>Tue, 23 Jul 2024 18:06:32 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/ztunnel-testing/</guid>
      <description>
        
        
        &lt;p&gt;由于在开发过程中我&lt;a href=&#34;https://blog.howardjohn.info/posts/ideal-ci/&#34; title=&#34;真的不喜欢等待&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;真的不喜欢等待&lt;/a&gt;，所以在构建 Ztunnel（一个为 Istio 的新 &lt;a href=&#34;https://istio.io/latest/blog/2022/introducing-ambient-mesh/&#34; title=&#34;Ambient 模式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ambient 模式&lt;/a&gt;设计的底层网络代理）时，我的首要任务之一便是确保测试的快速进行（包括运行和编写测试），并且易于调试。&lt;/p&gt;
&lt;p&gt;这一任务颇为棘手，因为在大多数真实场景中，Ztunnel 高度依赖 Kubernetes。虽然它能够完全独立于 Kubernetes 运行，但许多关键代码路径的行为完全不同，使得仅通过这种方式进行测试变得不可行。&lt;/p&gt;
&lt;p&gt;下图为典型的 Ztunnel 部署架构：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/trans/ztunnel-testing/ztunnel-architecture.svg&#34; data-img=&#34;/trans/ztunnel-testing/ztunnel-architecture.svg&#34; alt=&#34;image&#34; data-caption=&#34;Ztunnel 架构概览&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Ztunnel 架构概览&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;在此架构中，用户将运行一个包含多个节点的 Kubernetes 集群。每个节点上都运行着一个 Ztunnel，配置了宿主机和每个 pod 的网络栈。&lt;/p&gt;
&lt;p&gt;此外，Ztunnel 实际上进入了每个 pod 的网络命名空间，并代表其发送/接收流量。这一点非常奇特且酷炫，但也大大增加了测试的难度！（&lt;a href=&#34;https://www.youtube.com/watch?v=cuMeEhpyH5s&#34; title=&#34;详细信息&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;详细信息&lt;/a&gt;）&lt;/p&gt;
&lt;h2 id=&#34;加速测试&#34;&gt;加速测试&lt;/h2&gt;
&lt;p&gt;启动完整的 Kubernetes 环境、重建镜像、部署到每个节点的过程非常缓慢且难以调试。&lt;/p&gt;
&lt;p&gt;黄金标准应该是将所有操作运行在一个简单的单一二进制文件中——仅需执行 &lt;code&gt;cargo test&lt;/code&gt;。这种方式避开了复杂的设置和缓慢的重建，并使调试变得轻而易举（当然，你可以将调试器连接到正在运行的 pod，但这很麻烦）。&lt;/p&gt;
&lt;h2 id=&#34;设置网络&#34;&gt;设置网络&lt;/h2&gt;
&lt;p&gt;如果我们去除无尽的抽象层，Kubernetes pod 实际上只是几个 Linux 命名空间和挂载的组合。Docker 在这方面管理得很好，&lt;a href=&#34;https://github.com/p8952/bocker&#34; title=&#34;bash&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bash&lt;/a&gt; 也可以。&lt;/p&gt;
&lt;p&gt;我们特别关注的是&lt;a href=&#34;https://man7.org/linux/man-pages/man7/network_namespaces.7.html&#34; title=&#34;网络命名空间&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;网络命名空间&lt;/a&gt;，它可以实现网络栈的隔离。每个 pod 都有自己的网络命名空间，通过各种机制连接，允许与同一节点上的其他 pod、其他节点以及外部目的地通信。&lt;/p&gt;
&lt;p&gt;好消息是创建网络命名空间非常简单。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ sudo ip netns add testing
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们的最终目标是设置一系列的网络命名空间，外观与我们在 Kubernetes 上的真实架构类似：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/trans/ztunnel-testing/ztunnel-network-namespaces.svg&#34; data-img=&#34;/trans/ztunnel-testing/ztunnel-network-namespaces.svg&#34; alt=&#34;image&#34; data-caption=&#34;所需的网络命名空间设置&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;所需的网络命名空间设置&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;在网络命名空间之间建立连接稍微复杂一些。像  &lt;a href=&#34;https://www.cni.dev/docs/cnitool/&#34; title=&#34;&amp;lt;code&amp;gt;cnitool&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;cnitool&lt;/code&gt;&lt;/a&gt; 这样的工具可以帮助我们完成（它实际上执行了一些 Kubernetes 环境中用于设置网络的相同逻辑，但作为 CLI 工具），但你也可以完全手动操作。我们选择了后者。&lt;/p&gt;
&lt;p&gt;最终，我们的设置如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;每个测试都拥有自己的网络命名空间，通过一个桥接设备（&lt;code&gt;br0&lt;/code&gt;）来促进节点之间的流量。&lt;/li&gt;
&lt;li&gt;每个节点配置了一个 &lt;code&gt;veth&lt;/code&gt; 设备。一端成为节点上的 &lt;code&gt;eth0&lt;/code&gt;，另一端连接到根命名空间中的 &lt;code&gt;br0&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;每个 pod 都配置了一个 &lt;code&gt;veth&lt;/code&gt; 设备。一端成为 pod 上的 &lt;code&gt;eth0&lt;/code&gt;，另一端位于节点网络命名空间中。&lt;/li&gt;
&lt;li&gt;为每个 pod 设置路由以将流量发送到节点。&lt;/li&gt;
&lt;li&gt;为每对节点设置路由，以实现跨节点流量。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/trans/ztunnel-testing/ztunnel-network-devices.svg&#34; data-img=&#34;/trans/ztunnel-testing/ztunnel-network-devices.svg&#34; alt=&#34;image&#34; data-caption=&#34;所需的网络连接设置&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;所需的网络连接设置&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;除了根命名空间/桥接设备外，这与许多现实世界中的 Kubernetes 集群的运行方式相同（在现实世界中，根命名空间是两台机器之间的物理网络）。&lt;/p&gt;
&lt;p&gt;你可以在&lt;a href=&#34;https://github.com/istio/ztunnel/blob/34fce85a6a2b2a85eb170a04096731e2ea4e0e9f/src/test_helpers/netns.rs#L194&#34; title=&#34;这里&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;找到所有细节。&lt;/p&gt;
&lt;h2 id=&#34;运行测试&#34;&gt;运行测试&lt;/h2&gt;
&lt;p&gt;一旦我们有了这些命名空间，我们仍然需要一种实际使用它们的方法。幸运的是，Linux 允许在运行时更改当前命名空间线程（这是接下来重要的内容）。这让我们建立了一个基本的帮助函数（真实的代码稍微更复杂）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;run_in_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;original_namespace&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_current_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;original_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;有了这个，我们可以轻松地从任意的“pods”或“nodes”执行代码。&lt;/p&gt;
&lt;p&gt;然而，我们仍然面临一个问题。我们的所有代码都运行在 &lt;a href=&#34;https://tokio.rs/&#34; title=&#34;tokio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;tokio&lt;/a&gt; 异步运行时中，它会根据需要将我们的各种任务安排到物理操作系统线程上（类似于 Go 运行时的工作方式）。由于网络命名空间是线程相关的，所以当我们的任务在线程之间跳转时，这一切都会崩溃。&lt;/p&gt;
&lt;p&gt;幸运的是，Rust 给了我们比 Go 更多的关于异步运行时的灵活性——我们可以同时拥有多个！借此，我们能够构建一个能够异步执行 &lt;code&gt;run_in_namespace&lt;/code&gt;。对于我们想要执行的每个函数，我们启动一个新线程并构建一个专用的单线程异步运行时来处理它：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;k&#34;&gt;async&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;async_run_in_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;async&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Fn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;thread&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;spawn&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;move&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run_in_namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;||&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rt&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tokio&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;runtime&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;Builder&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new_current_thread&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;enable_all&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;build&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;block_on&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;f&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;});&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们为每个命名空间运行一次这个函数，因此这里的开销是最小的。如果我们想要运行许多小函数，可以在顶层构建一个抽象来发送工作到线程以执行。&lt;/p&gt;
&lt;p&gt;我们需要的最后一件事是一种合理的方法来识别如何调用每个目的地。虽然它们都会被分配一个 IP（基于我们代码中的简单 IPAM 策略），但我们不希望每个测试都必须猜测 IP。为了处理这个问题，我们构建了一个简单的名称解析器。这就像 DNS，但简单得多：对于我们创建的每个“pod”，我们记录一个&lt;code&gt;name -&amp;gt; IP&lt;/code&gt;的映射，并允许查找 IP。&lt;/p&gt;
&lt;p&gt;将所有这些放在一起，一个简单的测试启动了 3 个 pods（客户端、服务器和 ztunnel）在一个单一节点上看起来像这样：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#[tokio::test]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;async&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;simple_test&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(){&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ztunnel&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;deploy_ztunnel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;no&#34;&gt;DEFAULT_NODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;await&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;workload_builder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;server&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;DEFAULT_NODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;register&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;await&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run_tcp_server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;server&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;workload_builder&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;client&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;no&#34;&gt;DEFAULT_NODE&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;register&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;await&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;run_tcp_client&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;manager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;resolve&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;server&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;?&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// ... some assertions here }
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;放弃权限&#34;&gt;放弃权限&lt;/h2&gt;
&lt;p&gt;上述设置效果很好，但也带来了一些问题。&lt;/p&gt;
&lt;p&gt;基本上设置的每一步都需要提升的 root 权限；这让简单的 &lt;code&gt;cargo test&lt;/code&gt; 案例的开箱即用变得乏味，通常也不可取。&lt;/p&gt;
&lt;p&gt;此外，这会在主机环境中污染大量的命名空间。虽然我们有一些清理过程，但这些并不是 100% 可靠，可能会导致悬挂的命名空间阻碍未来的执行。&lt;/p&gt;
&lt;p&gt;解决拥有太多命名空间的问题的方法？更多的命名空间！为此，我们需要的不仅仅是网络命名空间。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://man7.org/linux/man-pages/man7/user_namespaces.7.html&#34; title=&#34;用户命名空间&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;用户命名空间&lt;/a&gt; 允许我们实质上假装是 UID 0 (root)，同时实际上将其映射回我们原始的 UID。这里的力量在于，在该命名空间中，我们可以做一些本来需要 root 权限的事情——特别是创建新的网络命名空间。&lt;/p&gt;
&lt;p&gt;然而，我们不能做的一件事是修改主机-root 拥有的文件（这将是明显的权限违规）。尽管我们可能可以绕过它们，但我们在测试中使用的很多工具喜欢触摸 root 文件。这再次可以通过 &lt;a href=&#34;https://man7.org/linux/man-pages/man7/mount_namespaces.7.html&#34; title=&#34;mount 命名空间&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mount 命名空间&lt;/a&gt; 解决，它允许我们将我们拥有的文件绑定挂载到主机-root 拥有的文件上，而不会影响命名空间外的事物。&lt;/p&gt;
&lt;p&gt;将所有这些放在一起，我们有这样的东西：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;original_uid&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;get_uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// 首先，进入一个新的用户命名空间。unshare(CloneFlags::CLONE_NEWUSER).unwrap(); // 将用户命名空间中的 root 映射到我们原始的 UID File::create(&amp;#34;/proc/self/uid_map&amp;#34;).write(format!(&amp;#34;0 {original_uid} 1&amp;#34;)); // 设置一个新的网络命名空间 unshare(CloneFlags::CLONE_NEWNET).unwrap(); // 设置一个新的挂载命名空间 unshare(CloneFlags::CLONE_NEWNS).unwrap(); // 将一个文件夹在我们的每个测试目录中挂载到 /var/run/netns mount(tmp_dir.join(&amp;#34;netns&amp;#34;), &amp;#34;/var/run/netns&amp;#34;, MS_BIND); // 一个方便手动调试的好帮手信息，如果需要的话。let pid = get_pid(); eprintln!(&amp;#34;Starting test in {tmp_dir}. Debug with `sudo nsenter --mount --net -t {pid}`&amp;#34;);
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如上所述，一个技巧是，进入命名空间是按线程进行的。我们需要在生成任何额外线程之前设置这一点。&lt;/p&gt;
&lt;p&gt;Rust 实际上为我们提供了这样做的能力，但这意味着我们失去了 &lt;code&gt;#[tokio::test]&lt;/code&gt; 宏帮助。我们可以写自己的宏，但这有点痛苦。幸运的是，通过 &lt;a href=&#34;https://crates.io/crates/ctor&#34; title=&#34;链接器的花招&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;链接器的花招&lt;/a&gt; 我们可以迫使我们的代码在进程执行的非常早期运行。&lt;/p&gt;
&lt;p&gt;Go 中的类似方法也有效（请参见 &lt;a href=&#34;https://github.com/howardjohn/unshare-go&#34; title=&#34;我写的帮助库&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我写的帮助库&lt;/a&gt;），实际上在那里是必需的，因为设置必须在 Go 运行时启动之前完成（这通常在任何用户代码运行之前很久）。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;有了所有这些设备，一个完整的测试只需要大约 200 毫秒。一切都在一个单一进程中运行，使调试变得轻而易举。所有的测试也都是完全隔离的，因此可以完全并行运行测试（包括相同的测试，用于压力测试以消除测试缺陷）。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>探索 Kubernetes Ingress、Gateway API 与 Istio 的演进和转型</title>
      <link>https://jimmysong.io/blog/gateway-api-istio-ingress-evolution/</link>
      <pubDate>Tue, 02 Jul 2024 19:40:40 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/gateway-api-istio-ingress-evolution/</guid>
      <description>
        
        
        &lt;p&gt;随着 Istio 1.22 版本的发布，Istio API 已正式升级至 v1 版本，同期，Kubernetes Gateway API 也更新至 v1.1 版本。本篇文章旨在深入探索 Ingress API、Istio API 与 Kubernetes Gateway API 之间的联系与区别，并详述它们在现实应用中的选择及迁移策略。&lt;/p&gt;
&lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;之前，我曾撰写一篇文章，讨论了 &lt;a href=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/&#34; title=&#34;为何 Gateway API 是 Kubernetes 与服务网格入口中的未来方向&#34;&gt;为何 Gateway API 是 Kubernetes 与服务网格入口中的未来方向&lt;/a&gt;。文章中指出，作为 Kubernetes 的初始入口网关，Ingress 的资源模型由于过于简单，难以满足当下的可编程网络需求。作为其接班人，Gateway API 近年来发展迅速，获得了广泛支持，包括众多新兴的开源网关项目如 &lt;a href=&#34;https://gateway.envoyproxy.io&#34; title=&#34;Envoy Gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy Gateway&lt;/a&gt; 也选择基于 Gateway API 开发。此外，一些传统网关项目也开始适配 Gateway API，或通过 &lt;a href=&#34;https://github.com/kubernetes-sigs/ingress2gateway&#34; title=&#34;ingress2gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ingress2gateway&lt;/a&gt; 这样的工具进行迁移。&lt;/p&gt;
&lt;p&gt;Gateway API，作为 Kubernetes 入口网关的最新成果，通过角色划分来分离关注点，并支持跨 namespace，更适合多云环境。它整合了入口网关（南北向）与服务网格（东西向，集群内路由）的重叠功能，为云原生时代的统一流量管理提供了新的参考模型。&lt;/p&gt;
&lt;p&gt;Ingress API、Gateway API 与 Istio API 都能实现网关功能，它们之间具体有何联系与区别？本文将为你揭晓这一迷题，并提供 Kubernetes 环境中网关的选择和迁移策略。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中的流量管理&#34;&gt;Kubernetes 中的流量管理&lt;/h2&gt;
&lt;p&gt;随着微服务架构的广泛应用和日益增长的复杂性，Kubernetes 的流量管理工具也在不断演进以适应各种技术需求。Ingress API、Istio API 与 Kubernetes Gateway API 分别标志着这一演变的不同阶段。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ingress API&lt;/strong&gt; 提供了 Kubernetes 的基本流量管理功能，允许用户通过定义简单的路由规则（例如 HTTP 和 HTTPS）来管理外部访问集群内服务的流量。其设计虽简洁，但功能有限，主要适用于规模较小、结构较简单的应用场景。&lt;/p&gt;
&lt;p&gt;相比之下，&lt;strong&gt;Istio API&lt;/strong&gt; 作为服务网格的一部分，提供了一系列高级流量管理功能，如流量镜像、金丝雀发布和断路器，适合于需要复杂流量管理的大规模微服务架构。&lt;/p&gt;
&lt;p&gt;为了克服 Ingress API 的局限性并集成类似 Istio 的高级功能，&lt;strong&gt;Kubernetes Gateway API&lt;/strong&gt; 因应而生。它不仅在设计上提供了更高的灵活性和扩展性，还通过社区的广泛支持，成为连接传统 Ingress 实现和现代服务网格技术如 Istio 的桥梁，目前主流的开源网关都是基于 Gateway API 或已进行适配。&lt;/p&gt;
&lt;p&gt;以下表格概述了这三者的核心特点和推荐使用场景：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;API 名称&lt;/th&gt;
&lt;th&gt;对象类型&lt;/th&gt;
&lt;th&gt;状态&lt;/th&gt;
&lt;th&gt;推荐使用场景&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Ingress API&lt;/td&gt;
&lt;td&gt;&lt;code&gt;Ingress&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;稳定 (Kubernetes v1.19)&lt;/td&gt;
&lt;td&gt;适用于小规模和简单的应用场景，主要用于基本的路由配置&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Istio API&lt;/td&gt;
&lt;td&gt;&lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;Gateway&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;稳定 (Istio 1.22)&lt;/td&gt;
&lt;td&gt;适用于高度复杂的微服务架构，需细粒度控制和高级流量管理特性的场景&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Gateway API&lt;/td&gt;
&lt;td&gt;&lt;code&gt;HTTPRoute&lt;/code&gt;、&lt;code&gt;Gateway&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;稳定 (Gateway API v1.1)&lt;/td&gt;
&lt;td&gt;适用于新部署或现有部署，需提高灵活性和可扩展性的场景，特别是结合 Istio 使用&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/blog/2024/05/09/gateway-api-v1-1/&#34; title=&#34;Gateway API v1.1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway API v1.1&lt;/a&gt; 的推出，特别是其在提升与现有 Ingress 配置兼容性方面的改进，为用户提供了一个平稳的迁移途径，使从传统的 Ingress 解决方案向更现代的、功能更全面的 Gateway API 的过渡变得更为顺畅。&lt;/p&gt;
&lt;h2 id=&#34;从-ingress-迁移到-kubernetes-gateway-api&#34;&gt;从 Ingress 迁移到 Kubernetes Gateway API&lt;/h2&gt;
&lt;p&gt;若想从 Ingress 迁移到 Gateway API，请按以下步骤操作：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;理解关键差异&lt;/strong&gt;：与 Ingress 相比，Gateway API 引入了多种新的概念和资源类型，如 &lt;code&gt;Gateway&lt;/code&gt;、&lt;code&gt;HTTPRoute&lt;/code&gt; 和 &lt;code&gt;TLSRoute&lt;/code&gt;。这些资源提供了更多的配置选项和灵活性，请参阅 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/guides/&#34; title=&#34;Gateway API 文档&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway API 文档&lt;/a&gt;以了解其配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;配置入口点&lt;/strong&gt;：创建 &lt;code&gt;Gateway&lt;/code&gt; 资源配置，明确定义如何接收外部流量，包括配置协议、端口和 TLS 终端。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;映射旧资源&lt;/strong&gt;：将现有的 Ingress 资源映射到对应的 Gateway API 资源。例如，Ingress 中的 host 和 path 规则需要转换为 HTTPRoute 中的路由规则。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;测试与部署&lt;/strong&gt;：在正式迁移之前，在测试环境中验证新的 Gateway API 配置，确保所有流量路由正常，无安全漏洞。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为了简化迁移过程，你可以使用工具如 &lt;a href=&#34;https://github.com/kubernetes-sigs/ingress2gateway&#34; title=&#34;ingress2gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ingress2gateway&lt;/a&gt;，该工具能自动将 Ingress 配置转换为 Gateway API 格式。&lt;/p&gt;
&lt;h2 id=&#34;实际迁移示例&#34;&gt;实际迁移示例&lt;/h2&gt;
&lt;p&gt;以下是一个简单的 HTTP 网关配置示例，展示了如何将 Ingress 迁移到 Gateway API。&lt;/p&gt;
&lt;p&gt;假设现有一个 Ingress 配置如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pathType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;要将其迁移到 Gateway API，首先需要创建一个 Gateway 对象：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway.networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gatewayClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-gateway-class&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;listeners&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;allowedRoutes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kinds&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;请确保 &lt;code&gt;gatewayClassName&lt;/code&gt; 指向你集群中配置的有效 GatewayClass。GatewayClass 通常由集群管理员设置，是一个为 Gateway 提供配置的资源。&lt;/p&gt;
&lt;p&gt;接下来，创建 HTTPRoute 资源来定义路由规则，将流量路由到后端服务：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway.networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-httproute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;parentRefs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PathPrefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backendRefs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;example-service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在此示例中，我们看到：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Ingress&lt;/code&gt; 对象中的规则被直接映射到 &lt;code&gt;HTTPRoute&lt;/code&gt; 对象中。&lt;/li&gt;
&lt;li&gt;路由规则中的主机名匹配、路径匹配以及后端服务配置保持不变，只是对象和字段名称有所不同。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;考虑的挑战&#34;&gt;考虑的挑战&lt;/h2&gt;
&lt;p&gt;虽然可以将 Ingress 迁移到 Gateway API，并可能同时运行它们，但需要考虑以下挑战和迁移的必要性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;功能差异&lt;/strong&gt;：某些 Ingress 控制器的特定功能可能在 Gateway API 中没有直接对应，可能需要通过额外的配置或自定义资源来实现。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多资源管理&lt;/strong&gt;：Gateway API 的使用可能涉及比 Ingress 更多的资源类型和更复杂的配置，这可能增加管理的复杂性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于现有的 Ingress 和 Istio API 用户，是否需要迁移到 Gateway API 取决于具体情况。以下是一些迁移建议：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;新部署&lt;/strong&gt;：建议直接采用 Gateway API，以便利用其先进特性和预见未来的发展。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;现有部署&lt;/strong&gt;：如果现有系统运行稳定且无需高级特性，可以继续使用现有 API；如果希望利用 Gateway API 的新特性或计划未来长期发展，逐步迁移则是一个理智的选择。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于不同网关对 Gateway API 的支持情况，可以参考 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/implementations/v1.1/&#34; title=&#34;Gateway API 实现项目的一致性报告&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway API 实现项目的一致性报告&lt;/a&gt;了解详细信息。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;Ingress API、Istio API 和 Kubernetes Gateway API 各具特色，适应不同的应用场景和需求。选择合适的 API，进行合理的规划和管理，可以显著提高系统的灵活性和稳定性。随着 Gateway API 的持续发展和成熟，它将越来越成为未来流量管理的主流选择。&lt;/p&gt;
&lt;p&gt;选择合适的网关技术，结合你的具体需求和现有架构，可以更好地管理和优化流量，确保应用的高效和稳定运行。随着技术的进步和社区的发展，Gateway API 提供了一个强大且灵活的框架，使得从传统的 Ingress 迁移到更现代的解决方案变得更为简单和高效。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gateway-api.sigs.k8s.io/guides/migrating-from-ingress/&#34; title=&#34;Migrating from Ingress - gateway-api.sigs.k8s.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Migrating from Ingress - gateway-api.sigs.k8s.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://istio.io/latest/blog/2022/gateway-api-beta/&#34; title=&#34;Extending Gateway API support in Istio - istio.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Extending Gateway API support in Istio - istio.io&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>电子书：Kubernetes 网络和 Cilium 网络工程师指南</title>
      <link>https://jimmysong.io/blog/ebook-cilium-for-network-engineer/</link>
      <pubDate>Mon, 29 Apr 2024 09:27:49 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/ebook-cilium-for-network-engineer/</guid>
      <description>
        
        
        &lt;p&gt;亲爱的云原生社区的朋友们，我很高兴向大家推荐 Isovalent 最新推出的电子书《&lt;a href=&#34;https://isovalent.com/blog/post/introducing-the-new-kubernetes-networking-and-cilium-for-the-network-engineer-ebook/&#34; title=&#34;Kubernetes 网络和 Cilium 网络工程师指南（英文原版）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 网络和 Cilium 网络工程师指南（英文原版）&lt;/a&gt;》。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    &lt;img src=&#34;https://jimmysong.io/img/blog/ebook-cilium-for-network-engineer/cover.webp&#34; data-img=&#34;https://jimmysong.io/img/blog/ebook-cilium-for-network-engineer/cover.webp&#34; alt=&#34;image&#34; data-caption=&#34;《Kubernetes 网络和 Cilium 网络工程师指南》电子书封面&#34;&gt;
  
  
  &lt;figcaption&gt;《Kubernetes 网络和 Cilium 网络工程师指南》电子书封面&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;作为一名资深的云原生倡导者，我深知 Kubernetes 网络对于网络工程师来说是一个巨大的挑战。但是，随着 Kubernetes 在企业中的广泛应用，学习 Kubernetes 网络知识已经变得非常重要和紧迫。这本电子书正是为了帮助网络工程师们克服这些挑战而诞生的。&lt;/p&gt;
&lt;p&gt;这本 56 页的电子书由 &lt;em&gt;Isovalent 的 Senior Staff Technical Marketing Engineer&lt;/em&gt; Nico Vibert 撰写，内容涵盖了 Kubernetes 网络的方方面面，包括 Cilium 这个事实上的 Kubernetes 网络层。即使你不是网络工程师，相信你也能轻松理解和学习这本书的内容。&lt;/p&gt;
&lt;p&gt;这本电子书就像一本使用说明手册，为网络工程师们提供了一个循序渐进的学习路径。从 Kubernetes 网络的基础知识，到 Cilium 的高级功能，再到实际的部署和运维，应有尽有。相信这本书一定会成为网络工程师学习 Kubernetes 网络的必备资料。&lt;/p&gt;
&lt;p&gt;根据这本由 Isovalent 推出的电子书《Kubernetes Networking and Cilium: An Instruction Manual for the Network Engineer》的内容，我为大家总结了以下几点。&lt;/p&gt;
&lt;h2 id=&#34;本书亮点&#34;&gt;本书亮点&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;全面介绍了 Kubernetes 网络的基础知识，包括容器网络接口 (CNI)、网络模型等，为网络工程师打下坚实的基础。&lt;/li&gt;
&lt;li&gt;深入探讨了 Cilium 这个事实上的 Kubernetes 网络层，详细讲解了它提供的各种功能，如路由、交换、负载均衡、防火墙、监控等。&lt;/li&gt;
&lt;li&gt;系统介绍了如何在 Kubernetes 中配置和管理网络，包括使用 kubectl 命令行工具、应用 YAML 配置文件等。&lt;/li&gt;
&lt;li&gt;重点阐述了 Cilium 的身份感知安全机制，以及如何使用网络策略进行精细化的网络访问控制。&lt;/li&gt;
&lt;li&gt;讲解了 Kubernetes 中的负载均衡机制，包括 ClusterIP、NodePort 和 Ingress 等服务类型。&lt;/li&gt;
&lt;li&gt;探讨了 Kubernetes 集群跨多个集群的联通方案，以及如何实现跨集群的负载均衡和安全策略。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;适读人群&#34;&gt;适读人群&lt;/h2&gt;
&lt;p&gt;这本电子书主要面向 Kubernetes 网络工程师，帮助他们全面掌握 Kubernetes 网络的方方面面知识。即使不是网络工程师，对云原生技术感兴趣的读者也能从中受益，学习 Kubernetes 网络的基础知识。&lt;/p&gt;
&lt;h2 id=&#34;中文版&#34;&gt;中文版&lt;/h2&gt;
&lt;p&gt;如果你想阅读该书的中文版，请访问&lt;a href=&#34;https://isovalent.com/books/kubernetes-networking-and-cilium-zh/&#34; title=&#34;这里&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;获取。中文版由 Isovalent 的黄力一翻译。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>深入解读 CNI：容器网络接口</title>
      <link>https://jimmysong.io/blog/cni-deep-dive/</link>
      <pubDate>Mon, 15 Apr 2024 13:54:49 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/cni-deep-dive/</guid>
      <description>
        
        
        &lt;p&gt;在容器化环境中，有效管理网络是至关重要的。容器网络接口（CNI）是一个标准，定义了容器应如何配置网络。本文将深入探讨 CNI 的基础知识，并带你了解 CNI 与 CRI 的关系。&lt;/p&gt;
&lt;h2 id=&#34;what-is-cni&#34;&gt;什么是 CNI？&lt;/h2&gt;
&lt;p&gt;CNI（容器网络接口）规范为容器运行时和网络插件之间提供了一个通用的接口，旨在实现容器网络配置的标准化。&lt;/p&gt;
&lt;p&gt;CNI 规范包含以下几个核心组成部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网络配置的格式&lt;/strong&gt;：定义了管理员如何定义网络配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;请求协议&lt;/strong&gt;：描述了容器运行时如何向网络插件发出网络配置或清理请求。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;插件执行过程&lt;/strong&gt;：详细阐述了插件如何根据提供的配置执行网络设置或清理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;插件委派&lt;/strong&gt;：允许插件将特定功能委托给其他插件执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;结果返回&lt;/strong&gt;：定义了插件执行完成后如何向运行时返回结果的数据格式。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CNI 规范通过定义这些核心组成部分，确保了不同的容器运行时和网络插件能够以一致的方式进行交互，实现网络配置的自动化和标准化。&lt;/p&gt;



&lt;div class=&#34;alert alert-note-container&#34;&gt;
  
  &lt;div class=&#34;alert-note-title px-2 py-2&#34;&gt;
    CNI 规范的一些要点
  &lt;/div&gt;
  
  &lt;div class=&#34;alert-note px-2&#34;&gt;
    &lt;ul&gt;
&lt;li&gt;CNI 是一个插件化的容器化网络解决方案&lt;/li&gt;
&lt;li&gt;CNI 插件为可执行文件&lt;/li&gt;
&lt;li&gt;单个 CNI 插件的职责是单一的&lt;/li&gt;
&lt;li&gt;CNI 插件是呈链式调用的&lt;/li&gt;
&lt;li&gt;CNI 规范为一个容器定义一个 Linux 网络命名空间&lt;/li&gt;
&lt;li&gt;CNI 的网络定义存储为 JSON 格式&lt;/li&gt;
&lt;li&gt;网络定义通过 STDIN 输入流传输到插件，这意味着宿主机上不会存储网络配置文件，其他的配置参数通过环境变量传递给插件&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;CNI 插件根据操作类型，接收相应的网络配置参数，执行网络配置或清理任务，并返回执行结果。这一流程确保了容器网络的动态配置与容器生命周期的同步。&lt;/p&gt;
&lt;p&gt;下图展示了 CNI 包含了众多的网络插件。&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/cdc38d55a4fc4468ab20df85ab63c2c7.svg&#34; data-img=&#34;/blog/cni-deep-dive/cdc38d55a4fc4468ab20df85ab63c2c7.svg&#34; alt=&#34;image&#34; data-caption=&#34;CNI 插件的种类&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;CNI 插件的种类&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;根据 &lt;a href=&#34;https://github.com/containernetworking/cni/blob/main/SPEC.md#section-2-execution-protocol&#34; title=&#34;CNI 规范&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNI 规范&lt;/a&gt;，一个 CNI 插件负责以某种方式配置容器的网络接口。插件可分为两大类：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;接口&amp;quot;插件，负责在容器内部创建网络接口并确保其具有连通性。&lt;/li&gt;
&lt;li&gt;&amp;ldquo;链式&amp;quot;插件，调整已创建接口的配置（但可能需要创建更多接口以完成此操作）。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;relationship&#34;&gt;CNI 与 CRI 的关系&lt;/h2&gt;
&lt;p&gt;CNI 和 CRI（容器运行时接口）是 Kubernetes 中两个关键的接口，它们分别处理容器的网络配置和运行时管理。在 Kubernetes 集群中，CRI 调用 CNI 插件来配置或清理容器的网络，这确保了网络配置的过程与容器的创建和销毁过程紧密协调。&lt;/p&gt;
&lt;p&gt;下图直观地展示了 CNI 如何与 CRI 协同运行的：&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/5451dd983a8c3858a265283d74b7536b.svg&#34; data-img=&#34;/blog/cni-deep-dive/5451dd983a8c3858a265283d74b7536b.svg&#34; alt=&#34;image&#34; data-caption=&#34;CNI 如何与 CRI 协同运行的&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;CNI 如何与 CRI 协同运行的&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Kubelet 到 CRI&lt;/strong&gt;：Kubelet 指示 CRI 创建已调度的 Pod 的容器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CRI 到 Pod&lt;/strong&gt;：容器运行时在 Pod 中启动容器。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pod 到 CRI&lt;/strong&gt;：一旦容器运行，它会向容器运行时发出信号。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CRI 到 Kubelet&lt;/strong&gt;：容器运行时通知 Kubelet 容器已准备就绪。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubelet 到 CNI&lt;/strong&gt;：容器已启动，Kubelet 调用 CNI 为 Pod 设置网络。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNI 到 Pod&lt;/strong&gt;：CNI 为 Pod 配置网络，将其连接到必要的网络接口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pod 到 CNI&lt;/strong&gt;：网络配置完成后，Pod 向 CNI 确认网络设置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CNI 到 Kubelet&lt;/strong&gt;：CNI 通知 Kubelet Pod 的网络已准备就绪。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubelet 到 Pod&lt;/strong&gt;：现在 Pod 完全可操作，两个容器均已运行且网络已配置。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;下图展示了在 Kubernetes 中为 Pod 设置网络所涉及的详细步骤：&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/4f3017abf23385a5007302ea17241bdf.svg&#34; data-img=&#34;/blog/cni-deep-dive/4f3017abf23385a5007302ea17241bdf.svg&#34; alt=&#34;image&#34; data-caption=&#34;在 Kubernetes 中为 Pod 设置网络所涉及的详细步骤&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;在 Kubernetes 中为 Pod 设置网络所涉及的详细步骤&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Pod 调度&lt;/strong&gt;：Kubelet 在节点上调度一个 Pod 运行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;请求网络设置&lt;/strong&gt;：已调度的 Pod 请求 Kubelet 进行网络设置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调用 CNI&lt;/strong&gt;：Kubelet 调用 CNI 处理 Pod 的网络设置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;创建网络命名空间&lt;/strong&gt;：CNI 为 Pod 创建一个网络命名空间，隔离其网络环境。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分配 IP 地址&lt;/strong&gt;：CNI 通过其 IP 地址管理（IPAM）插件为 Pod 分配一个 IP 地址。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;设置网络接口&lt;/strong&gt;：CNI 在 Pod 的网络命名空间内设置必要的网络接口，将其连接到网络。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络设置完成&lt;/strong&gt;：Pod 通知 Kubelet 其网络设置已完成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;带有网络运行的 Pod&lt;/strong&gt;：Pod 现在已经运行，并且其网络已配置，可以与 Kubernetes 集群中的其他 Pod 和服务通信。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;cni-process&#34;&gt;CNI 工作流程&lt;/h2&gt;
&lt;p&gt;容器网络接口（CNI）规范定义了容器如何配置网络，其中包括 &lt;code&gt;ADD&lt;/code&gt;、&lt;code&gt;CHECK&lt;/code&gt;、&lt;code&gt;DELETE&lt;/code&gt;、&lt;code&gt;GC&lt;/code&gt; 和 &lt;code&gt;VERSION&lt;/code&gt; 五种操作。容器运行时通过调用各种 CNI 插件来执行这些操作，从而实现容器网络的动态管理和更新。&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/893d64215a1ed2a7e409925b258f32ee.svg&#34; data-img=&#34;/blog/cni-deep-dive/893d64215a1ed2a7e409925b258f32ee.svg&#34; alt=&#34;image&#34; data-caption=&#34;CNI 工作流程&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;CNI 工作流程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;为了详细说明序列图中描述的每个步骤，涉及 Kubelet、Pod、CNI 插件（包括接口和链式 CNI 插件）、网络设置和 IP 地址管理（IPAM）之间的交互，让我们深入了解这个过程：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;调度 Pod&lt;/strong&gt;：Kubelet 安排一个 Pod 在节点上运行。这一步启动了 Kubernetes 集群中 Pod 的生命周期。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;请求网络设置&lt;/strong&gt;：Pod 向 Kubelet 发出网络设置请求。这个请求触发了为 Pod 配置网络的过程，确保它可以在 Kubernetes 集群内进行通信。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调用 CNI 插件&lt;/strong&gt;：Kubelet 调用配置的容器网络接口（CNI）插件。CNI 定义了一个标准化的方式，用于容器管理系统在 Linux 容器中配置网络接口。Kubelet 将必要的信息传递给 CNI 插件，以启动网络设置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调用接口插件&lt;/strong&gt;：CNI 框架调用一个接口 CNI 插件，负责为 Pod 设置主要的网络接口。这个插件可能会创建一个新的网络命名空间、连接一对 veth 或执行其他操作，以确保 Pod 具有所需的网络接口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;设置网络接口&lt;/strong&gt;：接口 CNI 插件为 Pod 配置网络接口。这个设置包括分配 IP 地址、设置路由和确保接口准备好通信。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调用链式插件&lt;/strong&gt;：在设置网络接口之后，接口 CNI 插件或 CNI 框架调用链式 CNI 插件。这些插件执行额外的网络配置任务，比如设置 IP 伪装、配置入口/出口规则或应用网络策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分配 IP 地址&lt;/strong&gt;：作为链式过程的一部分，链式 CNI 插件中的一个可能涉及 IP 地址管理（IPAM）。IPAM 插件负责为 Pod 分配一个 IP 地址，确保每个 Pod 在集群或命名空间内具有唯一的 IP。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IP 地址已分配&lt;/strong&gt;：IPAM 插件分配了一个 IP 地址，并将分配信息返回给调用插件。这些信息通常包括 IP 地址本身、子网掩码和可能的网关。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用网络策略&lt;/strong&gt;：链式 CNI 插件将任何指定的网络策略应用于 Pod 的网络接口。这些策略可以规定允许的入口和出口流量，确保根据集群的配置要求进行网络安全和隔离。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;链式配置完成&lt;/strong&gt;：一旦所有链式插件完成了它们的任务，Pod 的整体网络配置被认为已完成。CNI 框架或链中的最后一个插件向 Kubelet 发送信号，表明网络设置已完成。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络设置完成&lt;/strong&gt;：Kubelet 收到了 Pod 的网络设置完成的确认。此时，Pod 具有完全配置的网络接口，具有 IP 地址、路由规则和应用的网络策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;带有网络运行的 Pod&lt;/strong&gt;：Pod 现在已经运行，并配置了网络。它可以与 Kubernetes 集群中的其他 Pod 通信，根据网络策略访问外部资源，并执行其指定的功能。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以下是针对 &lt;a href=&#34;https://github.com/containernetworking/cni/blob/main/SPEC.md#appendix-examples&#34; title=&#34;CNI 官方示例&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNI 官方示例&lt;/a&gt;中的 &lt;code&gt;ADD&lt;/code&gt; 操作、&lt;code&gt;CHECK&lt;/code&gt; 操作和 &lt;code&gt;DELETE&lt;/code&gt; 操作的示例序列图以及详细说明。通过这些操作，容器运行时与 CNI 插件之间进行交互，实现容器网络配置的动态管理和更新。&lt;/p&gt;
&lt;h3 id=&#34;add&#34;&gt;ADD 操作示例&lt;/h3&gt;
&lt;p&gt;以下是 ADD 操作的示例序列图以及详细说明：&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/4c05303a04984692bbba9bac12928387.svg&#34; data-img=&#34;/blog/cni-deep-dive/4c05303a04984692bbba9bac12928387.svg&#34; alt=&#34;image&#34; data-caption=&#34;ADD 操作流程&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;ADD 操作流程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Portmap 插件&lt;/strong&gt;：容器运行时通过调用 Portmap 插件执行 ADD 操作，配置容器的端口映射。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portmap 配置完成&lt;/strong&gt;：Portmap 插件完成端口映射配置，并将结果返回给容器运行时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Tuning 插件&lt;/strong&gt;：容器运行时调用 Tuning 插件执行 ADD 操作，配置容器的网络调优参数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tuning 配置完成&lt;/strong&gt;：Tuning 插件完成网络调优参数配置，并将结果返回给容器运行时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Bridge 插件&lt;/strong&gt;：容器运行时调用 Bridge 插件执行 ADD 操作，配置容器的网络接口和 IP 地址。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridge 插件调用 Host-local 插件&lt;/strong&gt;：在完成自身配置之前，Bridge 插件调用 Host-local 插件执行 ADD 操作，配置容器的 IP 地址。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPAM 配置完成&lt;/strong&gt;：Host-local 插件作为 IP 地址管理（IPAM）的授权方，完成 IP 地址分配，并将结果返回给 Bridge 插件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridge 配置完成&lt;/strong&gt;：Bridge 插件完成网络接口和 IP 地址配置，并将结果返回给容器运行时。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些操作确保了在容器启动时，其所需的网络配置能够按照预期进行设置，包括端口映射、网络调优和 IP 地址分配等。&lt;/p&gt;
&lt;h3 id=&#34;check&#34;&gt;CHECK 操作示例&lt;/h3&gt;
&lt;p&gt;以下是 CHECK 操作的示例序列图以及详细说明：&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/eaf27d3bee18f3fe637b78d765c66d3c.svg&#34; data-img=&#34;/blog/cni-deep-dive/eaf27d3bee18f3fe637b78d765c66d3c.svg&#34; alt=&#34;image&#34; data-caption=&#34;CHECK 操作流程&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;CHECK 操作流程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Bridge 插件进行检查&lt;/strong&gt;：容器运行时通过调用 Bridge 插件执行 CHECK 操作，检查容器的网络配置是否符合预期。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridge 插件调用 Host-local 插件&lt;/strong&gt;：Bridge 插件调用 Host-local 插件执行 CHECK 操作，检查 IP 地址分配是否正常。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;返回无错误&lt;/strong&gt;：Host-local 插件检查 IP 地址分配无异常，并返回无错误给 Bridge 插件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;返回 0 返回码&lt;/strong&gt;：Bridge 插件检查网络配置无异常，并返回 0 返回码给容器运行时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Tuning 插件进行检查&lt;/strong&gt;：容器运行时调用 Tuning 插件执行 CHECK 操作，检查网络调优参数是否符合预期。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;操作成功&lt;/strong&gt;：Tuning 插件检查网络调优参数无异常，返回操作成功给容器运行时。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些操作确保了在容器运行期间，其网络配置和网络调优参数能够按照预期进行检查和验证，以确保网络配置的一致性和正确性。&lt;/p&gt;
&lt;h3 id=&#34;delete&#34;&gt;DELETE 操作示例&lt;/h3&gt;
&lt;p&gt;以下是 DELETE 操作的示例序列图以及详细说明：&lt;/p&gt;

&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/cni-deep-dive/f7506b2840f92ecda6ad52e98a92e79c.svg&#34; data-img=&#34;/blog/cni-deep-dive/f7506b2840f92ecda6ad52e98a92e79c.svg&#34; alt=&#34;image&#34; data-caption=&#34;DELETE 操作流程&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;DELETE 操作流程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Portmap 插件&lt;/strong&gt;：容器运行时通过调用 Portmap 插件执行 DELETE 操作，删除容器的端口映射配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portmap 删除完成&lt;/strong&gt;：Portmap 插件完成端口映射的删除，并将结果返回给容器运行时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Tuning 插件&lt;/strong&gt;：容器运行时调用 Tuning 插件执行 DELETE 操作，删除容器的网络调优参数配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tuning 删除完成&lt;/strong&gt;：Tuning 插件完成网络调优参数的删除，并将结果返回给容器运行时。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;容器运行时调用 Bridge 插件&lt;/strong&gt;：容器运行时调用 Bridge 插件执行 DELETE 操作，删除容器的网络接口和 IP 地址配置。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridge 插件调用 Host-local 插件&lt;/strong&gt;：在完成自身删除之前，Bridge 插件调用 Host-local 插件执行 DELETE 操作，删除容器的 IP 地址分配。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IPAM 删除完成&lt;/strong&gt;：Host-local 插件完成 IP 地址分配的删除，并将结果返回给 Bridge 插件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bridge 删除完成&lt;/strong&gt;：Bridge 插件完成网络接口和 IP 地址的删除，并将结果返回给容器运行时。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这些操作确保了在容器停止运行时，其所需的网络配置能够被正确清理和移除，以确保网络资源的有效释放和管理。&lt;/p&gt;
&lt;p&gt;通过对 ADD、CHECK 和 DELETE 操作的示例序列图及详细说明，可以清晰地了解容器运行时与 CNI 插件之间的交互过程，以及如何实现容器网络配置的动态管理和更新。&lt;/p&gt;
&lt;h2 id=&#34;summary&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;CNI 为容器化环境中的网络管理提供了一种标准化的接口，通过与 CRI 的配合，确保了 Kubernetes 集群中容器的网络配置高效且一致。通过深入理解 CNI，开发者和系统管理员可以更好地管理和优化其容器网络。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/containernetworking/cni/blob/main/SPEC.md&#34; title=&#34;CNI 规范&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNI 规范&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>解密 Kubernetes 网络：跟随数据包的奇妙旅程</title>
      <link>https://jimmysong.io/trans/kubernetes-networking-by-using-cilium-beginner-level/</link>
      <pubDate>Fri, 08 Mar 2024 12:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/kubernetes-networking-by-using-cilium-beginner-level/</guid>
      <description>
        
        
        &lt;p&gt;最近对于理解 Kubernetes 中的网络有很大的兴趣。本文是我对这个话题的贡献。我会尽力用直观的方式解释，并将技术部分翻译成易懂的语言，以便任何人都能理解。&lt;/p&gt;
&lt;p&gt;最好的学习网络的方式是通过“追踪数据包”或“数据包的生命周期”。基本上，你要跟随数据包从发送者到接收者的旅程，并在每一步停下来。我以前就用 &lt;a href=&#34;https://www.dbi-services.com/blog/exploration-of-calico-in-minikube/&#34; title=&#34;Calico 实现的 Pod 到另一个 Pod 的通信&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Calico 实现的 Pod 到另一个 Pod 的通信&lt;/a&gt; 进行了这样的操作。这次我将使用另一个容器网络接口 (CNI) 叫做 &lt;a href=&#34;https://cilium.io/&#34; title=&#34;Cilium&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cilium&lt;/a&gt;，它基于 eBPF（了解快速和灵活的路由），并带有许多强大的功能和工具。让我们开始吧！&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中的传统网络&#34;&gt;Kubernetes 中的传统网络&lt;/h2&gt;
&lt;p&gt;我们将从头开始。我会假设你对网络一无所知。也许你已经知道 IP 地址是什么？IP 地址是计算机网络接口的数字地址。这就是你的计算机可以连接到你的 Wi-Fi 网络并让你访问互联网的方式。如果你使用的是笔记本电脑，你的 Wi-Fi 网络接口有一个 IP 地址。这个网络接口还有另一个由硬件提供商烧录的唯一地址。这个地址称为介质访问控制 (MAC) 地址。&lt;/p&gt;
&lt;p&gt;IP 地址属于一个组（IP 子网）。为了知道它属于哪个组，它使用一种称为子网掩码的东西。当子网掩码应用到 IP 地址时，会得到一个结果，对于属于同一组的每个 IP 地址来说，这个结果都是相同的。这就像你所在的社区一样。&lt;/p&gt;
&lt;p&gt;让我们用下面的图来做类比：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/kubernetes-networking-by-using-cilium-beginner-level/f1_hu1ec4ddf4497af64f7910a5d59042bceb_91871_1024x488_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/kubernetes-networking-by-using-cilium-beginner-level/f1.png&#34; data-img=&#34;/trans/kubernetes-networking-by-using-cilium-beginner-level/f1.png&#34; data-width=&#34;1024&#34; data-height=&#34;488&#34; alt=&#34;image&#34; data-caption=&#34;传统网络&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;传统网络&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;房子是一台计算机、服务器或虚拟机。它的大小可以不同，根据它的 CPU 和内存，但为了简单起见，我们使用相同的大小。一栋房子有一扇门，这就是你的网络接口。门上的序列号是你的 MAC 地址，房子上的数字（通常是钉在门上的）是你的 IP 地址。只有在你换门时，你的序列号才会改变。然而，你的房子号码是由你的社区的建筑师分配的，如果有重新分配或设计更改，它可能会改变。&lt;/p&gt;
&lt;p&gt;蓝色的第 10 个社区（使用从 10 到 19 的数字）属于同一组（同一 IP 子网），而绿色的第 20 个社区是另一组。在每个社区中，有五栋房子，所以有空间让社区成长。在每个社区里，门直接连接到一个喷泉，代表一个交换机。在喷泉处，有一个指示每条路径的标志，指示你可以到达哪扇门。是的，喷泉不知道房子号码，只知道门的序列号。对于人类来说，这不是很方便，所以我们使用一张地图（称为 ARP 表），它提供了房子号码与门的序列号之间的转换。&lt;/p&gt;
&lt;p&gt;如果你住在 14 号房子，想拜访 15 号房子，你会使用这条路（只有一条，而且是你的，所以不会有交通堵塞！）先到达喷泉，然后看看标志。你从地图上知道哪个序列号对应哪个房子，所以你可以沿着通往 15 号房子的路线前往。在这种星形拓扑中，你总是先去喷泉，而不是直接去你想要拜访的房子，因为没有直接的路径。社区内的路径代表了第 2 层链接。你无法通过这些路径到达另一个社区。&lt;/p&gt;
&lt;h3 id=&#34;在社区之间旅行&#34;&gt;在社区之间旅行&lt;/h3&gt;
&lt;p&gt;现在，如果从你的 14 号房子，你想要去拜访 24 号房子怎么办？这是另一个社区，这意味着 14 号的 IP 地址/子网掩码与 24 号不同。实际上，第 10 和第 20 社区是不同的。所以你知道目的地是另一个社区，这种情况下，你必须首先去找你的门卫（但总是通过喷泉，正如我们所见）。他是你社区的默认网关，他住在 11 号房子。规则是去找他，对于任何目的地在你社区之外的地方。&lt;/p&gt;
&lt;p&gt;只有他有地图（路由表）能够到达第 20 号社区，并且知道应该走哪条路（这被称为第 3 层路由，因为你正在离开你的社区）。这张地图显示了到达 20 号社区的正确门。等一下，如果一扇门是一个网络接口，那么门卫房子是不是还有另一扇门？完全正确！11 号房子有另一扇门，门上有另一个号码（101），当然这扇门上有另一个序列号（MAC 地址）。&lt;/p&gt;
&lt;p&gt;通过这扇门出去，你现在可以沿着路径到达第 20 号社区，这个社区有自己的门卫在 21 号房子。这个门卫的地图（路由表）指导你到达目的地的正确门。这扇门让你进入了第 20 号社区，因为你的目的地 24 属于它。门卫还给了你地图（ARP 表），所以你可以在喷泉上找到方向。现在，你可以沿着通往绿色喷泉的路径走了。从那里，你只需跟着标志和路径到达 24 号房子。当你想回家时，你沿着相反的方向走同样的路径回去。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中的网络&#34;&gt;Kubernetes 中的网络&lt;/h2&gt;
&lt;p&gt;现在你了解了网络的基础知识，让我们来看看在 Kubernetes 中它是如何工作的。是的，它稍微复杂一些，但让我们一步一步来，使用下面的图片来更好地理解：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/kubernetes-networking-by-using-cilium-beginner-level/f2_hu1d380b19e7d07adf8d3996151ce876d9_50384_1024x586_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/kubernetes-networking-by-using-cilium-beginner-level/f2.png&#34; data-img=&#34;/trans/kubernetes-networking-by-using-cilium-beginner-level/f2.png&#34; data-width=&#34;1024&#34; data-height=&#34;586&#34; alt=&#34;image&#34; data-caption=&#34;使用 Cilium 的 Kubernetes 网络&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;使用 Cilium 的 Kubernetes 网络&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;我们现在没有房子，而是建筑。建筑之间的网络与传统网络仍然相同，中间有一个交换机/喷泉。建筑的入口有一扇门，上面有建筑的号码（它的 IP 地址），它是 1000 个社区的一份子。一个建筑将代表我们 Kubernetes 集群的一个节点。&lt;/p&gt;
&lt;p&gt;你知道 Kubernetes 是一个容器编排器。一个容器包装成一个 pod。为了简单起见，让我们假设一个 pod 只有一个容器，因此这两个术语在这里是等价的。这个 pod 就像我们建筑中的一个私人部分。公寓的大小可以不同，因为它可能有 2、3 或 4 个卧室，这将是你的容器在节点上需要的 CPU 和内存容量。有些公寓是空的，所以建筑仍然有一些容量。然而，在 Kubernetes 中，pod 是根据需要创建和删除的。所以在我们的建筑中，这意味着有时会创建一个 2 卧室的公寓，当不再使用时，它可能会被从建筑物中移除。然后，如果建筑有足够的空间，可能会创建一个 5 卧室的公寓。然后想象一下，这是一座乐高建筑，里面你可以根据需要建造和拆除不同大小的公寓！这不是很棒吗？&lt;/p&gt;
&lt;p&gt;在每个建筑物中，容器/pod 有自己的社区（IP 子网）。在 Kubernetes 中，CNI 的功能基本上是为 pod 分配号码（IP 地址），以便它们可以彼此通信。默认情况下，Cilium 为每个建筑使用不同的社区。当创建一个公寓时，Cilium 会为其分配一个号码。当删除并重新创建一个公寓时，它将获得另一个号码，因此它是临时的。这里蓝色的社区使用 10 号范围，绿色的社区使用 20 号。你可以注意到蓝色和绿色社区的数字范围与建筑物的范围不同。只是为了让你知道，这种设计被称为叠加网络。还有其他可能的，但这是常用的一种。这是一个在节点网络之上的 pod 网络。&lt;/p&gt;
&lt;h3 id=&#34;在同一建筑中的公寓之间旅行&#34;&gt;在同一建筑中的公寓之间旅行&lt;/h3&gt;
&lt;p&gt;现在，你住在 12 号公寓，你要怎么去拜访 14 号公寓？就像我们在传统网络示例中所做的那样，你是我们要追踪的数据包！当然，你通过它的门（它的网络接口）离开公寓。与我们之前的示例不同之处在于，你现在不是离开房子，而是离开了你的公寓，但仍然在建筑物内部。然后你走过一个私人走廊，到达另一扇门（这是 LXC 接口）。&lt;/p&gt;
&lt;p&gt;这扇门给了你进入建筑的公共空间的访问，这里进行了路由和派发。我们称之为 Cilium 大厅（蓝色矩形）。当选择 Cilium 为这个 Kubernetes 集群提供通信时，每个建筑物都安装了这个大厅的 Cilium 代理。大厅里有一个门卫，他不住在公寓里，而是在大厅的一个甲板上等待。他有一个服务人员团队，在建筑物的不同门处等候提供指导。这是因为 Cilium 使用一个叫做 eBPF 的魔法路由地图，有效地帮助旅行者。&lt;/p&gt;
&lt;p&gt;当你到达走廊尽头的门时，你向等在这里的服务人员表示你要去 14 号。他在他的魔法 eBPF 地图中找到了一个与 14 号相匹配的项目，并直接向你展示了右上角的走廊门。你不必去大厅，他向你展示了一条秘密通道，直接到达那里。然后你打开那扇门，跟着走廊，到达了 14 号公寓。你回去到 12 号公寓，沿着相同的路径和过程，但是方向相反。&lt;/p&gt;
&lt;p&gt;因此，这种调度与传统的交换方式不同，并且非常快速，这要归功于魔法 eBPF 地图！&lt;/p&gt;
&lt;h3 id=&#34;在不同建筑物的公寓之间旅行&#34;&gt;在不同建筑物的公寓之间旅行&lt;/h3&gt;
&lt;p&gt;现在，从 12 号公寓，你想去拜访另一个建筑物里的 22 号公寓。你的旅行开始和以前一样，你离开你的公寓，沿着走廊，询问等待在这里的服务人员的方向。由于目的地是另一个社区的 22 号，这次他把你引导到了大厅。在这里，与传统网络一样，你需要大厅中的门卫的帮助。门卫查看他的地图（路由表），指引你去 22 号的方向，并向你展示要使用的门号码 11（cilium_host）。&lt;/p&gt;
&lt;p&gt;当你打开那扇门时，你会看到后面有另一扇门：那就是蓝色的三角形，称为 VXLAN 接口。这扇门通向一个漂亮的透明隧道，穿过建筑物的主门。你受到雨水的保护，可以欣赏到另一个建筑物的景色。你甚至可以看到室外的喷泉！当你到达绿色建筑物时，你离开隧道，去见在绿色三角形（VXLAN 接口）处等待你的服务人员。你告诉他你的目的地，他在他的魔法 eBPF 地图中找到了与 22 号相匹配的项目，并向你展示了一条通往左上角走廊门的秘密通道。然后你跟着走廊，到达了你的目的地。和以前一样，你回去的路线将沿着相同的路径，但方向相反。&lt;/p&gt;
&lt;p&gt;这就是第 3 层路由，因为目的社区与你的不同。你可以看到在 Kubernetes 中比传统路由稍微复杂一些。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;希望这有助于你理解传统网络和 Kubernetes 网络之间的区别，也希望后者现在对你来说更清晰了。如果这就是你所需要的，那么我很高兴你阅读了这篇博文，希望你喜欢它。如果你现在想了解更多关于 Kubernetes 网络的内容，请保持关注，因为我将写一篇 &lt;a href=&#34;https://www.dbi-services.com/blog/kubernetes-networking-by-using-cilium-intermediate-level-part-1/&#34; title=&#34;中级篇&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;中级篇&lt;/a&gt;，你将在其中看到一个真实集群上建筑物的样子！&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Cilium 的控制平面升级之路：xDS API 的引入与应用</title>
      <link>https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/</link>
      <pubDate>Mon, 29 Jan 2024 20:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/</guid>
      <description>
        
        
        &lt;p&gt;在这篇博客中，我们将探讨当前的 Cilium 控制平面设计，&lt;a href=&#34;https://github.com/cilium/cilium/issues/30283&#34; title=&#34;大规模部署可能出现的限制的位置和原因&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;大规模部署可能出现的限制的位置和原因&lt;/a&gt;，以及社区如何使用 CNCF 的 &lt;a href=&#34;https://github.com/cncf/xds&#34; title=&#34;通用数据平面 (xDS) API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;通用数据平面 (xDS) API&lt;/a&gt; 推进这个架构。&lt;/p&gt;
&lt;h2 id=&#34;了解-cilium-的控制平面架构&#34;&gt;了解 Cilium 的控制平面架构&lt;/h2&gt;
&lt;p&gt;Cilium 遵循基于“数据平面”和“控制平面”的常见网络架构。在 Cilium 中，数据平面部署在每个主机（或 Kubernetes 节点）上，包括用于处理 L3/L4 连接和策略的 eBPF 程序。为了简化起见，对于完整性，Cilium 还在其数据平面中使用 Envoy 代理处理 L7 策略，但我们将省略这部分。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f1_huc884a16806c306e29d90f188177ce15d_29921_704x1024_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f1.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/f1.jpg&#34; data-width=&#34;704&#34; data-height=&#34;1024&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;Cilium 控制平面以 cilium-agent 守护程序的形式实现，部署在每个 Kubernetes 节点上。每个 cilium-agent 都是控制平面的单独、独立的实例。&lt;/p&gt;
&lt;p&gt;cilium-agent 连接到 Kubernetes API 服务器，监视配置更改，然后使用它来配置数据平面。cilium-agent 还将配置写入 Kubernetes API，表示正在其各自节点上创建的端点或标识。&lt;/p&gt;
&lt;p&gt;例如，当在 Kubernetes 节点上启动一个 Pod 时，cilium-agent 负责编写一个 CiliumEndpoint 自定义资源（CR），并可能是一个表示 Pod 网络标识的 CiliumIdentity CR。cilium-agent 还会更新与标识和端点映射相关的节点上的 eBPF 映射。其他 Kubernetes 节点上的 cilium-agent 也会监视这些新的 CiliumEndpoint 和 CiliumIdentity CR 的创建，并更新其本地的 eBPF 数据平面以执行策略。这种机制能够协调每个节点上的全局策略执行配置，以便所有节点看到相同的执行行为。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f2_hu9bc46edfbf4c7931aa282f5d845e7a5b_99091_2048x1350_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f2.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/f2.jpg&#34; data-width=&#34;2048&#34; data-height=&#34;1350&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;构建控制平面的最佳实践&#34;&gt;构建控制平面的最佳实践&lt;/h2&gt;
&lt;p&gt;我们以前 &lt;a href=&#34;https://www.solo.io/blog/building-a-control-plane-for-envoy/&#34; title=&#34;曾多次在博客中&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾多次在博客中&lt;/a&gt; &lt;a href=&#34;https://www.solo.io/blog/guidance-for-building-a-control-plane-for-envoy-part-3-domain-specific-configuration/&#34; title=&#34;讨论过构建&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;讨论过构建&lt;/a&gt; &lt;a href=&#34;https://www.solo.io/blog/why-the-control-plane-matters/&#34; title=&#34;可扩展、安全、高效的控制平面的最佳实践&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;可扩展、安全、高效的控制平面的最佳实践&lt;/a&gt;。在深入研究如何扩展 Cilium 的控制平面之前，我们应该回顾一些这些最佳实践。&lt;/p&gt;
&lt;p&gt;网络架构中的数据平面应该尽可能简单，性能高，以及高效完成它需要做的事情：在本例中，来回传输字节，实施策略，并执行安全性。控制平面的作用是保护数据平面免受复杂性的干扰，以及任何分散数据平面核心任务的事物。&lt;/p&gt;
&lt;p&gt;另一方面，用户需要能够以最适合他们用户体验的形式指定配置和策略。很多时候，通过某种 &lt;a href=&#34;https://www.solo.io/blog/guidance-for-building-a-control-plane-for-envoy-part-3-domain-specific-configuration/&#34; title=&#34;特定领域的配置格式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;特定领域的配置格式&lt;/a&gt; 来实现。然后需要将这种更高级别的用户配置与基础设施状态相结合，并将其转化为较低级别的数据平面格式。转译是一半的战斗。还需要将较低级别的配置分发到数据平面，并高效地执行。这就是控制平面出现在画面中的地方。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f3_hu287aa85ed2f8c6a5d0c7f8770bc2f8d7_23325_768x1104_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f3.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/f3.jpg&#34; data-width=&#34;768&#34; data-height=&#34;1104&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;控制平面允许配置解耦并与平台的其他部分集成，这些部分随后可以通知数据平面。在许多方面，这个图表与我们构建应用程序时使用的 &lt;a href=&#34;https://learn.microsoft.com/en-us/azure/architecture/guide/architecture-styles/n-tier&#34; title=&#34;三层架构&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;三层架构&lt;/a&gt; 类似：表示层，解耦的业务逻辑层和数据存储。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f4_hu1e09b223e67c243936ca8ec32625a375_17623_718x1024_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f4.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/f4.jpg&#34; data-width=&#34;718&#34; data-height=&#34;1024&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;在网络架构的情况下，控制平面层将处理读取/写入 Kubernetes API 和创建网络标识等敏感数据。由于它是一个单独的层，我们可以对其进行安全和硬化处理，并消除数据平面需要执行这些任务的权限。在许多情况下，虽然开始时更简单，但合并一些层会导致效率低下、安全问题和扩展/耦合问题。&lt;/p&gt;
&lt;h2 id=&#34;cilium-控制平面架构的扩展考虑&#34;&gt;Cilium 控制平面架构的扩展考虑&lt;/h2&gt;
&lt;p&gt;集群中的每个 cilium-agent 负责将全局集群配置更新到其本地数据平面配置。每个 cilium-agent 可能会监视多达 15 种 CRD 类型。&lt;/p&gt;
&lt;p&gt;随着集群在节点、Pod、命名空间和网络策略方面的规模增长，每个 cilium-agent 需要执行的工作量也会增加。为了服务和更新所有这些状态，会对 Kubernetes apiserver 造成压力，可能导致 &lt;a href=&#34;https://github.com/cilium/cilium/issues/29127&#34; title=&#34;问题&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;问题&lt;/a&gt;。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f5_hue7ed0158ce51c9b331ab31adb8afb3a0_126407_2048x1286_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f5.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/f5.jpg&#34; data-width=&#34;2048&#34; data-height=&#34;1286&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;在大规模部署中，这种对 Kubernetes API 服务器的压力可能最终会减慢 &lt;em&gt;甚至导致&lt;/em&gt; 集群中的所有操作。&lt;/p&gt;
&lt;p&gt;在查看集群中的常见操作以及 cilium-agent 处理它的方式时，全局配置状态对每个节点的影响确实开始放大：工作负载和命名空间被标记、重新标记或取消标记。&lt;/p&gt;
&lt;p&gt;cilium-agent 负责为调度到其节点上的 Pod 编写 CiliumEndpoint 和 CiliumIdentity 资源。由于这些资源依赖于 Pod 和命名空间标签的组合，标签的更改将导致所有依赖资源的更新。这会导致大量的写操作和相应的读取操作，因为此状态随后会传播到所有 cilium-agent，它们必须做出反应并重新配置其本地数据平面。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;cilium.io/v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CiliumIdentity&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;50568&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium.k8s.policy.cluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.cilium.k8s.policy.serviceaccount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sleep-v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;io.kubernetes.pod.namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;security-labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:io.cilium.k8s.namespace.labels.team&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;loyalty&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:io.cilium.k8s.namespace.labels.version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v10.45&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:io.cilium.k8s.namespace.labels.kubernetes.io/metadata.name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:io.cilium.k8s.policy.cluster&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:io.cilium.k8s.policy.serviceaccount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;sleep-v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:io.kubernetes.pod.namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;k8s:version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;代码清单 1：&lt;code&gt;CiliumIdentity&lt;/code&gt; 资源结合了 &lt;em&gt;Pod&lt;/em&gt; 和 &lt;em&gt;命名空间&lt;/em&gt; 标签。对任一者的更改都会强制重新计算并生成新的 &lt;code&gt;CiliumIdentity&lt;/code&gt;。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对集群中的命名空间进行标记等操作对于 Cilium 可能非常昂贵，并且有可能导致 API 服务器操作减慢到爬行的程度（&lt;a href=&#34;https://docs.cilium.io/en/stable/operations/performance/scalability/identity-relevant-labels/&#34; title=&#34;请参阅用于标识目的包括/排除标签的建议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;请参阅用于标识目的包括/排除标签的建议&lt;/a&gt;）。例如，在中等规模集群中更改命名空间的标签可能会导致足够多的 cilium-agent 导致 Kubernetes API 服务器响应延迟约 &lt;strong&gt;4 分钟&lt;/strong&gt;。这将有效地使集群上的所有操作停滞不前。&lt;/p&gt;
&lt;p&gt;考虑以下环境：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;200 个节点的 Kubernetes 集群&lt;/li&gt;
&lt;li&gt;5 个命名空间&lt;/li&gt;
&lt;li&gt;每个命名空间有 50 个部署&lt;/li&gt;
&lt;li&gt;每个部署有 80 个副本（总共 20,000 个 Pod）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在一次更新跨命名空间的标签的测试中，我们看到 CPU 利用率急剧上升，约为 150%，并且内存在整个集群的所有节点上升到约 1 GB。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g1_hua52c85a8206eb9df0debde7d5516fdf4_45787_2048x566_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g1.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/g1.jpg&#34; data-width=&#34;2048&#34; data-height=&#34;566&#34; alt=&#34;image&#34; data-caption=&#34;图 1：所有节点上的 CPU 和内存峰值&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 1：所有节点上的 CPU 和内存峰值&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;在整个集群的所有节点上同时提高 CPU 和内存是不希望看到的行为，然而更严重的是 cilium-agent 事件的读写如何影响 Kubernetes API 服务器的延迟。在下图中，我们看到延迟增长到 3 到 4 &lt;em&gt;分钟&lt;/em&gt;。这肯定会导致各种类型的停机！不幸的是，由于这种控制平面架构，通过增加容量来处理扩展问题的典型方法不起作用；实际上，添加更多节点和/或更多工作负载会放大这种行为。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g2_hucb4e599317ac8eb6b090155fc0fe3321_85993_2048x840_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g2.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/g2.jpg&#34; data-width=&#34;2048&#34; data-height=&#34;840&#34; alt=&#34;image&#34; data-caption=&#34;图 2：Kubernetes API 服务器延迟增加到 3 - 4 分钟&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 2：Kubernetes API 服务器延迟增加到 3 - 4 分钟&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;减轻-kubernetes-api-服务器的压力&#34;&gt;减轻 Kubernetes API 服务器的压力&lt;/h2&gt;
&lt;p&gt;对于较大的 Cilium 集群，您可以通过使用&lt;a href=&#34;https://docs.cilium.io/en/latest/kvstore/&#34; title=&#34;专用的键值存储&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;专用的键值存储&lt;/a&gt; 来减轻 Kubernetes API 服务器上的压力。键值存储用于存储工作负载标识、端点和 IP 到标识映射等内容。Cilium 不再将此信息存储在 Kubernetes 自定义资源（CRD）中，而是在其自己的数据库中直接监视、操作和写入对象。Cilium Helm 图表支持将 etcd 作为专用键值存储来进行安装，以满足此目的。&lt;/p&gt;
&lt;p&gt;随着集群的增长，使用 kv-store 来卸载 Cilium 对象的读/写操作可能是一个好主意，而不是给 Kubernetes API 服务器施加压力。&lt;/p&gt;
&lt;p&gt;注意：Cilium 还进行了其他优化，以减轻 Kubernetes API 服务器的压力，例如策略状态更新。有关更多信息，请参阅&lt;a href=&#34;https://docs.cilium.io/en/stable/internals/cilium_operator/#policy-status-update&#34; title=&#34;k8s-events-handover 文档&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;k8s-events-handover 文档&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;如果我们在存在 kv-store 的情况下重新运行先前的测试，我们会看到对 Kubernetes API 服务器的压力减轻，尽管 CPU 可能没有减轻。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g3_hu03ee2df6886e0aead8ba1c0e8a4bfd85_40363_2048x469_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g3.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/g3.jpg&#34; data-width=&#34;2048&#34; data-height=&#34;469&#34; alt=&#34;image&#34; data-caption=&#34;图 3：所有节点上的 CPU 峰值，内存保持在 300-400 MB 范围内&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 3：所有节点上的 CPU 峰值，内存保持在 300-400 MB 范围内&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;与先前情况下的 150% CPU 消耗不同，CPU 在大约 100% 左右波动，而内存保持在大约 300 到 400 MB 的范围内。这是因为对每个 Pod 和每个标识（Cilium 在更改标签时创建所有新标识，并且必须更新引用旧标识的所有 eBPF 映射的 CiliumEndpoint 和 CiliumIdentity 对象的重新计算和生成需要 CPU 计算资源来完成，无论使用何种后备存储（CRD、kv-store 等）。&lt;/p&gt;
&lt;p&gt;如果我们观察 kv-store，我们会看到在此命名空间标签事件期间，事件操作/秒和延迟会急剧上升：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g4_hu9a2efd15f71651839149532ec8fba102_21221_1024x247_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g4.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/g4.jpg&#34; data-width=&#34;1024&#34; data-height=&#34;247&#34; alt=&#34;image&#34; data-caption=&#34;图 4：kv-store 上的事件操作和延迟在此命名空间标签事件期间急剧上升&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 4：kv-store 上的事件操作和延迟在此命名空间标签事件期间急剧上升&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;在这种特殊情况下，我们看到 kv-store 承受了相当大的负载，通过事件 IO，我们看到 kv-store 调用的延迟降低到约 15 秒左右。总之，这对于整个集群操作而言要好得多，而不是用请求使 Kubernetes API 服务器饱和。事实上，在图 5 中，我们可以看到 Kubernetes API 服务器的延迟保持在 10 到 40 毫秒的可接受范围内，而在先前的示例中，延迟升高到 4 分钟。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g5_huff501482344fa25fe8b78a743ca16b56_55565_2048x821_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g5.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/g5.jpg&#34; data-width=&#34;2048&#34; data-height=&#34;821&#34; alt=&#34;image&#34; data-caption=&#34;图 5：Kubernetes API Server 延迟在 10 到 40ms 之间&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 5：Kubernetes API Server 延迟在 10 到 40ms 之间&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;使用 kv-store 后端来存储 Cilium 对象是一种缓解 Kubernetes API 服务器压力的好方法，但它也有其缺点。现在有两个持久存储需要维护，而且随着规模的增加，运维负担也增加。在生产环境中运行数据库或持久存储（总体来说）以支持规模化并非易事。如果失去一致性，恢复过程是必需的，因为现在有两个“真相源”。许多平台完全管理 Kubernetes API 服务器及其存储，但 kv-store 并不是如此。由于绝大多数负载是读取操作，缓存将在减少运维复杂性的同时产生相同的改进。&lt;/p&gt;
&lt;h2 id=&#34;使用-xds-改进-cilium-的控制平面扩展安全性和效率&#34;&gt;使用 xDS 改进 Cilium 的控制平面扩展、安全性和效率&lt;/h2&gt;
&lt;p&gt;如果我们可以兼顾两全呢？既减轻 Kubernetes API 服务器的压力，又消除维护单独数据存储的昂贵生产操作的需要？甚至可能解决一些其他尚未解决的 Cilium 扩展和安全性问题？&lt;/p&gt;
&lt;p&gt;在 Solo.io，我们很高兴为 Cilium 社区中更广泛的 xDS 工作作出贡献，并帮助推动该项目朝着可扩展、安全和高效的控制平面迈进。使用&lt;a href=&#34;https://github.com/cncf/xds&#34; title=&#34;xDS 协议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS 协议&lt;/a&gt;使我们能够在集群中扩展到数千甚至数万个节点。这种方法解决了上面讨论的许多问题，以及其他问题，如单节点妥协影响范围和规模上的 CiliumIdentity 重复。让我们看看它是如何工作的。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/cncf/xds&#34; title=&#34;xDS 协议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS 协议&lt;/a&gt;最初是一种动态配置&lt;a href=&#34;https://www.envoyproxy.io/&#34; title=&#34;Envoy 代理&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy 代理&lt;/a&gt;的方式，但是它建立的理念是可以用来支持“通用数据平面”。该协议已成为在多个节点之间同步状态的有效方式，&lt;a href=&#34;https://github.com/cncf/xds&#34; title=&#34;现在由 CNCF 工作组管理&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;现在由 CNCF 工作组管理&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;最终，我们希望消除每个 cilium-agent 所做的冗余工作，将诸如标识创建之类的复杂且权限敏感的操作集中在一起，并以高效的方式为代理提供状态，同时不损害 Kubernetes 作为整体的可靠性。&lt;/p&gt;
&lt;p&gt;为了做到这一点，我们将不再让每个 cilium-agent 充当独立的控制平面，而是考虑让 cilium-agent 充当智能集中控制平面的简单只读客户端。控制平面将保护代理免受复杂和权限敏感的操作。&lt;/p&gt;
&lt;p&gt;cilium-agent（现在属于数据平面的一部分）与控制平面之间的通信将采用&lt;a href=&#34;https://github.com/cncf/xds&#34; title=&#34;xDS 协议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS 协议&lt;/a&gt;。数据平面不允许从数据平面到控制平面的写操作，因此 cilium-agent 不需要对后端存储（CRD/kv-store）具有写入访问权限。xDS 控制平面服务可以得到安全加固，是唯一需要支持对 Kubernetes API 服务器进行读/写操作的组件。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f6_hud06f088070b8a4b45fcfc26cbe240d6e_75149_1536x1136_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/f6.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/f6.jpg&#34; data-width=&#34;1536&#34; data-height=&#34;1136&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;这种架构减轻了 Kubernetes API 服务器的负载，并且不需要任何外部管理的数据存储。它看起来也更接近之前讨论的三层控制平面架构。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g6_hu490d613048364fd74eba646cc8785540_43458_1572x796_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/scaling-cilium-to-new-heights-with-xds/g6.jpg&#34; data-img=&#34;/trans/scaling-cilium-to-new-heights-with-xds/g6.jpg&#34; data-width=&#34;1572&#34; data-height=&#34;796&#34; alt=&#34;image&#34; data-caption=&#34;图 6：xDS 实现的初始测试显示 CPU 和内存使用的预期行为&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 6：xDS 实现的初始测试显示 CPU 和内存使用的预期行为&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;在这种架构中，我们确实看到了 xDS 控制平面 pods 中的 CPU 和内存开销，正如预期的那样，每个节点仍然需要处理 eBPF 数据平面的一些 CPU/内存处理开销。&lt;/p&gt;
&lt;p&gt;这种模型带来的其他好处包括在节点受损时更小的影响范围，以及消除了 cilium-agent 创建的重复标识。在原始架构（CRD 或 kv-store）中，每个节点都有一个完整的控制平面，需要特殊权限来读取和写入&lt;code&gt;CiliumEndpoints&lt;/code&gt;和&lt;code&gt;CiliumIdentity&lt;/code&gt;。如果某个节点上的 cilium-agent 受到妥协，那么整个控制平面将受到威胁，并使攻击者能够影响其他节点。这可能导致整个集群妥协。在 xDS 模型中，cilium-agent 被允许从控制平面读取数据（不允许写入），单个 cilium-agent 的妥协不会给予对整个控制平面或集群的访问权限。正如前面提到的，xDS 控制平面被视为特权组件，可以进行锁定和安全设置，甚至可以完全在集群之外运行。&lt;/p&gt;
&lt;p&gt;xDS 方法的另一个好处是通过集中标识创建来消除 Cilium 中重复标识的生成。在现有模型中，每个 cilium-agent 都独立充当控制平面，与其他节点隔离，正如在现有模型中，它试图做出可能是重复的决策。例如，当 Pod 分配到节点时，CNI 负责设置网络端点，当 cilium-agent 识别到一个新的端点，它没有现有的&lt;code&gt;CiliumIdentity&lt;/code&gt;时，它将尝试创建它。如果命名空间标签发生更改并且需要重新计算所有标识，那么也会发生相同的情况。由于标识创建在多个节点上独立进行，因此有很大机会为相同标识创建多个&lt;code&gt;CiliumIdentity&lt;/code&gt;（在极端情况下，&lt;a href=&#34;https://docs.google.com/document/d/1Hcc_2mB9OOUxrqQgZ-gSYDPnLYE_If_TCzVbUGDOdGM/edit?pli=1#heading=h.yzvq0akbw7z9&#34; title=&#34;如此描述的易于重现&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;如此描述的易于重现&lt;/a&gt;）。在 xDS 方法中，&lt;code&gt;CiliumIdentity&lt;/code&gt;在集中创建，从而消除了这种情况。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;Cilium 在 eBPF 基础上构建了强大的数据平面，但要使 Cilium 在规模上有效运行，我们可以利用 xDS 协议来改进控制平面架构。xDS 是一种高效的协议，允许我们利用多年来学到的构建控制平面的最佳实践。事实上，如果我们将 xDS 控制平面 &lt;a href=&#34;https://docs.google.com/document/d/1U4pO_dTaHERKOtrneNA8njW19HSVbq3sBM3x8an4878/edit#heading=h.ghzkbpzc9oea&#34; title=&#34;直接构建到 cilium-operator 中&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;直接构建到 cilium-operator 中&lt;/a&gt;，那么从这个实施中不会增加新的复杂性。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>KEDA vs. 原生 Kubernetes：谁是云原生应用的自动伸缩王者？</title>
      <link>https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/</link>
      <pubDate>Fri, 12 Jan 2024 08:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/</guid>
      <description>
        
        
        &lt;h3 id=&#34;1-引言自动伸缩的重要性&#34;&gt;1. 引言：自动伸缩的重要性&lt;/h3&gt;
&lt;p&gt;在今天的云原生生态系统中，波动的工作负载和动态的流量模式是常态。适应这种不可预测的行为需要能够实时调整的系统。自动伸缩是必需的，可以确保资源的最佳分配，遏制过度成本，并促进资源的高效使用。&lt;/p&gt;
&lt;p&gt;自动伸缩不仅关乎成本。它在维护应用性能和吞吐量方面发挥着关键作用。通过避免欠配置（导致用户体验不佳）和过度配置（导致不必要的成本），自动伸缩可以实现合理的平衡。&lt;/p&gt;
&lt;h3 id=&#34;2-竞争者了解基础知识&#34;&gt;2. 竞争者：了解基础知识&lt;/h3&gt;
&lt;h3 id=&#34;水平-pod-自动伸缩器hpa&#34;&gt;水平 Pod 自动伸缩器（HPA）&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/&#34; title=&#34;HPA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HPA&lt;/a&gt;，作为 Kubernetes 的本地解决方案，根据观察到的指标（主要是 CPU 和内存）来扩展 Pod 的数量。虽然对于统一的工作负载来说非常直接和有益，但当考虑到其无法扩展到零并且完全依赖 CPU 和内存指标时，它的局限性就变得明显了。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/1_hu71fb034953f4bdfa1b239b10f67e172e_30637_1159x447_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/1.jpg&#34; data-img=&#34;/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/1.jpg&#34; data-width=&#34;1159&#34; data-height=&#34;447&#34; alt=&#34;image&#34; data-caption=&#34;HPA 改变 Pod 的数量&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;HPA 改变 Pod 的数量&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h3 id=&#34;垂直-pod-自动伸缩器vpa&#34;&gt;垂直 Pod 自动伸缩器（VPA）&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler#intro&#34; title=&#34;VPA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VPA&lt;/a&gt;更多地涉及资源的调整而不是扩展它们。它评估需求并动态调整资源，确保工作负载的合适适配。但这里有一个问题：增强型的 Pod 并不一定更好。有时，拥有更多的工作进程来处理数据比拥有一个大而强大的工作进程更高效。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/2_hu8ec066d116ed7a51a6c50fd6fe3605d3_39117_1302x581_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/2.jpg&#34; data-img=&#34;/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/2.jpg&#34; data-width=&#34;1302&#34; data-height=&#34;581&#34; alt=&#34;image&#34; data-caption=&#34;VPA 调整 Pod 的大小&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;VPA 调整 Pod 的大小&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;3-限制当原生-kubernetes-自动伸缩器不足以应对时&#34;&gt;3. 限制：当原生 Kubernetes 自动伸缩器不足以应对时&lt;/h2&gt;
&lt;p&gt;尽管内置的 Kubernetes 自动伸缩器如 HPA 和 VPA 提供了基本的扩展能力，但它们在范围上天然有限。它们主要关注 CPU 和内存指标可能对于现代应用来说是一个重大限制，因为这些应用可能需要对各种指标做出反应，其中一些甚至可能不是来自应用程序本身的指标。&lt;/p&gt;
&lt;p&gt;现代应用面临的引人注目的挑战之一是根据外部系统的事件来进行扩展。例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;消息队列：&lt;/strong&gt; 应用程序可能需要根据队列中的消息数量（如 RabbitMQ 或 Kafka）来进行扩展。如果有大量未处理的消息涌入，这可能是一个扩展的指标。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据库触发器：&lt;/strong&gt; 数据库中的更改或更新（如某个表的行突然增加）可能需要将应用程序进行扩&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;展以处理或分析数据的涌入。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;外部 Webhook：&lt;/strong&gt; 来自第三方服务的传入 Webhook（例如 GitHub 推送或电子商务交易事件）可能需要更多的资源来处理额外的负载。&lt;/li&gt;
&lt;li&gt;‍&lt;strong&gt;IoT 信号：&lt;/strong&gt; 对于连接到物联网设备的应用程序，来自这些设备的信号可能是需要扩展的指标。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，还存在将扩展到零的必要来有效管理资源的情况，或者存在不同指标的组合决定扩展逻辑的情况，例如 CPU 利用率与数据库读/写速率。这些微妙的需求突显了内置 Kubernetes 自动伸缩器的不足之处。‍&lt;/p&gt;
&lt;h3 id=&#34;hpa-的自定义指标扩展&#34;&gt;HPA 的自定义指标扩展&lt;/h3&gt;
&lt;p&gt;Kubernetes 引入了一个&lt;a href=&#34;https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/#scaling-on-custom-metrics&#34; title=&#34;自定义指标&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自定义指标&lt;/a&gt;的接口，旨在为水平 Pod 自动伸缩器（HPA）提供更多超越 CPU 和内存指标的适应性。然而，实际实现中出现了挑战。&lt;/p&gt;
&lt;p&gt;尽管强大，但自定义指标 API 并不直观易用。它要求对 Kubernetes 内部有详细的了解，使设置和调整变得繁琐。‍&lt;/p&gt;
&lt;h3 id=&#34;插曲prometheus-适配器&#34;&gt;插曲：Prometheus 适配器&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes-sigs/prometheus-adapter&#34; title=&#34;Prometheus 适配器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prometheus 适配器&lt;/a&gt;试图通过利用自定义指标 API 来弥合这一差距，引入了 Prometheus 的广泛指标。但它也有一些缺点：复杂、不直观的配置以及仅与 Prometheus 指标相关联。实施和维护配置需要不断的警觉性。基础架构或应用程序的更改可能会触发重新配置的需求。&lt;/p&gt;
&lt;h3 id=&#34;4-登场-keda对决中的英雄&#34;&gt;4. 登场 KEDA：对决中的英雄&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://keda.sh/&#34; title=&#34;Kubernetes 事件驱动自动伸缩（KEDA）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 事件驱动自动伸缩（KEDA）&lt;/a&gt;不仅与 Kubernetes 的自定义指标 API 集成，还使其变得更加可访问。这是用户友好界面如何改变体验的证明，使自动伸缩真正具有可定制性和多功能性。&lt;/p&gt;
&lt;h3 id=&#34;keda-的好处&#34;&gt;KEDA 的好处&lt;/h3&gt;
&lt;p&gt;KEDA 提供了多个技术优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件驱动自动伸缩：&lt;/strong&gt; KEDA 能够响应特定事件，甚至扩展到零，确保资源得到明智地使用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易于使用：&lt;/strong&gt; 其直观的配置使实施变得轻松，允许开发人员专注于应用逻辑而不是配置语法。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;广泛应用：&lt;/strong&gt; 除了仅扩展 Pod 外，KEDA 还可以基于事件安排 Kubernetes 作业，适用于不需要持续运行但可能需要定期大量资源的任务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;多功能集成：&lt;/strong&gt; 支持多种身份验证提供程序，集成 KEDA 既简单又安全。‍&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;keda-在实践中的应用&#34;&gt;KEDA 在实践中的应用&lt;/h3&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/3_hu31b978290a4d134e0518f442ee726eb2_35380_1220x799_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/3.jpg&#34; data-img=&#34;/trans/battle-of-the-pods-kubernetes-autoscaling-showdown-keda-vs-vanilla-kubernetes/3.jpg&#34; data-width=&#34;1220&#34; data-height=&#34;799&#34; alt=&#34;image&#34; data-caption=&#34;KEDA 扩展 Kafka Consumer 应用程序&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;KEDA 扩展 Kafka Consumer 应用程序&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;虽然传统的指标如 CPU 和内存提供了一些见解，但现实世界的应用程序通常需要更精细和多样化的指标来进行有效的自动伸缩。以下是一些要考虑的情景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;事件驱动应用程序：&lt;/strong&gt; 考虑一个基于 Kafka 的设置。虽然 CPU 使用率可能保持稳定，但传入 Kafka 事件的激增是确定负载的真正指标。在这种情况下，自动伸缩应该理想地对入站事件的速率或消息积压做出响应。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;电子商务交易：&lt;/strong&gt; 在电子商务框架中，特殊销售活动可能会导致订单结帐激增。CPU 可能不受影响，但真正的负载可能是数据库队列中积累的未处理订单。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;流数据管道：&lt;/strong&gt; 从平台（如 Apache Kafka 或 AWS Kinesis）处理数据流的应用程序会经历可变的数据流入率。在这里，相关的指标可能是处理的积压或滞后，而不是 CPU 或内存消耗。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Selenium 测试工作者：&lt;/strong&gt; 在持续集成（CI）流水线中，当提交新代码时，可能会触发一系列 Selenium 测试。这里真正的度量标准可能是等待测试的队列。如果有大量等待测试的测试存在瓶颈，基于这个队列来自动伸缩 Selenium 工作者比仅仅观察 CPU 或内存指标更有效。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API 速率限制：&lt;/strong&gt; 对于大量依赖第三方 API 且具有速率限制的应用程序，接近速率限制可能是需要进行伸缩的信号。与对速率限制错误的被动反应不同，基于 API 调用频率进行主动伸缩可以确保操作顺利进行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这样多样化的现实场景强调了需要一种多功能的自动伸缩解决方案，能够理解并响应多种度量标准。KEDA 凭借其灵活性和适应性有效地应对了这些挑战。&lt;/p&gt;
&lt;h3 id=&#34;5-结论keda-自动伸缩的未来&#34;&gt;5. 结论：KEDA 自动伸缩的未来&lt;/h3&gt;
&lt;p&gt;尽管 Kubernetes 拥有原生的自动伸缩工具如 HPA 和 VPA，以及像 Prometheus 适配器这样的扩展，但它们通常伴随着复杂性。而 KEDA 提供了一个简单的平台，适用于各种各样的自动伸缩需求。它处理事件驱动的扩展，包括缩减到零，这是一个重大优势。此外，设置 KEDA 更加简单，减少了用户在处理 Kubernetes 自定义指标时通常会遇到的典型障碍。&lt;/p&gt;
&lt;p&gt;KEDA 的活跃社区证明了它的实用性。对该项目的定期贡献、像 Kedify 或 Microsoft 这样的供应商以及不断增加的&lt;a href=&#34;https://keda.sh/community/#end-users&#34; title=&#34;企业采用&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;企业采用&lt;/a&gt;显示出它在 Kubernetes 生态系统中日益重要。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>如何使用 Calico 构建和管理 Kubernetes Cluster Mesh</title>
      <link>https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/</link>
      <pubDate>Tue, 09 Jan 2024 08:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/</guid>
      <description>
        
        
        &lt;p&gt;Kubernetes 是构建灵活可扩展基础设施以运行动态工作负载的优秀解决方案。然而，随着我们的集群扩展，我们可能会面临同时扩展和管理多个集群的不可避免情况。这个概念可能会给我们的日常工作负载维护带来很多复杂性，并增加在所有环境中保持所有策略和服务的最新性的难度。在这种情况下，&lt;a href=&#34;https://www.tigera.io/blog/using-calico-to-create-a-kubernetes-cluster-mesh-for-multi-cluster-environments/&#34; title=&#34;集群网格&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;集群网格&lt;/a&gt; 可以在这些集群之间建立无缝的连接，并将工作负载集成到统一的网络环境中。&lt;/p&gt;
&lt;p&gt;集群网格是连接独立 Kubernetes 集群并在不同集群中的资源之间提供连接性的绝佳方式，以提供超出单个集群情况下可能的容错性和高可用性。&lt;/p&gt;
&lt;p&gt;在本博客文章中，我们将引导你完成构建多集群环境并建立集群网格所需的步骤，利用 Calico Open Source 的多功能能力。我们将探讨不同的方法，如顶级机架 (TOR) 和 overlay，以建立集群网格，解决不同环境提出的独特网络挑战。这是可能的，因为 Calico 提供了建立多集群环境的多种方法，灵活适应你的网络基础设施和特定要求。此外，我们还将介绍如何加入 DNS 连通性以增强集群间通信。&lt;/p&gt;
&lt;p&gt;随着你的集群网格环境扩展，我们将讨论涉及&lt;a href=&#34;https://www.tigera.io/learn/guides/kubernetes-security/kubernetes-federation/&#34; title=&#34;联邦&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;联邦&lt;/a&gt;和使用 Calico Enterprise 进行多集群管理的下一步，以及涉及联邦集群。我们将展示 Calico 如何提供多集群管理平面，允许在集群间无缝实施安全性和可观测性。&lt;/p&gt;
&lt;p&gt;最后，我们将涉及到 Calico Enterprise 联邦身份如何在&lt;a href=&#34;https://www.tigera.io/learn/guides/kubernetes-networking/kubernetes-multi-cluster/&#34; title=&#34;多集群&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;多集群&lt;/a&gt;环境中弥合差距，提供一种统一的方式来定制网络策略，可以引用来自不同集群的资源并构建跨集群边界负载平衡请求的服务。&lt;/p&gt;
&lt;h2 id=&#34;什么是集群网格&#34;&gt;什么是集群网格？&lt;/h2&gt;
&lt;p&gt;集群网格连接了两个或多个独立集群内部资源。通常，每个 Kubernetes 集群将为内部资源分配私有 IP 地址，除非将&lt;strong&gt;节点端口&lt;/strong&gt;或&lt;strong&gt;负载均衡器&lt;/strong&gt;服务与它们关联，否则这些资源对任何外部实体都不可见。然而，将资源暴露给所有人可能会带来安全风险，并破坏你应该保持的&lt;a href=&#34;https://www.tigera.io/learn/guides/zero-trust/zero-trust-security/&#34; title=&#34;零信任安全&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;零信任安全&lt;/a&gt;姿态，以保护你的环境。此外，它可以通过允许恶意用户利用漏洞并在关键服务中占据立足点来危及整个环境。&lt;/p&gt;
&lt;p&gt;在多集群环境中建立集群网格提供了一种安全机制，用于促进集群之间的直接通信。这种通信可以通过指定的集群服务或私有 IP 地址进行，确保强大而受控制的交互，同时减轻了将内部资源暴露给更广泛网络的风险。&lt;/p&gt;
&lt;h3 id=&#34;如何构建多集群环境并建立集群网格&#34;&gt;如何构建多集群环境并建立集群网格&lt;/h3&gt;
&lt;p&gt;以下图片说明了 Calico 如何在你的集群之间建立集群网格连接。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/1_huc6e3bf5c860d4951a5c56f583a803318_23942_958x587_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/1.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/1.png&#34; data-width=&#34;958&#34; data-height=&#34;587&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;Calico 提供了不同的方式，你可以使用这些方式来构建多集群环境，从而提供了与你的网络基础设施和需求相匹配的灵活性。Calico 最好的部分是，在将两个集群连接在一起后，它将自动提供集群网格，你可以通过使用它们的内部集群服务和 IP 地址开始在不同的集群中使用资源。&lt;/p&gt;
&lt;h3 id=&#34;在扁平网络环境中的集群网格&#34;&gt;在扁平网络环境中的集群网格&lt;/h3&gt;
&lt;p&gt;集群网格的配置可以根据底层基础设施的不同而变化，但其基本目的保持不变，实质上是用于建立独立集群之间的连接。&lt;/p&gt;
&lt;p&gt;例如，在我们的集群的参与节点通过广播域直接连接的环境中，我们可以通过传播内部路由到外部实体的路由协议来快速建立一个网格。这将允许我们广告内部路由，而无需通过&lt;strong&gt;节点端口&lt;/strong&gt;服务将它们暴露给我们的目标服务。&lt;/p&gt;
&lt;p&gt;以下图片说明了扁平网络的常见设计：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/2_hu9fb4ef0fa3c0b12b4cd895c6fa568fcd_7488_358x364_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/2.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/2.png&#34; data-width=&#34;358&#34; data-height=&#34;364&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;考虑观看我们的视频，&lt;a href=&#34;https://www.youtube.com/watch?v=PefluN8YM9o&amp;amp;ab_channel=ProjectCalico&#34; title=&#34;使用 Calico 开源进行 Kubernetes 的 BGP&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 Calico 开源进行 Kubernetes 的 BGP&lt;/a&gt;，以了解使用全网格方法部署集群网格的全面教程。&lt;/p&gt;
&lt;h3 id=&#34;在企业或云网络环境中的集群网格&#34;&gt;在企业或云网络环境中的集群网格&lt;/h3&gt;
&lt;p&gt;在复杂的网络环境中，例如云或企业网络，形成集群的基础设施资源通常分为单独的广播域。这是因为这些域中的每个实体都被要求通过网关来到达其目的地。但是，默认情况下，这个额外的跳跃（网关）需要了解我们在 Kubernetes 集群中创建的内部集群资源。因此，网关会丢弃前往这些内部资源的数据包，使简单的路由方法无法满足要求。&lt;/p&gt;
&lt;p&gt;以下图片说明了复杂网络环境的常见设计：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/3_hu131d697ea25f60816a99dfe45f7913bf_16473_579x357_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/3.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/3.png&#34; data-width=&#34;579&#34; data-height=&#34;357&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;既然我们知道了问题，让我们看看如何利用 Calico 来解决这个问题。&lt;/p&gt;
&lt;p&gt;为了在这样的环境中建立集群网格，我们可以使用两种方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;顶层机架（TOR）&lt;/li&gt;
&lt;li&gt;overlay&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;tor-方法推荐&#34;&gt;TOR 方法（推荐）&lt;/h4&gt;
&lt;p&gt;在企业或云环境中，资源通常通过中间网关互连。通常，我们建议我们的客户使用 TOR，因为通过与云提供商自动建立路由传播机制来使你的集群了解你监管下的所有云资源，从而使你的集群具备高可用性。这也在云提供商的底层网络基础设施上发挥了作用，从而使你的集群在网络基础设施的支持下具备高可用性。&lt;/p&gt;
&lt;p&gt;假设你可以配置云网关并将其与像 Calico 这样的强大的&lt;a href=&#34;https://www.tigera.io/learn/guides/kubernetes-networking/kubernetes-cni/&#34; title=&#34;容器网络接口（CNI）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;容器网络接口（CNI）&lt;/a&gt;配对，那么你可以利用 BGP 路由来建立集群网格。Calico BGP 集成提供了动态路由，允许你将内部 Pod 和集群 IP 路由传播到网络基础设施中的其他资源。&lt;/p&gt;
&lt;p&gt;以下图片说明了支持 BGP 的云环境的常见设计：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/4_hu9fc30ce6bdbd6078a2ff08a4f9f44a5b_7195_310x452_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/4.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/4.png&#34; data-width=&#34;310&#34; data-height=&#34;452&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;在许多情况下，TOR（顶层机架）提高了高可用性和容错性。这种方法优化了网络流量分布，减轻了单点故障，并进一步增强了你的基础设施的可靠性和弹性。&lt;/p&gt;
&lt;p&gt;注意：要了解使用 TOR 方法部署集群网格的详细指南，请查看&lt;a href=&#34;https://docs.tigera.io/calico/latest/networking/configuring/bgp#top-of-rack-tor&#34; title=&#34;此处&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;此处&lt;/a&gt;的教程。&lt;/p&gt;
&lt;h4 id=&#34;ipip-overlay&#34;&gt;IPIP overlay&lt;/h4&gt;
&lt;p&gt;在某些情况下，你可能无法访问网关以修改其设置，或者它可能不支持 BGP 对等连接。在这种情况下，你可以使用 IPIP overlay 来封装流向目标集群的流量。overlay 网络允许网络设备在底层网络（称为底层）上相互通信，而底层网络不需要了解连接到 overlay 网络的设备。&lt;/p&gt;
&lt;p&gt;注意：如果你想了解更多关于 overlay 网络的信息，请单击&lt;a href=&#34;https://docs.tigera.io/calico/latest/about/kubernetes-training/about-networking#overlay-networks&#34; title=&#34;此处&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;
&lt;h4 id=&#34;vxlan-overlay-calico-enterprise&#34;&gt;VXLAN overlay (Calico Enterprise)&lt;/h4&gt;
&lt;p&gt;即将发布的 Calico Enterprise（3.18+）版本将在多集群环境下启用 VXLAN 网络。这种方法的一个显著优势之一是能够使用身份感知策略来保护跨集群的流量（你将在接下来的联邦部分了解有关此功能的信息）。通过其多集群网络功能，Calico Enterprise 自动扩展 overlay 网络，以在集群之间建立 Pod IP 路由。&lt;/p&gt;
&lt;p&gt;在使用 VXLAN 的 Calico Enterprise 集群网格设置中，每个集群都充当本地集群和远程集群，本地集群配置为从远程集群的加密通道中检索端点和路由数据。VXLAN 集群网格提供了一种安全、可扩展和高效的解决方案，用于管理多集群网络，实现了跨集群的无缝通信和身份感知策略强制执行。&lt;/p&gt;
&lt;p&gt;注意：如果你想了解有关 VXLAN overlay 的更多信息，请单击&lt;a href=&#34;https://www.tigera.io/news/tigera-introduces-powerful-enhancements-to-calico-open-source-and-calico-cloud-to-elevate-security-scalability-and-performance/&#34; title=&#34;此处&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;此处&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;以下图片说明了没有 BGP 能力的云环境的常见设计：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/5_huf3baf178438fbb5f9a3ae4e5014ff10c_9335_353x445_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/5.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/5.png&#34; data-width=&#34;353&#34; data-height=&#34;445&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;注意：要了解使用 TOR 方法部署集群网格的全面指南，请查看&lt;a href=&#34;https://youtu.be/rv-DnExi6SM?t=2287&#34; title=&#34;此教程&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;此教程&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;dns-连接&#34;&gt;DNS 连接&lt;/h3&gt;
&lt;p&gt;在建立多集群之后，各个集群可以在 IP 级别进行通信。然而，根据你的网络规模以及 Kubernetes IP 地址的性质，这些地址可以随时动态更改，因此你需要实现一种更容易建立这些集群之间连接的方式。域名解析可以成为你的集群网格的重要补充，允许更容易进行集群间通信。&lt;/p&gt;
&lt;p&gt;在大多数 Kubernetes 部署中，CoreDNS 作为负责解析集群域名的主要工作负载。要将 DNS 与集群网格无缝集成，只需对 CoreDNS 配置映射进行简单的修改即可。具体来说，你需要将其他集群的 CoreDNS 内部服务 IP 添加为转发器到你的配置中。&lt;/p&gt;
&lt;p&gt;这个简单的调整使你的集群能够通过向其他集群发送查询来解析名称，并检索所需资源的相应 IP 地址。这种集成大大简化了集群网格内的通信，增强了整体连通性，并提高了管理效率。&lt;/p&gt;
&lt;p&gt;注意：考虑观看&lt;a href=&#34;https://youtu.be/rv-DnExi6SM?t=2574&#34; title=&#34;此视频&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;此视频&lt;/a&gt;以了解有关 DNS 连接的全面教程。&lt;/p&gt;
&lt;h2 id=&#34;联邦和多集群管理下一步&#34;&gt;联邦和多集群管理（下一步）&lt;/h2&gt;
&lt;p&gt;随着你的环境扩展，你可能会遇到多个团队必须同时在所有集群上工作的情况。多集群管理（MCM）通常解决的一个常见问题是以集中的方式处理来自不同集群的对象，包括网络策略、Pod、&lt;a href=&#34;https://www.tigera.io/learn/guides/kubernetes-security/kubernetes-compliance/&#34; title=&#34;合规性&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;合规性&lt;/a&gt;报告、可观测性和安全日志。&lt;/p&gt;
&lt;p&gt;虽然从技术上讲，可以通过 kubectl 为每个集群手动创建策略、网络集和其他资源，但这种方法会在你的日常维护任务中引入相当复杂性，并可能为意外的凭据泄漏开辟一条途径。此外，与我们在前一节中探讨的类似，它反映了没有良好结构的多集群环境所面临的挑战，特别是在集群管理、网络、故障排除和可观测性方面。&lt;/p&gt;
&lt;h3 id=&#34;使用-calico-enterprise-进行多集群管理&#34;&gt;使用 Calico Enterprise 进行多集群管理&lt;/h3&gt;
&lt;p&gt;Calico Enterprise 提供了一个 MCM 平面，通过在这些集群之间建立安全连接，实现了多集群的安全和可观测性。该架构还支持跨集群联邦&lt;a href=&#34;https://www.tigera.io/learn/guides/kubernetes-security/kubernetes-network-policy/&#34; title=&#34;网络策略&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;网络策略&lt;/a&gt;资源，并为真正的集中式管理、可观测性和集群维护奠定了基础。&lt;/p&gt;
&lt;p&gt;以下图像是列出所有已连接集群的 MCM 页面的示例。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/6_huc3d79e412370b7beb0d46279371e4b91_31348_1914x597_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/6.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/6.png&#34; data-width=&#34;1914&#34; data-height=&#34;597&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;MCM 的安全功能不仅限于集群的网络方面。由于 MCM 完全集成了 Kubernetes 基于角色的访问控制（RBAC），你可以制定授权，允许用户仅查看他们需要查看的信息。&lt;/p&gt;
&lt;p&gt;注意：使用&lt;a href=&#34;https://www.tigera.io/tutorials/?_sft_tutorial_product=calico-enterprise&#34; title=&#34;这个&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这个&lt;/a&gt;实际操作的工作坊来了解更多关于多集群管理的信息。&lt;/p&gt;
&lt;h3 id=&#34;利用-calico-enterprise-的联邦身份和统一策略执行&#34;&gt;利用 Calico Enterprise 的联邦身份和统一策略执行&lt;/h3&gt;
&lt;p&gt;Calico Enterprise 联邦将工作负载和服务端点与在集群之间共享的唯一身份关联起来。&lt;/p&gt;
&lt;p&gt;联邦身份可以与网络安全策略关联，以创建引用位于不同集群中的端点的唯一资源，从而实现对集群间安全的无缝控制。&lt;/p&gt;
&lt;p&gt;此外，通过联邦服务，你可以发现并与位于不同集群中的远程 Pod 互动。这两个关键功能使得可以创建精确、细粒度的安全控制，加强了跨多个集群的整体安全姿态。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/7_hue11fa8a0a0e071e4d2a90f475f46ffbe_43942_950x406_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/7.png&#34; data-img=&#34;/trans/what-is-a-kubernetes-cluster-mesh-and-what-are-the-benefits/7.png&#34; data-width=&#34;950&#34; data-height=&#34;406&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;通过实施联邦层和策略，你可以灵活地定义网络安全策略，这些策略可以普遍适用于所有集群，也可以专门针对一组定义的集群。这种方法提供了一种有效的手段，以在扩展部署以包括多个集群的同时扩展安全措施。通过将这些安全控制扩展到现有和新的集群，你有效地减少了策略的重复和简化了从创建到维护的整个过程。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;总结一下，集群网格连接不同 Kubernetes 集群中的内部资源。Calico 的灵活集群网格设置为在任何环境中连接到多个集群提供了构建块。&lt;/p&gt;
&lt;p&gt;Calico Enterprise MCM、联邦和联邦策略强制执行成为多集群架构的缺失环节，允许无缝通信，同时优先考虑安全性。Calico 在这个领域的能力使你能够无缝提供多集群管理、可观测性、联邦服务和身份，从而使你的组织能够自信而高效地应对现代网络的复杂性。随着组织的继续扩展和扩大规模，整合这些策略将在塑造多集群环境的未来中发挥关键作用。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes 在裸机上比虚拟机表现更好吗：Kubernetes 性能对比实验</title>
      <link>https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/</link>
      <pubDate>Mon, 18 Dec 2023 14:30:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/</guid>
      <description>
        
        
        &lt;p&gt;许多人认为部署在裸机上的 Kubernetes 集群比部署在虚拟机上的性能更好，但直到现在都没有关于这一假设的证据。在 Gcore，我们只提供基于充分证据的信息给客户，因此我们决定自行测试 Kubernetes 是否在&lt;a href=&#34;https://thenewstack.io/bare-metal-in-a-cloud-native-world/&#34; title=&#34;裸机上&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;裸机上&lt;/a&gt;比在虚拟机上表现更好，如果是的话，差距有多大。我将分享我们内部测试的结果。&lt;/p&gt;
&lt;p&gt;我故意不讨论虚拟节点与裸机节点竞争的其他方面，如&lt;a href=&#34;https://gcore.com/blog/kubernetes-on-bare-metal/&#34; title=&#34;成本效益或基础设施控制级别&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;成本效益或基础设施控制级别&lt;/a&gt;。这超出了本文的范围，本文只关注性能比较。&lt;/p&gt;
&lt;h2 id=&#34;vm-和裸机-kubernetes-之间的区别&#34;&gt;VM 和裸机 Kubernetes 之间的区别&lt;/h2&gt;
&lt;p&gt;当您在虚拟机上部署 Kubernetes 集群时，与裸机（BM）相比，您会得到额外的基础设施层，即虚拟机监视器和客户操作系统。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781_hu27ac17046494e97f5da336cf7b6b4aec_150631_1920x836_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/39ff19bc-image1a-e1700581613781.png&#34; data-width=&#34;1920&#34; data-height=&#34;836&#34; alt=&#34;image&#34; data-caption=&#34;显示裸机和虚拟机架构差异的图表&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;显示裸机和虚拟机架构差异的图表&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 1：裸机和虚拟机架构的差异。&lt;/p&gt;
&lt;p&gt;这些层占用物理 CPU 和 RAM 来运行，从工作负载中拿走一些计算能力。虚拟化还会影响网络和存储性能：虚拟网络和存储比物理网络和存储慢。&lt;/p&gt;
&lt;p&gt;相比之下，当您在&lt;a href=&#34;https://thenewstack.io/provision-bare-metal-kubernetes-with-the-cluster-api/&#34; title=&#34;裸机服务器上部署 Kubernetes 集群&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;裸机服务器上部署 Kubernetes 集群&lt;/a&gt;时，您没有任何额外的基础设施层和虚拟化。服务器的物理资源完全专用于您的工作负载，容器化应用程序可以直接访问这些资源。&lt;/p&gt;
&lt;h2 id=&#34;我们如何比较虚拟机和裸机-k8s-性能&#34;&gt;我们如何比较虚拟机和裸机 K8s 性能&lt;/h2&gt;
&lt;p&gt;为了全面了解虚拟机和裸机集群性能的比较，我们测量了以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPU：&lt;/strong&gt; 速度和利用率&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RAM：&lt;/strong&gt; 延迟&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;存储：&lt;/strong&gt; 每秒事务（TPS）和延迟&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;网络：&lt;/strong&gt; 带宽和延迟&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为了保持工作负载的一致性，所有测试应用程序都以容器化方式部署在比较的工作节点上。&lt;/p&gt;
&lt;h3 id=&#34;我们的测试条件&#34;&gt;我们的测试条件&lt;/h3&gt;
&lt;p&gt;在测试中，我们使用了运行在&lt;a href=&#34;https://gcore.com/cloud/managed-kubernetes&#34; title=&#34;Gcore 托管的 Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gcore 托管的 Kubernetes&lt;/a&gt;上的 K8s 集群。然而，由于托管的 Kubernetes 不会增加工作节点性能的任何开销，因此这些结果也与标准 Kubernetes 相关。&lt;/p&gt;
&lt;p&gt;为了保持工作负载的相同条件，我们选择了相似的虚拟机和裸机工作节点的配置。以下是这种比较配置的示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;裸机工作节点：&lt;/strong&gt; 1x Intel Xeon E-2388 8C/16T 3.2 GHz / 64 GB / Ubuntu 22.04&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;虚拟机工作节点：&lt;/strong&gt; 16 vCPU / 64 GiB 内存 / Ubuntu 22.04&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;测试结果摘要&#34;&gt;测试结果摘要&lt;/h2&gt;
&lt;p&gt;在测试中，我们比较了两个 Kubernetes 集群，一个部署在虚拟机（VMs）上，另一个部署在裸机上。它们的配置相似。作为测试工作负载，我们运行了以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用于 CPU 测试的 CPU 基准测试&lt;/li&gt;
&lt;li&gt;用于 RAM 测试的 Sysbench&lt;/li&gt;
&lt;li&gt;用于存储测试的 Pgbench&lt;/li&gt;
&lt;li&gt;用于网络测试的 Netperf&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是总结最重要的测试结果的表格：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1_hu068d1b36957dce082fad71aedf8b692d_70229_1800x698_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/417a03ef-summary1.jpg&#34; data-width=&#34;1800&#34; data-height=&#34;698&#34; alt=&#34;image&#34; data-caption=&#34;测试结果表格&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;测试结果表格&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;显然，裸机集群在所有情况下效率更高。&lt;/p&gt;
&lt;p&gt;让我们详细查看结果，并确定裸机性能对您的工作负载意味着什么。&lt;/p&gt;
&lt;h2 id=&#34;详细测试结果&#34;&gt;详细测试结果&lt;/h2&gt;
&lt;p&gt;现在，让我们详细查看每个评估标准下裸机和 VM 集群的性能。&lt;/p&gt;
&lt;h2 id=&#34;cpu-速度和利用率&#34;&gt;CPU 速度和利用率&lt;/h2&gt;
&lt;p&gt;对于 CPU 速度比较，我们使用了 Alex Dedyura 的 &lt;a href=&#34;https://github.com/alexdedyura/cpu-benchmark&#34; title=&#34;CPU 基准测试&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CPU 基准测试&lt;/a&gt;。这是一个计算到 10,000 位小数的 pi 的脚本。以秒为单位的计算时间，平均值在 10 次测试中被视为测试结果。计算 pi 是一个 CPU 密集型任务，因此该基准测试清晰地显示了被测试 CPU 的性能。&lt;/p&gt;
&lt;p&gt;以下是 CPU 速度比较的结果：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a_hu8acf870943b3ee86bfc2079c92800984_20901_1999x878_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/f35507b7-image3a.png&#34; data-width=&#34;1999&#34; data-height=&#34;878&#34; alt=&#34;image&#34; data-caption=&#34;图表显示，裸机集群的 CPU 速度比虚拟机集群的 CPU 快了两倍多&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图表显示，裸机集群的 CPU 速度比虚拟机集群的 CPU 快了两倍多&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 3：裸机集群的 CPU 速度比虚拟机集群的 CPU 快了两倍多。&lt;/p&gt;
&lt;p&gt;虚拟机集群的 10 次重试的平均时间为 47.07 秒；而裸机集群为 21.46 秒。因此，裸机集群快了两倍多。&lt;/p&gt;
&lt;p&gt;以下是虚拟机集群的 CPU 利用率测试结果：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a_huc2a2bed3317dd210c5fad67a650fe171_51217_1999x426_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/12670f56-image4a.png&#34; data-width=&#34;1999&#34; data-height=&#34;426&#34; alt=&#34;image&#34; data-caption=&#34;平均利用率为 86.81%&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;平均利用率为 86.81%&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 4：虚拟机集群的 CPU 平均利用率为 86.81%。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a_hu5a9ab61ed358d8066a27bf4dbfff558b_20194_1999x219_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/ef618156-image5a.png&#34; data-width=&#34;1999&#34; data-height=&#34;219&#34; alt=&#34;image&#34; data-caption=&#34;图 5：虚拟机集群 CPU 的每个核心使用信息&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 5：虚拟机集群 CPU 的每个核心使用信息&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 5：虚拟机集群 CPU 的每个核心使用信息。&lt;/p&gt;
&lt;p&gt;在上图 4 中，红色点表示最大的 CPU 核心负载*，绿色表示所有核心的总 CPU 负载。在执行脚本期间，大部分时间内核心都以 100% 的利用率运行；平均值为 86.81%。还有一个小的窃取时间峰值，大约在 15:16（参见图 4），这是一个常见情况，当一个虚拟机由于等待物理 CPU 共享计算资源而没有运行时会发生。&lt;/p&gt;
&lt;p&gt;*&lt;strong&gt;最大 CPU 核心负载：&lt;/strong&gt; 这个指标通常是指在虚拟机内或主机上所有虚拟机中观察到的单个 CPU 核心的最高利用率百分比。它表示在给定时刻一个特定的 CPU 核心有多重地被利用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;总 CPU 核心负载：&lt;/strong&gt; 此指标表示主机机器上所有可用 CPU 核心的整体 CPU 利用率。它考虑了所有 CPU 核心的综合使用情况，提供了运行在主机上的所有虚拟机使用了多少 CPU 容量的综合视图。&lt;/p&gt;
&lt;p&gt;以下是裸机集群的 CPU 利用率测试结果：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a_hu9ddbefe05fdb1ac82de520b0f02b4e31_60116_1999x420_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/d79f8453-image6a.png&#34; data-width=&#34;1999&#34; data-height=&#34;420&#34; alt=&#34;image&#34; data-caption=&#34;图表显示，裸机集群的 CPU 平均利用率为 43.75%&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图表显示，裸机集群的 CPU 平均利用率为 43.75%&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 6：裸机集群的 CPU 平均利用率为 43.75%。&lt;/p&gt;
&lt;p&gt;平均 CPU 负载约为 43.75%，最大负载为 62.57%，没有窃取时间。因此，就 CPU 性能而言，测试显示裸机集群约为虚拟机集群的两倍有效。&lt;/p&gt;
&lt;h2 id=&#34;ram-延迟&#34;&gt;RAM 延迟&lt;/h2&gt;
&lt;p&gt;对于 RAM 测试，&lt;a href=&#34;https://github.com/akopytov/sysbench&#34; title=&#34;我们使用了 sysbench&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;我们使用了 sysbench&lt;/a&gt; 并通过 RAM 传输了 6400 GB 的数据。以下是执行的写入和读取操作的关键结果：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a_hu5c5182f7b5a8160d8fffd31c89448f18_26318_1999x935_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/684e605e-7a.png&#34; data-width=&#34;1999&#34; data-height=&#34;935&#34; alt=&#34;image&#34; data-caption=&#34;图 7：裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 7：裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 7：裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍。&lt;/p&gt;
&lt;p&gt;虚拟机集群执行写入操作的平均时间为 174.53 毫秒，而裸机集群相同操作仅需 62.02 毫秒。读取操作分别在 173.75 和 47.33 毫秒内完成。&lt;/p&gt;
&lt;p&gt;这意味着裸机集群的 RAM 大约比虚拟机集群的 RAM 快三倍。&lt;/p&gt;
&lt;h2 id=&#34;存储-tps-和延迟&#34;&gt;存储 TPS 和延迟&lt;/h2&gt;
&lt;p&gt;为了测试存储性能，我们运行了一个 PostgreSQL 集群，并使用了 &lt;a href=&#34;https://www.postgresql.org/docs/current/pgbench.html&#34; title=&#34;pgbench 基准测试&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pgbench 基准测试&lt;/a&gt;。我们测量了 TPS（每秒事务数）和延迟。我们还变化了工作负载，测试了相同集群配置下的 8 GB 和 75 GB 数据库。&lt;/p&gt;
&lt;p&gt;以下是这些实例的配置：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a_huffbbd08389e2f14687d50805f04a0fdc_38292_1999x551_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/87869729-image8a.png&#34; data-width=&#34;1999&#34; data-height=&#34;551&#34; alt=&#34;image&#34; data-caption=&#34;图 8：存储测试的裸机和虚拟机集群配置&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 8：存储测试的裸机和虚拟机集群配置&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 8：存储测试的裸机和虚拟机集群配置。&lt;/p&gt;
&lt;h3 id=&#34;存储-tps-结果&#34;&gt;存储 TPS 结果&lt;/h3&gt;
&lt;p&gt;以下是 TPS 比较的平均结果：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a_hu0ee6bfdb91c77088450cbbe04207741c_24629_1999x935_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/7bda97df-image9a.png&#34; data-width=&#34;1999&#34; data-height=&#34;935&#34; alt=&#34;image&#34; data-caption=&#34;图 9：裸机集群的存储 TPS 值大约是虚拟机集群的两倍&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 9：裸机集群的存储 TPS 值大约是虚拟机集群的两倍&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 9：裸机集群的存储 TPS 值大约是虚拟机集群的两倍。&lt;/p&gt;
&lt;p&gt;在运行 8 GB 数据库时，虚拟机集群显示了 7,359 TPS，而裸机集群为 14,087 TPS。75 GB 数据库的性能结果分别为 4,636 和 12,029 TPS。&lt;/p&gt;
&lt;h3 id=&#34;存储延迟结果&#34;&gt;存储延迟结果&lt;/h3&gt;
&lt;p&gt;以下是延迟测试的平均结果：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10_hud023dac9efbc60874abb889bd08f12c3_24857_1999x935_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/311dd007-image10.png&#34; data-width=&#34;1999&#34; data-height=&#34;935&#34; alt=&#34;image&#34; data-caption=&#34;图表显示，8 GB 测试中裸机集群的存储延迟约为虚拟机集群的一半，在 75 GB 测试中几乎是其三倍&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图表显示，8 GB 测试中裸机集群的存储延迟约为虚拟机集群的一半，在 75 GB 测试中几乎是其三倍&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 10：裸机在存储延迟方面优于虚拟机。&lt;/p&gt;
&lt;p&gt;在运行 8 GB 数据库时，虚拟机集群的延迟为 34.78 毫秒，而裸机集群的延迟为 18.17 毫秒。对于 75 GB 数据库，延迟分别为 55.21 毫秒和 21.28 毫秒。&lt;/p&gt;
&lt;p&gt;对于 8 GB 数据库，裸机集群的存储性能约为虚拟机集群的两倍。对于 75 GB 数据库，裸机集群相对于虚拟机集群的优势更加明显。&lt;/p&gt;
&lt;h2 id=&#34;网络带宽和延迟&#34;&gt;网络带宽和延迟&lt;/h2&gt;
&lt;p&gt;为了测试网络性能，我们使用了 &lt;a href=&#34;https://github.com/kubernetes/perf-tests/tree/master/network/benchmarks/netperf&#34; title=&#34;netperf 基准测试&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;netperf 基准测试&lt;/a&gt;，其中 MSS（最大段大小）从 1 到 65,536 不等。MSS 中的“段”元素是在网络上传输的一种 IP 数据包捆绑。因此，MSS 越大，传输的流量就越多。&lt;/p&gt;
&lt;p&gt;我们在两个物理节点上部署了三个工作节点：Worker 1 和 Worker 2 位于第一个节点上，而 Worker 3 位于第二个节点上。然后，我们测试了所有三个工作节点之间的网络性能。在所有情况下，结果趋势都相似 — 裸机优于虚拟机。&lt;/p&gt;
&lt;p&gt;最有趣的测试是物理距离最远的测试之一，即 Worker 1/Worker 2（位于第一个节点上）与 Worker 3（位于第二个节点上）之间的距离，当流量在第一个和第二个物理节点之间传输时。我们可以将这看作是所有测试中最具挑战性的条件。图 10 和图 11 显示了此测试的结果。图 10 显示了 MSS 值为 1、2、4 和 8 时的网络带宽比较：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11_hu6d156c35875b2a62cf2aa654edd2f92d_23424_1999x912_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/4d53bfd2-image11.png&#34; data-width=&#34;1999&#34; data-height=&#34;912&#34; alt=&#34;image&#34; data-caption=&#34;图 11：裸机集群的网络带宽比虚拟机集群的网络带宽大五倍&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 11：裸机集群的网络带宽比虚拟机集群的网络带宽大五倍&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 11：裸机集群的网络带宽比虚拟机集群的网络带宽大五倍。&lt;/p&gt;
&lt;p&gt;虚拟机集群的带宽范围从 MSS=1 时的 862 KB/秒到 MSS=8 时的 6.52 MB/秒，而裸机集群的带宽在相同的 MSS 值范围内从 4.17 MB/秒到 31 MB/秒不等。平均而言，裸机集群的带宽比虚拟机集群的带宽大五倍。&lt;/p&gt;
&lt;p&gt;图 12 显示了使用相同 MSS 值的网络延迟比较：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12_hu269aa8260c5cb7ccc76de9f0945579fd_24084_1999x912_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12.png&#34; data-img=&#34;/trans/does-kubernetes-really-perform-better-on-bare-metal-vs-vms/5f29719e-image12.png&#34; data-width=&#34;1999&#34; data-height=&#34;912&#34; alt=&#34;image&#34; data-caption=&#34;图 12：裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图 12：裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图 12：裸机集群的网络延迟比虚拟机集群的网络延迟低了多达六倍。&lt;/p&gt;
&lt;p&gt;正如我们所见，当使用 MSS=8 时，虚拟机集群的延迟约为 145 微秒（us），而裸机的延迟为 24.5 微秒。此外，在裸机集群的情况下，随着 MSS 的增加，延迟增长较慢。&lt;/p&gt;
&lt;p&gt;对于所有测试，请注意我们报告的是&lt;em&gt;内部&lt;/em&gt;集群网络的网络性能比较。我们在一个网络中的节点之间测量了带宽和延迟，位于一个位置。如果我们使用不同位置的节点，这将增加互联网延迟，这是不稳定的，并且可能因提供商而异。我们保持了合成纯净的条件；这可能无法在实际环境中复制。但是，一般趋势可以预期会被重现。&lt;/p&gt;
&lt;h2 id=&#34;裸机性能优势意味着什么&#34;&gt;裸机性能优势意味着什么&lt;/h2&gt;
&lt;p&gt;更好的裸机性能相对于虚拟机提供了两个简单但关键的优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://thenewstack.io/how-do-applications-run-on-kubernetes/&#34; title=&#34;部署在裸机工作节点上的应用程序&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;部署在裸机工作节点上的应用程序&lt;/a&gt;运行和响应速度比部署在虚拟机上的应用程序更快。&lt;/li&gt;
&lt;li&gt;因此，当选择裸机时，客户在使用您的产品时将有更好的体验。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们的测试结果证实了一个普遍的期望，即裸机对于需要高性能和低延迟的计算密集型工作负载（例如数据库、AI/ML 模型和其他类型的实时应用程序）更为适用。虚拟机则更适合不需要高计算和低延迟敏感性的工作负载，如 Web 服务器、网站和开发环境。如果高性能和低延迟对于您的用户至关重要，并直接影响您的业务，您应该考虑在 Kubernetes 集群中使用裸机。&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;我们的测试证实了裸机工作节点优于虚拟机工作节点的假设。即裸机比起虚拟机：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在 CPU 速度和利用率方面高三倍&lt;/li&gt;
&lt;li&gt;RAM 延迟是虚拟机的 1/3&lt;/li&gt;
&lt;li&gt;存储性能高两倍多&lt;/li&gt;
&lt;li&gt;网络延迟是虚拟机的 1/5&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>外部服务别名：ExternalName 与 ServiceEntry 对比</title>
      <link>https://jimmysong.io/blog/externalname-and-serviceentry/</link>
      <pubDate>Fri, 10 Nov 2023 14:27:49 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/externalname-and-serviceentry/</guid>
      <description>
        
        
        &lt;p&gt;随着 Kubernetes 不断演进，Istio 功能逐渐在 Kubernetes 中找到对应实现，如 &lt;a href=&#34;https://kubernetes.io/blog/2023/08/25/native-sidecar-containers/&#34; title=&#34;Sidecar 容器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sidecar 容器&lt;/a&gt;、&lt;a href=&#34;https://gateway-api.sigs.k8s.io/&#34; title=&#34;Gateway API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway API&lt;/a&gt; 以及本文的主题 &lt;a href=&#34;https://kubernetes.io/zh-cn/docs/concepts/services-networking/service/#externalname&#34; title=&#34;ExternalName&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ExternalName&lt;/a&gt;。ExternalName 和 ServiceEntry 都能起到引入 Kubernetes 集群外部服务的作用，但是它们的功能和使用场景也有所区别，本文将为你详细解析。&lt;/p&gt;
&lt;h2 id=&#34;externalname-vs-serviceentry&#34;&gt;ExternalName vs ServiceEntry&lt;/h2&gt;
&lt;p&gt;下表从多个方面对比了 &lt;code&gt;ExternalName&lt;/code&gt; 和 &lt;code&gt;ServiceEntry&lt;/code&gt; ：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;特性/用例&lt;/th&gt;
&lt;th&gt;ExternalName&lt;/th&gt;
&lt;th&gt;ServiceEntry&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;流量控制&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;有限，仅支持 TCP 和 UDP&lt;/td&gt;
&lt;td&gt;更灵活，支持 TCP、UDP、HTTP 等多种协议，可以指定端口、TLS 等选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;服务发现&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;适用于外部服务的简单别名&lt;/td&gt;
&lt;td&gt;适用于描述网格内外服务，包括外部和内部服务的详细配置&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;配置复杂性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;简单，适用于基本的服务发现需求&lt;/td&gt;
&lt;td&gt;较复杂，适用于需要高级流量控制和详细配置的场景&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;TLS 支持&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;有限，较简单&lt;/td&gt;
&lt;td&gt;更丰富的 TLS 支持，可以指定证书等详细选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;安全性&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;较基本，适用于简单的用例&lt;/td&gt;
&lt;td&gt;更强大的安全性支持，可以定义 &lt;code&gt;subjectAltNames&lt;/code&gt; 等选项&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;用途&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;适用于简单的外部服务别名&lt;/td&gt;
&lt;td&gt;适用于复杂的流量管理和服务发现需求，尤其是在多协议和复杂网络拓扑中&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;使用场景&#34;&gt;使用场景&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;ExternalName 的使用情况：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;简单的服务别名：&lt;/strong&gt; 外部服务只需一个简单别名，无需复杂流量控制，可选用 &lt;code&gt;ExternalName&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;无详细流量控制需求：&lt;/strong&gt; 不需要对服务流量进行详细控制，只需简单的服务别名访问，选用 &lt;code&gt;ExternalName&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;ServiceEntry 的使用情况：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;复杂流量控制需求：&lt;/strong&gt; 需要更复杂的流量控制，如指定协议、端口、TLS 选项等，选择 &lt;code&gt;ServiceEntry&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;描述网格内外服务：&lt;/strong&gt; 需要描述网格内外服务，包括外部和内部服务的详细配置，&lt;code&gt;ServiceEntry&lt;/code&gt; 更适合。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对服务详细属性有要求：&lt;/strong&gt; 需要为服务定义特殊属性，如 &lt;code&gt;subjectAltNames&lt;/code&gt; 等，需使用 &lt;code&gt;ServiceEntry&lt;/code&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;在-istio-中使用-externalname-可能遇到的问题&#34;&gt;在 Istio 中使用 ExternalName 可能遇到的问题&lt;/h3&gt;
&lt;p&gt;在 Istio 1.20 以前，网格内存在 ExternalName 类型的 Service 时，若该 Service 的端口与其他外部服务的端口重叠，流量可能错误路由到该 ExternalName Service。该问题已在 Istio 1.20 版本中解决，详见 &lt;a href=&#34;https://github.com/istio/istio/issues/37331&#34; title=&#34;Better support ExternalName #37331&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Better support ExternalName #37331&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在服务网格的选择中，ExternalName 和 ServiceEntry 分别提供了简单的服务别名和更复杂的流量管理与服务发现选项。ExternalName 适用于简单的外部服务别名，而 ServiceEntry 在处理复杂流量控制和网格内外服务时更具优势。在实际应用中，根据具体需求和配置的复杂性权衡，灵活选择合适的机制。随着 Istio 和 Kubernetes 的不断演进，这些功能的使用方式可能会受到影响，因此保持关注相关社区的更新和最佳实践是保持系统健康和高效运行的关键。选择合适的服务网格组件将有助于构建可靠、安全且高度可扩展的微服务架构。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes Gateway API 如何增强云原生网络</title>
      <link>https://jimmysong.io/blog/kubernetes-gateway-api-enhancement-cloud-native-network/</link>
      <pubDate>Thu, 09 Nov 2023 17:10:49 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/kubernetes-gateway-api-enhancement-cloud-native-network/</guid>
      <description>
        
        
        &lt;p&gt;上周 Kubernetes Gateway API 的&lt;a href=&#34;https://kubernetes.io/blog/2023/10/31/gateway-api-ga/&#34; title=&#34;正式发布公告&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;正式发布公告&lt;/a&gt;标志着 Kubernetes 生态系统内 Gateway 能力的重要里程碑。与此同时，Kubernetes 社区一致认同&lt;a href=&#34;https://backstage.io/docs/features/kubernetes/&#34; title=&#34;Backstage&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Backstage&lt;/a&gt;是内部开发平台和门户的领先解决方案。Kubernetes Gateway API 和 Backstage 都从一开始就鼓励社区的可扩展性。可以说 API Gateway 的出现为增强 Kubernetes 网络提供了巨大的机会。&lt;/p&gt;
&lt;h2 id=&#34;gateway-api-vs-istio-服务网格&#34;&gt;Gateway API vs Istio 服务网格&lt;/h2&gt;
&lt;p&gt;不过也有人对 Gateway API 与 Istio 服务网格的关系存在疑问。对于 Gateway API 和 Istio 服务网格，两者都是为了解决 Kubernetes 网络中的问题。然而，Gateway API 着重于提供一种标准化和简化的方式来配置和部署 Ingress 和 Egress，是一个更加通用的 API。另一方面，Istio 服务网格更关注于服务到服务的通信，提供丰富的流量管理，安全，策略和遥测功能。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-gateway-api-的未来&#34;&gt;Kubernetes Gateway API 的未来&lt;/h2&gt;
&lt;p&gt;Kubernetes Gateway API 代表了 API Gateway 的关键基础，引入了一种标准，基于角色的，高度适应性的方法来配置和部署 Gateway。Kubernetes Gateway API 相比现有的 Kubernetes Ingress 的显著改进之一是其基于角色的 API 结构。这使得基础设施，平台和应用程序领域的各种角色能够拥有直接与他们的用例相关的 API 的各个方面。Gateway API 的另一个关键特性是其针对可扩展性的设计 - API 专注于核心 Gateway 和路由用例，具有扩展附加能力的可能性，例如安全性，速率限制和转换。&lt;/p&gt;
&lt;h2 id=&#34;什么是-backstage&#34;&gt;什么是 Backstage？&lt;/h2&gt;
&lt;p&gt;Backstage 是一个开源的开发者平台，它集成了所有开发者需要的服务，提供了一个统一的视图。这包括版本控制系统、持续集成/持续部署（CI/CD）系统、监控、日志、警报和文档。它旨在让开发者更高效地进行日常任务，而无需在多个工具之间切换，它也可以帮助开发者更好地理解和管理他们的软件。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/kubernetes-gateway-api-enhancement-cloud-native-network/backstage-ui_hua52e60b9053969deab1710e8a901f784_165668_1547x997_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/kubernetes-gateway-api-enhancement-cloud-native-network/backstage-ui.png&#34; data-img=&#34;/blog/kubernetes-gateway-api-enhancement-cloud-native-network/backstage-ui.png&#34; data-width=&#34;1547&#34; data-height=&#34;997&#34; alt=&#34;image&#34; data-caption=&#34;Backstage UI&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Backstage UI&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Backstage 可以应用在多种使用场景中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;作为服务目录&lt;/strong&gt;：Backstage 的软件目录功能可以帮助开发者找到并了解公司内部的所有服务和应用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;作为自动化工具&lt;/strong&gt;：Backstage 的软件模板可以自动化 API 上线流程，使得开发者能够更快速、更安全地部署他们的 API。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;提供中心化的 API 文档&lt;/strong&gt;：Backstage 的 Tech Docs 功能可以提供中心化的 API 文档，使得开发者能够在一个地方查找所有的 API 文档，而无需在多个工具间切换。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;作为开发者门户&lt;/strong&gt;：Backstage 可以集成多种开发工具，提供一站式的开发者服务，简化开发者的工作流程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Backstage 通过其&lt;a href=&#34;https://backstage.io/docs/features/software-catalog/&#34; title=&#34;软件目录&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;软件目录&lt;/a&gt;用于发现 API，&lt;a href=&#34;https://backstage.io/docs/features/software-templates/&#34; title=&#34;软件模板&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;软件模板&lt;/a&gt;用于提供带有防护栏的自动 API 上线流程，以及&lt;a href=&#34;https://backstage.io/docs/features/techdocs/&#34; title=&#34;Tech Docs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tech Docs&lt;/a&gt;用于提供 API 文档的中心用例，用于围绕 API Gateway 的协作。&lt;/p&gt;
&lt;p&gt;Backstage 的目标是简化开发者工作流程，提供一站式的解决方案，它使开发者能够在一个平台上查找他们需要的所有信息，而不是在多个工具间切换。此外，Backstage 可以让开发团队专注于编码，而不是管理工具。它还支持多种插件，可以根据团队的需求进行定制。&lt;/p&gt;
&lt;h2 id=&#34;关于未来&#34;&gt;关于未来&lt;/h2&gt;
&lt;p&gt;Backstage 和 Kubernetes Gateway API 已经牢固地将自己建立为云原生 API Gateway 的基础支柱，两个项目都在各自的路线图中充满创新。其中最有趣的领域是 Kubernetes Gateway API 超越其传统的南北入口能力，包括东西服务至服务通信，通过引入&lt;a href=&#34;https://developer.gamma.co.uk/guides/overview.html&#34; title=&#34;GAMMA API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GAMMA API&lt;/a&gt;。在真实的流量在每个方向上流动的情况下，为南北和东西流量提供单一基础将有助于提高任何容器化应用的安全性，弹性和可观测性。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>WebAssembly 能够取代 Kubernetes 吗？探索其优势和限制</title>
      <link>https://jimmysong.io/trans/wasm-vs-kubernetes/</link>
      <pubDate>Mon, 11 Sep 2023 19:03:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/wasm-vs-kubernetes/</guid>
      <description>
        
        
        &lt;p&gt;摘要：WebAssembly 可以作为一种部署应用程序的方式，可以在服务器操作系统上运行，且在许多不同的硬件环境中表现出色。与 Kubernetes 相比，WebAssembly 的优点在于简易性和安全性。但是，Kubernetes 始终有其用途，它将始终用于编排微服务和容器。因此，对于某些用例来说，WebAssembly 可以替代 Docker 和容器，但是在高度分布式的云原生环境中，使用 WebAssembly 来编排容器和微服务程度上与 Kubernetes 相同的程度是不可能的。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;是的，WebAssembly 可以解决 Kubernetes 的一些问题。&lt;/p&gt;
&lt;p&gt;WebAssembly 或 Wasm 被证明是一种在 Web 浏览器上运行代码的非常实用的方式，它可以作为编译器。它已经作为一种语言运行得非常好，以至于世界万维网联盟（W3C）在 2019 年将其命名为 Web 标准，成为第四个 Web 标准，与 HTML、CSS 和 JavaScript 一起。&lt;/p&gt;
&lt;p&gt;主要的 Web 浏览器，包括 Mozilla、Chrome、Internet Explorer 等，都兼容 Wasm，用于编写代码和创建 Web 浏览器应用程序的使用越来越普遍。除了 Web 工作马车 JavaScript 外，Wasm 还可以容纳其他语言，包括 Go、.NET、C++、Java、PHP、Rust 和 Python。&lt;/p&gt;
&lt;p&gt;Adobe 依赖于 Wasm/WASI 平台在浏览器上直接运行 C++ 代码，这是其中一个更有趣的用例。这使得用户可以在浏览器上直接运行 Adobe 的 Photoshop 和 Acrobat，从而无需在用户的计算机上下载这些软件工具进行工作。&lt;/p&gt;
&lt;p&gt;最终，开发人员意识到 Wasm 也可以在服务器操作系统上运行，现在它的使用范围扩展到硬件平台。它在许多不同的硬件环境中表现出色，从服务器端到边缘部署和物联网设备，或者任何可以直接在 CPU 上运行代码的地方。代码打包在整洁的 Wasm 可执行文件中，可以将其与容器或甚至可以与较少配置的代码和目标运行的迷你操作系统进行比较。无论在哪里部署代码，应用程序都比仅限于 Web 浏览器环境更加广泛。&lt;/p&gt;
&lt;p&gt;在许多方面，Wasm 的功能可以与一个“大杂烩”多语言编译器相比。然而，与编译器相比，同一二进制可执行文件的 Wasm 可以针对多个平台进行目标和运行，而无需在 Wasm 代码和目标设备上进行配置。&lt;/p&gt;
&lt;p&gt;因此，与编译器相比，Wasm 在完美针对多个目标运行二进制可执行文件时显然比较优越。而在这种情况下，单个二进制可执行文件可以针对多个目标运行，而无需重新配置：这就是 Wasm 的优美之处。&lt;/p&gt;
&lt;p&gt;“Wasm 终于让我们在不涉及开发人员的情况下在服务器、云和边缘设备之间移动代码。这将最终结束开发人员花费大量时间担心调整他们的代码以及为不同的目标平台提供支持的时代，”Enterprise Management Associates（EMA）的分析师 Torsten Volk 告诉 The New Stack。“Wasm 的工作是在所有这些平台上提供一致的运行时。”&lt;/p&gt;
&lt;p&gt;因此，Wasm 可以在某些情况下为 Kubernetes 提供很好的替代方案。与 Kubernetes 相比的主要优点是：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;简易性&lt;/strong&gt;。在部署应用程序时，即使将应用程序分发到不同的终端，也会有许多明显缺少的步骤。Cosmonic 的 PaaS 版本可以用几个命令行在图形界面中部署应用程序。当使用 Fermyon 和 Fastly 的 Compute@Edge 时，情况也是如此。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;安全性&lt;/strong&gt;。在 Kubernetes 这种高度分布式的环境中，安全性是一个真正的问题，并且问题点的详尽列表太长，这里不再赘述。微服务之间的互连性意味着，在一个 Pod 中有数百个入口点中获得访问权限的攻击者可能会对组织的整个基础架构造成严重破坏。&lt;a href=&#34;https://thenewstack.io/kubernetes-secrets-management-3-approaches-9-best-practices/&#34; title=&#34;秘密管理&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;秘密管理&lt;/a&gt;是另一个问题，并且与名称一样，在容器中指定谁可以访问它们也存在困难。&lt;/p&gt;
&lt;p&gt;Wasm 的可移植性和一致性可以使安全性和合规性更易于管理（再次强调，它在 CPU 级别的二进制格式中运行）。此外，Wasm 结构的简单性意味着代码在几乎直接到达端点的封闭沙箱环境中发布。Wasm 并非没有漏洞可以利用。只是相对于 Kubernetes，它的漏洞利用可能性更少。&lt;/p&gt;
&lt;h2 id=&#34;但它们并不是同一件事情&#34;&gt;但它们并不是同一件事情&lt;/h2&gt;
&lt;p&gt;Wasm 提供了巨大的机会，并且可能会作为一种部署应用程序的方式，在未来几个月和几年中，我们将看到供应商变得更加有创造力，以便用户可以利用它。相比之下，那些预测 Wasm 最终将吃掉 Kubernetes 的午餐并完全取代它的人，可以说是错过了重点。不可能说会发生什么，以及其他用于在云环境中部署和管理高度分布式应用程序的技术可能最终取代 Kubernetes。但是，它高度不可能是 Wasm。&lt;/p&gt;
&lt;p&gt;这是因为 Kubernetes 始终有其用途。它将始终用于编排微服务，以及当然还有容器。它也可以被认为实际上就是 Wasm 将在其中运行的东西，并且其支持者已经说过 Wasm 非常适合在 Kubernetes 环境中运行。&lt;/p&gt;
&lt;p&gt;“&lt;a href=&#34;https://thenewstack.io/webassembly/serverless-webassembly-for-browser-developers/&#34; title=&#34;Wasm 是为开发人员提供无需编写和维护大量基础设施 YAML 的无服务器运行时&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wasm 是为开发人员提供无需编写和维护大量基础设施 YAML 的无服务器运行时&lt;/a&gt;。Wasm 为应用程序代码提供了一组标准 API，以便访问关键的运行时服务，例如 SQL 或 NoSQL、Kafka 消息传递或代码调试，”Volk 说。“但是，然后 Wasm 依赖于资源编排层，可以由 Kubernetes 或任何其他调度器提供，以提供这些服务所需的基础设施资源。这些资源可以以容器、虚拟机、裸机或一些未曾想到的花哨未来技术的形式交付。”&lt;/p&gt;
&lt;p&gt;然而，并非所有人都认为 Kubernetes 作为容器编排的能力将无限期地保持其首选。许多 Wasm 领域的人都倾向于 HashiCorp 的 Nomad 调度器。的确，Fermyon 已经放弃了 Krustlet（Wasm-on-Kubernetes），并将重点转向 HashiCorp Nomad 作为其调度器。Butcher 说：“Nomad 在调度容器方面与 Kubernetes 相当，但具有一个至关重要的附加功能：它可以调度非容器工作负载。在 Fermyon 中，我们能够使 Nomad 调度和执行 WebAssembly 应用程序，而无需编写任何自定义代码。”&lt;/p&gt;
&lt;p&gt;与此同时，Kubernetes 开发人员需要在低级别上&lt;a href=&#34;https://thenewstack.io/webassembly/what-is-webassembly-and-why-do-you-need-it/&#34; title=&#34;接受 WebAssembly&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;接受 WebAssembly&lt;/a&gt;，并更改内置的、容器特定的假设，Butcher 说。微软是第一家真正拥抱这个概念的公司，它的&lt;a href=&#34;https://github.com/containerd/runwasi&#34; title=&#34;runwasi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;runwasi&lt;/a&gt;项目是 WebAssembly 如何在 Kubernetes 内部执行的示例，Butcher 说。&lt;/p&gt;
&lt;p&gt;“runwasi 项目仅仅是 Kubernetes 需要经历的一系列转型中的第一步，如果它不想被 Nomad 和 Wasm 超越，它的开发人员和维护人员需要快速采取行动。”Butcher 说。“Kubernetes 的游戏要输，但如果它不想被 Nomad 和 Wasm 取代，它们需要迅速采取行动。”&lt;/p&gt;
&lt;h2 id=&#34;存在的威胁&#34;&gt;存在的威胁&lt;/h2&gt;
&lt;p&gt;WebAssembly 对于 Docker 以及容器构成了一种存在的威胁，尽管在超越 Kubernetes 方面，WebAssembly 的简单性、可移植性和安全性等优势使其成为弥补 Docker 缺陷的良好选择，特别是对于边缘和分布式应用。然而，Butcher 指出，Docker 在以下两种应用程序提供环境时表现出色：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;长时间运行的过程，如数据库和消息队列，这些过程需要强大的 I/O 和内存管理能力。&lt;/li&gt;
&lt;li&gt;遗留（传统）代码，该代码在应用程序中保留状态并大量使用线程。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“Butcher 说：“我对 Docker 的看法是，它在市场上有一个强大且不可撼动的地位，WebAssembly 不太可能取代它。但是，当涉及到微服务和 Web 应用程序后端时，我认为 WebAssembly 有望削减 Docker 的使用。”&lt;/p&gt;
&lt;p&gt;因此，对于某些用例来说，Wasm 可以替代 Docker 和容器，但是在高度分布式的云原生环境中，使用 Wasm 来编排容器和微服务程度上与 Kubernetes 相同的程度是不可能的。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>创建高效 Kubernetes 策略的 7 个步骤</title>
      <link>https://jimmysong.io/trans/7-steps-to-highly-effective-kubernetes-policies/</link>
      <pubDate>Mon, 11 Sep 2023 09:03:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/7-steps-to-highly-effective-kubernetes-policies/</guid>
      <description>
        
        
        &lt;p&gt;你刚刚开始了一份新工作，在这个工作中，你第一次有责任操作和管理 Kubernetes 基础设施。你对更深入地了解云原生充满了热情，但同时也非常担心。&lt;/p&gt;
&lt;p&gt;是的，你关注的是编写符合命名和资源使用控制最佳实践的安全应用程序的最佳方法，但是关于已经部署到生产环境中的所有其他内容呢？你打开一个新的工具来查看正在发生的情况，发现有 100 个高或严重的 CVE 和 YAML 配置问题。你关闭标签页告诉自己，你以后会处理所有这些问题的。&lt;/p&gt;
&lt;p&gt;你会吗？&lt;/p&gt;
&lt;p&gt;也许最有雄心壮志和无所畏惧的人会，但问题在于云原生社区喜欢谈论安全、标准化和“左移”，但这些对话都无法减轻因安全、资源、语法和工具问题而产生的不安全感。没有一个开发范式或工具似乎发现了在不压垮人的情况下让错误配置可见的正确方式。&lt;/p&gt;
&lt;p&gt;就像我们可能面对的所有待办事项列表一样，无论是工作还是家务，我们的大脑只能有效地处理有限数量的问题。太多问题了，我们就会迷失在上下文切换和优先处理不完整的临时解决方案之间。我们需要更好的方法来限制范围（即分类），设置里程碑，最终使安全工作可管理。&lt;/p&gt;
&lt;p&gt;是时候忽略问题的数量，专注于交互地塑造，然后强制执行你的组织使用已建立策略的方式，以产生影响——无需产生不安全感。&lt;/p&gt;
&lt;h2 id=&#34;云原生策略的历史&#34;&gt;云原生策略的历史&lt;/h2&gt;
&lt;p&gt;从 Kubernetes 的第一天开始，YAML 配置就是构建完整集群和运行应用程序的基石。作为开发人员应用程序代码和运维工程师维护集群之间的必要桥梁，它们不仅难以正确获取，而且还是 Kubernetes 中大多数部署/服务级别问题的根源。更有甚者，没有人——既不是开发人员，也不是运维工程师——想独自对此负责。&lt;/p&gt;
&lt;p&gt;策略作为一种自动化的方式进入了云原生空间，用于编写和审批为生产环境编写的 YAML 配置。如果没有一个人或团队想要根据内部样式指南手动检查每个配置，那么策略可以慢慢塑造团队解决安全、资源使用和云原生最佳实践中的常见配置错误的方式。更不用说任何唯一应用程序的规则或习语了。&lt;/p&gt;
&lt;p&gt;Kubernetes 中策略的挑战在于它对如何、何时和为什么执行它们是不可知的。你可以用多种方式编写规则，在软件开发生命周期（SDLC）的不同点执行它们，并出于不同的原因使用它们。&lt;/p&gt;
&lt;p&gt;在此混乱中，没有比 Pod 安全策略（PSP）更好的例子了，它在 2016 年 v1.3 中进入 Kubernetes 生态系统。PSP 的设计目的是控制 pod 的操作方式并拒绝任何不符合要求的配置。例如，它允许 K8s 管理员防止开发人员在任何地方运行特权 pod，从而实质上将低级别的 Linux 安全决策与开发生命周期分离开来。&lt;/p&gt;
&lt;p&gt;PSP 从未离开 beta 阶段，有几个很好的理由。这些政策仅在人或进程请求创建 pod 时应用，这意味着没有办法对 PSP 进行改进或默认启用。Kubernetes 团队承认 PSP 使意外授予过于广泛的权限变得太容易了，除了&lt;a href=&#34;https://youtu.be/SFtHRmPuhEw?feature=shared&amp;amp;t=970&#34; title=&#34;其他困难&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;其他困难&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Kubernetes 安全领域的 PSP 时代充满了风险，这启发了一个新的发布周期管理规则：任何 Kubernetes 项目不能超过两个发布周期处于 beta 状态，必须成为稳定的或者标记为[弃用](&lt;a href=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&#34; title=&#34;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/#disable-psp&lt;/a&gt; &lt;a href=&#34;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&#34; title=&#34;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/&lt;/a&gt;)和删除。&lt;/p&gt;
&lt;p&gt;另一方面，PSP 使 Kubernetes 安全领域朝着积极的方向发展：通过将 Kubernetes 安全策略的创建和实例化分离，PSP 开辟了一个新的外部接入控制器和策略执行工具生态系统，例如&lt;a href=&#34;https://kyverno.io/&#34; title=&#34;Kyverno&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kyverno&lt;/a&gt;、&lt;a href=&#34;https://open-policy-agent.github.io/gatekeeper/website/&#34; title=&#34;Gatekeeper&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gatekeeper&lt;/a&gt;和&lt;a href=&#34;https://monokle.io/&#34; title=&#34;Monokle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Monokle&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我们用这些工具摆脱了 PSP 的束缚，并用 Pod Security Standard（PSS）替换了它。一会我们再来谈这个巨大的区别。&lt;/p&gt;
&lt;h2 id=&#34;基于阶段的-kubernetes-策略方法&#34;&gt;基于阶段的 Kubernetes 策略方法&lt;/h2&gt;
&lt;p&gt;在确定了策略创建和实例化之间的解耦后，您现在可以在不管您选择哪些工具的情况下，在您的集群、环境和团队之间应用一致的策略语言。您也可以随时更改您用于创建和实例化的工具，并在您的集群中获得可靠的结果。&lt;/p&gt;
&lt;p&gt;创建通常发生在集成开发环境（IDE）中，这意味着您可以继续使用您当前最喜欢的语言来使用规则特定的语言，如&lt;a href=&#34;https://monokle.io/learn/what-is-opa-for-the-kubernetes-connoisseur-its-as-essential-as-salt&#34; title=&#34;Open Policy Agent (OPA)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Policy Agent (OPA)&lt;/a&gt;、Kyverno 的声明性语法或 Go 或 TypeScript 等编程语言。&lt;/p&gt;
&lt;p&gt;实例化和强制执行可以在软件开发生命周期的不同部分进行。正如我们在我们之前的&lt;a href=&#34;https://medium.com/kubeshop-i/kubernetes-yaml-policies-101-649a23780371&#34; title=&#34;101 级帖子&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;101 级帖子&lt;/a&gt;中看到的那样，您可以在配置生命周期的一个或多个点应用验证：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过开发人员的命令行界面（CLI）或 IDE 直接预提交&lt;/li&gt;
&lt;li&gt;通过您的CI/CD流水线进行预部署&lt;/li&gt;
&lt;li&gt;通过像 Kyverno 或 Gatekeeper 这样的&lt;a href=&#34;https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/&#34; title=&#34;接入控制器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;接入控制器&lt;/a&gt;进行后部署，或者&lt;/li&gt;
&lt;li&gt;在集群中检查部署状态是否仍符合您的策略标准。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;策略的实例化、验证和强制执行越晚，危险的错误配置就越容易滑入生产环境，发现和修复任何发现的错误配置的原始来源所需的工作也越多。您可以在几个阶段实例化和强制执行策略，但越早越好——这正是 Monokle 擅长的，具有强大的预提交和预部署验证支持。&lt;/p&gt;
&lt;p&gt;有了这个场景，以及对 Kubernetes 策略景观的理解，您可以开始消除您面前的误配置。&lt;/p&gt;
&lt;h3 id=&#34;步骤-1实施-pod-security-标准&#34;&gt;步骤 1：实施 Pod Security 标准&lt;/h3&gt;
&lt;p&gt;让我们从前面提到的 PSS 开始。Kubernetes 现在描述了&lt;a href=&#34;https://kubernetes.io/docs/concepts/security/pod-security-standards/&#34; title=&#34;三个包容性策略&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;三个包容性策略&lt;/a&gt;，您可以快速在整个集群中实施和执行。 “特权”策略完全不受限制，应该仅保留给由管理员管理的系统和基础设施工作负载。&lt;/p&gt;
&lt;p&gt;您应该从实例化“基线”策略开始，它允许最小规格的 Pod，这是大多数新接触 Kubernetes 的开发人员开始的地方：&lt;/p&gt;
&lt;p&gt;从基线开始的好处是，您无需修改所有现有的 Dockerfile 和 Kubernetes 配置即可防止已知的权限升级。会有一些例外情况，稍后我会谈到。&lt;/p&gt;
&lt;p&gt;在命名空间级别上创建和实例化这个策略级别是相对简单的：&lt;/p&gt;
&lt;p&gt;您肯定会有一些特殊的服务需要比基线允许的访问权限更多，例如用于收集日志和可观测性的&lt;a href=&#34;https://grafana.com/docs/loki/latest/clients/promtail/&#34; title=&#34;Promtail 代理&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Promtail 代理&lt;/a&gt;。在这些情况下，您需要在特权策略下运行那些命名空间。您需要跟进该供应商的安全改进，以限制您的风险。&lt;/p&gt;
&lt;p&gt;通过强制执行 Pod Security 标准的基线水平来处理大多数配置，并允许一些特权配置，然后修复违反这些策略的任何误配置，您就完成了下一个策略里程碑。&lt;/p&gt;
&lt;h3 id=&#34;步骤-2修复标签和注释&#34;&gt;步骤 2：修复标签和注释&lt;/h3&gt;
&lt;p&gt;标签用于标识资源进行分组或过滤，而注释则用于重要但不用于识别的上下文。如果您的头脑仍在旋转，来自 Ambassador Labs 的 Richard Li 的&lt;a href=&#34;https://blog.getambassador.io/kubernetes-labels-vs-annotations-95fc47196b6d&#34; title=&#34;一个方便的定义&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一个方便的定义&lt;/a&gt;可能会帮助：“标签是为 Kubernetes 而设计的，而注释是为人类而设计的。”&lt;/p&gt;
&lt;p&gt;标签应仅用于其预定目的，即使在这种情况下，您在何处以及如何应用它们时也要小心。过去，&lt;a href=&#34;https://sysdig.com/blog/exposed-prometheus-exploit-kubernetes-kubeconeu/&#34; title=&#34;攻击者已使用标签&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;攻击者已使用标签&lt;/a&gt;深入探索 Kubernetes 集群的架构，包括哪些节点运行单个 Pod，而不留下运行的查询的日志。&lt;/p&gt;
&lt;p&gt;同样的想法也适用于注释：虽然它们是为人类而设计的，但它们经常被用于&lt;a href=&#34;https://github.com/kubernetes/ingress-nginx/issues/8503&#34; title=&#34;获取凭证&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;获取凭证&lt;/a&gt;，进而获得访问更多秘密的权限。如果您使用注释来描述应在出现问题的情况下联系的人员，请知道您正在为社交工程攻击创建额外的软目标。&lt;/p&gt;
&lt;h3 id=&#34;步骤-3迁移到受限制的-pss&#34;&gt;步骤 3：迁移到受限制的 PSS&lt;/h3&gt;
&lt;p&gt;虽然基线是可允许但相对安全的，但“受限制”Pod Security 标准采用了目前加固 Pod 的最佳实践。正如 Red Hat 的 Mo Khan&lt;a href=&#34;https://youtu.be/SFtHRmPuhEw?t=1951&#34; title=&#34;曾经描述&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;曾经描述&lt;/a&gt;的那样，受限制的标准确保“您能做的最糟糕的事情是毁掉自己”，而不是您的集群。&lt;/p&gt;
&lt;p&gt;使用受限制的标准，开发人员必须编写在只读模式下运行的应用程序，仅启用 Pod 运行所需的 Linux 功能，不能在任何时候升级特权等。&lt;/p&gt;
&lt;p&gt;我建议从基线开始并稍后迁移到受限制，作为单独的里程碑，因为后者几乎总是需要对现有的 Dockerfile 和 Kubernetes 配置进行主动更改。一旦您实例化并强制执行了受限制策略，您的配置将需要遵守这些策略，否则它们将被您的验证器或接入控制器拒绝。&lt;/p&gt;
&lt;h3 id=&#34;步骤-3a压制而不是忽略不可避免的误报&#34;&gt;步骤 3a：压制而不是忽略不可避免的误报&lt;/h3&gt;
&lt;p&gt;在完成基线和受限制的里程碑时，您正在接近策略管理的更成熟（和复杂）水平。为了确保每个人都在当前策略里程碑方面保持一致，您应该开始处理虚假阳性或必须显式允许的配置，尽管违反了受限制的 PSS。&lt;/p&gt;
&lt;p&gt;在忽略规则或抑制规则之间进行选择时，始终选择抑制规则。这需要一个可审计的操作，具有日志或配置更改，以将例外情况编码为已建立的策略框架。您可以在源中添加抑制规则，直接添加到您的 K8s 配置中或在外部添加，其中开发人员请求其运维同行重新配置其验证器或接入控制器，以允许“误配置”通过。&lt;/p&gt;
&lt;p&gt;在 Monokle 中，您可以将抑制直接添加到您的配置中作为注释，使用&lt;a href=&#34;https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html&#34; title=&#34;静态分析结果交换格式（SARIF）规范&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;静态分析结果交换格式（SARIF）规范&lt;/a&gt;所称的&lt;a href=&#34;https://docs.oasis-open.org/sarif/sarif/v2.1.0/os/sarif-v2.1.0-os.html#_Toc34317739&#34; title=&#34;理由&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;理由&lt;/a&gt;：&lt;/p&gt;
&lt;h3 id=&#34;第-4-步加入常见加固指南&#34;&gt;第 4 步：加入常见加固指南&lt;/h3&gt;
&lt;p&gt;在这一步中，您已经超越了已有的 Kubernetes 安全框架，这意味着您需要更多地积极构建和努力实现自己的里程碑。&lt;/p&gt;
&lt;p&gt;美国国家安全局（NSA）和网络安全和基础设施安全局（CISA）有一份受欢迎的&lt;a href=&#34;https://media.defense.gov/2022/Aug/29/2003066362/-1/-1/0/CTR_KUBERNETES_HARDENING_GUIDANCE_1.2_20220829.PDF&#34; title=&#34;Kubernetes 加固指南&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 加固指南&lt;/a&gt;，其中详细介绍了不仅是 Pod 级别的改进措施，如有效地使用不可变容器文件系统，还包括网络分离、审计日志和威胁检测。&lt;/p&gt;
&lt;h3 id=&#34;第-5-步插入并播放&#34;&gt;第 5 步：插入并播放&lt;/h3&gt;
&lt;p&gt;在实施了一些或所有已有的加固指南之后，每个新的策略都涉及选择、信任和权衡。花些时间在谷歌或 StackOverflow 上，你就会发现很多推荐的插入和播放策略。&lt;/p&gt;
&lt;p&gt;你可以从众包策略中受益，其中许多来自于那些有着更独特经验的人，但请记住，虽然规则可能是出于良好意图的，但你并不了解推荐者的优先事项或操作上下文。他们知道如何实现某些“高挂水果”政策，因为他们不得不这样做，而不是因为这些政策普遍有价值。&lt;/p&gt;
&lt;p&gt;目前正在进行的辩论是是否以及如何严格限制容器的资源需求。对于请求限制也是如此。不配置限制可能会引入安全风险，但如果严重限制 Pod，它们可能无法正常运行。&lt;/p&gt;
&lt;h3 id=&#34;第-6-步添加自定义规则以应对未预料的特殊情况&#34;&gt;第 6 步：添加自定义规则以应对未预料的特殊情况&lt;/h3&gt;
&lt;p&gt;现在，你已经到了 Kubernetes 策略的远端，远离了导致生产负面影响的 20％的错误配置和漏洞。但即使现在，即使已经实施了所有的最佳实践和集体云原生知识，你仍然无法免疫不会意地引发事故或停机的错误配置 - 安全和稳定的奇妙未知未知。&lt;/p&gt;
&lt;p&gt;一个好的经验法则是，如果一个奇特的（错）配置在生产中引起了两次问题，那么就该将其编码为一条自定义规则，在开发过程中强制执行，或由准入控制器强制执行。它太重要了，不能仅在内部悄悄地记录下来，希望开发人员阅读它，在彼此的拉取请求审查中注意到它并捕获它。&lt;/p&gt;
&lt;p&gt;一旦编码到您现有的策略中，自定义规则就成为了您尽可能接近开发人员执行的防护栏杆。如果你可以在开发人员提交工作之前就用验证到达开发人员，Monokle Cloud 就可以无缝地执行这一点，使用自定义插件和您本地运行的开发服务器，那么您可以节省整个组织大量的重复工作和调整他们的拇指等待 CI/CD 管道无可避免地失败时他们可以构建新功能或修复错误。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;如果您实施了以上所述的所有框架和里程碑，并对您的 Dockerfile 和 Kubernetes 配置进行了所有必要的更改以满足这些新策略，那么您可能会发现您的 90 个主要漏洞清单已经减少到了一个更易管理的数量。&lt;/p&gt;
&lt;p&gt;您正在看到我们逐步塑造和执行 Kubernetes 策略的方法的价值。您与新策略和规则的影响互动得越多，就像 Monokle 在提交之前唯一做到的那样，就越容易在不压垮自己或其他人的情况下逐步迈出步伐。&lt;/p&gt;
&lt;p&gt;您甚至可能会自豪地宣称，您的 Kubernetes 环境完全没有配置错误。这是一种胜利，毫无疑问，但这不是保证 - 总会有新的 Kubernetes 版本、新的应用程序和新的最佳实践融入到您已经完成的工作中。利用框架和加固指南的优势在于，您有更好的共同基础来谈论您在认证、合规和长期安全目标方面的影响。&lt;/p&gt;
&lt;p&gt;对于非专家来说，哪种听起来更有说服力：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;您将 CVE 数量从 90 个降至 X 个，&lt;/li&gt;
&lt;li&gt;还是您完全符合美国国家安全局的 Kubernetes 加固指南？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们越早不再担心数字，而是更多地关注共同里程碑，在应用程序生命周期的早期（理想情况下是 pre-commit！）尽早执行，我们就能找到每个云原生策略的可持续甜蜜点。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes 故障排除智慧的演变</title>
      <link>https://jimmysong.io/trans/can-chatgpt-save-collective-kubernetes-troubleshooting/</link>
      <pubDate>Sun, 10 Sep 2023 19:03:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/can-chatgpt-save-collective-kubernetes-troubleshooting/</guid>
      <description>
        
        
        &lt;p&gt;摘要：本文讨论了在 Kubernetes 故障排除中的两种路径：一种是增强操作员的分析工作，通过自动化和简化对故障排除知识的访问来提供帮助；另一种是将操作员从故障排除中排除，通过使用 AI/ML 模型和可观测性数据来自动化故障修复。同时强调了数据的重要性，以及继续共享故障排除经验和建立对可观测性的一致认识的必要性。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;本文译自：https://thenewstack.io/can-chatgpt-save-collective-kubernetes-troubleshooting/&lt;/p&gt;
&lt;p&gt;数十年前，系统管理员们开始在互联网上分享他们每天面临的技术问题。他们进行了长时间、充满活力且富有价值的讨论，探讨如何调查和解决问题的根本原因，然后详细说明最终对他们有效的解决方案。&lt;/p&gt;
&lt;p&gt;这股洪流从未停歇，只是改变了流向。如今，这些讨论仍在 Stack Overflow、Reddit 以及企业工程博客上进行。每一次讨论都是对全球 IT 系统故障排除经验的宝贵贡献。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://roadmap.sh/kubernetes&#34; title=&#34;Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt;也从根本上改变了这种流向。与几十年来困扰系统管理员和 IT 人员的虚拟机（VM）和单体应用程序相比，&lt;a href=&#34;https://thenewstack.io/microservices/&#34; title=&#34;微服务架构&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务架构&lt;/a&gt;要复杂得多。由于 Kubernetes 缺乏数据持久性，往往无法对规模化的 K8s 错误进行本地重现。即使能够捕获，观测数据也会在多个平台上分散，而资源和依赖关系的相互关联关系也难以捕捉。&lt;/p&gt;
&lt;p&gt;现在，凭直觉并不一定足够。您需要知道如何调试集群以获得下一步的线索。&lt;/p&gt;
&lt;p&gt;这种复杂性意味着公开的故障排除讨论比以往任何时候都更为重要，但现在我们开始看到这股宝贵的洪流不是被重定向，而是完全被堵住了。你在谷歌上看到了这一点。任何与 Kubernetes 相关问题的搜索都会出现一半以上的付费广告和至少一页 SEO 驱动的文章，这些文章缺乏技术深度。&lt;a href=&#34;https://thenewstack.io/stack-overflow-adds-ai-will-the-community-respond/&#34; title=&#34;Stack Overflow&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow&lt;/a&gt; 正在失去其作为技术人员首选问答资源的主导地位，Reddit 在过去几年中也陷入了争议。&lt;/p&gt;
&lt;p&gt;现在，每个 Kubernetes 的 DevOps 平台都在建立最后一个堤坝：将您的故障排除知识集中在其平台上，并用&lt;a href=&#34;https://thenewstack.io/70-percent-of-developers-using-or-will-use-ai-says-stack-overflow-survey/&#34; title=&#34;人工智能（AI）和机器学习（ML）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;人工智能（AI）和机器学习（ML）&lt;/a&gt;取而代之，直到整个堆栈对于甚至是最有经验的云原生工程师来说都成为一个黑盒。当发生这种情况时，您失去了逐个探测、排除故障和修复系统的能力。这种趋势将曾经是众包故障排除技能洪流变成了过去所能提供的仅仅是一滴水。&lt;/p&gt;
&lt;p&gt;当我们依赖于平台时，故障排除技术的集体智慧就会消失。&lt;/p&gt;
&lt;h2 id=&#34;故障排除智慧的传承&#34;&gt;故障排除智慧的传承&lt;/h2&gt;
&lt;p&gt;起初，系统管理员依靠实体书籍进行技术文档和整体最佳实践的实施。随着互联网在 80 年代和 90 年代的普及，这些人通常通过&lt;a href=&#34;https://today.duke.edu/2010/05/usenet.html&#34; title=&#34;Usenet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Usenet&lt;/a&gt;与同行进行交流，并在像 comp.lang.* 这样的新闻组中提出工作中的技术问题，这类新闻组类似于我们今天所知的论坛的简化版本。&lt;/p&gt;
&lt;p&gt;随着互联网的普及迅速，并几乎完全改变了故障排除智慧的洪流。工程师和管理员们不再聚集在新闻组中，而是涌向包括 Experts Exchange 在内的数千个论坛，该论坛于 1996 年上线。在积累了大量的问题和答案之后，Experts Exchange 团队将所有答案都放在了每年 250 美元的付费墙后面，这使得无数宝贵的讨论无法公开获取，最终导致了该网站的影响力下降。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.joelonsoftware.com/2018/04/06/the-stack-overflow-age/&#34; title=&#34;Stack Overflow 随后出现&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Stack Overflow 随后出现&lt;/a&gt;，再次向公众开放了这些讨论，并通过声望点数对讨论进行游戏化，这些声望点数可以通过提供见解和解决方案来获得。其他用户随后对“最佳”解决方案进行投票和验证，这有助于其他搜索者快速找到答案。Stack Overflow 的游戏化、自我管理和社区使其成为了洪流式故障排除知识的唯一渠道。&lt;/p&gt;
&lt;p&gt;但是，就像其他时代一样，没有什么好事能永远持续下去。近 10 年来，人们一直在预测&lt;a href=&#34;https://johnslegers.medium.com/the-decline-of-stack-overflow-7cb69faa575d&#34; title=&#34;“Stack Overflow 的衰落”&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“Stack Overflow 的衰落”&lt;/a&gt;，并指出由于其具有攻击性的性质和由拥有最多声望点数的人进行管理的结构，它“讨厌新用户”。虽然 Stack Overflow 的影响力和流行度确实下降了，但 Reddit 的开发/工程专注的 subreddit 填补了这个空白，它仍然是公开可访问的故障排除知识的最大存储库。&lt;/p&gt;
&lt;p&gt;特别是对于 Kubernetes 和云原生社区来说，这仍然是一个重要的资源，因为它们仍然在经历重大的增长阵痛。而这是一种宝贵的资源，因为如果您认为现在的 Kubernetes 已经很复杂了&amp;hellip;&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-的复杂性问题&#34;&gt;Kubernetes 的复杂性问题&lt;/h2&gt;
&lt;p&gt;在一篇关于“直观调试”失败的精彩文章中，软件交付顾问 Pete Hodgson 认为，构建和交付软件的现代架构（如 Kubernetes 和微服务）比以往任何时候都更加复杂。他写道：“对于我们大多数人来说，为服务器命名为希腊神话角色，并通过 ssh 进入服务器运行&lt;code&gt;tail&lt;/code&gt;和&lt;code&gt;top&lt;/code&gt;的日子已经一去不复返了。”但是，“这种转变是有代价的……传统的理解和故障排除生产环境的方法在这个新世界中已经行不通了。”&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin_hua353e1f3a668859fa4d7a161556969e4_94124_1000x889_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin.jpg&#34; data-img=&#34;/trans/can-chatgpt-save-collective-kubernetes-troubleshooting/cynfin.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;889&#34; alt=&#34;image&#34; data-caption=&#34;Cynefin 模型&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Cynefin 模型&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;&lt;em&gt;Cynefin 模型。来源：维基百科&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Hodgson 使用&lt;a href=&#34;https://en.wikipedia.org/wiki/Cynefin_framework&#34; title=&#34;Cynefin 模型&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cynefin 模型&lt;/a&gt;来说明软件架构过去是复杂的，因为有足够的经验，人们可以理解故障排除和解决方案之间的因果关系。&lt;/p&gt;
&lt;p&gt;他认为，分布式微服务架构是复杂的，即使经验丰富的人对根本原因以及如何进行故障排除也只有“有限的直觉”。他们必须花更多时间通过可观测性数据提出问题和回答问题，最终假设可能出错的原因。&lt;/p&gt;
&lt;p&gt;如果我们同意 Hodgson 的前提 - Kubernetes 本质上是复杂的，并且在响应之前需要花费更多的时间分析问题，那么与 Kubernetes 一起工作的工程师学会了哪些问题最重要，然后用可观测性数据回答，以进行最佳的下一步行动，似乎是至关重要的。&lt;/p&gt;
&lt;p&gt;这正是新一代以 AI 驱动的故障排除平台所提供的智慧。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-故障排除的两种路径&#34;&gt;Kubernetes 故障排除的两种路径&lt;/h2&gt;
&lt;p&gt;多年来，像 OpenAI 这样的公司一直在根据 Stack Overflow、Reddit 等公开数据进行抓取和训练模型，这意味着这些 AI 模型可以访问大量的系统和应用知识，包括 Kubernetes。还有一些人意识到组织的可观测性数据是训练 AI/ML 模型分析新场景的宝贵资源。&lt;/p&gt;
&lt;p&gt;他们都在问同一个问题：我们如何利用关于 Kubernetes 的现有数据来简化搜索最佳解决方案的过程？他们正在构建的产品采取非常不同的路径。&lt;/p&gt;
&lt;h3 id=&#34;第一种增强操作员的分析工作&#34;&gt;第一种：增强操作员的分析工作&lt;/h3&gt;
&lt;p&gt;这些工具自动化和简化对公开在线发布的大量故障排除知识的访问。它们不会取代进行适当故障排除或&lt;a href=&#34;https://aws.amazon.com/opensearch-service/resources/root-cause-analysis/&#34; title=&#34;根本原因分析&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;根本原因分析&lt;/a&gt;（RCA）所需的人类直觉和创造力，而是有条不紊地自动化操作员查找相关信息的方式。&lt;/p&gt;
&lt;p&gt;例如，如果一个刚接触 Kubernetes 的开发人员在运行&lt;code&gt;kubectl get pods&lt;/code&gt;时发现&lt;code&gt;CrashLoopBackOff&lt;/code&gt;状态导致他们无法部署应用程序，他们可以查询一个 AI 驱动的工具以获得建议，比如运行&lt;code&gt;kubectl describe $POD&lt;/code&gt;或&lt;code&gt;kubectl logs $POD&lt;/code&gt;。这些步骤可能会进一步引导开发人员使用&lt;code&gt;kubectl describe $DEPLOYMENT&lt;/code&gt;来调查相关的部署情况。&lt;/p&gt;
&lt;p&gt;在&lt;a href=&#34;https://botkube.io/&#34; title=&#34;Botkube&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Botkube&lt;/a&gt;，我们对使用 AI 在大量故障排除智慧的基础上自动化这个来回查询的概念非常感兴趣。用户应该能够直接在 Slack 中提问，如“我如何排除这个无法正常工作的服务？”并收到 ChatGPT 撰写的回答。在一次公司范围的黑客马拉松活动中，我们着手实施这一概念，为我们的协作故障排除平台构建了一个新的插件。&lt;/p&gt;
&lt;p&gt;通过&lt;a href=&#34;https://botkube.io/blog/use-chatgpt-to-troubleshoot-kubernetes-errors-with-botkubes-doctor&#34; title=&#34;Doctor&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Doctor&lt;/a&gt;，您可以利用大量的故障排除知识，通过 Botkube 作为您的 Kubernetes 集群和消息/协作平台之间的桥梁，无需在 Stack Overflow 或 Google 搜索广告中漫游，这对于新手 Kubernetes 开发人员和操作员特别有用。&lt;/p&gt;
&lt;p&gt;该插件还通过生成一个带有&lt;strong&gt;获取帮助&lt;/strong&gt;按钮的 Slack 消息进一步自动化，用于任何错误或异常，然后查询 ChatGPT 以获取可行的解决方案和下一步操作。您甚至可以将 Doctor 插件的结果导入其他操作或集成，以简化您主动使用现有广泛的 Kubernetes 故障排除知识来更直观地调试和感知问题的方式。&lt;/p&gt;
&lt;h3 id=&#34;第二种将操作员从故障排除中排除&#34;&gt;第二种：将操作员从故障排除中排除&lt;/h3&gt;
&lt;p&gt;这些工具不关心公开知识的泛滥。如果它们可以基于实际的可观测性数据训练通用的 AI/ML 模型，然后根据您的特定架构进行微调，它们可以试图完全剔除人为操作员在根本原因分析和故障修复中的作用。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.causely.io/platform/causely-for-kubernetes-applications/&#34; title=&#34;Causely&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Causely&lt;/a&gt;就是这样一家初创公司，他们并不回避使用 AI 来“消除人为故障排除”的愿景。该平台连接到您现有的可观测性数据，并处理它们以微调因果关系模型，理论上可直接进行修复步骤 - 无需探测或使用&lt;code&gt;kubectl&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;如果说有时候有一个 Kubernetes 神灵听起来很诱人，那我可能会撒谎，但我对像 Causely 这样的工具夺走运维工作并不担心。我担心的是在 Causely 引领的未来中，我们宝贵的故障排除知识会发生什么。&lt;/p&gt;
&lt;h3 id=&#34;这两种路径之间的差距数据&#34;&gt;这两种路径之间的差距：数据&lt;/h3&gt;
&lt;p&gt;我不是在为“人工智能将取代所有 DevOps 工作”发表言论。我们已经读过太多这样的末日场景，适用于每个小众和行业。我更关心这两种路径之间的差距：用于训练和回答问题或呈现结果的数据是什么？&lt;/p&gt;
&lt;p&gt;第一种路径通常使用现有的公开数据。尽管有关 AI 公司爬取这些站点进行训练数据的担忧-Reddit 和 Twitter，但这些数据的开放性仍然提供了一个激励循环，以保持开发人员和工程师继续在 Reddit、Stack Overflow 和其他平台上共享知识的持续泛滥。&lt;/p&gt;
&lt;p&gt;云原生社区通常也倾向于共享技术知识，认同共享技术知识和一个“涨潮（Kubernetes 故障排除技巧的涨潮）抬高所有船（压力巨大的 Kubernetes 工程师）”的想法。&lt;/p&gt;
&lt;p&gt;第二条路径看起来更为暗淡。随着以 AI 驱动的 DevOps 平台的兴起，越来越多的故障排除知识被锁定在这些仪表板和驱动平台的专有 AI 模型中。我们都同意，Kubernetes 基础架构将继续变得更加复杂，而不是更简单，这意味着随着时间的推移，我们对节点、Pod 和容器之间发生的情况的理解将变得更少。&lt;/p&gt;
&lt;p&gt;当我们停止互相分析问题和感知解决方案时，我们变得依赖于平台。这对每个人来说都是一条失败的道路，除了平台之外。&lt;/p&gt;
&lt;h3 id=&#34;我们如何不失去或失去得更少&#34;&gt;我们如何不失去（或失去得更少）？&lt;/h3&gt;
&lt;p&gt;我们能做的最好的事情是继续在线上发布关于我们在 Kubernetes 和其他领域的故障排除经验的惊人内容，比如“&lt;a href=&#34;https://learnk8s.io/troubleshooting-deployments&#34; title=&#34;关于故障排除 Kubernetes 部署的视觉指南&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;关于故障排除 Kubernetes 部署的视觉指南&lt;/a&gt;”；通过游戏化创造教育性应用程序，比如&lt;a href=&#34;https://sadservers.com/&#34; title=&#34;SadServers&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SadServers&lt;/a&gt;；在故障排除系统时采取我们最喜欢的第一步，比如“&lt;a href=&#34;https://rachelbythebay.com/w/2018/03/26/w/&#34; title=&#34;为什么在排除未知机器问题时我通常首先运行‘w’&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;为什么在排除未知机器问题时我通常首先运行‘w’&lt;/a&gt;”；并进行详细的事后分析，详细描述了探测、感知和应对潜在灾难性情况的压力故事，比如&lt;a href=&#34;https://mail.tarsnap.com/tarsnap-announce/msg00050.html&#34; title=&#34;2023 年 7 月的 Tarsnap 故障&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2023 年 7 月的 Tarsnap 故障&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;我们还可以超越技术解决方案，比如讨论我们如何在紧张的故障排除场景中管理和支持同事，或者在组织范围内建立对可观测性的一致认识。&lt;/p&gt;
&lt;p&gt;尽管它们目前面临困境，但 Stack Overflow 和 Reddit 将继续是讨论故障排除和寻求答案的可靠渠道。如果它们最终与 Usenet 和 Experts Exchange 齐名，它们可能会被其他可公开获得的替代品所取代。&lt;/p&gt;
&lt;p&gt;无论何时何地以何种方式发生，我希望您能加入我们在 Botkube 和全新的 Doctor 插件中，为在 Kubernetes 中协作解决复杂问题构建新的渠道。&lt;/p&gt;
&lt;p&gt;无论 AI 驱动的 DevOps 平台是否继续基于抓取的公共 Kubernetes 数据训练新模型，只要我们不自愿地将好奇心、冒险精神和解决问题的能力全部放入这些黑匣子中，就会始终有一条新路径，让宝贵的故障排除知识源源不断地流动。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Docker 发展史：四个重大举措，影响深远！</title>
      <link>https://jimmysong.io/blog/docker-four-milestones/</link>
      <pubDate>Thu, 06 Apr 2023 21:25:40 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/docker-four-milestones/</guid>
      <description>
        
        
        &lt;p&gt;在 2017 年的容器编排大战中，Docker 公司失败后沉寂了几年，但近年来又开始频繁行动，例如腾退开源组织账号，支持 WebAssembly 等。本文将回顾 Docker 公司发展过程中的四个重大举措，这些措施深深地影响了 Docker 公司的发展，也对 Docker 甚至 Kubernetes 社区产生了深远的影响。&lt;/p&gt;
&lt;h2 id=&#34;what-are-we-talking-about-docker&#34;&gt;当我们在谈论 Docker 时我们在谈论什么？&lt;/h2&gt;
&lt;p&gt;首先我们需要先确定 Docker 这个词的含义。当人们在谈论 Docker 时可能指的是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Docker 公司&lt;/li&gt;
&lt;li&gt;Docker 软件栈&lt;/li&gt;
&lt;li&gt;Docker 命令行工具&lt;/li&gt;
&lt;li&gt;Docker 容器运行时&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;为什么同一个词会有这么多不同的意思呢？这都是有历史原因的。Docker 软件于 2013 年发布，起初定位为开发者工具。作为最早发布的容器工具，它迅速走红，并成为容器技术的代名词。但它最初只是在单机上运行，有太多耦合的接口设计。后来容器集群出现，才需要用到容器编排调度工具。因为 Kubernetes 具有丰富的功能和扩展性，Docker 公司推出的 Swarm 在这场容器编排大战中败下阵来。归根结底，Docker 面向开发者，而容器运行时则面向机器，只需要对应的接口即可，不需要那么丰富的管理工具。如今，Docker 仍然是最受开发者喜爱的容器工具之一，其 Docker Hub 是全球最大的镜像仓库。&lt;/p&gt;
&lt;h2 id=&#34;rename-docker-to-moby&#34;&gt;将 Docker 项目改名为 Moby&lt;/h2&gt;
&lt;p&gt;2017 年 4 月，Docker 公司将 Docker 项目重命名为 Moby，详见 &lt;a href=&#34;https://www.docker.com/blog/introducing-the-moby-project/&#34; title=&#34;Introducing Moby Project: a new open-source project to advance the software containerization movement&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introducing Moby Project: a new open-source project to advance the software containerization movement&lt;/a&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/moby/moby&#34; title=&#34;Moby Project&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Moby Project&lt;/a&gt; 是 Docker 公司为了应对容器技术在各个领域和用例中普及的趋势而发起的一个开源项目。&lt;/li&gt;
&lt;li&gt;Moby Project 是 Docker 公司作为一个开放的研发实验室，与整个生态系统合作，实验，开发新的组件，并协作构建容器技术的未来。&lt;/li&gt;
&lt;li&gt;Moby Project 不是 Docker 产品的替代品，而是 Docker 产品的基础。&lt;/li&gt;
&lt;li&gt;Moby Project 包括三个层次：组件层，框架层和装配层。
&lt;ul&gt;
&lt;li&gt;组件层包括一些可复用的开源组件，如 runc, containerd, LinuxKit, InfraKit 等，可以用于构建各种类型的容器系统。&lt;/li&gt;
&lt;li&gt;框架层提供了一些工具和库，用于将组件组装成系统，并管理其生命周期。&lt;/li&gt;
&lt;li&gt;装配层是一个社区驱动的平台，用于分享和协作构建基于 Moby 框架的系统。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Moby Project 是一个新的开源项目，旨在推动软件容器化运动的发展，帮助生态系统让容器技术走向主流。它提供了一个组件库，一个用于将组件组装成定制的基于容器的系统的框架，以及一个让所有容器爱好者可以实验和交流想法的地方。&lt;/p&gt;
&lt;p&gt;Moby Project 和 Docker 的区别和联系是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moby Project 是一个开源项目，Docker 是一个商业产品。&lt;/li&gt;
&lt;li&gt;Moby Project 是 Docker 产品的基础，Docker 产品是 Moby Project 的一个实例。&lt;/li&gt;
&lt;li&gt;Moby Project 是一个通用的框架，可以用于构建各种类型和用例的容器系统，Docker 是一个针对特定用例的容器系统，即构建，运行和共享应用程序。&lt;/li&gt;
&lt;li&gt;Moby Project 是一个开放的研发实验室，用于实验和协作开发新的容器技术，Docker 是一个成熟的产品，用于提供稳定和可靠的容器服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;support-kubernetes&#34;&gt;支持 Kubernetes 调度&lt;/h2&gt;
&lt;p&gt;Docker 公司在 2017 年 12 月发布的 Docker 17.12 版本中开始支持 Kubernetes。在此之前，Docker 公司一直在发展自己的容器编排和调度工具 Docker Swarm。然而，Kubernetes 在容器编排和调度方面具有更广泛的支持和社区贡献，已经成为了业界标准。因此，Docker 公司决定将 Kubernetes 集成到 Docker 平台中，以提供更广泛的选择和更好的用户体验。Docker 公司在 Docker Desktop 和 Docker Enterprise 中提供了 Kubernetes 的集成支持，使得 Kubernetes 和 Docker 容器可以更加方便地部署和管理。同时，Docker 公司也开发了一些工具，如 Kompose 和 Docker Compose，使得用户可以将 Docker Compose 配置文件转换为 Kubernetes YAML 文件，以便更加方便地将应用程序从 Docker Swarm 迁移到 Kubernetes。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-not-support-docker&#34;&gt;Kubernetes 不再支持 Docker 运行时&lt;/h2&gt;
&lt;p&gt;Kubernetes 从 v1.20 起不再支持 Docker 运行时并在 2022 年 4 月发布的 v1.24 中被完全移除，如下图所示。这意味着在 Kubernetes 中只能使用 containerd 或 CRI-O 容器运行时，不过你依然可以使用 Docker 镜像，只是无需使用 docker 命令或 Docker 守护程序。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/docker-four-milestones/cri.svg&#34; data-img=&#34;/blog/docker-four-milestones/cri.svg&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes v1.24 正式移除 Docker 运行时&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes v1.24 正式移除 Docker 运行时&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Kubernetes v1.24 正式移除 Docker 运行时&lt;/p&gt;
&lt;h2 id=&#34;deprecate-open-source-organization&#34;&gt;腾退开源组织账号&lt;/h2&gt;
&lt;p&gt;2023 年 3 月，据 &lt;a href=&#34;https://blog.alexellis.io/docker-is-deleting-open-source-images/&#34; title=&#34;Alex Ellis 的博客&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alex Ellis 的博客&lt;/a&gt; 介绍，Docker 公司决定删除一些开源组织的账户和镜像，除非他们升级到付费的团队计划，这对开源社区造成了很大的困扰和不安。很多 Docker 忠实拥护者和贡献者对 Docker 的这一举动表示了不满和失望。&lt;/p&gt;
&lt;p&gt;这一事件是这样的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker 公司给所有创建过组织的 Docker Hub 用户发了一封邮件，告知他们如果不升级到付费的团队计划，他们的账户和镜像都将被删除。&lt;/li&gt;
&lt;li&gt;这一举动只影响开源社区经常使用的组织账户，个人账户没有变化。&lt;/li&gt;
&lt;li&gt;付费的团队计划每年需要 420 美元，很多开源项目没有足够的资金支持。&lt;/li&gt;
&lt;li&gt;Docker 公司的开源项目计划（DSOS）要求非常苛刻，与开源项目的可持续性相悖。&lt;/li&gt;
&lt;li&gt;Docker 公司的沟通方式非常脱节，引起了开源社区的反感和担忧。&lt;/li&gt;
&lt;li&gt;文章作者建议开源项目使用其他的容器镜像仓库，如 GitHub Container Registry、&lt;a href=&#34;http://quay.io/&#34; title=&#34;Quay.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Quay.io&lt;/a&gt;、各大云厂商的镜像仓库等。&lt;/li&gt;
&lt;li&gt;开源社区还提供了一些迁移镜像和重命名镜像的方法和工具。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;support-webassembly-runtime&#34;&gt;增加对 WebAssembly 运行时的支持&lt;/h2&gt;
&lt;p&gt;2022 年 10 月，Docker 公司发布了 Docker+Wasm 技术预览，这是一个特殊的构建，可以让开发者更容易地使用 Docker 运行 Wasm 工作负载。作为这次发布的一部分，Docker 还宣布将加入 Bytecode Alliance 作为一个投票成员。&lt;/p&gt;
&lt;p&gt;Wasm 是一种新技术，可让你在沙箱环境中运行 40 多种语言的应用程序代码，包括 Rust，C，C++，JavaScript 和 Golang。最初，Wasm 的用例是在浏览器中运行本地代码，如 Figma，AutoCAD 和 Photoshop 等。现在，一些公司如 Vercel，Fastly，Shopify 和 Cloudflare 等支持使用 Wasm 在边缘和云端运行代码。&lt;/p&gt;
&lt;p&gt;Docker+Wasm 技术预览包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker 的目标是帮助开发者通过克服应用开发的复杂性来实现他们的想法。&lt;/li&gt;
&lt;li&gt;Docker 将 Wasm 视为与 Linux 容器相辅相成的技术，开发者可以根据用例选择使用哪种技术（或两者都用）。&lt;/li&gt;
&lt;li&gt;Docker 想要帮助开发者更容易地使用熟悉的经验和工具来开发，构建和运行 Wasm 应用。&lt;/li&gt;
&lt;li&gt;要获取技术预览，需要下载并安装适合你系统的版本，然后启用 containerd 镜像存储（设置 &amp;gt; 开发中的功能 &amp;gt; 使用 containerd 拉取和存储镜像）。&lt;/li&gt;
&lt;li&gt;这个预览支持使用 WasmEdge 运行时引擎运行 Wasm 容器，并可以通过容器仓库如 DockerHub 等分享。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2023 年 3 月 Docker 公司又发布了 Docker+Wasm 技术预览 2，包括了三个新的 Wasm 运行时引擎：Fermyon 的 spin，Deislabs 的 slight，和 Bytecode Alliance 的 wasmtime。&lt;/p&gt;
&lt;p&gt;该版本的主要更新是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Docker+Wasm 技术预览 2 是在 Docker Desktop 4.15 版本中发布的，旨在让开发者更容易地运行 Wasm 工作负载，并扩展运行时支持。&lt;/li&gt;
&lt;li&gt;Docker+Wasm 技术预览 2 支持四种 Wasm 运行时引擎，包括之前已经支持的 WasmEdge，以及新增加的 spin，slight，和 wasmtime。&lt;/li&gt;
&lt;li&gt;这四种 Wasm 运行时引擎都基于 runwasi 库，这是一个 Rust 库，可以让容器管理器 containerd 运行 Wasm 工作负载，并创建一种新的容器类型。&lt;/li&gt;
&lt;li&gt;runwasi 库基于 WASI 标准，这是一个为 WebAssembly 提供通用平台接口的模块化系统接口。这意味着如果一个程序编译成目标是 WASI，它就可以在任何符合 WASI 的运行时上运行。&lt;/li&gt;
&lt;li&gt;Wasm 容器通常只包含一个编译好的 Wasm 字节码文件，不需要任何额外的二进制库，这使得它比 Linux 容器更小。这也意味着 Wasm 容器通常启动更快，更可移植。&lt;/li&gt;
&lt;li&gt;由于 Wasm 容器直接被 containerd 支持，在 Docker Desktop 最新版本中尝试 Docker+Wasm 技术预览 2 只需要启用“使用 containerd”选项。&lt;/li&gt;
&lt;li&gt;通过这种方式，Wasm 容器可以与 Linux 容器一起使用 Docker Compose 或其他编排平台如 Kubernetes 运行。&lt;/li&gt;
&lt;li&gt;此外，Docker Desktop 还能够将一个 Wasm 应用打包成一个 OCI 容器，并在其中嵌入一个 Wasm 运行时，以便通过容器仓库如 DockerHub 等分享。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;summary&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;本文介绍了 Docker 发展过程中的四个重大举措：Moby Project、支持 Kubernetes、删除开源组织账号和增加对 WebAssembly 运行时的支持。其中，Moby Project 旨在推动容器技术走向主流，支持 Kubernetes 的举措提供了更广泛的选择和更好的用户体验，删除开源组织账号的举措引起了开源社区的不满和失望，增加对 WebAssembly 运行时的支持的举措则扩展了 Docker 的应用场景。&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/blog/introducing-the-moby-project/&#34; title=&#34;Introducing Moby Project: a new open-source project to advance the software containerization movement&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introducing Moby Project: a new open-source project to advance the software containerization movement&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/blog/docker-windows-desktop-now-kubernetes/&#34; title=&#34;Docker for Windows Desktop… Now With Kubernetes!&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker for Windows Desktop… Now With Kubernetes!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/blog/docker-wasm-technical-preview/&#34; title=&#34;Introducing the Docker&amp;#43;Wasm Technical Preview&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introducing the Docker+Wasm Technical Preview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.docker.com/blog/announcing-dockerwasm-technical-preview-2/&#34; title=&#34;Announcing Docker&amp;#43;Wasm Technical Preview 2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Announcing Docker+Wasm Technical Preview 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.alexellis.io/docker-is-deleting-open-source-images/&#34; title=&#34;Docker is deleting Open Source organisations - what you need to know&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker is deleting Open Source organisations - what you need to know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/zh-cn/blog/2020/12/02/dont-panic-kubernetes-and-docker/&#34; title=&#34;别慌：Kubernetes 和 Docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;别慌：Kubernetes 和 Docker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes 安全的 6 大零信任原则</title>
      <link>https://jimmysong.io/trans/the-top-6-zero-trust-principles-for-kubernetes-security/</link>
      <pubDate>Tue, 13 Dec 2022 13:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/the-top-6-zero-trust-principles-for-kubernetes-security/</guid>
      <description>
        
        
        &lt;p&gt;传统的网络安全依赖于围绕可信内部网络的强大防御边界，以将不良行为者拒之门外，将敏感数据拒之门外。在日益复杂的网络环境中，维护强大的边界越来越困难。&lt;/p&gt;
&lt;p&gt;零信任安全正在成为企业保护其传统和现代云原生应用程序的首选方法。零信任网络架构颠覆了边界安全的假设。在零信任网络中，每个资源都在内部受到保护，就好像它暴露在开放的互联网中一样。&lt;/p&gt;
&lt;p&gt;为了为行业和美国联邦政府建立零信任安全指南，美国国家标准与技术研究院 (NIST) 在一系列出版物中建立了零信任安全指南，从 SP 800-207 开始，介绍一般的零信任架构及其配套&lt;a href=&#34;https://tetr8.io/3zi85IC&#34; title=&#34;SP 800-204 微服务安全标准系列&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SP 800-204 微服务安全标准系列&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;以下是 NIST 的核心零信任架构原则以及建议在实践中应用它们的 Kubernetes 和 Istio 参考架构。&lt;/p&gt;
&lt;h2 id=&#34;零信任网络的六项原则&#34;&gt;零信任网络的六项原则&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;无论网络位置如何，所有通信都应该是安全的&lt;/strong&gt;。网络位置和可达性并不意味着信任。企业拥有或其他专用网络内部的访问请求必须满足与来自任何其他位置的通信相同的安全要求。零信任系统的一个标准是，您可以将它暴露在开放的互联网上，并且它仍然是安全的，没有未经授权的系统、数据或通信访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;所有通信都应加密&lt;/strong&gt;。线路上的加密可防止窃听，并确保消息真实且未被篡改。这意味着至少为所有通信实施 TLS，将&lt;a href=&#34;https://tetr8.io/3Na982k&#34; title=&#34;mTLS 和相关的安全工作负载身份作为服务间通信的最佳实践&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mTLS 和相关的安全工作负载身份作为服务间通信的最佳实践&lt;/a&gt;。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对每个资源的访问都应该根据动态策略进行身份验证和授权&lt;/strong&gt;。在允许任何访问之前，对服务身份和最终用户凭据进行动态身份验证和授权。访问请求的动态上下文应该是访问决策的一部分。这可能包括行为属性，如与观察到的使用模式的偏差或请求资产的状态，如安装的软件版本、网络位置和请求的时间 / 日期。授予访问权限时，应以所需的最低权限授予它。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对资源的访问应该在空间上有界&lt;/strong&gt;。围绕资源的信任范围应尽可能小 —— 理想情况下为零。访问应该由每个能够检索和执行访问决策的资源前面的策略执行点 (PEP) 进行调解。这应该适用于所有入站、出站和服务到服务的访问。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应及时限制对资源的访问&lt;/strong&gt;。身份验证和授权绑定到一个短暂的会话，之后它们必须重新建立。这可确保频繁做出访问决策，并使用最新的可用上下文。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;对资源的访问应该是可观察的&lt;/strong&gt;。应收集并使用尽可能多的信息来改善安全态势。这允许持续监控所有资产的完整性和安全状况，并持续确保策略执行。此外，应反馈从观察中获得的见解以改进政策。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;为什么零信任安全性更好&#34;&gt;为什么零信任安全性更好&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;网络可达性不是授权&lt;/strong&gt;。与边界安全性不同，对服务的访问不会仅仅因为该服务可访问而被授予。它也必须经过明确的身份验证和授权。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;周边突破口的有限爆炸半径可防止攻击者横向移动&lt;/strong&gt;。经过身份验证和授权的工作负载免受边界破坏。及时限制凭证泄露的风险。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;细粒度策略&lt;/strong&gt;。空间边界允许高粒度的策略执行。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;频繁的政策评估&lt;/strong&gt;。通过在短期会话上执行动态策略来及时绑定可确保授权基于最新的策略。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安全、真实的通信&lt;/strong&gt;。加密和强大的工作负载身份限制了侦察并提供了通信的真实性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;安全状况和合规性的实时和可审计保证&lt;/strong&gt;。细粒度的可观测性允许实时保证和政策实施的事后审计以及故障排除和分析所需的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;如何使用-istio-在-kubernetes-中实现零信任安全现代微服务应用程序的参考架构&#34;&gt;如何使用 Istio 在 Kubernetes 中实现零信任安全：现代微服务应用程序的参考架构&lt;/h2&gt;
&lt;p&gt;作为 NIST 的一般零信任架构标准的补充，NIST 还发布了如何将零信任原则专门应用于微服务应用程序的标准。这些标准由 Tetrate 创始工程师 Zack Butcher 共同编写，并编入&lt;a href=&#34;https://tetr8.io/3zi85IC&#34; title=&#34;NIST 的 SP 800-204 系列&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NIST 的 SP 800-204 系列&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在该标准中，NIST 建立了一个由 Kubernetes 组成的参考平台，用于编排和资源管理，并使用 Istio 服务网格提供核心安全功能。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-安全漏洞&#34;&gt;Kubernetes 安全漏洞&lt;/h2&gt;
&lt;p&gt;由于 Kubernetes 主要专注于编排、资源管理和基本连接，因此它将零信任网络安全问题留给其他方解决。Kubernetes 中的主要网络安全漏洞是（NIST SP 800-204B，§2.1.1）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;默认情况下不安全的通信&lt;/li&gt;
&lt;li&gt;缺少在 pod 之间强制执行 TLS 所需的内置证书管理机制&lt;/li&gt;
&lt;li&gt;缺乏身份和访问管理机制&lt;/li&gt;
&lt;li&gt;在 OSI L3 而非 L7 运行的防火墙策略，因此无法窥视数据包或做出元数据驱动的决策&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;服务网格填补了-kubernetes-的安全漏洞微服务应用程序的安全内核&#34;&gt;服务网格填补了 Kubernetes 的安全漏洞：微服务应用程序的安全内核&lt;/h2&gt;
&lt;p&gt;为了增强 Kubernetes 的安全性，Istio 充当 NIST 参考架构中的安全内核。Istio 满足参考监视器的三个要求（NIST SP 800-204B，§5.1）。Istio 是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不可旁路&lt;/li&gt;
&lt;li&gt;防止修改&lt;/li&gt;
&lt;li&gt;验证和测试是正确的&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Envoy 数据平面通过每个服务前面以及每个入口和出口网关的不可绕过的策略执行点 (PEP) 提供参考监视器。服务网格代码独立于应用程序，因此它的生命周期可以独立管理，并且不能在运行时修改。而且，网格是系统的一个严格控制的元素，可以通过更多的眼睛和更仔细的检查来强化（NIST SP 800-204B，§5.1）。&lt;/p&gt;
&lt;p&gt;而且，作为专用的基础架构层，Istio 提供：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;解决&lt;strong&gt;横切应用程序问题的&lt;/strong&gt;统一方法；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;快速解决这些问题的标准插件&lt;/strong&gt;和构建自定义插件的框架；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;简化&lt;/strong&gt;操作复杂性；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;易于管理&lt;/strong&gt;第三方开发人员和集成商；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;降低&lt;/strong&gt;开发和运营成本。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;下一步&#34;&gt;下一步&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;要从联邦安全标准的合著者那里了解有关&lt;strong&gt;如何实施零信任架构的更多信息，&lt;/strong&gt;&lt;a href=&#34;https://tetr8.io/zta-wp&#34; title=&#34;请阅读 Zack Butcher 的零信任架构白皮书&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;请阅读 Zack Butcher 的零信任架构白皮书&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;有关 NIST 安全建议的深入指南以及 Tetrate 如何帮助您实施该标准，请查看&lt;a href=&#34;https://tetr8.io/3Ccg6Qt&#34; title=&#34;Tetrate 的微服务联邦安全要求指南&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate 的微服务联邦安全要求指南&lt;/a&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果您正在寻找使用 Istio 投入生产的最快方式，请查看我们的开源&lt;a href=&#34;https://istio.tetratelabs.io/&#34; title=&#34;Tetrate Istio Distro (TID)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Istio Distro (TID)&lt;/a&gt;。TID 是经过审查的 Istio 上游发行版 ——Istio 的强化映像，具有持续支持，更易于安装、管理和升级。对于在联邦监管环境中运营的组织，Tetrate Istio Distro 是唯一&lt;a href=&#34;https://istio.tetratelabs.io/fips-request/&#34; title=&#34;具有可用 FIPS 验证构建&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;具有可用 FIPS 验证构建&lt;/a&gt;的 Istio 发行版。&lt;/p&gt;
&lt;p&gt;如果您需要一种统一且一致的方式来保护和管理一系列应用程序中的服务，请查看 &lt;a href=&#34;https://tetrate.io/tetrate-service-bridge/&#34; title=&#34;Tetrate Service Bridge (TSB)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Service Bridge (TSB)&lt;/a&gt;，这是我们基于 Istio 和 Envoy 构建的全面的边缘到工作负载应用程序连接平台。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>零信任 Kubernetes 安全的三大 mTLS 最佳实践</title>
      <link>https://jimmysong.io/trans/top-3-mtls-best-practices-for-zero-trust-kubernetes-security/</link>
      <pubDate>Tue, 13 Dec 2022 10:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/top-3-mtls-best-practices-for-zero-trust-kubernetes-security/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34; title=&#34;Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt; 是编排现代云原生工作负载的事实标准。但是，它不提供开箱即用的安全通信。这意味着每个需要实施传输中加密以对其 Kubernetes 部署&lt;a href=&#34;https://tetr8.io/3FCXsDn&#34; title=&#34;采用零信任安全态势的&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;采用零信任安全态势的&lt;/a&gt;人都需要自己解决这个问题。&lt;/p&gt;
&lt;p&gt;幸运的是，有很多易于理解的方法可以实现，在本文中，我们将介绍在 Kubernetes 中实现双向 TLS（mTLS）的三大最佳实践。&lt;/p&gt;
&lt;h2 id=&#34;什么是-mtls为什么对安全来说很重要&#34;&gt;什么是 mTLS，为什么对安全来说很重要？&lt;/h2&gt;
&lt;p&gt;传输层安全性（SSL 的后继者）是部署最广泛的安全通信标准，在 HTTPS 中最为明显。TLS 非常适合在需要向客户端证明其身份的服务器之间建立既保密（防窃听）又真实（防篡改）的安全通信。但是，在双方都需要向对方证明身份的情况下（例如在 Kubernetes 应用程序中的微服务之间），TLS 是不够的。&lt;/p&gt;
&lt;p&gt;这就是双向 TLS (mTLS) 的用武之地。mTLS 是 TLS，但双方在建立安全通信通道之前向对方证明自己的身份。这是 Kubernetes 中安全通信所需的必要部分。mTLS 提供：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在线加密以确保机密性和防篡改&lt;/li&gt;
&lt;li&gt;相互的、加密的安全身份证明以确保真实性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;要深入了解 mTLS 的工作原理，请参阅我们关于 &lt;a href=&#34;https://tetr8.io/3NEcL0Q&#34; title=&#34;mTLS 的文章&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mTLS 的文章&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;mtls-的困难部分证明身份&#34;&gt;mTLS 的困难部分：证明身份&lt;/h2&gt;
&lt;p&gt;困难的部分是为服务建立一个安全机制来向彼此证明它们的身份。&lt;/p&gt;
&lt;p&gt;对于常规 TLS，过去很难管理向其客户端证明服务器身份的证书。&lt;a href=&#34;https://letsencrypt.org/&#34; title=&#34;随着 Let&amp;amp;rsquo;s Encrypt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;随着 Let&amp;rsquo;s Encrypt&lt;/a&gt; 和 &lt;a href=&#34;https://en.wikipedia.org/wiki/Automatic_Certificate_Management_Environment&#34; title=&#34;ACME 协议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ACME 协议&lt;/a&gt;的出现，这变得容易多了。然而，在像 Kubernetes 这样的动态（并且主要是私有的）环境中管理服务身份和证书更加困难，因为有许多通常是短暂的服务需要强大的、可证明的身份，但实际上不能使用公共 ACME 服务。&lt;/p&gt;
&lt;p&gt;推出自己的自动化证书管理系统是不切实际且有风险的。正确管理 mTLS 证书很困难，错误的后果很严重。您需要一种可信赖的、经过验证的方法来做到这一点；这就是服务网格的用武之地。&lt;/p&gt;
&lt;h2 id=&#34;使用服务网格nist-微服务安全标准&#34;&gt;使用服务网格，NIST 微服务安全标准&lt;/h2&gt;
&lt;p&gt;在&lt;a href=&#34;https://tetr8.io/3zi85IC&#34; title=&#34;微服务安全标准&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务安全标准&lt;/a&gt;中，美国国家标准与技术研究院 (NIST) 建议使用服务网格作为专用基础设施层来提供核心网络安全功能。这些核心功能之一是支持 mTLS 的强大服务身份和证书管理。而且，Istio——&lt;a href=&#34;https://tetr8.io/3UsARgY&#34; title=&#34;使用最广泛的服务网格&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用最广泛的服务网格&lt;/a&gt;—— 为您提供开箱即用的 mTLS 支持。Istio 透明地提供基础设施 —— 包括安全命名、强大的服务身份和证书管理 —— 用于 Kubernetes 工作负载之间的安全通信以及与外界的连接。&lt;/p&gt;
&lt;p&gt;如果您想详细了解 NIST 的微服务安全标准以及 Tetrate 如何帮助满足这些标准，请查看 &lt;a href=&#34;https://tetr8.io/3Ccg6Qt&#34; title=&#34;Tetrate 的微服务联邦安全要求指南&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate 的微服务联邦安全要求指南&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;最佳实践一不要使用自签名证书&#34;&gt;最佳实践一：不要使用自签名证书&lt;/h2&gt;
&lt;p&gt;虽然 Istio 将为您实施 mTLS，但它默认使用自签名证书，因此您可以立即看到网格工作，只需最少的配置。这使得初始用户体验变得简单，但它并非不适合生产环境。NIST 的指南（NIST SP 800-204A，SM-DR12）是完全禁用生成自签名证书的能力。&lt;/p&gt;
&lt;h2 id=&#34;最佳实践二将-istio-的信任根植于现有-pki&#34;&gt;最佳实践二：将 Istio 的信任根植于现有 PKI&lt;/h2&gt;
&lt;p&gt;如果不应该使用 Istio 的默认自签名证书，还有什么选择？简短的回答是，您应该 &lt;a href=&#34;https://tetr8.io/3DDcAOJ&#34; title=&#34;将 Istio 的信任根植于您现有的公钥基础设施 (PKI) 中&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;将 Istio 的信任根植于您现有的公钥基础设施 (PKI) 中&lt;/a&gt;。这将通过确保它们都具有相同的信任根来实现跨其他集群中的 Istio 部署的通信。观看我们关于 &lt;a href=&#34;https://www.youtube.com/watch?v=4b3H7isIAnQ&#34; title=&#34;使用 Istio 的外部 CA 的视频，了解更多信息&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 Istio 的外部 CA 的视频，了解更多信息&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;最佳实践三使用中间证书&#34;&gt;最佳实践三：使用中间证书&lt;/h2&gt;
&lt;p&gt;确切地说，您如何让 Istio 信任您现有的 PKI？Tetrate 的创始工程师和 NIST 微服务安全标准的合著者 Zack Butcher &lt;a href=&#34;https://tetr8.io/3DDcAOJ&#34; title=&#34;在此处提供了所有详细信息&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在此处提供了所有详细信息&lt;/a&gt;。但是，简而言之，我们的建议是使用您组织的根证书颁发机构颁发的中间证书。这将：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;允许细粒度的证书撤销，而无需同时在整个基础架构中强制使用新证书。&lt;/li&gt;
&lt;li&gt;启用签名证书的轻松轮换。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;有关如何自动化 Istio 证书颁发机构 (CA) 轮换的分步说明，请参阅我们关于 &lt;a href=&#34;https://tetrate.io/blog/automate-istio-ca-rotation-in-production-at-scale/&#34; title=&#34;在大规模生产中自动化 Istio CA 轮换的&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在大规模生产中自动化 Istio CA 轮换的&lt;/a&gt;文章。&lt;/p&gt;
&lt;h2 id=&#34;下一步&#34;&gt;下一步&lt;/h2&gt;
&lt;p&gt;如果您不熟悉服务网格和 Kubernetes 安全性，我们在 &lt;a href=&#34;https://tetr8.io/academy&#34; title=&#34;Tetrate Academy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Academy&lt;/a&gt; 提供一系列免费在线课程，可以让您快速了解 Istio 和 Envoy。&lt;/p&gt;
&lt;p&gt;如果您正在寻找一种快速将 Istio 投入生产的方法，请查看 &lt;a href=&#34;https://tetr8.io/tid&#34; title=&#34;Tetrate Istio Distribution (TID)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Istio Distribution (TID)&lt;/a&gt;。TID 是 Tetrate 的强化、完全上游的 Istio 发行版，具有经过 FIPS 验证的构建和支持。这是开始使用 Istio 的好方法，因为您知道您有一个值得信赖的发行版，有一个支持您的专家团队，并且如果需要，还可以选择快速获得 FIPS 合规性。&lt;/p&gt;
&lt;p&gt;一旦启动并运行 Istio，您可能需要更简单的方法来管理和保护您的服务，而不仅仅是 Istio 中可用的方法，这就是 Tetrate Service Bridge 的用武之地。您可以&lt;a href=&#34;https://tetr8.io/tsb&#34; title=&#34;在这里&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在这里&lt;/a&gt;详细了解 Tetrate Service Bridge 如何使服务网格更安全、更易于管理和弹性，或&lt;a href=&#34;https://tetr8.io/contact&#34; title=&#34;联系我们进行快速演示&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;联系我们进行快速演示&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;更多资源&#34;&gt;更多资源&lt;/h2&gt;
&lt;p&gt;观看我们的视频：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4b3H7isIAnQ&#34; title=&#34;使用 Istio 的外部 CA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 Istio 的外部 CA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=nYJJ57WCkxE&#34; title=&#34;Istio Ingress Gateway 中的 SSL 证书&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio Ingress Gateway 中的 SSL 证书&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=o8AnLk4Da7M&#34; title=&#34;如何将服务网格用于混合云和遗留工作负载&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;如何将服务网格用于混合云和遗留工作负载&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=mHR7rR83KjM&#34; title=&#34;如何将 VM 工作负载连接到网格&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;如何将 VM 工作负载连接到网格&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=E_D4bjvX8Xw&amp;amp;t=2s&#34; title=&#34;Tetrate 如何帮助美国国防部将 Istio 用于零信任架构&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate 如何帮助美国国防部将 Istio 用于零信任架构&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes 真的能提供多云可移植性吗？</title>
      <link>https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/</link>
      <pubDate>Wed, 23 Nov 2022 09:16:27 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/</guid>
      <description>
        
        
        &lt;p&gt;从 2017 年起我们就开始与 Kubernetes 社区合作，将 Kubernetes 作为后端容器编排平台，将无数应用程序迁移到云端。其中有些迁移进展顺利，而另一些则颇具挑战性。同样，我们利用云服务提供商（CSP）的本地容器编排解决方案来执行相同的操作，在易于迁移的情况下获得了类似的结果。本文无意讨论这些经验，也无意说明一种技术胜过另一种技术，而是讨论业务领导者和架构师选择利用 Kubernetes 的原因。&lt;/p&gt;
&lt;p&gt;根据我们的经验，根据你的组织结构和运营模式，大规模利用 Kubernetes 比利用其他 CSP 原生解决方案，如 AWS Elastic Container Service（ECS）、AWS Batch、Lambda、Azure App Service、Azure Functions 或 Google Cloud Run 的开销更大。&lt;/p&gt;
&lt;p&gt;Kubernetes 是一种开源容器编排引擎，其本质旨在在任何地方运行。它的架构在如何通过本地使用插件和扩展来实现这种可移植性方面非常出色。但是，&lt;strong&gt;这是集群运维的责任&lt;/strong&gt;，由他们来管理和操作这些插件。我们知道，某些服务（如 EKS、GKE 和 AKS）正在努力改善这种体验。即使那样，你也必须选择你的 Kubernetes 版本，安装和配置插件，并确保你的部署清单、应用程序接口和 Kubernetes 集群公开的 API 以及这些插件之间的兼容性。我们知道这是大多数企业的“正常”维护，不会吓跑他们，但我们想问问为什么。你为什么要承担这项维护工作？当 CSP 原生解决方案保持其 API 的向后兼容性比 Kubernetes 长多年时，为什么要负担这部分开销？当我们推动这个话题时，最常见的反应是业务领导者和架构师担心供应商锁定和 / 或认为他们的应用程序必须在多个 CSP 中积极运行。但是，这些相同的组织中的大多数正在为其数据库利用 CSP 原生解决方案，并且在某些情况下，为其未开发的应用程序利用函数即服务（FaaS）功能。如果一家公司真的担心供应商锁定到这个水平，它应该完全依赖 Kubernetes，运行自己的数据库，并托管所有自己的工具和系统，而不是完全利用 CSP 原生解决方案。利用 FaaS 为其新建应用程序提供服务。&lt;/p&gt;
&lt;p&gt;有些行业（高科技）可能需要工程能力才能在这个级别或规模上运行 Kubernetes，但大多数行业（银行、汽车、制造等）通常没有相同的业务驱动因素。如果你发现自己身处这样的行业，并希望最大限度地发挥云所能带来的价值，那么本文适合你。&lt;/p&gt;
&lt;p&gt;我们实验的结果（详见下文）表明，给定一个应用程序设计为在一个 CSP 的托管 Kubernetes 中运行并与其他 CSP 的服务（例如 DNS、LB、数据库等）集成，它与将该应用程序迁移到另一个 CSP 管理的 Kubernetes 的努力，就像将该应用程序迁移到另一个 CSP 的原生容器编排服务一样。根据我们的调查结果，我们认为，那些仅仅为了未来的可移植性而默认使用 Kubernetes 的组织正在限制云可以为他们提供的价值，尤其是考虑到大量更广泛的技术驱动因素在起作用。对于要最大化云价值的组织，他们应该利用可用于给定工作负载的最高阶 CSP 原生云服务，&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugkjya9j30u010jmzp_hu58ed320c50cef200f490b1c9b6b60238_71305_821x1000_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugkjya9j30u010jmzp.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugkjya9j30u010jmzp.jpg&#34; data-width=&#34;821&#34; data-height=&#34;1000&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;本实验&#34;&gt;本实验&lt;/h2&gt;
&lt;p&gt;我们的工作假设托管 Kubernetes 是一个不错的选择，应用程序架构和数据引力都是云迁移的最大因素。在某些场景下，Kubernetes 是唯一的选择，例如无法在 Google Cloud Run 和 Azure App Service 中运行的应用程序。并非所有 CSP 都提供可以以与 Kubernetes 类似的方式编排容器的服务 —— 相反，这些 CSP 选择提供托管 Kubernetes。因此，我们不会分析属于此类的工作负载，因为如果确实需要多云，它们很可能默认属于 Kubernetes。&lt;/p&gt;
&lt;p&gt;对于我们的实验，我们选择了一个由 Google 发布的 12-factor 应用程序，称为 &lt;a href=&#34;https://github.com/GoogleCloudPlatform/microservices-demo&#34; title=&#34;microservices-demo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;microservices-demo&lt;/a&gt;。然后，我们将应用程序置于谷歌云的 GKE、Azure AKS、AWS EKS 和 AWS ECS 中，并测量了使用 Kubernetes 在所有三个 CSP 之间迁移工作负载的工作量，以及将工作负载从 Google GKE 迁移到 AWS ECS 的工作量。工程工作的结果详述如下，记录的大部分工作是在初始系统设置中。我们认为，所有三种计算解决方案的进一步迁移将大大缩短，但计算解决方案之间也没有区别。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugophbij30s402q0sw_hu74fe78abdb22d1261bf472691c69c1f8_15479_1000x97_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugophbij30s402q0sw.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugophbij30s402q0sw.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;97&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;microservices-demo app 的应用架构如下：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugu4pawj30sg0nc75f_hu2726c733a6a42bcb9d900f38bf836d28_54313_1000x820_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugu4pawj30sg0nc75f.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugu4pawj30sg0nc75f.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;820&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;在应用程序运行且日志中没有错误并将日志卸载到日志聚合解决方案后，我们认为“迁移”已完成。虽然我们承认需要更多的努力来准备好产品生产；应用程序本身不是生产就绪产品，因此我们省略了这个范围。我们还增加了挑战，即我们不会修改微服务演示应用程序的源代码，因为更改源代码可以使我们的工作更轻松并影响我们的发现。&lt;/p&gt;
&lt;h2 id=&#34;gke&#34;&gt;GKE&lt;/h2&gt;
&lt;p&gt;Google 在其 &lt;a href=&#34;https://github.com/GoogleCloudPlatform/microservices-demo&#34; title=&#34;microservices-demo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;microservices-demo&lt;/a&gt; 中提供了所需的 Kubernetes 部署配置；但是，它不提供必要基础设施的代码。我们选择使用 GKE-Autopilot 类型的集群部署，让部署和管理变得更加轻松。&lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview&#34; title=&#34;Autopilot&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Autopilot&lt;/a&gt; 类型的部署确保了 GKE 提供和管理集群的底层基础设施，包括节点和节点池，为我们提供了一个优化的集群和一个无需干预的体验。下面是应用程序在 GKE 中运行的架构。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugmom1pj30sg0pvdi1_hu1ce714a7bc0198d8f69c32fc73faf083_90675_1000x909_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugmom1pj30sg0pvdi1.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugmom1pj30sg0pvdi1.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;909&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;在 GKE 集群中启动和运行应用程序的过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为 GKE 设置所需的 VPC。&lt;/li&gt;
&lt;li&gt;设置必要的 DNS 区域。external-dns 服务将使用这些区域为应用程序创建所需的 DNS 记录。&lt;/li&gt;
&lt;li&gt;使用 Autopilot 构建 GKE 集群&lt;/li&gt;
&lt;li&gt;设置必要的服务帐户权限，以允许 Autopilot 配置基本的集群监控功能。&lt;/li&gt;
&lt;li&gt;为 external-dns 创建必要的服务帐户来管理 DNS 记录。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Kubernetes 部署完成后，还需要为 Kubernetes 部署采取其他步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;安装外部 DNS 服务。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ManagedCertificate&lt;/strong&gt; 需要通过 &lt;strong&gt;networking.gke.io/v1&lt;/strong&gt; API 为负载均衡器上使用的 SSL 证书定义。&lt;/li&gt;
&lt;li&gt;创建了一个使用 GKE &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/concepts/alias-ips&#34; title=&#34;VPC 原生集群中&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VPC 原生集群中&lt;/a&gt;&lt;a href=&#34;https://cloud.google.com/load-balancing/docs/negs#zonal-neg&#34; title=&#34;的网络端点组 (NEG)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;的网络端点组 (NEG)&lt;/a&gt; 的&lt;strong&gt;服务&lt;/strong&gt;定义。Ingress 是使用容器原生负载均衡的推荐方式，因为它具有许多可简化 NEG 管理的功能。当 &lt;a href=&#34;https://cloud.google.com/kubernetes-engine/docs/how-to/container-native-load-balancing&#34; title=&#34;NEG 与 GKE Ingress 一起使用时&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NEG 与 GKE Ingress 一起使用时&lt;/a&gt;，Ingress 控制器有助于创建负载均衡器的所有方面，包括创建虚拟 IP 地址、转发规则、健康检查、防火墙规则等。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FrontEndConfig&lt;/strong&gt; 定义是通过 networking.gke.io/v1beta1 API 创建的，以确保存在将 HTTP 流量重定向到 HTTPS 的规则。&lt;/li&gt;
&lt;li&gt;利用先前创建的服务和 FrontEndConfig 创建了一个新的 **Ingress 。**这个 Ingress 定义也将被 external-dns 服务利用，它将配置必要的记录以指向负载均衡器。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的来说，集群的配置和带有额外配置的微服务演示的部署大约花了两天时间。&lt;/p&gt;
&lt;p&gt;但是，必须注意定义负载均衡器配置并确保将 HTTP 重定向到 HTTPS 的 Ingress 规则使用的 API 仍处于测试阶段 (networking.gke.io/v1beta1)；此配置的另一个关键注意事项是 FrontEndConfig 还将创建另一个负载均衡器来转发流量，如下所示。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugqg2pej312w0dvq3o_hu928f1d7db9dc89e1cfbe5a9c24b781c3_20578_1000x356_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugqg2pej312w0dvq3o.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugqg2pej312w0dvq3o.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;356&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;aks--两天的迁移工作&#34;&gt;AKS — 两天的迁移工作&lt;/h2&gt;
&lt;p&gt;对于 AKS，为了测试可移植性的易用性，我们决定使用利用 &lt;a href=&#34;https://docs.microsoft.com/en-us/azure/aks/virtual-nodes&#34; title=&#34;AKS 虚拟节点&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AKS 虚拟节点&lt;/a&gt;类型部署的 AKS 群集。使用虚拟节点，我们可以快速配置 pod，并且只需按秒为它们的执行时间付费。你无需等待 Kubernetes 集群自动缩放器部署 VM 计算节点来运行额外的 pod。但是，我们注意到微服务演示的&lt;strong&gt;前端&lt;/strong&gt;和 &lt;strong&gt;redis-cart&lt;/strong&gt; 部署的组件在特定负载下会间歇性地失败。因此，我们决定将这些组件部署到一个单独的节点池，并允许将剩余的服务部署到虚拟节点。下面是应用程序在 AKS 中运行的架构。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugrzmjij30sg0m6n00_hu2fa4b84c526c68196db25069b1207557_113081_1000x779_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugrzmjij30sg0m6n00.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8eugrzmjij30sg0m6n00.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;779&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;为了设置集群并部署微服务演示，我们采取了以下步骤：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为 AKS 设置 Azure 网络。作为这项工作的一部分，创建了三个独立的子网，一个用于虚拟节点 (ACI)，一个供网关使用，另一个用于其余集群组件。&lt;/li&gt;
&lt;li&gt;设置必要的 DNS 区域。&lt;/li&gt;
&lt;li&gt;为 AKS 群集设置 Log Analytics 工作区。&lt;/li&gt;
&lt;li&gt;设置 AKS 群集。&lt;/li&gt;
&lt;li&gt;启用了以下 Kubernetes 附加组件：&lt;/li&gt;
&lt;li&gt;监控：Container Insights 监控集群&lt;/li&gt;
&lt;li&gt;虚拟节点 (ACI)：在集群中使用虚拟节点&lt;/li&gt;
&lt;li&gt;ingress-appgw：带有 AKS 群集的应用程序网关入口控制器&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;基础设施完成后，需要完成以下 Kubernetes 部署配置：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;安装和配置&lt;strong&gt;外部 DNS&lt;/strong&gt; 服务&lt;/li&gt;
&lt;li&gt;安装和配置&lt;strong&gt;的证书管理器&lt;/strong&gt;服务&lt;/li&gt;
&lt;li&gt;更改了微服务演示提供的部署定义，以允许通过定义所需的 &lt;strong&gt;nodeSelector&lt;/strong&gt; 和 &lt;strong&gt;tolerations 在虚拟节点节点池上完成部署&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;需要定义使用 ingress-appgw 附加组件和 cert-manager 服务的 Ingress **。**这个 Ingress 定义也将被 external-dns 服务利用，它将配置必要的记录以指向网关。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的来说，集群的配置和带有额外配置的微服务演示的部署大约花了两天时间。&lt;/p&gt;
&lt;p&gt;但是，必须注意的是，由于整个 Kubernetes 体验所需的附加组件和服务，维护此集群所需的工作量增加了。与 GKE Autopilot 不同，需要使用虚拟节点和应用程序网关进行监控的 AKS 附加组件。此外，AKS 需要 cert-manager 服务来自动化负载均衡器上的证书管理。所有这些组件都需要集群管理员进行维护。&lt;/p&gt;
&lt;h2 id=&#34;eks--两天的迁移工作&#34;&gt;EKS — 两天的迁移工作&lt;/h2&gt;
&lt;p&gt;考虑到我们拥有来自 GKE 部署的 Kubernetes 清单，将工作负载转移到 EKS 并不像你想象的那么简单。我们选择不将 Fargate 用于 EKS 实施，因为当时日志记录需要一个 sidecar，我们选择了运行 DaemonSet 的 EC2 来收集日志。下面是 EKS 迁移的架构，后面是对迁移过程的描述。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8euhdkejej30sg0sggol_hu754c7c0fabb81d2fe79d4ad4b5c47f68_116246_1000x1000_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8euhdkejej30sg0sggol.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8euhdkejej30sg0sggol.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;1000&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h3 id=&#34;环境配置&#34;&gt;环境配置&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;为 EKS 设置 VPC。&lt;/li&gt;
&lt;li&gt;设置 Route53 域。&lt;/li&gt;
&lt;li&gt;从 ACM 提供证书。&lt;/li&gt;
&lt;li&gt;构建 EKS 集群。&lt;/li&gt;
&lt;li&gt;为集群供应受管节点组。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;迁移努力&#34;&gt;迁移努力&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;安装 Kubernetes 插件：&lt;/li&gt;
&lt;li&gt;外部 DNS 插件&lt;/li&gt;
&lt;li&gt;AWS 负载均衡器控制器&lt;/li&gt;
&lt;li&gt;使用 Fluent Bit 的 AWS Container Insights&lt;/li&gt;
&lt;li&gt;修改 Kubernetes 清单以使用新插件：&lt;/li&gt;
&lt;li&gt;修改了 &lt;strong&gt;nodeSelector&lt;/strong&gt; 和 &lt;strong&gt;tolerations&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;为处理创建 ALB、管理 R53 记录和应用先前创建的证书的应用程序的外部公开端点创建入口定义&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个过程花了我们大约两天的时间，其中大部分时间用于分析我们需要哪些插件才能通过 EKS 生态系统实现我们的目标。&lt;/p&gt;
&lt;p&gt;但是，与 AKS 配置非常相似，我们有一些插件需要安装、监控和运行，以便应用程序在 EKS 集群中成功运行。因此，组织将承担这些第三方插件的升级、维护和事件管理的负担。&lt;/p&gt;
&lt;h2 id=&#34;ecs--两天的迁移工作&#34;&gt;ECS — 两天的迁移工作&lt;/h2&gt;
&lt;p&gt;将工作负载转移到 ECS 起初似乎是一项艰巨的工作，但并不是那么具有挑战性。在让应用程序运行时，我们遇到了一个重大挑战。该应用程序使用其 GRPC 调用的不安全设置进行了硬编码。这导致了几个小时的挠头，因为我们可以直接访问容器，但无法通过 AWS Application Load Balancer 访问它们，因为 ALB 现在不支持 GRPC 的未加密流量。这不是 EKS 的问题，因为服务到服务的调用确实利用 ALB 进行东 / 西流量，以支持内置的 Kubernetes 服务。虽然这看起来像是一个障碍，但我们能够快速转向使用 AWS Cloud Map 来代替服务到服务的流量。解决 GRPC 问题后，ECS 解决方案的架构和步骤如下：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8euhbqubij30o80sg418_hu663567dbc379537d756334624793b8ce_105241_852x1000_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8euhbqubij30o80sg418.jpg&#34; data-img=&#34;/trans/does-kubernetes-really-give-you-multicloud-portability/008vxvgGgy1h8euhbqubij30o80sg418.jpg&#34; data-width=&#34;852&#34; data-height=&#34;1000&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h3 id=&#34;环境配置-1&#34;&gt;环境配置&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;为 ECS 设置 VPC。&lt;/li&gt;
&lt;li&gt;设置 Route53 域。&lt;/li&gt;
&lt;li&gt;从 ACM 提供证书。&lt;/li&gt;
&lt;li&gt;设置 Cloud Map。&lt;/li&gt;
&lt;li&gt;设置配置了 Fargate 和 Container Insights 的 ECS 集群。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;ecs-迁移工作&#34;&gt;ECS 迁移工作&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;利用来自 GKE 部署的 Kubernetes 清单来编写将部署 ECS 任务、ECS 服务、Route53 记录、配置 ALB 和配置 Cloud Map 的 Terraform 脚本。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这个过程花了我们大约两天的时间，我们让应用程序运行并记录日志，而实现日志记录所需的虚拟机和插件为零。&lt;/p&gt;
&lt;p&gt;ECS 与所有其他基于 Kubernetes 的部署之间最大的开发工作差异在于 ECS 任务和服务部署 Terraform 脚本的创建。这些花了一个下午的时间来编写，但是一旦我们编写了一次代码，我们就能够将它重新用于所有其他服务。在这种情况下，平台升级、维护和事件管理的维护负担转移到责任共担模型的 AWS 端，从而使组织的员工腾出时间来更多地关注驱动业务价值的差异化代码。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;总而言之，部署到托管 Kubernetes 不能被认为是完全可移植的（或可移植性的银弹），因为你需要安装和管理附加组件或服务以确保应用程序被部署和配置为它应该是样子。你在部署拓扑的核心组件上花费的时间更少，并且当你希望拥有关键功能时，大多数依赖于云的配置都会发挥作用，例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;自动 DNS 记录管理&lt;/li&gt;
&lt;li&gt;自动化托管证书&lt;/li&gt;
&lt;li&gt;监控&lt;/li&gt;
&lt;li&gt;负载均衡器管理&lt;/li&gt;
&lt;li&gt;秘密整合&lt;/li&gt;
&lt;li&gt;缩放&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果你使用托管节点（例如，AWS Fargate、AKS 虚拟节点、GKE Autopilot），你将遇到可能影响应用程序行为的限制，例如无法托管状态或使用守护进程集类型部署。回退到受管节点意味着，作为集群管理员，你现在负责管理升级和扩展。综上所述，Kubernetes 是企业维护性更高的解决方案，但这并不是坏事，因为它也是最灵活的解决方案。&lt;/p&gt;
&lt;p&gt;虽然肯定存在与 CSP 服务相关的云可移植性问题，但我们认为将这些问题应用于容器编排时并没有多大意义。从 GKE 迁移到 ECS Fargate 的努力类似于从 GKE 迁移到 EKS/AKS 的努力，我们认为这证明了“可移植性”的论点并没有真正站得住脚。当你转向利用高阶计算服务并开始将你的数据也转移到 CSP 管理的服务时，云中的供应商锁定在某种程度上是不可避免的。Kubernetes 是一个强大的工具，如果你有充分的技术原因（其中有很多），或者只是需要应用程序在云内外运行，那么 Kubernetes 可能适合你。然而，如果你想了解有关容器和多云可移植性的更多信息，我们的同事最近发表了&lt;a href=&#34;https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/getting-the-most-from-cloud-services-and-containers&#34; title=&#34;一篇文章&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一篇文章&lt;/a&gt;来讨论这一点。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>2022 年容器生态系统的 9 大趋势洞察</title>
      <link>https://jimmysong.io/trans/container-insights-2022/</link>
      <pubDate>Mon, 07 Nov 2022 10:16:27 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/container-insights-2022/</guid>
      <description>
        
        
        &lt;p&gt;这项研究建立在 Datadog 以前版本的&lt;a href=&#34;https://www.datadoghq.com/container-report-2021/&#34; title=&#34;容器使用报告&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;容器使用报告&lt;/a&gt;、&lt;a href=&#34;https://www.datadoghq.com/container-orchestration-2018/&#34; title=&#34;容器编排报告&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;容器编排报告&lt;/a&gt;和&lt;a href=&#34;https://www.datadoghq.com/docker-adoption/&#34; title=&#34;Docker 研究报告&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker 研究报告&lt;/a&gt;的基础上。&lt;/p&gt;
&lt;p&gt;现代工程团队继续扩展他们对容器的使用，如今基于容器的微服务应用程序无处不在。不断增长的容器使用正在推动组织采用互补技术来简化他们操作集群的方式，而这种不断扩展的容器环境给组织带来了安全挑战。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;在本报告中，我们检查了数万 Datadog 客户&lt;/strong&gt;运行的超过&lt;strong&gt;15 亿个容器&lt;/strong&gt;，以了解容器生态系统的状态。继续阅读，了解从最新的实际使用数据中收集的更多见解和趋势。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“这项调查表明，容器和 Kubernetes 革命正在不断发展壮大。结果揭示了使用容器和 Kubernetes 的云原生组织不仅发展得更快，而且获得了更大的信心——在比以往任何时候都更关键的生产环境中构建和部署更大型的应用程序和工作负载。&lt;/p&gt;
&lt;p&gt;得益于云原生生态系统中超过 175,000 名贡献者所推动的创新，云原生组织已为前进的道路做好了准备。他们正在创造可以让各种规模的工程团队都可以构建和运行应用程序的技术，以满足当今应用程序的需求。”&lt;/p&gt;
&lt;p&gt;— Priyanka Sharma，云原生计算基金会执行董事&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;趋势-1kubernetes-继续成为最受欢迎的容器管理系统&#34;&gt;趋势 1：Kubernetes 继续成为最受欢迎的容器管理系统&lt;/h2&gt;
&lt;p&gt;Kubernetes 比以往任何时候都更受欢迎。如今，近一半的容器组织运行 Kubernetes 来在不断发展的生态系统中部署和管理容器。Amazon Elastic Kubernetes Services (Amazon EKS) Blueprints 和 Amazon EKS Anywhere 等工具以及其他托管 Kubernetes 服务使团队可以轻松地在云中和本地运行 Kubernetes 集群。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wbyje5nkj30ku0ce757_hu605150b9258dcb402e9cb6fc94bc1f44_44318_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wbyje5nkj30ku0ce757.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wbyje5nkj30ku0ce757.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;“在 AWS，我们致力于为客户提供简化的 Kubernetes 体验，以便他们可以轻松管理和扩展集群，同时受益于完全托管的 AWS 服务的安全性和弹性。Amazon EKS Blueprints 和 Amazon EKS Anywhere 等新功能使客户能够更快、更轻松地跨 AWS 和本地环境配置和部署 Kubernetes 集群，因此他们可以在任何需要的地方获得相同、一致的 Amazon EKS 体验，以最好地支持他们的应用程序和最终用户。”&lt;/p&gt;
&lt;p&gt;— Barry Cooks，Amazon Web Services Kubernetes 副总裁&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;趋势-2无服务器容器技术在所有主要公共云中继续流行&#34;&gt;趋势 2：无服务器容器技术在所有主要公共云中继续流行&lt;/h2&gt;
&lt;p&gt;所有主要云提供商（包括 AWS App Runner、AWS Fargate、Azure Container Apps、Azure Container Instances (ACI) 和 Google Cloud Run）对无服务器容器技术的使用率从 2020 年的 21% 增加到 2022 年的 36%（年初至今）。这与我们在之前的研究中看到的增长相呼应，其中包括 Amazon ECS 用户转向 AWS Fargate。&lt;/p&gt;
&lt;p&gt;客户将减少配置和管理底层基础设施的需求列为容器采用无服务器技术的主要原因之一。那些不使用无服务器技术的客户更喜欢从管理自己的基础架构中获得的控制力和灵活性。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc0jp6mjj30ku0cewff_hu39dc4ec478403961eec2451ba1b23b7b_44951_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc0jp6mjj30ku0cewff.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wc0jp6mjj30ku0cewff.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;趋势-3多个云提供商的使用随着组织规模的增加而增加&#34;&gt;趋势 3：多个云提供商的使用随着组织规模的增加而增加&lt;/h2&gt;
&lt;p&gt;我们的数据显示，超过 30% 的使用 1,000 台或更多主机的容器组织在多个云中工作，并且组织运行的容器越少，多云使用率最低。此外，我们发现多云组织平均拥有比单云组织更多的容器。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc690cy0j30ku0ce750_hu7839fd102fc72384767579a5d4c0fc88_37329_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc690cy0j30ku0ce750.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wc690cy0j30ku0ce750.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;趋势-4kubernetes-ingress-使用率正在上升&#34;&gt;趋势 4：Kubernetes Ingress 使用率正在上升&lt;/h2&gt;
&lt;p&gt;为了大规模管理来自集群外部的请求，管理员经常使用 Ingress 来配置到集群中多个服务的路由。如今，超过 35% 的组织使用 Ingress，自 2020 年 8 月 Kubernetes 1.19 版本发布以来，Ingress 已经普遍可用。&lt;/p&gt;
&lt;p&gt;随着我们的客户操作更多的集群和 Pod，他们在路由和网络管理方面面临着越来越复杂的问题。许多 Kubernetes 的早期采用者使用云提供的负载均衡器将流量路由到他们的服务。但 Ingress 通常更具成本效益，并且自发布以来其采用率稳步提高。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gateway-api.sigs.k8s.io/&#34; title=&#34;Kubernetes Gateway API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Gateway API&lt;/a&gt;（于 2022 年 7 月完成测试版）是容器网络管理发展的下一步。Gateway API 提供高级网络功能，包括使用自定义资源和使用 API 资源对组织角色建模的面向角色的设计。我们期待看到 Gateway API 是否会取代 Ingress，或者这两种技术是否并排使用。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc8i70cdj30ku0cemxs_hu2be42c66794fdbe0bfd064929bc61fa2_33419_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc8i70cdj30ku0cemxs.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wc8i70cdj30ku0cemxs.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;趋势-5服务网格仍处于早期阶段istio-主导使用&#34;&gt;趋势 5：服务网格仍处于早期阶段，Istio 主导使用&lt;/h2&gt;
&lt;p&gt;服务网格提供服务发现、负载均衡、超时和重试，并允许管理员管理集群的安全性并监控其性能。我们之前的研究说明了服务网格的早期采用，我们看到的初始模式基本上没有变化。在我们的客户中，我们主要看到 Istio 和 Linkerd，其中 Istio 的受欢迎程度是 Linkerd 的三倍多。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc9fn7llj30ku0cewf3_hua9ba05b02f68f5f1da6d5e648485c71c_32702_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wc9fn7llj30ku0cewf3.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wc9fn7llj30ku0cewf3.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;“服务网格已经证明了为企业中的流量提供一致的安全性、可观测性和控制的价值。Istio 已明确将自己确立为领先的网格解决方案，我为社区为实现这一目标所做的工作感到自豪。最近完成的对 CNCF 的 Istio 捐赠将在这一成功的基础上发展壮大我们的社区。”&lt;/p&gt;
&lt;p&gt;——Louis Ryan，Istio 的联合创始人兼谷歌首席工程师&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;趋势-6大多数主机使用超过-18-个月的-kubernetes-版本&#34;&gt;趋势 6：大多数主机使用超过 18 个月的 Kubernetes 版本&lt;/h2&gt;
&lt;p&gt;Kubernetes 每年发布三个新版本，为用户提供新功能、安全改进和错误修复。我们在之前的研究中看到，用户通常更愿意等待一年多才能采用这些新版本。我们从轶事中了解到，一些客户延迟的原因是为了确保他们的集群的稳定性和与 API 版本的兼容性。如今，使用最多的版本是 v1.21，它于 2021 年 4 月发布，并于今年早些时候正式过了生命周期终结日。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcb5u0w5j30ku0cemy5_hu4386b95a1fb37efe49663ffff23a9aec_46952_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcb5u0w5j30ku0cemy5.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wcb5u0w5j30ku0cemy5.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;趋势-7超过-30-的运行-containerd-的主机使用不受支持的版本&#34;&gt;趋势 7：超过 30% 的运行 containerd 的主机使用不受支持的版本&lt;/h2&gt;
&lt;p&gt;先前的研究表明 containerd 的使用有所增加，这是组织可以采用的符合 CRI 的运行时之一，因为 Dockershim 正在被弃用。我们发现只有大约 69% 的 containerd 主机使用的是 1.5 或 1.6 版本，这是积极支持的版本。值得注意的是，大约 31% 的 containerd 主机正在使用 1.4 或更早的版本，这些版本已经过了生命周期的终结日。&lt;/p&gt;
&lt;p&gt;运行较旧的软件版本会带来有关安全性和合规性的问题，并且在容器运行时的情况下，会带来容器逃逸等漏洞的风险。许多主机使用不受支持的容器运行时版本这一事实凸显了组织在运行适当的工具以维护容器安全性和合规性方面面临的挑战。无服务器容器技术降低了过时运行时的风险和手动更新的负担，这可能是我们看到所有云都转向无服务器容器的原因之一。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcc9pjexj30ku0ce74y_hu64bc7a46b62035664bc4afffd0f51a2d_35026_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcc9pjexj30ku0ce74y.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wcc9pjexj30ku0ce74y.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;趋势-8访问管理正在改进但仍然是一个挑战&#34;&gt;趋势 8：访问管理正在改进，但仍然是一个挑战&lt;/h2&gt;
&lt;p&gt;Kubernetes 管理员使用基于角色的访问控制 (RBAC) 来允许主体（用户、组或服务账户）访问或修改集群中的资源。根据安全最佳实践，主体应该只有必要的权限，并且管理员在授予与升级风险相关的 RBAC 权限时必须谨慎。其中包括允许主体列出所有机密或创建工作负载、证书或令牌请求的权限，这些请求可以允许他们修改自己的权限。&lt;/p&gt;
&lt;p&gt;好消息是，随着组织部署更多集群，这些集群中使用过度宽松特权的百分比正在下降。我们怀疑随着组织采用权限审计等安全实践和自动化 RBAC 扫描仪等工具，这一数字正在下降。但是，我们发现大约 40% 的集群仍然使用宽松的权限，这会带来安全风险。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcdev59yj30ku0cet9l_hu2fa4e16bec496df813eb68081cdd0522_42964_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcdev59yj30ku0cet9l.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wcdev59yj30ku0cet9l.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;h2 id=&#34;趋势-9nginxredis-和-postgres-再次成为最受欢迎的容器镜像&#34;&gt;趋势 9：NGINX、Redis 和 Postgres 再次成为最受欢迎的容器镜像&lt;/h2&gt;
&lt;p&gt;截至 2022 年 9 月，最流行的现成容器镜像是：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;NGINX：这又是最流行的容器镜像。NGINX 为近 50% 的使用容器的组织提供缓存、负载平衡和代理功能。&lt;/li&gt;
&lt;li&gt;Redis：组织可以在容器中部署 Redis，用作键值数据存储、缓存或消息代理。&lt;/li&gt;
&lt;li&gt;Postgres：这个关系数据库的使用比去年略有增长。&lt;/li&gt;
&lt;li&gt;Elasticsearch：这个高性能的文档存储和搜索引擎仍然是最流行的镜像之一。&lt;/li&gt;
&lt;li&gt;Kafka：组织可以通过在容器中部署 Kafka 轻松地将事件流功能添加到应用程序中。&lt;/li&gt;
&lt;li&gt;RabbitMQ：RabbitMQ 在基于微服务的应用程序中支持解耦架构。&lt;/li&gt;
&lt;li&gt;MongoDB：MongoDB 仍然是最流行的 NoSQL 数据库之一。&lt;/li&gt;
&lt;li&gt;MySQL：这个开源数据库的排名比以前低。但是 MySQL 的性能和可扩展性使其在最流行的容器镜像列表中持续占有一席之地。&lt;/li&gt;
&lt;li&gt;Calico：Calico 是一个网络提供商，让管理员可以管理其 Kubernetes 集群内网络的安全性。&lt;/li&gt;
&lt;li&gt;GitLab：为了帮助团队采用和维护 DevOps 实践，GitLab 提供了存储库管理、问题跟踪和 CI/CD 管道。&lt;/li&gt;
&lt;li&gt;Vault：团队可以使用 Vault 来简化机密管理并帮助维护安全的应用程序。&lt;/li&gt;
&lt;/ol&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcim7nrxj30ku0cedgh_hu7b25f414d7b794f44f800c2cb4645b0c_34231_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wcim7nrxj30ku0cedgh.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wcim7nrxj30ku0cedgh.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;在 Kubernetes StatefulSets 中，我们发现 Redis、Postgres、Elasticsearch、RabbitMQ 和 Kafka 是最常部署的镜像。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wciyjri3j30ku0cet9d_hu638fd65250758e5537c5ba125e597e2b_34833_750x446_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/container-insights-2022/008vxvgGgy1h7wciyjri3j30ku0cet9d.jpg&#34; data-img=&#34;/trans/container-insights-2022/008vxvgGgy1h7wciyjri3j30ku0cet9d.jpg&#34; data-width=&#34;750&#34; data-height=&#34;446&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;

      </description>
    </item>
                           
    <item>
      <title>Gateway API：Kubernetes 和服务网格入口中网关的未来</title>
      <link>https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/</link>
      <pubDate>Wed, 02 Nov 2022 11:18:40 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/</guid>
      <description>
        
        
        &lt;p&gt;本文将以 Kubernetes Ingress、Istio 和 Envoy Gateway 为例，向你介绍 Kubernetes 中的入口网关和 Gateway API，同时介绍 Gateway API 使得 Kubernetes 和服务网格入口网关融合的新趋势。&lt;/p&gt;
&lt;h2 id=&#34;本文观点&#34;&gt;本文观点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ingress 作为 Kubernetes 的初代入口网关，它的资源模型过于简单以致于无法适应当今的可编程网络；&lt;/li&gt;
&lt;li&gt;Gateway API 作为 Kubernetes 入口网关的最新成果，它通过角色划分将关注点分离，并提供跨 namespace 支持使其更适应多云环境，已获得大多数 API 网关的支持；&lt;/li&gt;
&lt;li&gt;入口网关（南北向）与服务网格（东西向，集群内路由）存在部分功能重叠，Gateway API 为两者的融合提供了新的参考模型；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-入口网关的历史&#34;&gt;Kubernetes 入口网关的历史&lt;/h2&gt;
&lt;p&gt;2014 年 6 月 Kubernetes 开源，起初只能使用 NodePort 和 LoadBalancer 类型的 Service 对象来暴露集群内服务，后来才诞生了 &lt;a href=&#34;https://kubernetes.io/zh-cn/docs/concepts/services-networking/ingress/&#34; title=&#34;Ingress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress&lt;/a&gt;，两年后（Kubernetes 1.2）Ingress API 进入 Beta 版本，随后为了保持其轻量和可移植的特性，Ingress API 相较于 Kubernetes 其他 API 发展得比较缓慢，直到 Kubernetes 1.19 它才升级到 GA。&lt;/p&gt;
&lt;p&gt;Ingress 的主要目标是用简单的、声明性的语法来暴露 HTTP 应用。你可以在 Kubernetes 中部署多种 Ingress Controller，并在创建 Ingress 的时候通过 IngressClass 指定该网关使用的控制器，或者在 Kubernetes 中设置默认的默认的 IngressClass。Kubernetes 默认只支持 AWS、GCE 和 Nginx Ingress Controller，同时还支持大量的&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/#additional-controllers&#34; title=&#34;第三方 Ingress Controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;第三方 Ingress Controller&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下图展示了 Kubernetes Ingress 的工作流程。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/ingress-flow.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/ingress-flow.svg&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes Ingress 工作流程&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes Ingress 工作流程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;详细流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Kubernetes 集群管理员在 Kubernetes 中部署 Ingress Controller；&lt;/li&gt;
&lt;li&gt;Ingress Controller 会持续监视 Kubernetes  API Server 中的 IngressClass 和 Ingress 对象的变动；&lt;/li&gt;
&lt;li&gt;管理员应用 IngressClass 和 Ingress 来部署网关；&lt;/li&gt;
&lt;li&gt;Ingress Controller 会根据管理员的配置来创建对应的入口网关并配置路由规则；&lt;/li&gt;
&lt;li&gt;如果在云中，客户端会访问该入口网关的负载均衡器；&lt;/li&gt;
&lt;li&gt;网关将根据 HTTP 请求中的 host 和 path 将流量路由到对应的后端服务；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Istio 同时支持 Ingress 和 Gateway API，下面是一个使用 Istio 入口网关的配置示例，在后文中会使用 Gateway API 创建该配置。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IngressClass&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;controller&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio.io/ingress-controller&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ingressClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;pathType&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;service&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意：Ingress 的 spec 中必须在 &lt;code&gt;ingressClassName&lt;/code&gt; 字段中指定使用的 &lt;code&gt;IngressClass&lt;/code&gt;，否则将无法创建对应的入口网关。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-ingress-的局限性&#34;&gt;Kubernetes Ingress 的局限性&lt;/h2&gt;
&lt;p&gt;虽然 &lt;code&gt;IngressClass&lt;/code&gt; 实现了入口网关与后台实现的解耦，但是它仍然有着巨大的局限性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ingress 的配置过于简单，仅支持 HTTP 协议路由；&lt;/li&gt;
&lt;li&gt;HTTP 路由仅支持 host 和 path 匹配，对于高级路由功能没有通用配置，只能通过 annotation 来实现，比如&lt;a href=&#34;https://help.aliyun.com/document_detail/86533.html#section-xsg-g5g-1uy&#34; title=&#34;使用 Nginx Ingress Controller 实现 URL 重定向&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 Nginx Ingress Controller 实现 URL 重定向&lt;/a&gt;，需要配置 &lt;code&gt;nginx.ingress.kubernetes.io/rewrite-target&lt;/code&gt; annotation，已经无法适应可编程路由的需求；&lt;/li&gt;
&lt;li&gt;不同命名空间中的服务要绑定到同一个网关中的情况在实际情况下经常出现，而入口网关无法在多个命名空间中共享；&lt;/li&gt;
&lt;li&gt;入口网关的创建和管理的职责没有划分界限，导致开发者不仅要配置网关路由，还需要自己创建和管理网关；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-gateway-api&#34;&gt;Kubernetes Gateway API&lt;/h2&gt;
&lt;p&gt;Gateway API 是一个 API 资源的集合 —— &lt;code&gt;GatewayClass&lt;/code&gt;、&lt;code&gt;Gateway&lt;/code&gt;、&lt;code&gt;HTTPRoute&lt;/code&gt;、&lt;code&gt;TCPRoute&lt;/code&gt;、&lt;code&gt;ReferenceGrant&lt;/code&gt; 等。Gateway API 暴露了一个更通用的代理 API，可以用于更多的协议，而不仅仅是 HTTP，并为更多的基础设施组件建模，为集群运营提供更好的部署和管理选项。&lt;/p&gt;
&lt;p&gt;另外 Gateway API 通过将资源对象分离，实现配置上的解耦，可以由不同的角色的人员来管理，其中的 API 对象如下图所示。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/gateway-api-roles.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/gateway-api-roles.svg&#34; alt=&#34;image&#34; data-caption=&#34;Gateway API 及角色&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Gateway API 及角色&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;下面是在 Istio 中使用 Gateway API 的示例。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway.networking.k8s.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gatewayClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;listeners&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostname&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;*.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;allowedRoutes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;All&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway.networking.k8s.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;parentRefs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio-ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;httpbin.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;PathPrefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backendRefs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;与 Ingress 类似，Gateway 使用 &lt;code&gt;gatewayClassName&lt;/code&gt; 声明其使用的控制器，该控制器需要平台管理员创建，并允许客户端对 &lt;code&gt;*.example.com&lt;/code&gt; 域名的请求。应用开发者可以在其服务所在的命名空间中，在此示例中是 &lt;code&gt;default&lt;/code&gt; 创建路由规则，并通过 &lt;code&gt;parentRefs&lt;/code&gt; 绑定到 Gateway 上，当然这必须是在 Gateway 明确允许其绑定的情况下（通过 &lt;code&gt;allowRoutes&lt;/code&gt; 字段中的规则设置）。&lt;/p&gt;
&lt;p&gt;当你应用上面的配置后，Istio 会自动为你创建一个负载均衡网关，下图展示了 Gateway API 的工作流程。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/gateway-api-flow.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/gateway-api-flow.svg&#34; alt=&#34;image&#34; data-caption=&#34;Gateway API 工作流程&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Gateway API 工作流程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;详细流程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基础设施供应商提供了 &lt;code&gt;GatewayClass&lt;/code&gt; 和 Gateway 控制器；&lt;/li&gt;
&lt;li&gt;平台运维部署 Gateway（可以部署多个，或使用不同的 &lt;code&gt;GatewayClass&lt;/code&gt;）；&lt;/li&gt;
&lt;li&gt;Gateway Controller 会持续监视 Kubernetes  API Server 中的 &lt;code&gt;GatewayClass&lt;/code&gt; 和 &lt;code&gt;Gateway&lt;/code&gt; 对象的变动；&lt;/li&gt;
&lt;li&gt;Gateway Controller 会根据集群运维的配置来创建对应的网关；&lt;/li&gt;
&lt;li&gt;应用开发者应用 xRoute 并绑定服务上；&lt;/li&gt;
&lt;li&gt;如果在云中，客户端会访问该入口网关的负载均衡器；&lt;/li&gt;
&lt;li&gt;网关将根据流量请求中的匹配条件将路由到对应的后端服务；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;从以上步骤中我们可以看出 Gateway API 相比 Ingress 有了明确的角色划分，而且路由规则可以与网关配置解耦，这大大增加了管理的灵活性。&lt;/p&gt;
&lt;p&gt;下图展示了流量接入网关后经过处理的流程。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/traffic-flow.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/traffic-flow.svg&#34; alt=&#34;image&#34; data-caption=&#34;网关处理流程图&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;网关处理流程图&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;从图中我们可以看出路由是与网关绑定的，路由一般与其后端服务部署在同一个命名空间中，如果在不同的命名空间中时，需要在 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/api-types/referencegrant/&#34; title=&#34;&amp;lt;code&amp;gt;ReferenceGrant&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;ReferenceGrant&lt;/code&gt;&lt;/a&gt; 中明确赋予该路由跨命名空间的引用权限，例如下面的 &lt;code&gt;foo&lt;/code&gt; 命名空间中的 HTTPRoute &lt;code&gt;foo&lt;/code&gt; 可以引用 &lt;code&gt;bar&lt;/code&gt; 命名空间中的 &lt;code&gt;bar&lt;/code&gt; 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/bar&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;forwardTo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;---&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ReferenceGrant&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.gateway.k8s.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;to&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;目前，Gateway API 仅支持 &lt;code&gt;HTTPRoute&lt;/code&gt;，&lt;code&gt;TCPRoute&lt;/code&gt;、&lt;code&gt;UDPRoute&lt;/code&gt;、&lt;code&gt;TLSRoute&lt;/code&gt; 和 &lt;code&gt;GRCPRoute&lt;/code&gt; 还在实验阶段。Gateway API 已经得到了大量的网关和服务网格项目的支持，请&lt;a href=&#34;https://gateway-api.sigs.k8s.io/implementations/&#34; title=&#34;在 Gateway 官方文档中查看支持状况&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在 Gateway 官方文档中查看支持状况&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;入口网关与服务网格&#34;&gt;入口网关与服务网格&lt;/h2&gt;
&lt;p&gt;服务网格主要关注的是东西向流量，即 Kubernetes 集群内部的流量，但是大部分服务网格同样提供了入口网关功能，例如 Istio。但是 Istio 的功能和 API 过于复杂，在本文中我们就以 SMI 为例来说明入口网关和服务网格的关系。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://smi-spec.io/&#34; title=&#34;SMI&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SMI&lt;/a&gt;（Service Mesh Interface）是 CNCF 的孵化项目，开源与 2019 年，它定义了独立于供应商的在 Kubernetes 中运行的服务网格通用标准。&lt;/p&gt;
&lt;p&gt;下图说明 Gateway API 与服务网格 API 的重叠点。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/gateway-smi-overlay.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/gateway-smi-overlay.svg&#34; alt=&#34;image&#34; data-caption=&#34;Gateway API 与 SMI 有部分重合&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Gateway API 与 SMI 有部分重合&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;从图中我们可以看到 Gateway API 与 SMI 在流量规范部分有明显的重叠。这些重叠导致同样的功能，需要在 Gateway API 和服务网格中重复实现。&lt;/p&gt;
&lt;h3 id=&#34;istio-服务网格&#34;&gt;Istio 服务网格&lt;/h3&gt;
&lt;p&gt;当然，并不是所有的服务网格是完全符合 SMI 标准，Istio 是目前最流行的服务网格实现，它提供了丰富的流量管理功能，但是没有对这些功能制定单独的策略 API，而是耦合在 &lt;code&gt;VirtualService&lt;/code&gt; 和 &lt;code&gt;DestinationRule&lt;/code&gt; 中，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VirtualService&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;路由：金丝雀发布、基于用户身、URI、Header 等匹配路由等；&lt;/li&gt;
&lt;li&gt;错误注入：HTTP 错误代码注入、HTTP 延时注入；&lt;/li&gt;
&lt;li&gt;流量切分：基于百分比的流量切分路由；&lt;/li&gt;
&lt;li&gt;流量镜像：将一定百分比的流量镜像发送到其他集群；&lt;/li&gt;
&lt;li&gt;超时：设置超时时间，超过设置的时间请求将失败；&lt;/li&gt;
&lt;li&gt;重试：设置重试策略，如触发条件、重试次数、间隔时间等；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;DestinationRule&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负载均衡：设置负载均衡策略，如简单负载均衡、区域感知负载均衡、区域权重负载均衡；&lt;/li&gt;
&lt;li&gt;熔断（Circuit Breaking）：通过异常点检测（Outlier Detection）和连接池设置将异常节点从负载均衡池中剔除；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;VirtualService&lt;/code&gt; 主要处理路由相关功能，而 &lt;code&gt;DestinationRule&lt;/code&gt; 负责集群节点的开合和负载均衡。&lt;/p&gt;
&lt;h3 id=&#34;gateway-api-融合-kubernetes-和服务网格的入口网关&#34;&gt;Gateway API 融合 Kubernetes 和服务网格的入口网关&lt;/h3&gt;
&lt;p&gt;正如上文所述，Gateway API 与服务网格之间有部分功能交集，为了减少重复开发，促成对 Gateway API 与服务网格之间共同关注点的建模，Gateway API 工作组提出了 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/contributing/gamma/&#34; title=&#34;GAMMA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GAMMA&lt;/a&gt;（Gateway API Mesh Management and Administration）倡议。&lt;/p&gt;
&lt;p&gt;在该倡议的倡导下，那些在不同网关实现中的细节各不相同的高级流量管理功能，例如超时、重试、健康检查等，全部通过&lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/policy-attachment/&#34; title=&#34;策略附件&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;策略附件&lt;/a&gt;（Policy Attachment）的方式将由各个提供商来实现。你可以通过通过 &lt;code&gt;targetRef&lt;/code&gt; 字段指定策略附件所附加到的资源对象，例如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.acme.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;RetryPolicy&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;override&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxRetries&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;maxRetries&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;targetRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;gateway.networking.k8s.io/v1alpha2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在这里例子中重试策略被附加到了名为 &lt;code&gt;foo&lt;/code&gt; 和 &lt;code&gt;HTTPRoute&lt;/code&gt; 上。策略附件附加到不同的资源对象上，其生效的优先级也不同，例如 GatewayClass 是集群级的资源，如果策略附件覆盖在它上面的话，将优先生效。&lt;/p&gt;
&lt;p&gt;你可以给附加策略指定 &lt;code&gt;override&lt;/code&gt; 和 &lt;code&gt;default&lt;/code&gt; 值，其在入口和网格内不同资源上的层次结构的优先级是如下图所示。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/policy-attachment-priority.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/policy-attachment-priority.svg&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes 入口与网格中的覆盖和默认值的优先级&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes 入口与网格中的覆盖和默认值的优先级&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;目前，Gateway API 正在探索用来处理网格流量，并提出了一些&lt;a href=&#34;https://docs.google.com/document/d/1T_DtMQoq2tccLAtJTpo3c0ohjm25vRS35MsestSL9QU/edit#heading=h.6ks49gf06yii&#34; title=&#34;设计方案&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;设计方案&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;envoy-gateway&#34;&gt;Envoy Gateway&lt;/h2&gt;
&lt;p&gt;2022 年 10 月 Envoy Gateway 首个开源版本 &lt;a href=&#34;https://jimmysong.io/blog/envoy-gateway-release/&#34; title=&#34;v0.2 发布&#34;&gt;v0.2 发布&lt;/a&gt;，这是一个基于 Envoy 代理的遵循 Gateway API 而创建的网关，&lt;a href=&#34;https://tetrate.io&#34; title=&#34;Tetrate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate&lt;/a&gt; 是该项目的核心发起者之一。Envoy Gateway 的目标是降低用户采用 Envoy 作为 API 网关的障碍，以吸引更多用户采用 Envoy。它通过入口和 L4/L7 流量路由，表达式、可扩展、面向角色的 API 设计，使其成为供应商建立 API 网关增值产品的基础。&lt;/p&gt;
&lt;p&gt;早在 Envoy Gateway 发布之前，Envoy 作为最流行了云原生代理之一，已被大规模采用，有多款 Gateway 软件基于 Envoy 构建，Istio 服务网格使用它作为默认的 sidecar 代理，并通过 xDS 协议来配置这些分布式代理。在 Envoy Gateway 中，它同样使用 xDS 来配置 Envoy 集群，下图展示了 Envoy Gateway 的架构。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/envoy-gateway-arch.svg&#34; data-img=&#34;/blog/why-gateway-api-is-the-future-of-ingress-and-mesh/envoy-gateway-arch.svg&#34; alt=&#34;image&#34; data-caption=&#34;Envoy Gateway 架构图&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Envoy Gateway 架构图&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;基础设施供应商会为你提供 &lt;code&gt;GatewayGlass&lt;/code&gt;，你可以通过创建一个 Gateway 声明来创建一个 Envoy Gateway，你在 Gateway 中的路由和策略附件会通过 xDS 协议发送给 Envoy 集群。&lt;/p&gt;
&lt;p&gt;关于 Envoy Gateway 的进一步介绍，请阅读：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/hands-on-with-envoy-gateway/&#34; title=&#34;使用 Envoy Gateway 0.2 体验新的 Kubernetes Gateway API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 Envoy Gateway 0.2 体验新的 Kubernetes Gateway API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/envoy-gateway-to-the-future/&#34; title=&#34;面向未来的网关：新的 Kubernetes Gateway API 和 Envoy Gateway 0.2 介绍&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;面向未来的网关：新的 Kubernetes Gateway API 和 Envoy Gateway 0.2 介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;Gateway API 作为下一代 Kubernetes Ingress API，为 Kubernetes 网关供应商提供一定程度上的 API 规范，在保证其可移植性的前提下丰富了入口网关的功能，同时通过关注点分离方便不同角色的人员对网关进行管理。最后 GAMMA 倡议正在促进服务网格的入口网关与 Gateway API 的融合，策略附件可能将 Gateway API 的功能进一步扩展到东西向网关，我们拭目以待。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/book/kubernetes-handbook/service-discovery/gateway/&#34; title=&#34;Gateway API - jimmysong.io&#34;&gt;Gateway API - jimmysong.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://atbug.com/explore-k8s-gateway-api-policy-attachment/&#34; title=&#34;一文搞懂 Kubernetes Gateway API 的 Policy Attachment - atbug.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一文搞懂 Kubernetes Gateway API 的 Policy Attachment - atbug.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://atbug.com/why-smi-collaborating-in-gateway-api-gamma/&#34; title=&#34;SMI 与 Gateway API 的 GAMMA 倡议意味着什么？- atbug.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SMI 与 Gateway API 的 GAMMA 倡议意味着什么？- atbug.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kccncna19.sched.com/#&#34; title=&#34;Evolving the Kubernetes Ingress APIs to GA and Beyond - Christopher M Luciano, IBM &amp;amp;amp; Bowei Du, Google&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Evolving the Kubernetes Ingress APIs to GA and Beyond - Christopher M Luciano, IBM &amp;amp; Bowei Du, Google&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>如何理解 Istio Ingress，它与 API Gateway 有什么区别？</title>
      <link>https://jimmysong.io/blog/istio-servicemesh-api-gateway/</link>
      <pubDate>Fri, 06 Aug 2021 10:22:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/istio-servicemesh-api-gateway/</guid>
      <description>
        
        
        &lt;p&gt;API 网关作为客户端访问后端的入口，已经存在很长时间了，它主要是用来管理”南北向“的流量；近几年服务网格开始流行，它主要是管理系统内部，即“东西向”流量，而像 Istio 这样的服务网格还内置了网关，从而将系统内外部的流量纳入了统一管控。这经常给初次接触 Istio 的人带来困惑——服务网格与 API 网关之间是什么关系？是不是使用了 Istio 就可以替代了 API 网关？Istio 的 API 网关是如何运作的？有哪些方式暴露 Istio mesh 中的服务？这篇文章给为你解答。&lt;/p&gt;
&lt;h2 id=&#34;主要观点&#34;&gt;主要观点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;服务网格诞生的初衷是为了解决分布式应用的内部流量的管理问题，而在此之前 API 网关已存在很久了。&lt;/li&gt;
&lt;li&gt;虽然 Istio 中内置了 Gateway，但是你仍可以使用自定义的 Ingress Controller 来代理外部流量。&lt;/li&gt;
&lt;li&gt;API 网关和服务网格正朝着融合的方向发展。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;如何暴露-istio-mesh-中的服务&#34;&gt;如何暴露 Istio mesh 中的服务？&lt;/h2&gt;
&lt;p&gt;下图展示了使用 Istio Gateway、Kubernetes Ingress、API Gateway 及 NodePort/LB 暴露 Istio mesh 中服务的四种方式。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/istio-servicemesh-api-gateway/access-cluster.svg&#34; data-img=&#34;/blog/istio-servicemesh-api-gateway/access-cluster.svg&#34; alt=&#34;image&#34; data-caption=&#34;暴露 Kubernetes 中服务的几种方式&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;暴露 Kubernetes 中服务的几种方式&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;其中阴影表示的是 Istio mesh，mesh 中的的流量属于集群内部（东西向）流量，而客户端访问 Kubernetes 集群内服务的流量属于外部（南北向）流量。不过因为 Ingress、Gateway 也是部署在 Kubernetes 集群内的，这些节点访问集群内其他服务的流量就难以归属了。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;方式&lt;/th&gt;
&lt;th&gt;控制器&lt;/th&gt;
&lt;th&gt;功能&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NodePort/LoadBalancer&lt;/td&gt;
&lt;td&gt;Kubernetes&lt;/td&gt;
&lt;td&gt;负载均衡&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Kubernetes Ingress&lt;/td&gt;
&lt;td&gt;Ingress Controller&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、流量路由&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Istio Gateway&lt;/td&gt;
&lt;td&gt;Istio&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、高级流量路由、其他 Istio 的高级功能&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;API 网关&lt;/td&gt;
&lt;td&gt;API Gateway&lt;/td&gt;
&lt;td&gt;负载均衡、TLS、虚拟主机、流量路由、API 生命周期管理、权限认证、数据聚合、账单和速率限制&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;由于 NodePort/LoadBalancer 是 Kubernetes 内置的基本的暴露服务的方式，本文就不讨论这种方式了。下文将对其他三种方式分别作出说明。&lt;/p&gt;
&lt;h2 id=&#34;使用-kubernetes-ingress-暴露服务&#34;&gt;使用 Kubernetes Ingress 暴露服务&lt;/h2&gt;
&lt;p&gt;我们都知道 Kubernetes 集群的客户端是无法直接访问 Pod 的 IP 地址的，因为 Pod 是处于 Kubernetes 内置的一个网络平面中。我们可以将 Kubernetes 内的服务使用 NodePort 或者 LoadBlancer 的方式暴露到集群以外。同时为了支持虚拟主机、隐藏和节省 IP 地址，可以使用 &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34; title=&#34;Ingress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress&lt;/a&gt; 来暴露 Kubernetes 中的服务。Kubernetes Ingress 原理如下图所示。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/istio-servicemesh-api-gateway/ingress.svg&#34; data-img=&#34;/blog/istio-servicemesh-api-gateway/ingress.svg&#34; alt=&#34;image&#34; data-caption=&#34;使用 Kubernetes Ingress 暴露服务&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;使用 Kubernetes Ingress 暴露服务&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;简单的说，Ingress 就是从 Kubernetes 集群外访问集群的入口，将用户的 URL 请求转发到不同的服务上。Ingress 相当于 Nginx、Apache 等负载均衡方向代理服务器，其中还包括规则定义，即 URL 的路由信息，路由信息得的刷新由 &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/#ingress-controllers&#34; title=&#34;Ingress controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress controller&lt;/a&gt;来提供。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;annotations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kubernetes.io/ingress.class&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/status/*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;上面的例子中的 &lt;code&gt;kubernetes.io/ingress.class: istio&lt;/code&gt; 注解表明该 Ingress 使用的 Istio Ingress Controller。&lt;/p&gt;
&lt;h2 id=&#34;使用-istio-gateway-暴露服务&#34;&gt;使用 Istio Gateway 暴露服务&lt;/h2&gt;
&lt;p&gt;我们都知道 Istio 是继承 Kubernetes 之后发展出来的一个流行的服务网格实现，它实现了 Kubernetes 没有的一些功能，请参考&lt;a href=&#34;https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/&#34; title=&#34;什么是 Istio？为什么 Kubernetes 需要 Istio？&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;什么是 Istio？为什么 Kubernetes 需要 Istio？&lt;/a&gt;简要来说，正是因为 Istio 补足了 Kubernetes 对于云原生应用的流量管理、可观测性和安全方面的短板，使得流量管理变得对应用程序透明，使这部分功能从应用程序中转移到了平台层，成为了云原生基础设施。&lt;/p&gt;
&lt;p&gt;Istio 0.8 以前版本中使用 Kubernetes &lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress/&#34; title=&#34;Ingress&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress&lt;/a&gt; 来作为流量入口，其中使用 Envoy 作为 Ingress Controller。在 Istio 0.8 及以后的版本中，Istio 创建了 Gateway 对象。Gateway 和 VirtualService 用于表示 Istio Ingress 的配置模型，Istio Ingress 的缺省实现则采用了和 sidecar 相同的 Envoy 代理。通过该方式，Istio 控制面用一致的配置模型同时控制了入口网关和内部的 sidecar 代理。这些配置包括路由规则，策略检查、遥测收集以及其他服务管控功能。&lt;/p&gt;
&lt;p&gt;Istio Gateway 的功能与 Kubernetes Ingress 类似，它负责进出集群的南北流量。Istio Gateway 描述了一个负载均衡器，用于承载进出服务网格边缘的连接。该规范描述了一组开放端口和这些端口所使用的协议，以及用于负载均衡的 SNI 配置等。&lt;/p&gt;
&lt;p&gt;Istio Gateway 资源本身只能配置 L4 到 L6 的功能，例如暴露的端口、TLS 设置等；但 Gateway 可与 VirtualService 绑定，在 VirtualService 中可以配置七层路由规则，例如按比例和版本的流量路由，故障注入，HTTP 重定向，HTTP 重写等所有 Mesh 内部支持的路由规则。&lt;/p&gt;
&lt;p&gt;下面是一个 Gateway 与 VirtualService 绑定的示例。拥有 &lt;code&gt;istio: ingressgateway&lt;/code&gt; 标签的 pod 将作为 Ingress Gateway 并路由对 &lt;code&gt;httpbin.example.com&lt;/code&gt; 虚拟主机的 80 端口的 HTTP 访问，这相当于给 Kubernetes 敞开了一个外部访问的入口。这与使用 Kubernetes Ingress 最大的区别就是，需要我们手动将 VirtualService 与 Gateway 绑定，并指定 Gateway 所在的 pod。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;istio&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ingressgateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;80&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTP&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;httpbin.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面这个 VirtualService 通过 &lt;code&gt;gateways&lt;/code&gt; 与上面的网关绑定在了一起，以接受来自该网关的流量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.istio.io/v1alpha3&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;VirtualService&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hosts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;httpbin.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateways&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;httpbin-gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;uri&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;prefix&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/status&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;route&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;destination&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;number&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;httpbin&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;使用-api-网关暴露服务&#34;&gt;使用 API 网关暴露服务&lt;/h2&gt;
&lt;p&gt;API 网关是位于客户端和后端服务之间的 API 管理工具，一种将客户端接口与后端实现分离的方式，在微服务中得到了广泛的应用。当客户端发出请求时，API 网关会将其分解为多个请求，然后将它们路由到正确的位置，生成响应，并跟踪所有内容。&lt;/p&gt;
&lt;p&gt;API Gateway 是微服务架构体系中的一类型特殊服务，它是所有微服务的入口，它的职责是执行路由请求、协议转换、聚合数据、认证、限流、熔断等。大多数企业 API 都是通过 API 网关部署的。API 网关通常会处理跨 API 服务系统的常见任务，例如用户身份验证、速率限制和统计信息。&lt;/p&gt;
&lt;p&gt;在网格中可以有一个或多个 API Gateway。API 网关的职责有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;请求路由和版本控制&lt;/li&gt;
&lt;li&gt;方便单体应用到微服务的过渡&lt;/li&gt;
&lt;li&gt;权限认证&lt;/li&gt;
&lt;li&gt;数据聚合：监控和计费&lt;/li&gt;
&lt;li&gt;协议转换&lt;/li&gt;
&lt;li&gt;消息和缓存&lt;/li&gt;
&lt;li&gt;安全和报警&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上很多基本功能比如路由和权限认证通过 Istio Gateway 也可以实现，只是在功能的丰富度和扩展性方面有些成熟的 API Gateway 可能更占优势，不过在 Istio mesh 中再引入 API Gateway 也可能带来一些弊端。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;引入了 API Gateway，需要考虑 API Gateway 本身的部署、运维、负载均衡等场景，增加了后端服务的复杂度&lt;/li&gt;
&lt;li&gt;API Gateway 中承载了大量的接口适配，导致难以维护&lt;/li&gt;
&lt;li&gt;对于部分场景，增加了一跳可能导致性能的降低&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在 Istio mesh 中你可以使用多种 Kubernetes Ingress Controller 来充当入口网关，当然你还可以直接使用 Istio 内置的 Istio 网关，对于策略控制、流量管理和用量监控可以直接通过 Istio 网关来完成，这样做的好处是通过 Istio 的控制平面来直接管理网关，而不需要再借助其他工具。但是对于 API 生命周期管理、复杂的计费、协议转换和认证等功能，传统的 API 网关可能更适合你。所以，你可以根据自己的需求来选择，也可以组合使用。&lt;/p&gt;
&lt;p&gt;目前有些传统的反向代理也在向 Service Mesh 方向发展，如 Nginx 构建了 &lt;a href=&#34;https://www.nginx.com/products/nginx-service-mesh/&#34; title=&#34;Nginx Service Mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nginx Service Mesh&lt;/a&gt;，Traefik 构建了 &lt;a href=&#34;https://traefik.io/traefik-mesh/&#34; title=&#34;Traefik Mesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Traefik Mesh&lt;/a&gt;。还有的 API 网关产品也向 Service Mesh 方向挺进，比如 Kong 发展出了 &lt;a href=&#34;https://kuma.io&#34; title=&#34;Kuma&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kuma&lt;/a&gt;。在未来，我们会看到更多 API 网关、反向代理和服务网格的融合产品出现。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/evolving-kubernetes-networking-with-the-gateway-api/&#34; title=&#34;利用 Gateway API 发展 Kubernetes 网络&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;利用 Gateway API 发展 Kubernetes 网络&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/how-to-pick-gateway-for-service-mesh/&#34; title=&#34;如何为服务网格选择入口网关？&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;如何为服务网格选择入口网关？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/service-mesh-and-api-gateway/&#34; title=&#34;Service Mesh 和 API Gateway 关系深度探讨&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service Mesh 和 API Gateway 关系深度探讨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/using-traefik-ingress-controller-with-istio-service-mesh/&#34; title=&#34;在 Istio 服务网格中使用 Traefik Ingress Controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在 Istio 服务网格中使用 Traefik Ingress Controller&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>服务网格之旅——使用 Kubernetes 和 Istio Service Mesh 构建混合云</title>
      <link>https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/</link>
      <pubDate>Mon, 12 Jul 2021 22:22:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/</guid>
      <description>
        
        
        &lt;p&gt;这篇文章将带你了解使用 Kubernetes 和 Istio Service Mesh 构建多集群及混合云的过程和需要考虑的问题。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes&#34;&gt;Kubernetes&lt;/h2&gt;
&lt;p&gt;使用 Kubernetes 可以快速部署一个分布式环境，实现了云的互操作性，统一了云上的控制平面。并提供了 Service、Ingress 和 &lt;a href=&#34;https://kubernetes.io/blog/2021/04/22/evolving-kubernetes-networking-with-the-gateway-api/&#34; title=&#34;Gateway&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway&lt;/a&gt; 等资源对象来处理应用程序的流量。如下图所示，Kubernetes 中默认使用 Service 做服务注册和发现，服务之间可以使用服务名称来访问。Kubernetes API Server 与集群内的每个节点上的 &lt;code&gt;kube-proxy&lt;/code&gt; 组件通信，为节点创建 iptables 规则，并将请求转发到其他 pod 上。&lt;/p&gt;
&lt;p&gt;假定现在客户端要访问 Kubernetes 中的服务，首先请求会发送到 Ingress/Gateway 上，然后根据 Ingress/Gateway 里的路由配置转发到后端服务上（图中是服务 A），接着服务 A 对服务 B 请求的流量转发轮询到服务 B 的实例上。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg6a11l1j31lu0u042s_huc6b38aa7e76d49a90fd6d5b84ee198c4_101197_2082x1080_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg6a11l1j31lu0u042s.jpg&#34; data-img=&#34;/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg6a11l1j31lu0u042s.jpg&#34; data-width=&#34;2082&#34; data-height=&#34;1080&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;kubernetes-多集群管理&#34;&gt;Kubernetes 多集群管理&lt;/h2&gt;
&lt;p&gt;多集群管理最常见的使用场景包括服务流量负载均衡、隔离开发和生产环境、解耦数据处理和数据存储、跨云备份和灾难恢复、灵活分配计算资源、跨区域服务的低延迟访问以及避免厂商锁定等。一个企业内部往往有多个 Kubernetes 集群，由 MultiCluster SIG 开发的 KubeFed 实现 Kubernetes 集群联邦可以实现多集群管理的功能，这使得所有 Kubernetes 集群都通过同一个接口来管理。&lt;/p&gt;
&lt;p&gt;在使用集群联邦时需要解决以下几个通用问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;配置需要联邦哪些集群&lt;/li&gt;
&lt;li&gt;需要在集群中传播的 API 资源&lt;/li&gt;
&lt;li&gt;配置 API 资源如何分配到不同的集群&lt;/li&gt;
&lt;li&gt;对集群中 DNS 记录注册以实现跨集群的服务发现&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面是 KubeSphere 的多集群架构，也是最常用的一种 Kubernetes 多集群管理架构，其中 Host Cluster 作为控制平面，有两个成员集群，分别是 West 和 East。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg7a2ojvj31aa0u0491_hu6bf3df7ee7d747ee7a83c900fe11d701_142568_1666x1080_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg7a2ojvj31aa0u0491.jpg&#34; data-img=&#34;/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg7a2ojvj31aa0u0491.jpg&#34; data-width=&#34;1666&#34; data-height=&#34;1080&#34; alt=&#34;image&#34; data-caption=&#34;Multicluster&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Multicluster&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Host 集群需要能够访问 Member 集群的 API Server，Member 集群之间的网络连通性没有要求。管理集群 Host Cluster 独立于其所管理的成员集群，Member Cluster 并不知道 Host Cluster 存在，这样做的好处是当控制平面发生故障时不会影响到成员集群，已经部署的负载仍然可以正常运行，不会受到影响。&lt;/p&gt;
&lt;p&gt;Host 集群同时承担着 API 入口的作用，由 Host Cluster 将对 Member 集群的资源请求转发到 Member 集群，这样做的目的是方便聚合，而且也利于做统一的权限认证。我们看到在 Host Cluster 中有联邦控制平面，其中的 Push Reconciler 会将联邦集群中身份、角色及角色绑定传播到所有成员集群中。&lt;/p&gt;
&lt;h2 id=&#34;istio&#34;&gt;Istio&lt;/h2&gt;
&lt;p&gt;当我们在 Kubernetes 中运行着多语言、多版本的微服务，并需要更细粒度的金丝雀发布和统一的安全策略管理，实现服务间的可观测性时，可以考虑使用 Istio 服务网格。Istio 通过向应用程序 Pod 中注入 sidecar proxy，缺省使用 IPTables 透明得拦截进出应用程序的所有流量，从而实现了应用层到集群中其他启用服务网格的服务的智能应用感知负载均衡，并绕过了初级的 kube-proxy 负载均衡。Istio 控制平面与 Kubernetes API Server 通信可以获取集群中所有注册的服务信息。&lt;/p&gt;
&lt;p&gt;下图展示了 Istio 的基本原理，其中所有节点属于同一个 Kubernetes 集群。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg6sdrk2j32v60u0qbb_hu4a5a28b1404560a5b16a7cb9c4a5c77c_188375_3714x1080_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg6sdrk2j32v60u0qbb.jpg&#34; data-img=&#34;/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg6sdrk2j32v60u0qbb.jpg&#34; data-width=&#34;3714&#34; data-height=&#34;1080&#34; alt=&#34;image&#34; data-caption=&#34;Istio Service Mesh&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Istio Service Mesh&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;你可能最终会有至少几个 Kubernetes 集群，每个集群都承载着微服务。Istio 的多集群部署根据网络隔离、主备情况存在多种&lt;a href=&#34;https://istio.io/latest/docs/setup/install/multicluster/&#34; title=&#34;部署模式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;部署模式&lt;/a&gt;，可以使用 Istio Operator 部署时通过声明来指定。集群中的这些微服务之间的通信可以通过服务网格来加强。在集群内部，Istio 提供通用的通信模式，以提高弹性、安全性和可观测性。&lt;/p&gt;
&lt;p&gt;以上都是关于 Kubernetes 上的应用负载管理，但是对于虚拟机上遗留应用，如何在同一个平面中管理？如何管理多集群中的流量划分、网关和安全性呢？&lt;/p&gt;
&lt;h2 id=&#34;管理平面&#34;&gt;管理平面&lt;/h2&gt;
&lt;p&gt;在 Istio 之上再增加一层抽象，将网关、流量和安全分组管理，并将它们应用到不同的集群和命名空间上。下图展示的是 &lt;a href=&#34;https://www.tetrate.io/tetrate-service-bridge/&#34; title=&#34;Tetrate Service Bridge&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate Service Bridge&lt;/a&gt; 的多租户模型，利用 NGAC 来管理用户的访问权限，同时也有利于构建零信任网络。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg8ndcajj31il0u00z9_hu06d02813ed63cea7a6b148e5e8b8f920_143338_1965x1080_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg8ndcajj31il0u00z9.jpg&#34; data-img=&#34;/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg8ndcajj31il0u00z9.jpg&#34; data-width=&#34;1965&#34; data-height=&#34;1080&#34; alt=&#34;image&#34; data-caption=&#34;Management Plane&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Management Plane&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Istio 提供了工作负载识别，并由强大的 mTLS 加密保护。这种零信任模型比基于源 IP 等拓扑信息来信任工作负载更好。在 Istio 之上构建一个多集群管理的通用控制平面，然后再增加一个管理平面来管理多集群，提供多租户、管理配置、可观测性等功能。&lt;/p&gt;
&lt;p&gt;下图展示的是 Tetrate Service Bridge 的架构图。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg951mknj314g0u0dnf_hu58d60a0133ad773558f1d2001737b622_148231_1456x1080_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg951mknj314g0u0dnf.jpg&#34; data-img=&#34;/blog/multicluster-management-with-kubernetes-and-istio/008i3skNly1gsgg951mknj314g0u0dnf.jpg&#34; data-width=&#34;1456&#34; data-height=&#34;1080&#34; alt=&#34;image&#34; data-caption=&#34;Tetrate Service Bridge&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Tetrate Service Bridge&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;使用 Kubernetes 实现了异构集群的互操作性，Istio 将容器化负载和虚拟机负载纳入到一个同一个控制平面内，统一管理集群内的流量、安全和可观测性。但是，随着集群数量、网络环境和用户权限的越发复杂，人们还需要在 Istio 的控制平面至上再构建一层管理平面来进行混合云管理。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Istio 开源四周年回顾与展望</title>
      <link>https://jimmysong.io/blog/istio-4-year-birthday/</link>
      <pubDate>Mon, 24 May 2021 08:00:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/istio-4-year-birthday/</guid>
      <description>
        
        
        &lt;p&gt;Istio 是由 &lt;a href=&#34;https://tetrate.io/&#34; title=&#34;Tetrate&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tetrate&lt;/a&gt; 创始人 Varun Talwar 和谷歌首席工程师 Louis Ryan 命名并在 2017 年 5 月 24 日开源。今天是 Istio 开源四周年，让我们一起来回顾一下 Istio 四年来的发展并展望一下它的未来。&lt;/p&gt;
&lt;h2 id=&#34;istio-的开源历史&#34;&gt;Istio 的开源历史&lt;/h2&gt;
&lt;p&gt;2017 年是 Kubernetes 结束容器编排之战的一年，Google 为了巩固在云原生领域的优势，并弥补 Kubernetes 在服务间流量管理方面的劣势，趁势开源了 Istio。下面是截止目前 Istio 历史上最重要的几次版本发布。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;日期&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;版本&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;2017-05-24&lt;/td&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;td&gt;正式开源，该版本发布时仅一个命令行工具。确立了功能范围和 sidecar 部署模式，确立的 Envoy 作为默认 sidecar proxy 的地位。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2017-10-10&lt;/td&gt;
&lt;td&gt;0.2&lt;/td&gt;
&lt;td&gt;支持多运行时环境，如虚拟机。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018-06-01&lt;/td&gt;
&lt;td&gt;0.8&lt;/td&gt;
&lt;td&gt;API 重构。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2018-07-31&lt;/td&gt;
&lt;td&gt;1.0&lt;/td&gt;
&lt;td&gt;生产就绪，此后 Istio 团队被大规模重组。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2019-03-19&lt;/td&gt;
&lt;td&gt;1.1&lt;/td&gt;
&lt;td&gt;企业就绪，支持多 Kubernetes 集群，性能优化。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-03-03&lt;/td&gt;
&lt;td&gt;1.5&lt;/td&gt;
&lt;td&gt;回归单体架构，支持 WebAssembly 扩展，使得 Istio 的生态更加强大。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2020-11-18&lt;/td&gt;
&lt;td&gt;1.8&lt;/td&gt;
&lt;td&gt;正式放弃 Mixer，进一步完善对虚拟机的支持。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Istio 开源后经过了一年时间的发展，在 1.0 发布的前两个月发布了 0.8 版本，这是对 API 的一次大规模重构。而在 2018 年 7 月底发布 1.0 时，Istio 达到了生产可用的临界点，此后 Google 对 Istio 团队进行了大规模重组，多家以 Istio 为基础的 Service Mesh &lt;a href=&#34;https://istio.io/latest/about/ecosystem/#providers&#34; title=&#34;创业公司&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;创业公司&lt;/a&gt;诞生，可以说 2018 年是服务网格行业诞生的元年。&lt;/p&gt;
&lt;p&gt;2019 年 3 月 Istio 1.1 发布，而这距离 1.0 发布已经过去了近 9 个月，这已经远远超出一个开源项目的平均发布周期。我们知道迭代和进化速度是基础软件的核心竞争力，此后 Istio 开始以每个季度一个版本的固定&lt;a href=&#34;https://istio.io/v1.7/about/release-cadence/&#34; title=&#34;发布节奏&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;发布节奏&lt;/a&gt;，并在 2019 年成为了 &lt;a href=&#34;https://octoverse.github.com/#fastest-growing-oss-projects-by-contributors&#34; title=&#34;GitHub 增长最快的十大项目中排名第 4 名&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub 增长最快的十大项目中排名第 4 名&lt;/a&gt;！&lt;/p&gt;
&lt;h2 id=&#34;istio-社区&#34;&gt;Istio 社区&lt;/h2&gt;
&lt;p&gt;Istio 开源四年来，已经在 GitHub 上收获了 2.7 万颗星，获得了大量的&lt;a href=&#34;https://istio.io/latest/about/case-studies/&#34; title=&#34;社区用户&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;社区用户&lt;/a&gt;。下图是 &lt;a href=&#34;https://github.com/istio/istio&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt; 的 GitHub star 数增长情况。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/istio-4-year-birthday/008i3skNly1gqtm7n2hm1j31me0n2tag_huf35844f8f03e8442a7ccec3b9f55318a_61539_2102x830_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/istio-4-year-birthday/008i3skNly1gqtm7n2hm1j31me0n2tag.jpg&#34; data-img=&#34;/blog/istio-4-year-birthday/008i3skNly1gqtm7n2hm1j31me0n2tag.jpg&#34; data-width=&#34;2102&#34; data-height=&#34;830&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;2020 年 Istio 的项目管理开始走向成熟，治理方式也到了进化的阶段。2020 年，Istio 社区进行了第一次&lt;a href=&#34;https://istio.io/latest/blog/2020/steering-election-results/&#34; title=&#34;管委会选举&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;管委会选举&lt;/a&gt;，还把商标转让给了 &lt;a href=&#34;https://istio.io/latest/blog/2020/open-usage/&#34; title=&#34;Open Usage Commons&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Usage Commons&lt;/a&gt;。首届 &lt;a href=&#34;https://events.istio.io/istiocon-2021/&#34; title=&#34;IstioCon&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IstioCon&lt;/a&gt; 在 2021 年 2 月份成功举办，几千人参加了线上会议。在中国也有大量的 Istio 社区用户，2021 年也会有线下面对面的 Istio 社区 meetup 在中国举办。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/istio-4-year-birthday/008i3skNly1gquicfqg14j31lw0smwl2_hud4052566c974f082e6277319a241c49e_116422_2084x1030_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/istio-4-year-birthday/008i3skNly1gquicfqg14j31lw0smwl2.jpg&#34; data-img=&#34;/blog/istio-4-year-birthday/008i3skNly1gquicfqg14j31lw0smwl2.jpg&#34; data-width=&#34;2084&#34; data-height=&#34;1030&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;根据 CNCF 2020 年调查，46% 的组织在生产中使用服务网格或计划在未来 12 个月内使用。Istio 是在生产中使用的最多的网格。&lt;/p&gt;
&lt;h2 id=&#34;未来&#34;&gt;未来&lt;/h2&gt;
&lt;p&gt;经过 4 年的发展，围绕 Istio 不仅形成了庞大的用户群，还诞生了多家 Istio 供应商，你可以在最近改版的 &lt;a href=&#34;https://istio.io&#34; title=&#34;Istio 的官网首页&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 的官网首页&lt;/a&gt;中看到。在最近几个版本中，Istio 已经将发展中心转移到了提升 Day 2 Operation 体验上来了。我们还希望看到更多的 Istio 的采纳路径建议、案例研究、学习资料、培训及认证（例如来自 Tetrate 的业界的第一个 &lt;a href=&#34;https://academy.tetrate.io/courses/certified-istio-administrator&#34; title=&#34;Istio 管理员认证&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 管理员认证&lt;/a&gt;），这些都将有利于 Istio 的推广和采用。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>什么是 Istio？为什么 Kubernetes 需要 Istio？</title>
      <link>https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/</link>
      <pubDate>Wed, 28 Apr 2021 09:06:14 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/</guid>
      <description>
        
        
        &lt;p&gt;Istio 是当前&lt;a href=&#34;https://www.cncf.io/blog/2020/03/04/2019-cncf-survey-results-are-here-deployments-are-growing-in-size-and-speed-as-cloud-native-adoption-becomes-mainstream/&#34; title=&#34;最流行的服务网格实现&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;最流行的服务网格实现&lt;/a&gt;，它是在 Kubernetes 的基础上开发的，它跟 Kubernetes 在云原生应用的生态中拥有着不同的定位。本文不是直接为你介绍 Istio 具有哪些功能，而是先向你介绍 Istio 诞生的历史条件，然后带你从 Kubernetes 与 Istio 的分工开始，了解什么是 Istio。&lt;/p&gt;
&lt;p&gt;要想解释什么是 Istio，还得先了解 Istio 是在什么样的情况下出现的——即为什么会有 Istio？&lt;/p&gt;
&lt;p&gt;容器作为云原生应用的交付物，既解决了环境一致性的问题，又可以更细粒度的限制应用资源，但是随着微服务和 DevOps 的流行，容器作为微服务的载体得以广泛应用。2014 年，Google 开源了 Kubernetes，随后几年得到迅猛发展，在 2017 年奠定了容器编排调度标准的地位。Kubernetes 作为一种容器编排调度工具，解决了分布式应用程序的部署和调度问题。因为一台单机的资源有限，而互联网应用可能因为用户规模的急速扩张，或用户属性的不同在不同时间段会出现流量洪峰，因此对计算资源的弹性要求比较高。而一台单机显然无法满足一个如何规模庞大的应用，反之，对于一个规模很小的应用也没必要占用整台主机，那将导致巨大的浪费。&lt;/p&gt;
&lt;p&gt;简而言之，Kubernetes 定义服务的最终状态，并使系统自动地达到和维持在该状态。那么在应用部署完成后，如何管理服务上的流量呢？下面我们将看下 Kubernetes 中如何做服务管理，及在 Istio 中的变化。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中如何做服务管理&#34;&gt;Kubernetes 中如何做服务管理？&lt;/h2&gt;
&lt;p&gt;下图展示的是 Kubernetes 中的服务模型。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/service-model_hu5459c0360c2b0cb7a147d2df0eb350ca_292671_1920x1200_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/service-model.jpg&#34; data-img=&#34;/blog/what-is-istio-and-why-does-kubernetes-need-it/service-model.jpg&#34; data-width=&#34;1920&#34; data-height=&#34;1200&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes 服务模型&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes 服务模型&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;从上图中我们可以看出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;同一个服务的的不同示例可能被调度到不同的节点上；&lt;/li&gt;
&lt;li&gt;Kubernetes 通过 Service 对象将一个服务的多个实例组合在了一起，统一对外服务；&lt;/li&gt;
&lt;li&gt;Kubernetes 在每个 node 中安装了 &lt;code&gt;kube-proxy&lt;/code&gt;  组件来转发流量，它拥有的简单的负载均衡功能；&lt;/li&gt;
&lt;li&gt;Kubernetes 集群外部流量可以通过 Ingress 进入集群中（Kubernetes 还有其他几种暴露服务的方式，如 NodePort、LoadBalancer 等）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes 是用于资源集约管理的工具。但在为应用分配好资源后，如何保证应用的健壮性、冗余性，如何实现更细粒度的流量划分（不是根据服务中实例个数来实现），如何保障服务的安全性，如何进行多集群管理等，这些问题 Kubernetes 都不能很好地解决。&lt;/p&gt;
&lt;p&gt;服务具有多个版本，需要迭代和上线，在新版发布的时候需要切分流量，实现金丝雀发布；同时我们应该假定服务是不可靠的，可能因为各种原因导致请求失败，需要面向失败来编程，如何监控应用程序的指标，了解每个请求的耗时和状态？Istio 的发起这们就想到了在每个 pod 中注入一个代理，将代理的配置通过一个控制平面集中分发，然后将从 pod 中应用容器发起的每个请求都劫持到 sidecar 代理中，然后转发，这样不就可以完美的解决以上问题了吗？Kubernetes 优秀的架构和可扩展性，例如 CRD，pod 内的部署模式，可以完美的解决大量 sidecar 的注入和管理问题，使得 Istio 的实现成为可能。&lt;/p&gt;
&lt;h2 id=&#34;istio-的基本原理&#34;&gt;Istio 的基本原理&lt;/h2&gt;
&lt;p&gt;下图是 Istio 中的服务模型，它既可以支持 Kubernetes 中的工作负载，又可以支持虚拟机。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/istio_hu13bb8627e89e022149800eb13617e9e8_126905_1999x1134_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/what-is-istio-and-why-does-kubernetes-need-it/istio.jpg&#34; data-img=&#34;/blog/what-is-istio-and-why-does-kubernetes-need-it/istio.jpg&#34; data-width=&#34;1999&#34; data-height=&#34;1134&#34; alt=&#34;image&#34; data-caption=&#34;Istio&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Istio&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;从图中我们可以看出：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Istiod 作为控制平面，将配置下发给所有的 sidecar proxy 和 gateway（为了美观，图中没有画 Istiod 及 sidecar 之间的连接）&lt;/li&gt;
&lt;li&gt;Istio 不再使用 &lt;code&gt;kube-proxy&lt;/code&gt; 组件做流量转发，而是依托在每个 pod 中注入的 sidecar proxy，所有的 proxy 组成了 Istio 的数据平面；&lt;/li&gt;
&lt;li&gt;应用程序管理员可以和管理 Kubernetes 中的工作负载一样，通过声明式 API 操作 Istio mesh 中流量的行为；&lt;/li&gt;
&lt;li&gt;Ingress 被 Gateway 资源所替代，Gateway 是一种特殊的 proxy，实际上也是复用的 Sidecar proxy；&lt;/li&gt;
&lt;li&gt;可以在虚拟机中安装 sidecar proxy，将虚拟机引入的 Istio mesh 中；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;实际上在 Istio 之前，人们可以使用 SpringCloud、Netflix OSS 等，通过在应用程序中集成 SDK，编程的方式来管理应用程序中的流量。但是这通常会有编程语言限制，而且在 SDK 升级的时候，需要修改代码并重新上线应用，会增大人力负担。Istio 使得流量管理变得对应用程序透明，使这部分功能从应用程序中转移到了平台层，成为了云原生基础设施。&lt;/p&gt;
&lt;p&gt;正是因为 Istio 补足了 Kubernetes 对于云原生应用的流量管理、可观测性和安全方面的短板，在 2017 年由 Google、IBM 和 Lyft 共同发起的这个服务网格开源项目，并在三年来取得了长足的发展。关于 Istio 核心功能的介绍可以参考 &lt;a href=&#34;https://istio.io/latest/docs/concepts/what-is-istio/&#34; title=&#34;Istio 文档&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 文档&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Service Mesh 相当于云原生时代的 TCP/IP，解决应用程序网络通信、安全及可见性问题；&lt;/li&gt;
&lt;li&gt;Istio 是目前最流行的 service mesh 实现，依托于 Kubernetes，但也可以扩展到虚拟机负载；&lt;/li&gt;
&lt;li&gt;Istio 的核心由控制平面和数据平面组成，Envoy 是默认的数据平面代理；&lt;/li&gt;
&lt;li&gt;Istio 作为云原生基础设施的网络层，对应用透明。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>利用 Gateway API 发展 Kubernetes 网络</title>
      <link>https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/</link>
      <pubDate>Thu, 22 Apr 2021 10:03:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/</guid>
      <description>
        
        
        &lt;p&gt;Ingress 资源是 Kubernetes 众多成功案例中的一个。它创造了一个&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/&#34; title=&#34;多样化的 Ingress 控制器的生态系统&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;多样化的 Ingress 控制器的生态系统&lt;/a&gt;，这些控制器以标准化和一致的方式在数十万个集群中使用。这种标准化有助于用户采用 Kubernetes。然而，在 Ingress 创建五年后，有迹象表明它被分割成不同但&lt;a href=&#34;https://dave.cheney.net/paste/ingress-is-dead-long-live-ingressroute.pdf&#34; title=&#34;惊人相似的 CRD&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;惊人相似的 CRD&lt;/a&gt; 和 &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/&#34; title=&#34;过载的注释&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;过载的注释&lt;/a&gt;。Ingress 普遍存在的可移植性问题也限制了它的未来。&lt;/p&gt;
&lt;p&gt;那是在 2019 年圣地亚哥的 Kubecon 上，一群充满激情的贡献者聚集在一起，讨论 &lt;a href=&#34;https://static.sched.com/hosted_files/kccncna19/a5/Kubecon%20San%20Diego%202019%20-%20Evolving%20the%20Kubernetes%20Ingress%20APIs%20to%20GA%20and%20Beyond%20%5BPUBLIC%5D.pdf&#34; title=&#34;Ingress 的发展&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress 的发展&lt;/a&gt;。拥挤的人群溢出到了街对面的酒店大堂，而讨论出来的东西后来被称为 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/&#34; title=&#34;Gateway API&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gateway API&lt;/a&gt;。这次讨论是基于几个关键的假设：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;路由匹配、流量管理和服务暴露所依据的 API 标准已经商业化，对其实施者和用户提供的定制 API 的价值很小。&lt;/li&gt;
&lt;li&gt;可以通过共同的核心 API 资源来表示 L4/L7 的路由和流量管理。&lt;/li&gt;
&lt;li&gt;可以在不牺牲核心 API 的用户体验的前提下，为更复杂的功能提供扩展性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;gateway-api-介绍&#34;&gt;Gateway API 介绍&lt;/h2&gt;
&lt;p&gt;这产出了一些设计原则，使 Gateway API 能够在 Ingress 的基础上进行改进。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;表达性&lt;/strong&gt;：除了 HTTP 主机 / 路径匹配和 TLS 之外，Gateway API 还可以表达 HTTP 头操作、流量加权和镜像、TCP/UDP 路由等能力，以及其他只有在 Ingress 中通过自定义注释才能实现的能力。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;面向角色的设计&lt;/strong&gt;：API 资源模型反映了路由和 Kubernetes 服务网络中常见的责任分离。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;：这些资源允许在 API 的各个层面上进行任意的配置附加。这使得在最适当的地方进行细化的定制成为可能。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;灵活的一致性&lt;/strong&gt;：Gateway API 定义了不同的一致性级别 —— 核心（强制支持）、扩展（支持时可移植）和自定义（不保证可移植性），一起被称为&lt;a href=&#34;https://gateway-api.sigs.k8s.io/concepts/guidelines/#conformance&#34; title=&#34;灵活的一致性&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;灵活的一致性&lt;/a&gt;。这促进了高度可移植的核心 API（如 Ingress），仍然为 Gateway 控制器实施者提供了灵活性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;gateway-api-是什么样子的&#34;&gt;Gateway API 是什么样子的？&lt;/h3&gt;
&lt;p&gt;Gateway API 引入了一些新的资源类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/spec/#networking.x-k8s.io/v1alpha1.GatewayClass&#34; title=&#34;&amp;lt;strong&amp;gt;GatewayClasses&amp;lt;/strong&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;GatewayClasses&lt;/strong&gt;&lt;/a&gt; 是集群范围内的资源，作为模板，明确地定义由其衍生的网关的行为。这与 StorageClasses 的概念类似，但用于网络数据平面。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/spec/#networking.x-k8s.io/v1alpha1.Gateway&#34; title=&#34;&amp;lt;strong&amp;gt;Gateway&amp;lt;/strong&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;strong&gt;Gateway&lt;/strong&gt;&lt;/a&gt; 是 GatewayClasses 的部署实例。它们是执行路由的数据平面的逻辑表示，它可能是集群内的代理、硬件 LB 或云 LB。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;路由&lt;/strong&gt; 不是一个单一的资源，而是代表许多不同的特定协议的路由资源。&lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/spec/#networking.x-k8s.io/v1alpha1.HTTPRoute&#34; title=&#34;HTTPRoute&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;HTTPRoute&lt;/a&gt; 有匹配、过滤和路由规则，这些规则被应用到可以处理 HTTP 和 HTTPS 流量的网关。同样，还有 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/spec/#networking.x-k8s.io/v1alpha1.TCPRoute&#34; title=&#34;TCPRoutes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TCPRoutes&lt;/a&gt;、&lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/spec/#networking.x-k8s.io/v1alpha1.UDPRoute&#34; title=&#34;UDPRoutes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;UDPRoutes&lt;/a&gt; 和 &lt;a href=&#34;https://gateway-api.sigs.k8s.io/references/spec/#networking.x-k8s.io/v1alpha1.TLSRoute&#34; title=&#34;TLSRoutes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TLSRoutes&lt;/a&gt;，它们也有协议特定的语义。这种模式也允许网关 API 在未来逐步扩展其协议支持。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6ut5jlj31ed0u0jyp_hu990222c1ca711852583f78f01c4ea18d_62986_1000x596_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6ut5jlj31ed0u0jyp.jpg&#34; data-img=&#34;/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6ut5jlj31ed0u0jyp.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;596&#34; alt=&#34;image&#34; data-caption=&#34;Gateway API 资源&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Gateway API 资源&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h3 id=&#34;gateway-控制器的实现&#34;&gt;Gateway 控制器的实现&lt;/h3&gt;
&lt;p&gt;好消息是，虽然 Gateway 还在 &lt;a href=&#34;https://github.com/kubernetes-sigs/gateway-api/releases&#34; title=&#34;Alpha&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Alpha&lt;/a&gt; 阶段，但已经有几个 Gateway 控制器实现，你可以运行。由于它是一个标准化的规格，下面的例子都可以运行，而且功能应该完全相同。我们来看看如何安装和使用这些 Gateway 控制器。&lt;/p&gt;
&lt;h2 id=&#34;实践-gateway-api&#34;&gt;实践 Gateway API&lt;/h2&gt;
&lt;p&gt;在下面的例子中，我们将展示不同的 API 资源之间的关系，并引导你完成一个常见的使用案例。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;foo 团队在 foo 命名空间中部署了他们的应用程序。他们需要控制其应用程序的不同页面的路由逻辑。&lt;/li&gt;
&lt;li&gt;Team bar 正在 bar 命名空间中运行。他们希望能够对他们的应用程序进行蓝绿部署以减少风险。&lt;/li&gt;
&lt;li&gt;平台团队负责管理 Kubernetes 集群中所有应用程序的负载均衡器和网络安全。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面的 foo-route 对 foo 命名空间中的各种服务进行路径匹配，并且有一个到 404 服务器的默认路由。这通过 &lt;code&gt;foo.example.com/login&lt;/code&gt; 和 &lt;code&gt;foo.example.com/home&lt;/code&gt; 分别暴露了 foo-auth 和 foo-home 服务。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.x-k8s.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo-route&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;external-https-prod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;foo.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/login&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;forwardTo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo-auth&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/home&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;forwardTo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo-home&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Prefix&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;forwardTo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo-404&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在同一个 Kubernetes 集群的 bar 命名空间中运行的 bar 团队也希望将他们的应用程序暴露在互联网上，但他们也希望控制自己的金丝雀发布和蓝绿部署。下面的 HTTPRoute 被配置为以下行为。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;对于访问 &lt;code&gt;bar.example.com&lt;/code&gt;的流量：
&lt;ul&gt;
&lt;li&gt;将 90% 的流量发送到 bar-v1&lt;/li&gt;
&lt;li&gt;将 10% 的流量发送到 bar-v2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;对于访问 &lt;code&gt;bar.example.com&lt;/code&gt; 的流量，HTTP header 为 &lt;code&gt;env: canary&lt;/code&gt;：
&lt;ul&gt;
&lt;li&gt;将所有的流量发送到 bar-v2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6via0rj31np0fxq5x_hua5b28bd4b842f3fee5960ea68afb5c9c_41621_1000x267_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6via0rj31np0fxq5x.jpg&#34; data-img=&#34;/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6via0rj31np0fxq5x.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;267&#34; alt=&#34;image&#34; data-caption=&#34;The routing rules configured for the bar-v1 and bar-v2 Services&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;The routing rules configured for the bar-v1 and bar-v2 Services&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.x-k8s.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar-route&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;external-https-prod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostnames&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;bar.example.com&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;forwardTo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar-v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;90&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar-v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;weight&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;matches&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;headers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;env&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;canary&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;forwardTo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bar-v2&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;路由和网关绑定&#34;&gt;路由和网关绑定&lt;/h3&gt;
&lt;p&gt;因此，我们有两个 HTTPRoute 匹配并将流量路由到不同的服务。你可能想知道，这些服务在哪里可以访问？它们是通过哪些网络或 IP 暴露的？&lt;/p&gt;
&lt;p&gt;路由如何暴露给客户是由&lt;a href=&#34;https://gateway-api.sigs.k8s.io/concepts/api-overview/#route-binding&#34; title=&#34;路由绑定&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;路由绑定&lt;/a&gt;管理的，它描述了路由和网关如何在彼此之间建立双向关系。当路由与网关绑定时，意味着它们的集体路由规则被配置在底层负载均衡器或代理上，并且路由可以通过网关访问。因此，网关是一个网络数据平面的逻辑表示，可以通过路由配置。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6w3e9aj31fo0gotay_hu21849b8653517e0e2a45304fe89cf417_56615_1000x323_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6w3e9aj31fo0gotay.jpg&#34; data-img=&#34;/trans/evolving-kubernetes-networking-with-the-gateway-api/008i3skNly1gpsl6w3e9aj31fo0gotay.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;323&#34; alt=&#34;image&#34; data-caption=&#34;路由如何绑定到网关&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;路由如何绑定到网关&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h3 id=&#34;行政授权&#34;&gt;行政授权&lt;/h3&gt;
&lt;p&gt;网关和路由资源之间的分割允许集群管理员将一些路由配置委托给各个团队，同时仍然保留集中控制。下面的网关资源在 443 端口暴露 HTTPS，并用集群管理员控制的证书终止该端口的所有流量。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Gateway&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.x-k8s.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;prod-web&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gatewayClassName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;acme-lb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;listeners&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;  
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;protocol&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPS&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;443&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;routes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;matchLabels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;external-https-prod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespaces&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;All&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tls&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;certificateRef&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admin-controlled-cert&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;下面的 HTTPRoute 显示了 Route 如何通过它的 &lt;code&gt;kind&lt;/code&gt;（HTTPRoute）和资源标签（&lt;code&gt;gateway=external-https-prod&lt;/code&gt;）确保它与 Gateway 的选择器相匹配。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# 匹配网关上所需的 kind 选择器&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;HTTPRoute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;networking.x-k8s.io/v1alpha1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo-route&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;foo-ns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;c&#34;&gt;# 匹配网关上所需的标签选择器&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;gateway&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;external-https-prod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nn&#34;&gt;...&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;以角色为导向的设计&#34;&gt;以角色为导向的设计&lt;/h3&gt;
&lt;p&gt;当你把它放在一起时，你有一个单一的负载均衡基础设施，可以被多个团队安全地共享。Gateway API 不仅是一个用于高级路由的更具表现力的 API，而且是一个面向角色的 API，为多用户基础设施而设计。它的可扩展性确保了它在保持可移植性的同时，还能为未来的使用场景而发展。最终，这些特性将使 Gateway API 在未来适应不同的组织模式和实施方式。&lt;/p&gt;
&lt;h3 id=&#34;尝试和参与&#34;&gt;尝试和参与&lt;/h3&gt;
&lt;p&gt;有许多资源可供查阅，以了解更多。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查阅&lt;a href=&#34;https://gateway-api.sigs.k8s.io/guides/getting-started/&#34; title=&#34;用户指南&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;用户指南&lt;/a&gt;，看看可以解决哪些用例。&lt;/li&gt;
&lt;li&gt;试用现有的网关控制器。&lt;/li&gt;
&lt;li&gt;或者&lt;a href=&#34;https://gateway-api.sigs.k8s.io/contributing/community/&#34; title=&#34;参与进来&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;参与进来&lt;/a&gt;，帮助设计并影响 Kubernetes 服务网络的未来！&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>为什么在使用了 Kubernetes 后你可能还需要 Istio？</title>
      <link>https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/</link>
      <pubDate>Wed, 07 Apr 2021 08:27:17 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/</guid>
      <description>
        
        
        &lt;p&gt;如果你听说过服务网格，并尝试过 &lt;a href=&#34;https://istio.io/&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;，你可能有以下问题。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为什么 Istio 要在 Kubernetes 上运行？&lt;/li&gt;
&lt;li&gt;Kubernetes 和服务网格在云原生应用架构中分别扮演什么角色？&lt;/li&gt;
&lt;li&gt;Istio 扩展了 Kubernetes 的哪些方面？它解决了哪些问题？&lt;/li&gt;
&lt;li&gt;Kubernetes、Envoy 和 Istio 之间是什么关系？&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;本文将带大家了解 Kubernetes 和 Istio 的内部工作原理。此外，我会介绍 Kubernetes 中的负载均衡方法，并解释为什么有了 Kubernetes 后还需要 Istio。&lt;/p&gt;
&lt;p&gt;Kubernetes 本质上是通过声明式配置来实现应用生命周期管理，而服务网格本质上是提供应用间的流量、安全管理和可观测性。如果你已经使用 Kubernetes 搭建了一个稳定的应用平台，那么如何设置服务间调用的负载均衡和流量控制？是否有这样一个通用的工具或者说平台（非 SDK），可以实现？这就需要用到服务网格了。&lt;/p&gt;
&lt;p&gt;Envoy 引入了 xDS 协议，这个协议得到了各种开源软件的支持，比如 Istio、&lt;a href=&#34;https://mosn.io/&#34; title=&#34;MOSN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MOSN&lt;/a&gt; 等。Envoy 将 xDS 贡献给服务网格或云原生基础设施。Envoy 本质上是一个现代版的代理，可以通过 API 进行配置，在此基础上衍生出许多不同的使用场景–比如 API Gateway、服务网格中的 sidecar 代理和边缘代理。&lt;/p&gt;
&lt;p&gt;本文包含以下内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;kube-proxy 的作用描述。&lt;/li&gt;
&lt;li&gt;Kubernetes 在微服务管理方面的局限性。&lt;/li&gt;
&lt;li&gt;Istio 服务网格的功能介绍。&lt;/li&gt;
&lt;li&gt;Kubernetes、Envoy 和 Istio 服务网格中一些概念的比较。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-service-mesh&#34;&gt;Kubernetes vs Service Mesh&lt;/h2&gt;
&lt;p&gt;下图显示了 Kubernetes 中的服务访问关系和服务网格（每个 pod 模型一个 sidecar）。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/008eGmZEly1gpb7knfo4dj31hk0redrz_huccd458de9d144d6ef3ec0fe663834e3e_147219_1928x986_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/008eGmZEly1gpb7knfo4dj31hk0redrz.jpg&#34; data-img=&#34;/blog/why-do-you-need-istio-when-you-already-have-kubernetes/008eGmZEly1gpb7knfo4dj31hk0redrz.jpg&#34; data-width=&#34;1928&#34; data-height=&#34;986&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes vs Service Mesh&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes vs Service Mesh&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h3 id=&#34;流量转发&#34;&gt;流量转发&lt;/h3&gt;
&lt;p&gt;Kubernetes 集群中的每个节点都部署了一个 kube-proxy 组件，该组件与 Kubernetes API Server 进行通信，获取集群中的服务信息，然后设置 iptables 规则，将服务请求直接发送到对应的 Endpoint（属于同一组服务的 pod）。&lt;/p&gt;
&lt;h3 id=&#34;服务发现&#34;&gt;服务发现&lt;/h3&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/008eGmZEly1gpb7knwb79j30kq0fcjs9_hud635b5a7d5620df0f2977e864fb2f9f9_44451_746x552_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/008eGmZEly1gpb7knwb79j30kq0fcjs9.jpg&#34; data-img=&#34;/blog/why-do-you-need-istio-when-you-already-have-kubernetes/008eGmZEly1gpb7knwb79j30kq0fcjs9.jpg&#34; data-width=&#34;746&#34; data-height=&#34;552&#34; alt=&#34;image&#34; data-caption=&#34;Service Discovery&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Service Discovery&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Istio 可以跟踪 Kubernetes 中的服务注册，也可以在控制平面中通过平台适配器与其他服务发现系统对接；然后生成数据平面的配置（使用 CRD，这些配置存储在 etcd 中），数据平面的透明代理。数据平面的透明代理以 sidecar 容器的形式部署在每个应用服务的 pod 中，这些代理都需要请求控制平面同步代理配置。代理之所以“透明”，是因为应用容器完全不知道代理的存在。过程中的 kube-proxy 组件也需要拦截流量，只不过 kube-proxy 拦截的是进出 Kubernetes 节点的流量–而 sidecar 代理拦截的是进出 pod 的流量。&lt;/p&gt;
&lt;h3 id=&#34;服务网格的劣势&#34;&gt;服务网格的劣势&lt;/h3&gt;
&lt;p&gt;由于 Kubernetes 的每个节点上都运行着很多 pod，所以在每个 pod 中放入原有的 kube-proxy 路由转发功能，会增加响应延迟–由于 sidecar 拦截流量时跳数更多，消耗更多的资源。为了对流量进行精细化管理，将增加一系列新的抽象功能。这将进一步增加用户的学习成本，但随着技术的普及，这种情况会慢慢得到缓解。&lt;/p&gt;
&lt;h3 id=&#34;服务网格的优势&#34;&gt;服务网格的优势&lt;/h3&gt;
&lt;p&gt;kube-proxy 的设置是全局的，无法对每个服务进行细粒度的控制，而 service mesh 通过 sidecar proxy 的方式将 Kubernetes 中的流量控制从服务层中抽离出来–可以实现更大的弹性。&lt;/p&gt;
&lt;h3 id=&#34;kube-proxy-的不足之处&#34;&gt;Kube-proxy 的不足之处&lt;/h3&gt;
&lt;p&gt;首先，如果转发的 pod 不能正常服务，它不会自动尝试其他 pod。每个 pod 都有一个健康检查机制，当一个 pod 出现健康问题时，kubelet 会重启 pod，kube-proxy 会删除相应的转发规则。另外，节点 Port 类型的服务不能添加 TLS 或更复杂的消息路由机制。&lt;/p&gt;
&lt;p&gt;Kube-proxy 实现了一个 Kubernetes 服务的多个 pod 实例之间的流量负载均衡，但如何对这些服务之间的流量进行精细化控制–比如将流量按百分比划分给不同的应用版本（这些应用版本都是同一个服务的一部分，但在不同的部署上），或者做金丝雀发布（灰度发布）和蓝绿发布？&lt;/p&gt;
&lt;p&gt;Kubernetes 社区给出了一个使用 Deployment 做&lt;a href=&#34;https://kubernetes.io/docs/concepts/cluster-administration/manage-deployment/#canary-deployments&#34; title=&#34;金丝雀发布&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;金丝雀发布&lt;/a&gt;的方法，本质上是通过修改 pod 的标签来给部署的服务分配不同的 pod。&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-ingress-vs-istio-gateway&#34;&gt;Kubernetes Ingress vs Istio Gateway&lt;/h3&gt;
&lt;p&gt;如上所述，kube-proxy 只能在 Kubernetes 集群内路由流量。Kubernetes 集群的 pod 位于 CNI 创建的网络中。Ingress 是在 Kubernetes 中创建的资源对象，用于集群外部的通信。它由位于 Kubernetes 边缘节点上的入口控制器驱动，负责管理南北向流量。Ingress 必须与各种 Ingress 控制器对接，比如 &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34; title=&#34;nginx ingress 控制器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nginx ingress 控制器&lt;/a&gt;和 &lt;a href=&#34;https://traefik.io/&#34; title=&#34;traefik&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;traefik&lt;/a&gt;。Ingress 只适用于 HTTP 流量，使用简单。它只能通过匹配有限的字段来路由流量——如服务、端口、HTTP 路径等。这使得它无法对 TCP 流量进行路由，如 MySQL、Redis 和各种 RPC。这就是为什么你会看到人们在 ingress 资源注释中写 Nginx 配置语言的原因（注：使用 Nginx Ingress Controller 可以通过 &lt;a href=&#34;https://kubernetes.github.io/ingress-nginx/user-guide/exposing-tcp-udp-services/&#34; title=&#34;配置 ConfigMap 和 Service 的方式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;配置 ConfigMap 和 Service 的方式&lt;/a&gt;来变通支持 TCP 和 UDP  流量转发）。直接路由南北流量的唯一通行方法是使用服务的 LoadBalancer 或 NodePort，前者需要云厂商支持，后者需要额外的端口管理。&lt;/p&gt;
&lt;p&gt;Istio Gateway 的功能与 Kubernetes Ingress 类似，它负责进出集群的南北流量。Istio Gateway 描述了一个负载均衡器，用于承载进出服务网格边缘的连接。该规范描述了一组开放端口和这些端口所使用的协议，以及用于负载均衡的 SNI 配置等。Gateway 是一个 CRD 扩展，它也重用了 sidecar 代理的功能；详细配置请参见 &lt;a href=&#34;https://istio.io/latest/docs/reference/config/networking/gateway/&#34; title=&#34;Istio 网站&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio 网站&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;envoy&#34;&gt;Envoy&lt;/h2&gt;
&lt;p&gt;Envoy 是 Istio 中默认的 sidecar 代理。Istio 基于 Envoy 的 xDS 协议扩展了其控制平面。在讨论 Envoy 的 xDS 协议之前，我们需要先熟悉 Envoy 的基本术语。下面是 Envoy 的架构图。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/envoy-arch_hu12bbc733c2fbbbce68da6f443f5335d5_347524_1492x1080_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/envoy-arch.jpg&#34; data-img=&#34;/blog/why-do-you-need-istio-when-you-already-have-kubernetes/envoy-arch.jpg&#34; data-width=&#34;1492&#34; data-height=&#34;1080&#34; alt=&#34;image&#34; data-caption=&#34;Envoy 架构图&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Envoy 架构图&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h3 id=&#34;基础概念&#34;&gt;基础概念&lt;/h3&gt;
&lt;p&gt;以下是 Envoy 中你应该知道的基本术语。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;下游。下游主机连接到 Envoy，发送请求，并接收响应，即发送请求的主机。&lt;/li&gt;
&lt;li&gt;上游：上游主机。上游主机接收来自 Envoy 的连接和请求，并返回响应；即接收请求的主机。&lt;/li&gt;
&lt;li&gt;Listener：监听器。监听器是一个命名的网络地址（如端口、UNIX 域套接字等）；下游客户端可以连接到这些监听器。Envoy 将一个或多个监听器暴露给下游主机进行连接。&lt;/li&gt;
&lt;li&gt;集群。集群是一组逻辑上相同的上游主机，Envoy 连接到它们。Envoy 通过服务发现来发现集群的成员。可以选择通过主动的健康检查来确定集群成员的健康状态。Envoy 通过负载均衡策略来决定集群中哪个成员的请求路由。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在 Envoy 中可以设置多个监听器，每个监听器可以设置一个过滤链（过滤链表），而且过滤链是可扩展的，这样我们可以更方便地操纵流量的行为–比如设置加密、私有 RPC 等。&lt;/p&gt;
&lt;p&gt;xDS 协议是由 Envoy 提出的，是 Istio 中默认的 sidecar 代理，但只要实现了 xDS 协议，理论上也可以作为 Istio 中的 sidecar 代理 —— 比如蚂蚁集团开源的 &lt;a href=&#34;https://mosn.io&#34; title=&#34;MOSN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MOSN&lt;/a&gt;。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/arch_huaf89ca5c17af547775b71093dd7fd0ee_131942_1302x782_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/why-do-you-need-istio-when-you-already-have-kubernetes/arch.png&#34; data-img=&#34;/blog/why-do-you-need-istio-when-you-already-have-kubernetes/arch.png&#34; data-width=&#34;1302&#34; data-height=&#34;782&#34; alt=&#34;image&#34; data-caption=&#34;Istio 的架构&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Istio 的架构&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Istio 是一个功能非常丰富的服务网格，包括以下功能。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;流量管理。这是 Istio 最基本的功能。&lt;/li&gt;
&lt;li&gt;策略控制。实现访问控制系统、遥测采集、配额管理、计费等功能。&lt;/li&gt;
&lt;li&gt;可观测性。在 sidecar 代理中实现。&lt;/li&gt;
&lt;li&gt;安全认证。由 Citadel 组件进行密钥和证书管理。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;istio-中的流量管理&#34;&gt;Istio 中的流量管理&lt;/h2&gt;
&lt;p&gt;Istio 中定义了以下 CRD 来帮助用户进行流量管理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;网关。网关描述了一个运行在网络边缘的负载均衡器，用于接收传入或传出的 HTTP/TCP 连接。&lt;/li&gt;
&lt;li&gt;虚拟服务（VirtualService）。VirtualService 实际上是将 Kubernetes 服务连接到 Istio 网关。它还可以执行额外的操作，例如定义一组流量路由规则，以便在主机寻址时应用。&lt;/li&gt;
&lt;li&gt;DestinationRule。DestinationRule 定义的策略决定了流量被路由后的访问策略。简单来说，它定义了流量的路由方式。其中，这些策略可以定义为负载均衡配置、连接池大小和外部检测（用于识别和驱逐负载均衡池中不健康的主机）配置。&lt;/li&gt;
&lt;li&gt;EnvoyFilter。EnvoyFilter 对象描述了代理服务的过滤器，可以自定义 Istio Pilot 生成的代理配置。这种配置一般很少被主用户使用。&lt;/li&gt;
&lt;li&gt;ServiceEntry。默认情况下，Istio 服务 Mesh 中的服务无法发现 Mesh 之外的服务。ServiceEntry 可以在 Istio 内部的服务注册表中添加额外的条目，从而允许 Mesh 中自动发现的服务访问并路由到这些手动添加的服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-vs-xds-vs-istio&#34;&gt;Kubernetes vs xDS vs Istio&lt;/h2&gt;
&lt;p&gt;在回顾了 Kubernetes 的 kube-proxy 组件、xDS 和 Istio 对流量管理的抽象后，现在我们仅从流量管理的角度来看看这三个组件 / 协议的比较（注意，三者并不完全等同）。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;xDS&lt;/strong&gt;&lt;/th&gt;
&lt;th&gt;&lt;strong&gt;Istio service mesh&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;Endpoint&lt;/td&gt;
&lt;td&gt;WorkloadEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;VirtualService&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Route&lt;/td&gt;
&lt;td&gt;DestinationRule&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;kube-proxy&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;EnvoyFilter&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Ingress&lt;/td&gt;
&lt;td&gt;Listener&lt;/td&gt;
&lt;td&gt;Gateway&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Service&lt;/td&gt;
&lt;td&gt;Cluster&lt;/td&gt;
&lt;td&gt;ServiceEntry&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;核心观点&#34;&gt;核心观点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 的本质是应用生命周期管理，具体来说就是部署和管理（伸缩、自动恢复、发布）。&lt;/li&gt;
&lt;li&gt;Kubernetes 为微服务提供了一个可扩展、高弹性的部署和管理平台。&lt;/li&gt;
&lt;li&gt;服务网格是基于透明代理，通过 sidecar 代理拦截服务之间的流量，然后通过控制平面配置管理它们的行为。&lt;/li&gt;
&lt;li&gt;服务网格将流量管理与 Kubernetes 解耦，不需要 kube-proxy 组件来支持服务网格内的流量；通过提供更接近微服务应用层的抽象来管理服务间的流量、安全性和可观测性。&lt;/li&gt;
&lt;li&gt;xDS 是服务网格的协议标准之一。&lt;/li&gt;
&lt;li&gt;服务网格是 Kubernetes 中服务的一个更高层次的抽象。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;如果说 Kubernetes 管理的对象是一个 pod，那么服务网格管理的对象就是一个服务，所以用 Kubernetes 管理微服务，然后应用服务网格就可以了。如果你连服务都不想管理，那就用 &lt;a href=&#34;https://knative.dev/&#34; title=&#34;Knative&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Knative&lt;/a&gt; 这样的无服务器平台，不过这是后话。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>为什么 RBAC 不足以保障 Kubernetes 的安全？</title>
      <link>https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/</link>
      <pubDate>Thu, 17 Dec 2020 10:03:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/</guid>
      <description>
        
        
        &lt;p&gt;Kubernetes 不再是（只是）好玩的游戏了。它正在被用于生产；它是关键任务；所有旧有的安全和合规规则和法规都需要以某种方式加装到 Kubernetes 上。不幸的是，像 RBAC 这样的旧的访问控制工具根本无法应对挑战。&lt;/p&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes API 的设计与大多数现代 API 不同。&lt;/strong&gt; 它是基于意图的，这意味着使用 API 的人考虑的是他们想要 Kubernetes 做什么，而不是如何实现。其结果是一个令人难以置信的可扩展性、弹性，和一个强大而流行的系统。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;同时，其基于意图的 API 给安全带来了挑战。&lt;/strong&gt; 标准的访问控制解决方案（基于角色的访问控制、基于属性的访问控制、访问控制列表或 IAM 策略）都不够强大，无法强制执行基本的策略，比如谁可以更改 pod 上的标签，或者哪些镜像存储库是安全的。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes Admission Control 就是为了解决这个问题而设计的。&lt;/strong&gt; Kubernetes Admission Controller 并不能解决开箱即用的访问控制问题，但它们允许你使用 Webhook 来解决授权挑战与解耦策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kubernetes-基于意图的-api&#34;&gt;Kubernetes 基于意图的 API&lt;/h2&gt;
&lt;p&gt;Kubernetes API 接受了一个与我们大家习惯的 API 范式截然不同的 API。今天的大多数 API 都是所谓的 &lt;em&gt;基于行动的（action-based）&lt;/em&gt;，这意味着当你想到一个 API 调用时，你正在考虑你想要执行的行动，以改变软件的运行方式。例如，如果你想让一个应用程序暴露在互联网上，你可能会运行 API openport (443)，改变应用程序上的网络设置，使端口 443 打开。&lt;/p&gt;
&lt;p&gt;相比之下，Kubernetes 有所谓的 &lt;em&gt;基于意图的（intent-based）&lt;/em&gt; API（最近在网络领域流行，例如 &lt;a href=&#34;https://medium.com/r/?url=https%3A%2F%2Fwww.sdxcentral.com%2Fsdn%2Fdefinitions%2Fwhat-is-intent-based-networking%2F&#34; title=&#34;SDXCentral&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SDXCentral&lt;/a&gt;），这意味着当你想要进行一个 API 调用时，你要考虑的是你希望该系统处于何种状态。你并不关心用什么操作来实现这种希望的状态。你只需告诉系统你想要什么（你的意图），系统就会想出如何实现它 —— 采取哪些动作将系统过渡到期望的状态。例如，你可以说你的应用程序应该运行 1.7 版本的二进制文件，应该使用带加密的持久存储，并且应该连接到互联网。系统会计算出如何升级或降级二进制文件，如何开启加密，以及如何重新配置网络以允许互联网连接。&lt;/p&gt;
&lt;p&gt;架构上的关键区别在于，&lt;em&gt;基于意图的&lt;/em&gt; 系统既能理解系统当前所处的状态（有时称为 &lt;em&gt;实际状态&lt;/em&gt; ），也能理解你对系统应该处于何种状态的意图（&lt;em&gt;期望状态&lt;/em&gt;）。系统不断地计算两者之间的差距，并采取任何必要的行动使实际状态变成期望状态。用户可以直接通过 API 调用来改变期望状态，而依靠系统本身来改变实际状态。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glqzp7lpo7j30l20ept9z_hu93047701b134b58121532fa44dfc41b0_45983_758x529_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glqzp7lpo7j30l20ept9z.jpg&#34; data-img=&#34;/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glqzp7lpo7j30l20ept9z.jpg&#34; data-width=&#34;758&#34; data-height=&#34;529&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;Kubernetes 的 API 是基于意图的。每个 API 调用都允许你指定 Kubernetes 众多对象中的一个对象的期望状态：pod、service、ingress、configmap 等。例如，下面是你为一个 nginx 工作负载定义的期望状态。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c&#34;&gt;# nginx-pod.yaml&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx	&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后要把这个想要的状态发送到 Kubernetes，用 kubectl，把上面的 YAML 文件交给它就行了。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f nginx-pod.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;假设你想改变 nginx 的版本，挂载一个外部卷，或者提供额外的配置，你更新 nginx-pod.yaml 文件到任何你想要的状态，然后再使用 kubectl apply。更新 nginx-pod.yaml 文件到任何需要的状态，然后再使用 kubectl apply。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubectl apply -f nginx-pod.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这里的关键要点是，你不是在运行像 updateVersion 或 mountVolume 这样的 API，而是在改变一些描述系统应该处于什么状态的 YAML，并通过运行 apply 来说&amp;quot; 使之如此 &amp;ldquo;。&lt;/p&gt;
&lt;p&gt;Kubernetes 的 API 模型有几个优势：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;减少学习曲线&lt;/strong&gt;。你要学习每个对象的 YAML 格式和一系列动作，如创建、应用、获取、描述、删除。无论如何，你都需要学习每个对象的 YAML 配置格式（这样你才能读懂它）。相比之下，&lt;em&gt;基于动作的&lt;/em&gt; API 还需要你学习可能是 1,000 个动作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可扩展性&lt;/strong&gt;。Kubernetes 支持自定义资源定义（CRD）。因此，除了所有常见的 pod、service、ingress 等，你还可以定义自己的资源。这是可能的，因为 API 表面不需要扩展来处理新的资源类型。你只需要写一些描述资源的 YAML，然后调用同样的十几个动作，例如：创建、应用、获取、描述、删除。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;分布式系统&lt;/strong&gt;。在使用商用硬件构建的云上运行大规模系统，要求在面对故障时具有难以置信的弹性。Kubernetes 基于意图的架构让它知道自己应该做什么，所以当比如说发生硬件故障时，它可以尝试进行补偿。Brian Grant（Google Kubernetes 的联合技术负责人）曾就 &lt;a href=&#34;https://docs.google.com/document/d/1cLPGweVEYrVqQvBLJg6sxV-TrE5Rm2MNOBA_cxZP2WU/edit&#34; title=&#34;声明式应用管理&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;声明式应用管理&lt;/a&gt; 和 &lt;a href=&#34;https://docs.google.com/document/d/1RmHXdLhNbyOWPW_AtnnowaRfGejw-qlKQIuLKQWlwzs/edit&#34; title=&#34;Kubernetes 资源管理&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 资源管理&lt;/a&gt; 写过大量文章，并指出 Kubernetes API 是解决许多分布式系统问题的关键：故障、分布、自动伸缩、多所有者、可用性、性能、可逆性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;为什么-rbac-不足以保证-kubernetes-的-api-安全&#34;&gt;为什么 RBAC 不足以保证 Kubernetes 的 API 安全？&lt;/h2&gt;
&lt;p&gt;基于 Kubernetes 意图的 API 的挑战来自于你想要保护和保障 API 的安全时 —— 当你想要控制哪些人可以使用该 API 做什么时。想象一下，你是 Kubernetes 管理员，负责集群的运维、安全和合规性。新手 Kubernetes 开发人员需要护栏；安全团队需要控制和可见性；合规团队需要帮助将古老的规定映射到这个全新的系统；你从自己的经验中知道你需要采用哪些 Kubernetes 最佳实践。&lt;/p&gt;
&lt;p&gt;理想情况下，你会在 Kubernetes 本身内部通过设置访问控制来执行这些规则、法规和最佳实践。基于角色的访问控制（RBAC）是几十年来的解决方案，使你能够控制哪些用户可以在哪些资源上运行哪些 API。Kubernetes RBAC（自 &lt;a href=&#34;https://kubernetes.io/blog/2017/10/using-rbac-generally-available-18/&#34; title=&#34;2017 年末&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017 年末&lt;/a&gt; 开始提供）是你的第一道防线。它可以让你为特定的用户组提供对资源的只读访问。它让你通过给不同的用户组分配 Kubernetes 的不同部分（也就是 &lt;em&gt;namespace&lt;/em&gt;）来隔离不同的用户组（虽然不是完全隔离）。它可以让你限制 service account
的权限。所有这些都是有价值的。&lt;/p&gt;
&lt;p&gt;但与基于动作的系统相比，RBAC 处理了绝大部分的访问控制需求，Kubernetes 中的 RBAC 由于其基于意图的 API，提供的控制 &lt;em&gt;要少得多&lt;/em&gt;。从 API 的角度来看，只有十几个动作，这意味着如果 alice 可以更新一个资源，她就可以更新这个资源的任何部分。&lt;/p&gt;
&lt;p&gt;例如，SRE 需要读取集群中的大部分资源，以便在出现问题时能够诊断出问题。但当 SRE 发现某个节点上出现问题时，例如邻居有噪音，她可能需要对该节点进行排空（drain），以便将工作负载转移到不同的节点上，缓解问题。不幸的是，API 没有 drain 动作 —— 那些是 CLI 提供的宏，只是更新节点上的注释。使用 RBAC 试图达到这个级别的粒度是繁琐而复杂的，以至于不切实际。&lt;/p&gt;
&lt;p&gt;下面的基于意图的 K8s RBAC 图从概念上显示了你必须使用 RBAC 的工作内容 —— 你可以选择哪些用户 / 操作 / 资源组合是允许的。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr08337z4j30b908s75g_hu1fde108004ed619f9c0fae7fe61d2eb1_30833_405x316_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr08337z4j30b908s75g.jpg&#34; data-img=&#34;/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr08337z4j30b908s75g.jpg&#34; data-width=&#34;405&#34; data-height=&#34;316&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;相反，想象一下，如果 Kubernetes 是基于动作的（例如，它包括 cordon、drain、setImage、mountVolume、openPort 等 API）。那么我们就可以使用 RBAC 来授予读以及 cordon 和 drain，但没有其他的功能。基于动作的 API 只是有更多的名字，你可以在编写 RBAC 策略时使用。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr0978kbej30bc0d5wgf_hu57efb6b09c1384344ae2aae1b67b42aa_43744_408x473_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr0978kbej30bc0d5wgf.jpg&#34; data-img=&#34;/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr0978kbej30bc0d5wgf.jpg&#34; data-width=&#34;408&#34; data-height=&#34;473&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;简而言之，Kubernetes API 提供了一个强大的、可扩展的、统一的资源模型，但也正是这个资源模型使得 RBAC 对于很多用例来说过于粗粒度。RBAC 所能提供的控制是非常宝贵的，但比起其他系统，RBAC 还远不能满足 Kubernetes 的需要。&lt;/p&gt;
&lt;h3 id=&#34;我们需要什么来保证-k8s-的-api-安全&#34;&gt;我们需要什么来保证 K8s 的 API 安全？&lt;/h3&gt;
&lt;p&gt;那么如果 RBAC 不能提供足够的控制，我们该怎么做呢？我们来看一个例子。&amp;ldquo;所有的 pod 必须只使用来自受信任的存储库的镜像&amp;rdquo;（比如说，hooli.com）任何时候有人运行，比如说，kubectl apply，访问控制系统需要根据用户、动作 apply 和描述 pod 的 YAML 做出决定。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx-1493591563-bvl8q&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;production&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;privileged&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;hooli.com/frontend&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;frontend&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;privileged&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dnsPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterFirst&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;restartPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;为了做出正确的决策，访问控制系统需要提取镜像名称列表（如&lt;code&gt;nginx&lt;/code&gt;和&lt;code&gt;hooli.com/frontend&lt;/code&gt;），并进行字符串操作以提取仓库的名称（如默认的 repo 和 hooli.com）。&lt;/p&gt;
&lt;p&gt;一种方案是将一堆关于 Kubernetes 资源的知识构建到访问控制系统本身。然后管理员可以写一个策略，比如谁可以 &lt;code&gt;update-labels&lt;/code&gt;，&lt;code&gt;permitted-image-registries&lt;/code&gt; 是什么，等等。这就是大多数系统的做法 —— 发明一堆权限，然后在上面建立一个自定义的访问控制系统。&lt;/p&gt;
&lt;p&gt;但是构建一个自定义的访问控制系统对于 Kubernetes 来说是行不通的，因为它允许用户和厂商发明自己的 YAML 格式（自定义资源定义），并安装实现这些格式的代码。所以 Kubernetes 的资源可扩展性要求任何定制的 Kubernetes 访问控制系统本身都是可扩展的。&lt;/p&gt;
&lt;p&gt;所以，不管我们做什么，我们都需要一个访问控制系统，让管理员编写策略：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过 YAML 文件的层次结构进行递减。&lt;/li&gt;
&lt;li&gt;对数组中的元素进行迭代。&lt;/li&gt;
&lt;li&gt;操作字符串、IP、数字等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;标准的访问控制范式都不能满足这些要求。这包括基于角色的访问控制（RBAC）、基于属性的访问控制（ABAC）、访问控制列表（ACL），甚至是 IAM 风格的策略。&lt;/p&gt;
&lt;h3 id=&#34;使用准许控制来应急&#34;&gt;使用准许控制来应急&lt;/h3&gt;
&lt;p&gt;幸运的是，Kubernetes 团队预见到了这个问题，并创建了一个 &lt;a href=&#34;https://medium.com/r/?url=https%3A%2F%2Fkubernetes.io%2Fdocs%2Freference%2Faccess-authn-authz%2Fadmission-controllers%2F&#34; title=&#34;Admission Control&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Admission Control&lt;/a&gt; 机制，在这里你可以把控制的范围远远超过 RBAC 和标准的访问控制机制。Kubernetes API 服务器提供了一条访问控制的管道，分为 Authorization（如 RBAC），和 Admission。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr2h345xpj30rg06rq42_hu71380932dc0283c2e9b5f852d8863efa_43010_988x243_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr2h345xpj30rg06rq42.jpg&#34; data-img=&#34;/trans/why-rbac-is-not-enough-for-kubernetes-api-security/0081Kckwly1glr2h345xpj30rg06rq42.jpg&#34; data-width=&#34;988&#34; data-height=&#34;243&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;授权（Authorization）发生在每次 API 调用上，而准许（Addmission）只发生在更新（创建、更新和删除）上。通过授权，你将获得以下信息以做出决定：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;用户&lt;/strong&gt;：用户、组、认证提供的额外属性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动作&lt;/strong&gt;：路径、API 动词、HTTP 动词。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源&lt;/strong&gt;：资源、子资源、命名空间、API 组。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过 Admission，你会得到一个 YAML 中的 AdmissionReview 对象。它包括所有关于资源被修改的信息，以做出任何你想要的决定（见下面的 &lt;code&gt;request.object&lt;/code&gt;）。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;admission.k8s.io/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;AdmissionReview&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;request&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;frontend&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;object&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;creationTimestamp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;2018-10-27T02:12:20Z&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;app&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;frontend&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bbfee96d-d98d-11e8-b280-080027868e77&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;nginx&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resources&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;terminationMessagePath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/dev/termination-log&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;terminationMessagePolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;File&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumeMounts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;mountPath&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;/var/run/secrets/kubernetes.io/serviceaccount&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-token-tm9v8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;readOnly&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;dnsPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ClusterFirst&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;restartPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;schedulerName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-scheduler&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;securityContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;{}&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccount&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceAccountName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;terminationGracePeriodSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;30&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerations&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;effect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NoExecute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;node.kubernetes.io/not-ready&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Exists&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerationSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;effect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NoExecute&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;node.kubernetes.io/unreachable&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operator&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Exists&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;tolerationSeconds&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;300&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;volumes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-token-tm9v8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secret&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;secretName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default-token-tm9v8&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;status&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;phase&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pending&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;qosClass&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;BestEffort&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;oldObject&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; 
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;operation&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;CREATE&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;s1&#34;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;resource&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;pods&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;version&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;uid&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;bbfeef88-d98d-11e8-b280-080027868e77&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;userInfo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;groups&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;system:masters&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;system:authenticated&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;username&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;minikube-user &lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当然，你可以通过编写、部署和维护实现准入控制 webhook 协议（一个简单的 HTTP/json API）的自定义代码，编写任何你喜欢的逻辑来保护你的 API。现在，如果你不想支持和维护自定义代码，你可以使用 &lt;a href=&#34;https://medium.com/r/?url=https%3A%2F%2Fwww.openpolicyagent.org&#34; title=&#34;Open Policy Agent&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Open Policy Agent&lt;/a&gt; 作为 Kubernetes &lt;a href=&#34;https://www.openpolicyagent.org/docs/latest/kubernetes-tutorial/&#34; title=&#34;准入控制器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;准入控制器&lt;/a&gt;，并利用其声明式策略语言。该语言包括上述所需的表达能力：迭代、点注和 50 多个内置的可用于字符串操纵等。更多信息，请参见 &lt;a href=&#34;https://blog.openpolicyagent.org/securing-the-kubernetes-api-with-open-policy-agent-ce93af0552c3&#34; title=&#34;&amp;amp;rdquo; 利用 Open Policy Agent 确保 Kubernetes API 安全 &amp;amp;quot; 一文&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;rdquo; 利用 Open Policy Agent 确保 Kubernetes API 安全 &amp;quot; 一文&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;在这篇文章中，我们深入研究了 Kubernetes 所面临的 API 安全挑战，并重点介绍了以下几个关键要点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 基于意图的 API 让用户专注于他们希望 Kubernetes 处于什么状态，而不是如何实现它。&lt;/li&gt;
&lt;li&gt;基于意图的方法的核心好处之一是，它使 Kubernetes 在面对故障时具有弹性。因为系统知道自己应该做什么，所以当故障发生时，Kubernetes 知道如何恢复。&lt;/li&gt;
&lt;li&gt;Kubernetes 的 API 还提供了巨大的可扩展性。用户可以创建自己的自定义资源，而无需扩展 API。&lt;/li&gt;
&lt;li&gt;Kubernetes 的 API 所面临的挑战是，一个访问控制决策可能需要分析一个任意的 YAML 文档，例如使用点符号、迭代和字符串操纵。标准的访问控制系统，如 RBAC、ABAC、ACLs 和 IAM，根本没有足够的表达能力。&lt;/li&gt;
&lt;li&gt;Kubernetes 团队引入了准入控制（Admission Control），以赋予用户控制 API 的额外权力。你可以使用声明式授权解决方案（如 Open Policy Agent）作为 Kubernetes Admission Controller，为你提供所需的表达能力，以克服这些新的访问挑战，并提供真正有效的粒度。&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>亚马逊 EKS 发行版（EKS-D）介绍</title>
      <link>https://jimmysong.io/trans/introducing-amazon-eks-distro/</link>
      <pubDate>Tue, 01 Dec 2020 10:03:00 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/trans/introducing-amazon-eks-distro/</guid>
      <description>
        
        
        &lt;p&gt;今天，我们发布了 &lt;a href=&#34;https://distro.eks.amazonaws.com/&#34; title=&#34;Amazon EKS Distro&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon EKS Distro&lt;/a&gt;（EKS-D），这是一个基于 &lt;a href=&#34;https://amazonaws-china.com/eks/&#34; title=&#34;Amazon Elastic Kubernetes Service&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Amazon Elastic Kubernetes Service&lt;/a&gt;（Amazon EKS）的 Kubernetes 发行版，并由 Amazon EKS 用于创建可靠和安全的 Kubernetes 集群。通过 EKS-D，你可以依赖 EKS 部署的相同版本的 Kubernetes 及其依赖项。这包括最新的上游更新以及扩展的安全补丁支持。EKS-D 遵循与亚马逊 EKS 相同的 Kubernetes 版本发布周期，我们以 &lt;a href=&#34;https://github.com/aws/eks-distro&#34; title=&#34;GitHub 上的开源项目的方式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub 上的开源项目的方式&lt;/a&gt; 提供。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我们将介绍 EKS Distro，并使用合作伙伴生态系统中的例子来解释开始使用 EKS Distro 的不同方法。&lt;/p&gt;
&lt;h2 id=&#34;什么是-eks-d&#34;&gt;什么是 EKS-D？&lt;/h2&gt;
&lt;p&gt;通过 EKS Distro，你现在可以在通过 EKS 提供的相同 Kubernetes 发行版上实现标准化。这意味着你现在可以手动部署可靠和安全的集群，而无需持续测试和跟踪 Kubernetes 更新、依赖性和安全补丁。每个 EKS Distro 版本都遵循 &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-release-calendar&#34; title=&#34;EKS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EKS&lt;/a&gt; 验证新 Kubernetes 版本兼容性的 &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html#kubernetes-release-calendar&#34; title=&#34;流程&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;流程&lt;/a&gt;。你还可以选择使用提供的构建环境设置、工具和我们发布的镜像的哈希值重现 EKS Distro 的构建，以确认你的下载在传输过程中没有被篡改。通过 EKS-D，我们为社区支持到期后的 Kubernetes 版本提供了扩展支持，更新了以前版本的构建，现在有了最新的安全补丁。&lt;/p&gt;
&lt;p&gt;在过去两年大规模运营 Amazon EKS 之后（我们说的是全球数百万个各种规模的集群），我们现在能够确定哪些工作、&lt;a href=&#34;https://kccncna19.sched.com/event/Uaav/living-with-the-pathology-of-the-cloud-how-aws-runs-lots-of-clusters-micah-hausler-amazon&#34; title=&#34;哪些组件要运行以及如何运行&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;哪些组件要运行以及如何运行&lt;/a&gt;。我们已经了解到，客户希望在企业内部和云端获得一致的体验，以便进行迁移或实现混合云设置。例如，客户有一个用例，由于数据主权的原因，部分工作负载驻留在内部的 Kubernetes 集群中，而其他部分则运行在 EKS 上。现在你手头就有了基于 EKS 的解决方案参考系。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/introducing-amazon-eks-distro/0081Kckwgy1glhwzwpf3fj30rs0fst9y_hu4712f47304cd0cd3fd997f90c31d6f8e_56235_1000x568_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/introducing-amazon-eks-distro/0081Kckwgy1glhwzwpf3fj30rs0fst9y.jpg&#34; data-img=&#34;/trans/introducing-amazon-eks-distro/0081Kckwgy1glhwzwpf3fj30rs0fst9y.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;568&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;对于 EC2 上的 EKS，你可以 &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/worker.html&#34; title=&#34;自己&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自己&lt;/a&gt; 管理节点，也可以使用 &lt;a href=&#34;https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html&#34; title=&#34;托管节点组&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;托管节点组&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;为了解决一致性的要求，我们想到了 EKS Distro，我们基于 EKS 的 Kubernetes 发行版，你可以在任何环境下运行，无论是裸机还是虚拟机。EKS-D 将上游的（未修改的）Kubernetes 和包，按照一定的、特意的方式进行配置，称为 &lt;a href=&#34;https://github.com/cncf/k8s-conformance/blob/master/faq.md&#34; title=&#34;Kubernetes 发行版&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 发行版&lt;/a&gt;，并将这些 &lt;a href=&#34;https://github.com/aws/eks-distro&#34; title=&#34;作为开源&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;作为开源&lt;/a&gt; 提供。fork 和 distribution 之间的区别很重要：fork 是一个替代上游的代码库。另一方面，发行版是一个特定的下游代码库，比如 Linux 发行版有 Ubuntu 和 Amazon Linux 2，比如 Hadoop 发行版，EMR 中有由 Cloudera 提供的并发行版。&lt;/p&gt;
&lt;p&gt;从高层的角度来看，EKS Distro 的情况如下（考虑到一些上游的开源项目，包括 Kubernetes 和 etcd）。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/trans/introducing-amazon-eks-distro/0081Kckwgy1glhwzx24n5j30sg0p1q45_hucabde210ae687730480c81a97bb9a4f2_53985_1000x880_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/trans/introducing-amazon-eks-distro/0081Kckwgy1glhwzx24n5j30sg0p1q45.jpg&#34; data-img=&#34;/trans/introducing-amazon-eks-distro/0081Kckwgy1glhwzx24n5j30sg0p1q45.jpg&#34; data-width=&#34;1000&#34; data-height=&#34;880&#34; alt=&#34;image&#34; data-caption=&#34;&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
&lt;/figure&gt;
&lt;p&gt;通过 EKS Distro，你可以通过单一供应商安全地访问可安装、可复制的 Kubernetes 构建，以创建集群，并在社区支持到期后提供 Kubernetes 版本的扩展安全补丁支持。我们将根据 Amazon EKS 版本生命周期政策提供长达 14 个月的 Kubernetes 扩展维护支持，为你提供必要的时间窗口来更新你的基础设施，使其与你的软件生命周期保持一致。&lt;/p&gt;
&lt;h2 id=&#34;开始使用-eks-d&#34;&gt;开始使用 EKS-D&lt;/h2&gt;
&lt;p&gt;我们与一些 &lt;a href=&#34;https://amazonaws-china.com/eks/eks-distro&#34; title=&#34;合作伙伴合作&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;合作伙伴合作&lt;/a&gt;，提供安装方法以及与 EKS Distro 的集成。下面，我们将重点介绍几家合作伙伴，以及他们为帮助你开始使用 EKS-D 所做的工作。&lt;/p&gt;
&lt;h3 id=&#34;weaveworks&#34;&gt;Weaveworks&lt;/h3&gt;
&lt;p&gt;Weave Kubernetes Platform（WKP）为 Amazon EKS Distro（EKS-D）带来了 GitOps，并为内部安装、创建和管理 EKS-D 集群提供支持。与任何 Kubernetes 发行版一样，EKS-D 需要配置、升级以及额外的组件和附加组件，如日志、跟踪和指标。WKP 通过将 GitOps 添加到你的 Kubernetes 环境的每一层，为 EKS-D 或任何其他云端和企业内部的发行版解决了这些问题。通过利用 Cluster API 项目，GitOps 工作流可以管理整个集群生命周期，包括维护、升级和补丁，以及 Prometheus 和 Grafana 等平台组件的集群配置。通过 WKP 交付和管理 EKS-D 集群，应用开发团队可以获得最新的 GitOps 功能，从而实现更频繁的部署，缩短价值实现时间，提高可靠性和可重复性。平台团队还可以获得对内部部署 EKS-D 的全面洞察和观察能力。Weaveworks &lt;a href=&#34;https://weave.works/blog/on-prem-kubernetes-gitops-eks-distro&#34; title=&#34;发布的博客文章&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;发布的博客文章&lt;/a&gt; 进一步详细描述了 EKS-D 和 WKP 之间的关系。另外一篇文章则是 &lt;a href=&#34;https://weave.works/blog/multicluster-gitops-eks-d-wkp&#34; title=&#34;在 EKS-D 和 EKS-D 混合场景下的 WKP 演示&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在 EKS-D 和 EKS-D 混合场景下的 WKP 演示&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;kubestack&#34;&gt;Kubestack&lt;/h3&gt;
&lt;p&gt;Kubestack 就是要为 Terraform 和 Kubernetes 提供最佳的 GitOps 开发者体验，从本地开发，一直到生产。通过他们 &lt;a href=&#34;https://dev.to/kubestack/localhost-eks-development-environments-with-eks-d-and-kubestack-4p6&#34; title=&#34;发布博文&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;发布博文&lt;/a&gt; 了解如何使用 Kubestack 管理 EKS-D 集群，你也可以找到一个 &lt;a href=&#34;https://www.youtube.com/watch?v=TcVwtfFww4w&#34; title=&#34;视频 demo&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;视频 demo&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;kubermatic&#34;&gt;Kubermatic&lt;/h3&gt;
&lt;p&gt;你可以使用 Kubermatic 的 &lt;a href=&#34;https://www.kubermatic.com/products/kubeone/&#34; title=&#34;KubeOne&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KubeOne&lt;/a&gt; 安装 EKS-D。KubeOne 是一个基础设施对等的开源 Kubernetes 集群生命周期管理工具，可以自动部署和 Day 2 操作单个 Kubernetes 集群。了解如何使用 Kubermatic 的开源集群生命周期管理工具 KubeOne 在 AWS 和 Amazon Linux 2 上 &lt;a href=&#34;https://www.kubermatic.com/blog/run-amazon-eks-distro-with-kubeone&#34; title=&#34;安装 EKS-D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;安装 EKS-D&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;aqua-security&#34;&gt;Aqua Security&lt;/h3&gt;
&lt;p&gt;为了保护 EKS-D 的安全，你需要一个整体的方法来征服 Kubernetes 的复杂性。Aqua 提供 KSPM（Kubernetes 安全态势管理）来提高可观测性和补救错误配置，以及先进的、无代理的 Kubernetes 运行时保护。你还可以使用 Kubernetes 原生功能，为你的 Kubernetes 应用实现策略驱动的全生命周期保护和合规性。了解更多关于 &lt;a href=&#34;https://blog.aquasec.com/aws-security-eks-distro&#34; title=&#34;Aqua 的 EKS-D 集成的信息&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aqua 的 EKS-D 集成的信息&lt;/a&gt;。&lt;/p&gt;
&lt;h3 id=&#34;sysdig&#34;&gt;Sysdig&lt;/h3&gt;
&lt;p&gt;Sysdig 提供安全和可视性，以检测和响应运行时威胁，验证合规性，并监控和排除 EKS-D 上的容器。查看他们的 &lt;a href=&#34;https://sysdig.com/blog/security-compliance-visibility-amazon-eks-d&#34; title=&#34;发布博客文章&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;发布博客文章&lt;/a&gt;，了解更多关于使用 CNCF Falco 和 Sysdig Secure 管理 EKS-D 工作负载中的运行时安全的信息。&lt;/p&gt;
&lt;h3 id=&#34;tetrate&#34;&gt;Tetrate&lt;/h3&gt;
&lt;p&gt;Tetrate Service Bridge（TSB）&lt;a href=&#34;https://www.tetrate.io/blog/tetrate-expands-aws-partnership-to-bring-enterprise-grade-istio-for-eks-and-eks-distro/&#34; title=&#34;可在 EKS 和 EKS-D 上实现跨工作负载的统一应用连接和安全&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;可在 EKS 和 EKS-D 上实现跨工作负载的统一应用连接和安全&lt;/a&gt;。TSB 为企业级（上游或符合 FIPS 标准）Istio 和 Envoy Proxy 提供了便捷的访问和操作性。多租户、流量管理、网状和应用级可观测性、端到端 mTLS（相互传输层安全）、细粒度授权和应用安全是 TSB 的关键要素。&lt;/p&gt;
&lt;p&gt;一系列合作伙伴一直在开展更多与 EKS-D 有关的活动，包括：&lt;/p&gt;
&lt;h3 id=&#34;供应和管理&#34;&gt;供应和管理&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;了解如何 使用 Rancher 的 RKE2 部署 EKS-D&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://snapcraft.io/eks&#34; title=&#34;看看使用 Canonical 的 MicroK8s 安装 EKS-D&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;看看使用 Canonical 的 MicroK8s 安装 EKS-D&lt;/a&gt; 有多简单 &lt;a href=&#34;https://snapcraft.io/eks&#34; title=&#34;，一目了&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;，一目了&lt;/a&gt; 然&lt;/li&gt;
&lt;li&gt;探索如何使用 &lt;a href=&#34;https://rafay.co/the-kubernetes-current/how-to-provision-and-manage-amazons-eks-distribution-using-rafay&#34; title=&#34;Rafay 的托管 Kubernetes 平台（MKP）来管理 EKS-D 集群&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rafay 的托管 Kubernetes 平台（MKP）来管理 EKS-D 集群&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;查看如何 &lt;a href=&#34;https://pulumi.com/blog/amazon-eks-distro&#34; title=&#34;使用 Pulumi 配置 EKS-D 集群&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 Pulumi 配置 EKS-D 集群&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.upbound.io/eks-d-and-upbound/&#34; title=&#34;Upbound Cloud 使 EKS-D 用户可以轻松地将集群的配置整合&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Upbound Cloud 使 EKS-D 用户可以轻松地将集群的配置整合&lt;/a&gt; 到一个与环境无关的 Crossplane 配置库中。利用这些配置，集群就可以通过一个统一的 API 接口在企业内部、云端或边缘进行配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;观察性&#34;&gt;观察性&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;通过 Instana，你可以 &lt;a href=&#34;https://instana.com/blog/instana-brings-best-in-class-observability-with-the-new-amazon-kubernetes-distribution/&#34; title=&#34;自动监控和可视化&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自动监控和可视化&lt;/a&gt; EKS-D 的工作负载&lt;/li&gt;
&lt;li&gt;Sumo Logic 展示了他们如何 &lt;a href=&#34;https://www.sumologic.com/blog/monitor-aws-kubernetes-service/&#34; title=&#34;与 EKS-D 一起工作&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;与 EKS-D 一起工作&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Epsagon 使你能够 &lt;a href=&#34;https://epsagon.com/announcements/amazon-eks-distro/&#34; title=&#34;监控 EKS-D 工作负载&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;监控 EKS-D 工作负载&lt;/a&gt;，包括控制平面指标&lt;/li&gt;
&lt;li&gt;Datadog 提供了跨内部、混合和云计算基础设施的虚拟机、容器和无服务器环境的健康状况的可视性。了解有关 &lt;a href=&#34;https://www.datadoghq.com/blog/amazon-eks-distro-monitoring/&#34; title=&#34;EKS-D 支持&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;EKS-D 支持&lt;/a&gt; 的更多信息。&lt;/li&gt;
&lt;li&gt;Splunk 基础设施监控为所有 Kubernetes 环境 —— 云原生 Amazon EKS、与 Amazon Outposts 的混合 &lt;a href=&#34;https://www.splunk.com/en_us/blog/devops/monitor-amazon-eks-distro-eks-d-with-splunk.html&#34; title=&#34;环境&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;环境&lt;/a&gt; 以及内部 &lt;a href=&#34;https://www.splunk.com/en_us/blog/devops/monitor-amazon-eks-distro-eks-d-with-splunk.html&#34; title=&#34;自我管理的 EKS-D 环境&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自我管理的 EKS-D 环境&lt;/a&gt; 提供了企业级监控解决方案。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;安全&#34;&gt;安全&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;了解 &lt;a href=&#34;https://nirmata.com/2020/11/20/nirmata-delivers-consistent-hybrid-cloud-kubernetes-with-aws/&#34; title=&#34;Nirmata 的 EKS 管理器与 EKS-D 的集成&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nirmata 的 EKS 管理器与 EKS-D 的集成&lt;/a&gt;，以及如何使用它来加强你的安全态势&lt;/li&gt;
&lt;li&gt;Alcide 为跨越 EKS、Outposts 和 &lt;a href=&#34;https://blog.alcide.io/alcide-and-amazon-eks-distro&#34; title=&#34;新增加的 EKS-D 的&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;新增加的 EKS-D 的&lt;/a&gt; 混合部署提供集中统一的安全覆盖&lt;/li&gt;
&lt;li&gt;查看 Tigera 围绕 Calico 和 Calico Enterprise 支持所 做的工作 ，以实现运行 EKS-D 的集群的强大安全性和合规性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;你可以想象，这只是旅程的开始。你可能会问，下一步是什么？&lt;/p&gt;
&lt;h2 id=&#34;下一步&#34;&gt;下一步&lt;/h2&gt;
&lt;p&gt;要开始使用 EKS Distro，请访问 &lt;a href=&#34;https://distro.eks.amazonaws.com/&#34; title=&#34;https://distro.eks.amazonaws.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://distro.eks.amazonaws.com&lt;/a&gt;，并使用 kops 或 kubeadm 或上述任何一个合作伙伴提供的解决方案亲自尝试。&lt;/p&gt;
&lt;p&gt;你可以通过 GitHub 提供反馈和 PR，成为 EKS-D 社区的一员。如果你喜欢更多的互动交流，可以在 Kubernetes Slack 社区通过 #eks 频道或 AWS 开发者 Slack 频道加入我们，我们在那里设置了 #eks-d 频道。&lt;/p&gt;
&lt;p&gt;我们很高兴了解你使用 EKS Distro 的情况，并听取你的反馈和建议。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>云原生初学者入门必读</title>
      <link>https://jimmysong.io/blog/must-read-for-cloud-native-beginner/</link>
      <pubDate>Sun, 18 Oct 2020 14:18:40 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/must-read-for-cloud-native-beginner/</guid>
      <description>
        
        
        &lt;h2 id=&#34;为什么写这篇文章&#34;&gt;为什么写这篇文章&lt;/h2&gt;
&lt;p&gt;看到这个标题后，大家可能会问“都已经 2020 年了，Kubernetes 开源有 6 年时间了，为什么还要写一篇 Kubernetes 入门的文章？”我想说的是，Kubernetes 还远远没有达到我们想象的那么普及。众多的开发者，平时忙于各自的业务开发，学习新技术的时间有限；还有大量的学生群体，可能还仅仅停留在“知道有这门技术”的阶段，远远没有入门。这篇文章将助于各位有志于从事云原生领域工作或需要了解该领域背景的人群快速入门 Kubernetes 和云原生。&lt;/p&gt;
&lt;p&gt;因为云原生的知识体系过于庞杂，本文主要讲解容器、Kubernetes 及服务网格的入门概念，关于云原生的更多细节将在后续文章中推出。&lt;/p&gt;
&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34; title=&#34;Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt; 一词来自希腊语，意思是“飞行员”或“舵手”。这个名字很贴切，Kubernetes 可以帮助你在波涛汹涌的容器海洋中航行。&lt;/p&gt;
&lt;p&gt;Kubernetes 是做什么的？什么是 Docker？什么是容器编排？Kubernetes 是如何工作和扩展的？你可能还有很多其他的问题，本文将一一为你解答。&lt;/p&gt;
&lt;p&gt;这篇文章适合初学者，尤其是那些工作忙碌，没有办法抽出太多时间来了解 Kubernetes 和云原生的开发者们，希望本文可以帮助你进入 Kubernetes 的世界。&lt;/p&gt;
&lt;p&gt;简而言之，Kubernetes 提供了一个平台或工具来帮助你快速协调或扩展容器化应用，特别是在 &lt;a href=&#34;https://docker.com/&#34; title=&#34;Docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker&lt;/a&gt; 容器。让我们深入了解一下这些概念。&lt;/p&gt;
&lt;h2 id=&#34;容器和容器化&#34;&gt;容器和容器化&lt;/h2&gt;
&lt;p&gt;那么什么是容器呢？&lt;/p&gt;
&lt;p&gt;要讨论容器化首先要谈到虚拟机 (VM)，顾名思义，虚拟机就是可以远程连接的虚拟服务器，比如 AWS 的 EC2 或阿里云的 ECS。&lt;/p&gt;
&lt;p&gt;接下来，假如你要在虚拟机上运行一个网络应用——包括一个 MySQL 数据库、一个 Vue 前端和一些 Java 库，在 Ubuntu 操作系统 (OS) 上运行。你不用熟悉其中的每一个技术——你只要记住，一个应用程序由各种组件、服务和库组成，它们运行在操作系统上。&lt;/p&gt;
&lt;p&gt;现在，将应用程序打包成一个虚拟机镜像，这个镜像中包括了 Ubuntu 操作系统。这使得虚拟机变得非常笨重——通常有几个 G 的大小。&lt;/p&gt;
&lt;p&gt;虚拟机镜像包含了整个操作系统及所有的库，对应用程序来说，这个镜像过于臃肿，其中大部分组件并没有被应用程序直接调用。如果你需要重新创建、备份或扩展这个应用程序，就需要复制整个环境（虚拟机镜像），在新环境中启动应用通常需要几十秒甚至几分钟时间。如果你想单独升级应用中的某个组件，比如说 Vue 应用，就需要重建整个虚拟机镜像。另外，如果你的两个应用依赖同一个底层镜像，升级底层镜像会同时影响这两个应用，而有时候，你只需要升级其中一个应用的依赖而已。这就是所谓的“依赖陷阱”。&lt;/p&gt;
&lt;p&gt;解决这个问题的办法就是容器。容器是继虚拟机之后更高层次的抽象，在这层抽象中，整个应用程序的每个组件被单独打包成一个个独立的单元，这个单元就是所谓的容器。通过这种方式，可以将代码和应用服务从底层架构中分离出来，实现了完全的可移植性（在任何操作系统或环境上运行应用的能力）。所以在上面的例子中，Ubuntu 操作系统就是一个单元（容器）。MySQL 数据库是另一个容器，Vue 环境和随之而来的库也是一个容器。&lt;/p&gt;
&lt;p&gt;但是，MySQL 数据库是如何自己“运行”的？数据库本身肯定也要在操作系统上运行吧？没错！&lt;/p&gt;
&lt;p&gt;更高层次的容器，比如 MySQL 容器，实际上会包含必要的库来与底层的操作系统容器通信和集成。所以你可以把容器看成是整个应用堆栈中的一层，每层都依赖于下层的单元。而这就类似于船舶或港口中集装箱的堆叠方式，每个容器的稳定性都依赖于下面的容器的支持。所以应用容器的核心是一个受控的执行环境。它们允许你从头开始定义整个环境，从操作系统开始，到你要使用的各个版本的库，再到你要添加的代码版本。&lt;/p&gt;
&lt;p&gt;与容器相关的一个重要概念是&lt;strong&gt;微服务&lt;/strong&gt;。将应用程序的各个组件拆分并打包成独立的服务，这样每个组件都可以很容易地被替换、升级、调试。上面的例子中，我们会为 Vue 前端创建一个微服务，为 MySQL 数据库创建另一个微服务，为 Java 中间件部分创建另一个微服务，以此类推。很明显，微服务与容器化是相辅相成的。&lt;/p&gt;
&lt;h2 id=&#34;从-docker-开始&#34;&gt;从 Docker 开始&lt;/h2&gt;
&lt;p&gt;现在你已经对容器有一定了解了吧？Docker 是最常用的容器化工具，也是最流行的容器运行时。&lt;/p&gt;
&lt;p&gt;Docker 开源于 2013 年。用于打包和创建容器，管理基于容器的应用。所有 Linux 发行版、Windows 和 macOS 都支持 Docker。&lt;/p&gt;
&lt;p&gt;还有其他的容器化工具，如 &lt;a href=&#34;https://coreos.com/rkt/&#34; title=&#34;CoreOS rkt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CoreOS rkt&lt;/a&gt;、&lt;a href=&#34;http://mesos.apache.org/documentation/latest/mesos-containerizer/&#34; title=&#34;Mesos Containerizer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mesos Containerizer&lt;/a&gt; 和 &lt;a href=&#34;https://linuxcontainers.org/&#34; title=&#34;LXC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LXC&lt;/a&gt;。但是目前，绝大多数的容器化应用都是在 Docker 上运行的。&lt;/p&gt;
&lt;h2 id=&#34;再到-kubernetes&#34;&gt;再到 Kubernetes&lt;/h2&gt;
&lt;p&gt;首先，简单介绍一下历史。Kubernetes 是 Google 基于其内部容器调度平台 Borg 的经验开发的。2014 年开源，并作为 CNCF（云原生计算基金会）的核心发起项目。&lt;/p&gt;
&lt;p&gt;那么 Kubernetes 又跟容器是什么关系呢？让我们再回到上面的例子。假设我们的应用爆火，每天的注册用户越来越多。&lt;/p&gt;
&lt;p&gt;现在，我们需要增加后端资源，使浏览我们网站的用户在浏览页面时加载时间不会过长或者超时。最简单的方式就是增加容器的数量，然后使用负载均衡器将传入的负载（以用户请求的形式）分配给容器。&lt;/p&gt;
&lt;p&gt;这样做虽然行之有效，但也只能在用户规模有限的情况下使用。当用户请求达到几十万或几百万时，这种方法也是不可扩展的。你需要管理几十个也许是几百个负载均衡器，这本身就是另一个令人头疼的问题。如果我们想对网站或应用进行任何升级，也会遇到问题，因为负载均衡不会考虑到应用升级的问题。我们需要单独配置每个负载均衡器，然后升级该均衡器所服务的容器。想象一下，当你有 20 个负载均衡器和每周 5 或 6 个小的更新时，你将不得不进行大量的手工劳动。&lt;/p&gt;
&lt;p&gt;我们需要的是一种可以一次性将变更传递给所有受控容器的方法，同时也需要一种可以轻松地调度可用容器的方法，这个过程还必须要是自动化的，这正是 Kubernetes 所做的事情。&lt;/p&gt;
&lt;p&gt;接下来，我们将探讨 Kubernetes 究竟是如何工作的，它的各种组件和服务，以及更多关于如何使用 Kubernetes 来编排、管理和监控容器化环境。为了简单起见，假设我们使用的是 Docker 容器，尽管如前所述，Kubernetes 除了支持 Docker 之外，还支持其他几种容器平台。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-架构和组件&#34;&gt;Kubernetes 架构和组件&lt;/h2&gt;
&lt;p&gt;首先，最重要的是你需要认识到 Kubernetes 利用了“期望状态”原则。就是说，你定义了组件的期望状态，而 Kubernetes 要将它们始终调整到这个状态。&lt;/p&gt;
&lt;p&gt;例如，你想让你的 Web 服务器始终运行在 4 个容器中，以达到负载均衡的目的，你的数据库复制到 3 个不同的容器中，以达到冗余的目的。这就是你想要的状态。如果这 7 个容器中的任何一个出现故障，Kubernetes 引擎会检测到这一点，并自动创建出一个新的容器，以确保维持所需的状态。&lt;/p&gt;
&lt;p&gt;现在我们来定义一些 Kubernetes 的重要组件。&lt;/p&gt;
&lt;p&gt;当你第一次设置 Kubernetes 时，你会创建一个集群。所有其他组件都是集群的一部分。你也可以创建多个虚拟集群，称为命名空间 (namespace)，它们是同一个物理集群的一部分。这与你可以在同一物理服务器上创建多个虚拟机的方式非常相似。如果你不需要，也没有明确定义的命名空间，那么你的集群将在始终存在的默认命名空间中创建。&lt;/p&gt;
&lt;p&gt;Kubernetes 运行在节点 (node) 上，节点是集群中的单个机器。如果你有自己的硬件，节点可能对应于物理机器，但更可能对应于在云中运行的虚拟机。节点是部署你的应用或服务的地方，是 Kubernetes 工作的地方。有 2 种类型的节点——master 节点和 worker 节点，所以说 Kubernetes 是主从结构的。&lt;/p&gt;
&lt;p&gt;主节点是一个控制其他所有节点的特殊节点。一方面，它和集群中的任何其他节点一样，这意味着它只是另一台机器或虚拟机。另一方面，它运行着控制集群其他部分的软件。它向集群中的所有其他节点发送消息，将工作分配给它们，工作节点向主节点上的 API Server 汇报。&lt;/p&gt;
&lt;p&gt;Master 节点本身也包含一个名为 API Server 的组件。这个 API 是节点与控制平面通信的唯一端点。API Server 至关重要，因为这是 worker 节点和 master 节点就 pod、deployment 和所有其他 Kubernetes API 对象的状态进行通信的点。&lt;/p&gt;
&lt;p&gt;Woker 节点是 Kubernetes 中真正干活的节点。当你在应用中部署容器或 pod（稍后定义）时，其实是在将它们部署到 worker 节点上运行。Worker 节点托管和运行一个或多个容器的资源。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的逻辑而非物理的工作单位称为 pod。一个 pod 类似于 Docker 中的容器。记得我们在前面讲到，容器可以让你创建独立、隔离的工作单元，可以独立运行。但是要创建复杂的应用程序，比如 Web 服务器，你经常需要结合多个容器，然后在一个 pod 中一起运行和管理。这就是 pod 的设计目的——一个 pod 允许你把多个容器，并指定它们如何组合在一起来创建应用程序。而这也进一步明确了 Docker 和 Kubernetes 之间的关系——一个 Kubernetes pod 通常包含一个或多个 Docker 容器，所有的容器都作为一个单元来管理。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的 service 是一组逻辑上的 pod。把一个 service 看成是一个 pod 的逻辑分组，它提供了一个单一的 IP 地址和 DNS 名称，你可以通过它访问服务内的所有 pod。有了服务，就可以非常容易地设置和管理负载均衡，当你需要扩展 Kubernetes pod 时，这对你有很大的帮助，我们很快就会看到。&lt;/p&gt;
&lt;p&gt;ReplicationController 或 ReplicaSet 是 Kubernetes 的另一个关键功能。它是负责实际管理 pod 生命周期的组件——当收到指令时或 pod 离线或意外停止时启动 pod，也会在收到指示时杀死 pod，也许是因为用户负载减少。所以换句话说，ReplicationController 有助于实现我们所期望的指定运行的 pod 数量的状态。&lt;/p&gt;
&lt;h2 id=&#34;什么是-kubectl&#34;&gt;什么是 Kubectl？&lt;/h2&gt;
&lt;p&gt;kubectl 是一个命令行工具，用于与 Kubernetes 集群和其中的 pod 通信。使用它你可以查看集群的状态，列出集群中的所有 pod，进入 pod 中执行命令等。你还可以使用 YAML 文件定义资源对象，然后使用 kubectl 将其应用到集群中。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中的自动扩展&#34;&gt;Kubernetes 中的自动扩展&lt;/h2&gt;
&lt;p&gt;请记住，我们使用 Kubernetes 而不是直接使用 Docker 的原因之一，是因为 Kubernetes 能够自动扩展应用实例的数量以满足工作负载的需求。&lt;/p&gt;
&lt;p&gt;自动缩放是通过集群设置来实现的，当服务需求增加时，增加节点数量，当需求减少时，则减少节点数量。但也要记住，节点是“物理”结构——我们把“物理”放在引号里，因为要记住，很多时候，它们实际上是虚拟机。&lt;/p&gt;
&lt;p&gt;无论如何，节点是物理机器的事实意味着我们的云平台必须允许 Kubernetes 引擎创建新机器。各种云提供商对 Kubernetes 支持基本都满足这一点。&lt;/p&gt;
&lt;p&gt;我们再继续说一些概念，这次是和网络有关的。&lt;/p&gt;
&lt;h2 id=&#34;什么是-kubernetes-ingress-和-egress&#34;&gt;什么是 kubernetes Ingress 和 Egress？&lt;/h2&gt;
&lt;p&gt;外部用户或应用程序与 Kubernetes pod 交互，就像 pod 是一个真正的服务器一样。我们需要设置安全规则允许哪些流量可以进入和离开“服务器”，就像我们为托管应用程序的服务器定义安全规则一样。&lt;/p&gt;
&lt;p&gt;进入 Kubernetes pod 的流量称为 Ingress，而从 pod 到集群外的出站流量称为 egress。我们创建入口策略和出口策略的目的是限制不需要的流量进入和流出服务。而这些策略也是定义 pod 使用的端口来接受传入和传输传出数据 / 流量的地方。&lt;/p&gt;
&lt;h2 id=&#34;什么是-ingress-controller&#34;&gt;什么是 Ingress Controller？&lt;/h2&gt;
&lt;p&gt;但是在定义入口和出口策略之前，你必须首先启动被称为 Ingress Controller（入口控制器）的组件；这个在集群中默认不启动。有不同类型的入口控制器，Kubernetes 项目默认只支持 Google Cloud 和开箱即用的 Nginx 入口控制器。通常云供应商都会提供自己的入口控制器。&lt;/p&gt;
&lt;h2 id=&#34;什么是-replica-和-replicaset&#34;&gt;什么是 Replica 和 ReplicaSet？&lt;/h2&gt;
&lt;p&gt;为了保证应用程序的弹性，需要在不同节点上创建多个 pod 的副本。这些被称为 Replica。假设你所需的状态策略是“让名为 webserver-1 的 pod 始终维持在 3 个副本”，这意味着 ReplicationController 或 ReplicaSet 将监控活动副本的数量，如果其中有任何一个 replica 因任何原因不可用（例如节点的故障），那么 Deployment Controller 将自动创建一个新的系统（定义如下）。&lt;/p&gt;
&lt;p&gt;所需状态是在 deployment 中定义的。Master 节点的中有一个子系统叫做 Deployment Controller，负责实际执行并使当前状态不断趋向于所需状态。&lt;/p&gt;
&lt;p&gt;因此，举例来说，如果你目前有 2 个 pod 的副本，而你所希望的状态应该有 3 个，那么 Replication Controller 或 ReplicaSet 会自动检测到这个要求，并指示 Deployment Controller 根据预定义的设置部署一个新的 pod。&lt;/p&gt;
&lt;h2 id=&#34;什么是服务网格&#34;&gt;什么是服务网格？&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://jimmysong.io/blog/what-is-a-service-mesh/&#34; title=&#34;服务网格 (Service Mesh)&#34;&gt;服务网格 (Service Mesh)&lt;/a&gt; 用于管理服务之间的网络流量，是云原生的网络基础设施层，也是 &lt;a href=&#34;https://jimmysong.io/blog/post-kubernetes-era/&#34; title=&#34;Kubernetes 次世代的云原生应用&#34;&gt;Kubernetes 次世代的云原生应用&lt;/a&gt; 的重要组成部分。&lt;/p&gt;
&lt;p&gt;服务网格利用容器之间的网络设置来控制或改变应用程序中不同组件之间的交互。下面，我们用一个例子来说明。假设你想测试 Nginx 的新版本，检查它是否与你的 Web 应用兼容。你用新的 Nginx 版本创建了一个新的容器 (Container2)，并从当前容器 (Container1) 中复制了当前的 Nginx webserver 配置。但你不想影响组成 web 应用的其他微服务（假设每个容器对应一个单独的微服务）——就是 MySQL 数据库、Node.js 前端、负载均衡器等。&lt;/p&gt;
&lt;p&gt;所以使用服务网格，你可以立即只把 webserver 微服务改成 Container2（新 Nginx 版本的那个）进行测试。如果确定它不能工作，比如因为它导致网站出现一些兼容性问题，那么你就调用服务网格来快速切换回原来的 Container1。而这一切都不需要对其他容器进行任何配置变更——这些变更对其他容器是完全透明的。&lt;/p&gt;
&lt;p&gt;如果没有服务网格，对容器来说这项工作将十分繁琐，因为这涉及到逐一更改所有其他容器上的配置，将它们所包含的服务从 Container1 指向 Container2，然后在测试失败后，将它们全部改回来。&lt;/p&gt;
&lt;p&gt;在前面这部分 Kubernetes 指南中，我们介绍了一些与 Kubernetes 网络相关的概念。Kubernetes 中的网络可能很棘手，很难理解，如果你刚刚开始，你可能需要一些实践来理解这里。&lt;/p&gt;
&lt;p&gt;在下一部分中，我们将展开更多关于 Kubernetes 的话题：如何开始学习 Kubernetes，如何在本地安装和测试 Kubernetes，以及 Kubernetes 的一些优秀的监控工具。&lt;/p&gt;
&lt;h2 id=&#34;如何学习-kubernetes&#34;&gt;如何学习 Kubernetes？&lt;/h2&gt;
&lt;p&gt;自学 Kubernetes 知识基本上有三种不同的途径，我们在这里只提供了一个指导大纲。&lt;/p&gt;
&lt;h3 id=&#34;一从零开始学习和安装-kubernetes&#34;&gt;一、从零开始学习和安装 Kubernetes&lt;/h3&gt;
&lt;p&gt;要想真正掌握 Kubernetes，最好的办法莫过于自己从头开始安装 Kubernetes。不过要注意的是，从零开始安装 Kubernetes 并不是一件容易的事情。安装 Kubernetes 并不是简单的“下载文件 -&amp;gt; 点击安装”式的操作，Kubernetes 由多个组件组成，这些组件必须单独安装和配置。而在此之前，你也需要相当的技术储备来做安装前的准备，比如熟悉 Linux 操作系统。如果你决定使用这种方式学习的话，推荐你阅读 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook&#34; title=&#34;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&lt;/a&gt;。此外，请记住，尽管 Kubernetes 作为一个开源解决方案在技术上是免费的，但它确实有一些隐藏的成本，只不过对初学者来说可能并不明显。&lt;/p&gt;
&lt;h3 id=&#34;二kubernetes-自托管解决方案&#34;&gt;二、Kubernetes 自托管解决方案&lt;/h3&gt;
&lt;p&gt;这些解决方案样是一些工具和实用程序，大大简化了在本地计算机上安装和配置小型 Kubernetes 集群的任务。它们是学习 Kubernetes 的好方法，同时对于新手来说也不会太难，又足够小巧可以到安装在个人电脑上。最流行的自托管 Kubernetes 工具和环境是 &lt;a href=&#34;https://github.com/kubernetes/minikube&#34; title=&#34;Minikube&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Minikube&lt;/a&gt;、&lt;a href=&#34;https://github.com/ubuntu/microk8s&#34; title=&#34;MicroK8s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MicroK8s&lt;/a&gt;、&lt;a href=&#34;https://docs.docker.com/docker-for-windows/kubernetes/&#34; title=&#34;Docker Desktop&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker Desktop&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/kubernetes-sigs/kind&#34; title=&#34;Kind&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kind&lt;/a&gt;。这些解决方案往往有一些限制，例如，Minikube 只允许创建一个节点。尽管有这些缺点，但这些工具还是非常值得推荐，因为它们将易学性和成本效益结合起来，对于刚开始使用 Kubernetes 的初学者来说，是一个很好的选择。&lt;/p&gt;
&lt;h3 id=&#34;三云托管的解决方案&#34;&gt;三、云托管的解决方案&lt;/h3&gt;
&lt;p&gt;如今各大云供应商都提供了定制化的 Kubernetes 解决方案来。你也可以通过线上教学平台如 &lt;a href=&#34;https://katacoda.com/&#34; title=&#34;Katacoda&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Katacoda&lt;/a&gt; 上的免费课程来学习 Kubernetes，它们都是云托管的，你不需要自己安装，只不过你需要云供应商的集群需要付费。&lt;/p&gt;
&lt;h2 id=&#34;本地测试和调试-kubernetes&#34;&gt;本地测试和调试 Kubernetes&lt;/h2&gt;
&lt;p&gt;作为本地安装 Kubernetes 的一部分，你很可能还需要一些测试和调试能力，以确保一切都在顺利运行，特别是定义入口和出口策略等棘手的任务。此外，还有 Kubernetes 附加组件的生态系统，你可能想使用这些组件来扩展 Kubernetes 集群的功能。添加所有这些都需要进行更多的测试，以确保它们能与你的 Kubernetes 集群完美的集成。&lt;/p&gt;
&lt;p&gt;用于在本地开发和调试 Kubernetes 服务的工具有：&lt;a href=&#34;https://github.com/microsoft/mindaro&#34; title=&#34;Microsoft Bridge to Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Microsoft Bridge to Kubernetes&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/telepresenceio/telepresence&#34; title=&#34;telepresence&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;telepresence&lt;/a&gt;。这些工具可以让你在本地运行单个服务，同时将该服务连接到远程 Kubernetes 集群。这样你就可以让自己的本地机器作为 Kubernetes 集群中的一部分来运行——这对于在本地而不是在生产集群上开发服务非常有用。&lt;/p&gt;
&lt;p&gt;Kubernetes 项目也了解到了 Kubernetes 安装对端到端 (E2E) 测试的需求。为此，项目核心团队一直在确保在最近的版本中更恰当地支持 E2E 测试。这包括诸如允许测试重用和纳入更多附加组件和驱动程序的测试等。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-监控工具&#34;&gt;Kubernetes 监控工具&lt;/h2&gt;
&lt;p&gt;Kubernetes 提供了应用程序在集群的每个层次上的资源使用情况的详细信息——容器、pod、服务。这些详细信息使你能够评估应用程序的性能，确定哪些瓶颈可以解决以提高整体性能。&lt;/p&gt;
&lt;p&gt;毕竟，监控可以帮助你了解应用和集群运行情况的详细信息，这对于学习 Kubernetes 是十分有帮助的。&lt;/p&gt;
&lt;p&gt;Kubernetes 包含两个内置度量收集工具用于监控：&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/&#34; title=&#34;资源管道和全度量管道&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;资源管道和全度量管道&lt;/a&gt;。资源管道是一个较低级和较有限的工具，主要集中在与各种控制器相关的指标上。全指标管道，顾名思义，从几乎所有集群组件中获取并显示更丰富的指标。&lt;/p&gt;
&lt;p&gt;还有一些第三方工具可以安装并集成到 Kubernetes 集群中。对于 Kubernetes 来说，最普遍使用的两个工具是 Prometheus 和 Grafana。&lt;/p&gt;
&lt;h3 id=&#34;prometheus-监控&#34;&gt;Prometheus 监控&lt;/h3&gt;
&lt;p&gt;Prometheus 是一个功能丰富的开源监控和警报工具。Prometheus 包含一个内部数据存储用来收集指标，如生成的时间序列数据。Prometheus 还拥有众多插件，允许它将数据暴露给各种外部解决方案，并从其他数据源导入数据，包括所有主要公有云监控解决方案。&lt;/p&gt;
&lt;h3 id=&#34;grafana-仪表盘&#34;&gt;Grafana 仪表盘&lt;/h3&gt;
&lt;p&gt;Grafana 是一个优秀的仪表盘、分析和数据可视化工具。它没有 Prometheus 的全功能数据收集能力，但 Prometheus 又没有 Grafana 的数据呈现界面。事实上，他们最好是结合在一起使用——Prometheus 负责数据收集和汇总，Grafana 负责数据展示。它们共同创造了一个强大的组合，涵盖了数据收集、基本警报和可视化。&lt;/p&gt;
&lt;h3 id=&#34;高级警报&#34;&gt;高级警报&lt;/h3&gt;
&lt;p&gt;对于高级警报，你可以添加 &lt;a href=&#34;https://www.nagios.org/&#34; title=&#34;Nagios&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nagios&lt;/a&gt; 或 &lt;a href=&#34;https://github.com/prometheus/alertmanager&#34; title=&#34;Prometheus Alertmanager&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prometheus Alertmanager&lt;/a&gt; 等工具。这些警报工具通常有大量的集成。你可以为自定义值班团队，然后定义你想要监控的参数，例如“当任何 pod 不可用时”或“当任何节点无法访问时”、“当容量达到 90%”等，然后通过电子邮件、短信、手机应用提醒、电话呼叫等方式向值班人员发送自定义通知。你还可以创建升级策略，比如，如果一个被定义为“危急”的警报在 10 分钟内没有值班人员确认，那么就将警报升级（发送警报）到该人员的经理。&lt;/p&gt;
&lt;p&gt;现在，你应该已经对 Docker 和 Kubernetes 有了大体的认识。了解了 Kubernetes 的作用，知道它是如何进行容器化应用部署和管理的。&lt;/p&gt;
&lt;p&gt;调试和监控技术不仅仅是运维需要，你也可以把它当作学习方式。有什么比边做边学更好呢？&lt;/p&gt;
&lt;p&gt;请记住，如果你的应用规模太小，而且预计用户需求不会有太大变化或重大波动（比如一个只在公司内部使用的应用），那么 Kubernetes 对你来说可能没有必要，这种情况下，直接使用 Docker 就足够了。&lt;/p&gt;
&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;p&gt;云原生领域的开源项目众多（见 &lt;a href=&#34;https://jimmysong.io/awesome-cloud-native&#34; title=&#34;Awesome Cloud Native/云原生开源项目大全&#34;&gt;Awesome Cloud Native/云原生开源项目大全&lt;/a&gt;），其中有大量的优秀项目可供我们学习。此外，Kubernetes 开源已经多年时间，网上有大量的学习资料，业界出版过很多书籍，建议大家通过阅读&lt;a href=&#34;https://kubernetes.io&#34; title=&#34;官方文档&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方文档&lt;/a&gt;和实践来学习，也可以参考我编写的&lt;a href=&#34;https://jimmysong.io/book/kubernetes-handbook&#34; title=&#34;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&#34;&gt;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;推荐大家加入我发起创办的&lt;a href=&#34;https://cloudnative.to&#34; title=&#34;云原生社区&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生社区&lt;/a&gt;，这是一个立足中国，放眼世界的云原生终端用户社区，致力于云原生技术的传播和应用。云原生社区主办的&lt;a href=&#34;https://github.com/cloudnativeto/academy&#34; title=&#34;云原生学院&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生学院&lt;/a&gt;定期邀请云原生和开源领域的大咖在 B 站上进行直播分享，成员自发组织了多个 SIG（特别兴趣小组）进行讨论学习。欢迎加入我们，共同学习和交流云原生技术。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes 次世代的云原生应用</title>
      <link>https://jimmysong.io/blog/post-kubernetes-era/</link>
      <pubDate>Mon, 01 Jun 2020 18:13:19 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/post-kubernetes-era/</guid>
      <description>
        
        
        &lt;p&gt;Kubernetes 自开源至今已经走过六个年头了，&lt;a href=&#34;https://cloudnative.to/blog/cloud-native-era/&#34; title=&#34;云原生时代&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生时代&lt;/a&gt;也已到来，我关注云原生领域也四年有余了，最近开始思考云原生的未来走向，特此撰写本文作为&lt;a href=&#34;https://jimmysong.io/guide-to-cloud-native-app&#34; title=&#34;《云原生应用白皮书》&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《云原生应用白皮书》&lt;/a&gt;的开篇，更多关于云原生应用的介绍请转到白皮书中浏览。&lt;/p&gt;
&lt;h2 id=&#34;重点&#34;&gt;重点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;云原生基础设施已渡过了野蛮生长期，正朝着统一应用标准方向迈进。&lt;/li&gt;
&lt;li&gt;Kubernetes 的原语无法完整描述云原生应用体系，且在资源的配置上开发与运维功能耦合严重。&lt;/li&gt;
&lt;li&gt;Operator 在扩展了 Kubernetes 生态的同时导致云原生应用碎片化，亟需一个统一的应用定义标准。&lt;/li&gt;
&lt;li&gt;OAM 的本质是将云原生应用定义中的研发、运维关注点分离，资源对象进行进一步抽象，化繁为简，包罗万象。&lt;/li&gt;
&lt;li&gt;“Kubernetes 次世代”是指在 Kubernetes 成为基础设施层标准之后，云原生生态的关注点正在向应用层过度，近两年来火热的 Service Mesh 正是该过程中的一次有力探索，而基于 Kubernetes 的云原生&lt;strong&gt;应用&lt;/strong&gt;架构的时代即将到来。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes 已成为云原生应用的既定运行平台，本文以 Kubernetes 为默认平台展开，包括云原生应用的分层模型。&lt;/p&gt;
&lt;h2 id=&#34;云原生的不同发展阶段&#34;&gt;云原生的不同发展阶段&lt;/h2&gt;
&lt;p&gt;Kubernetes 从开源至今已经走过快&lt;a href=&#34;https://jimmysong.io/cloud-native/memo/open-source/&#34; title=&#34;六个年头&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;六个年头&lt;/a&gt;（2014 年 6 月开源）了，可以说是 Kubernetes 的诞生开启了整个云原生的时代。我粗略的将云原生的发展划分为以下几个时期。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/post-kubernetes-era/cloud-native-stages_hu0953b587bd346fd1129ec57414444e0c_66753_2096x508_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/post-kubernetes-era/cloud-native-stages.png&#34; data-img=&#34;/blog/post-kubernetes-era/cloud-native-stages.png&#34; data-width=&#34;2096&#34; data-height=&#34;508&#34; alt=&#34;image&#34; data-caption=&#34;云原生的发展阶段&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;云原生的发展阶段&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;第一阶段：孵化期（2014 年）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2014 年，Google 开源 Kubernetes，在此之前的 2013 年，Docker 开源，DevOps、微服务已变得十分流行，云原生的概念已经初出茅庐。在开源了 Kubernetes 之后，Google 联合其他厂商发起成立了 CNCF，并将 Kubernetes 作为初创项目捐献给了 CNCF。CNCF 作为云原生的背后推手，开始推广 Kubernetes。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二阶段：高速发展期（2015 年 - 2016 年）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这几年间，Kubernetes 保持着高速发展，并于 2017 年打败了 Docker Swarm、Mesos，确立了容器编排工具领导者的地位。CRD 和 Operator 模式的诞生，大大增强了 Kubernetes 的扩展性，促进了周边生态的繁荣。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三阶段：野蛮生长期（2017 年 - 2018 年）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2016 年之后的云原生基本都默认运行在 Kubernetes 平台上，2017、2018 年 Google 主导的 Istio、Knative 相继开源，这些开源项目都大量利用了 Kubernetes 的 Operator 进行了扩展，Istio 刚发布时就有 50 多个 CRD 定义。Istio 号称是&lt;a href=&#34;https://jimmysong.io/blog/service-mesh-the-microservices-in-post-kubernetes-era/&#34; title=&#34;后 Kubernetes 时代的微服务&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;后 Kubernetes 时代的微服务&lt;/a&gt;，它的出现第一次使得云原生以服务（应用）为中心。Knative 是 Google 在基于 Kubernetes 之上开源的 Serverless 领域的一次尝试。2018 年 Kubernetes 正式从 CNCF &lt;a href=&#34;https://www.cncf.io/blog/2018/03/06/kubernetes-first-cncf-project-graduate/&#34; title=&#34;毕业&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;毕业&lt;/a&gt;，Prometheus、Envoy 也陆续从 CNCF 毕业。CNCF 也与 2018 年修改了 charter，对云原生进行了重定义，从原来的三要素：”应用容器化；面向微服务架构；应用支持容器的编排调度“，修改为”云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API“。这一年，我曾写过两篇 Kubernetes 及云原生发展的年终总结和展望，见 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/appendix/kubernetes-and-cloud-native-summary-in-2017-and-outlook-for-2018.html&#34; title=&#34;2017 年&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017 年&lt;/a&gt;和 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/appendix/kubernetes-and-cloud-native-summary-in-2018-and-outlook-for-2019.html&#34; title=&#34;2018 年&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018 年&lt;/a&gt;的预测和总结。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第四阶段：普及推广期（2019 年至今）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;经过几年的发展，Kubernetes 已经得到的大规模的应用，云原生的概念开始深入人心，Kubernetes 号称是云原生的操作系统，基于 Operator 模式的生态大放异彩。整合 Kubernetes 和云基础设施，研发和运维关注点分离。Kubernetes 到 Service Mesh（后 Kubernetes 时代的微服务），基于 Kubernetes 的 Serverless 都在快速发展，OAM 诞生，旨在定义云原生应用标准。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-开辟了云原生时代&#34;&gt;Kubernetes 开辟了云原生时代&lt;/h2&gt;
&lt;p&gt;Kubernetes 开源之初就继承了 Google 内部调度系统 Borg 的经验，屏蔽掉了底层物理机、虚拟机之间的差异，经过几年时间的发展成为了容器编排标准，进而统一了 PaaS 平台的基础设施层。&lt;/p&gt;
&lt;p&gt;下图是 Kubernetes 原生内置的可以应用到一个 Pod 上的所有控制器、资源对象等。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/post-kubernetes-era/kubernetes-concepts_huc7f9b9987a9d4903fe8c8a4e926f7b29_121210_800x596_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/post-kubernetes-era/kubernetes-concepts.png&#34; data-img=&#34;/blog/post-kubernetes-era/kubernetes-concepts.png&#34; data-width=&#34;800&#34; data-height=&#34;596&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes 概念&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes 概念&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;图片来自图书 &lt;a href=&#34;https://www.redhat.com/cms/managed-files/cm-oreilly-kubernetes-patterns-ebook-f19824-201910-en.pdf&#34; title=&#34;Kubernetes Patterns（O’Reilly）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Patterns（O’Reilly）&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Kubernetes 作为云原生基础设施设计之初遵循了以下原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基础设施即代码（声明式 API）&lt;/li&gt;
&lt;li&gt;不可变基础设施&lt;/li&gt;
&lt;li&gt;幂等性&lt;/li&gt;
&lt;li&gt;调节器模式（Operator 的原理）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中声明式 API 可谓开创了云原生时代的基调，而调节器模式是 Kubernetes 区别于其他&lt;a href=&#34;https://jimmysong.io/cloud-native-infra/evolution-of-cloud-native-developments.html&#34; title=&#34;云部署形式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云部署形式&lt;/a&gt;的主要区别之一，这也为后来的 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/54633203&#34; title=&#34;Operator 框架的诞生&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Operator 框架的诞生&lt;/a&gt;打下了基础。&lt;/p&gt;
&lt;h3 id=&#34;声明式-api&#34;&gt;声明式 API&lt;/h3&gt;
&lt;p&gt;根据声明式 API 可以做应用编排，定义组件间的依赖，通常使用人类易读的 YAML 文件来表示。但是，YAML 文件声明的字段真的就是最终的状态吗？有没有可能动态改变？&lt;/p&gt;
&lt;p&gt;我们在创建 &lt;code&gt;Deployment&lt;/code&gt; 时会指定 Pod 的副本数，但是其实际副本数并不一定是一成不变的。假如集群中还有定义 HPA，那么 Pod 的副本数就可能随着一些外界因素（比如内存、CPU 使用率或者自定义 metric）而改变，而且如果集群中还有运行自定义的控制器话，那么也有可能修改应用的实例数量。在有多个控制器同时控制某个资源对象时，如何确保控制器之间不会发生冲突，资源对象的状态可预期？可以使用&lt;a href=&#34;https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/#monitoring-admission-webhooks&#34; title=&#34;动态准入控制&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;动态准入控制&lt;/a&gt;来达到这一点。&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-原生应用&#34;&gt;Kubernetes 原生应用&lt;/h3&gt;
&lt;p&gt;我们都知道要想运行一个应用至少需要以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用的业务逻辑（代码）、运行时（可运行的二进制文件、字节码或脚本）。&lt;/li&gt;
&lt;li&gt;应用的配置注入（配置文件、环境变量等），身份、路由、服务暴露等满足应用的安全性和可访问性。&lt;/li&gt;
&lt;li&gt;应用的生命周期管理（各种 Controller 登场）。&lt;/li&gt;
&lt;li&gt;可观测性、可运维、网络和资源及环境依赖、隔离性等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图展示了基于 Kubernetes 原语及 PaaS 平台资源的 Kubernetes 原生应用的组成。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/post-kubernetes-era/kubernetes-native-application-motion.gif&#34; data-img=&#34;/blog/post-kubernetes-era/kubernetes-native-application-motion.gif&#34; data-width=&#34;600&#34; data-height=&#34;334&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes 原生应用&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;Kubernetes 原生应用&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;我们都知道 Kubernetes 提供了大量的&lt;a href=&#34;https://kubernetes.io/docs/concepts/&#34; title=&#34;原语&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原语&lt;/a&gt;，用户可以基于这些原语来编排服务，管理应用的生命周期。上图展示的是基于 Kubernetes 原生应用可以使用的 Kubernetes 原语、扩展及平台层资源，从内向外的对象跟应用程序（业务逻辑）的关联度依次降低，到最外层基本只剩下平台资源依赖，已经与 Kubernetes 几乎没有关系了。该图里仅展示了部分资源和对象（包含阿里巴巴开源的 &lt;a href=&#34;https://github.com/openkruise/kruise&#34; title=&#34;OpenKruise&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenKruise&lt;/a&gt;、Istio），实际上 &lt;a href=&#34;https://operatorhub.io/&#34; title=&#34;Operator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Operator&lt;/a&gt; 资源之丰富，也是 Kubernetes 生态如此繁荣的原因之一。&lt;/p&gt;
&lt;p&gt;Kubernetes 本身的原语、资源对象、配置、常用的 CRD 扩展有几十、上百个之多。开发者需要了解这些复杂的概念吗？我只是想部署一个应用而已！不用所对于应用开发者，即使对于基础实施开发和运维人员也需要很陡峭的学习曲线才能完全掌握它。&lt;/p&gt;
&lt;p&gt;我将 Kubernetes 原生应用所需要的定义和资源进行了分层：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心层&lt;/strong&gt;：应用逻辑、服务定义、生命周期控制；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隔离与服务访问层&lt;/strong&gt;：资源限制与隔离、配置、身份、路由规则等；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调度层&lt;/strong&gt;：各种调度控制器，这也是 Kubernetes 原生应用的主要扩展层；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源层&lt;/strong&gt;：提供网络、存储和其他平台资源；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而这些不同的层，完全可以将其职责分配给相应的人员，比如核心层是由应用程序开发者负责，将其职责分离，可以很大程度上降低开发和运维的复杂度。&lt;/p&gt;
&lt;p&gt;云原生应用落实到 Kubernetes 平台之上，仅仅利用 Kubernetes 的对象原语已很难描述一个复杂的应用程序，所以诞生了各种各样的 Operator，但这也仅仅解决了单个应用的定义，对于应用的打包封装则无能为力。&lt;/p&gt;
&lt;p&gt;同一个资源对象又有多种实现方式，比如 Ingress 就有 &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1DnsHtdHbxjvHmxvlu7VhzWcWgLAn_Mc5L1WlhLDA__k/edit#gid=0&#34; title=&#34;10 多种实现&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10 多种实现&lt;/a&gt;，PV 就更不用说，对于对于开发者究竟如何选择，平台如何管理，这都是让人很头疼的问题。而且有时候平台所提供的扩展能力还可能会有冲突，这些能力有的可能互不相干，有的可能会有正交，有的可能完全重合。且应用本身与运维特性之间存在太多耦合，不便于复用。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          &lt;img src=&#34;https://jimmysong.io/blog/post-kubernetes-era/resources-motion.gif&#34; data-img=&#34;/blog/post-kubernetes-era/resources-motion.gif&#34; data-width=&#34;600&#34; data-height=&#34;363&#34; alt=&#34;image&#34; data-caption=&#34;资源交集动画&#34;&gt;
        
      
    
  
  
  &lt;figcaption&gt;资源交集动画&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;上图中不同颜色的方框代表不同的资源类别，红线框代表不能为一个资源同时应用该配置，否则会出现冲突，不同的颜色上面是一个动画，展示的是部分资源组合。图中仅包含了部分 Kubernetes 中的原语和 Istio 中的资源对象组合及自定义扩展，实际上用户可以根据应用的自身特点，基于 Kubernetes 原语和 CRD 创建出千变万化的组合。&lt;/p&gt;
&lt;p&gt;为了管理这些应用诞生出了众多的 &lt;a href=&#34;https://github.com/operator-framework/awesome-operators&#34; title=&#34;Operator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Operator&lt;/a&gt;。Kubernetes 1.7 版本以来就引入了&lt;a href=&#34;https://kubernetes.io/docs/concepts/api-extension/custom-resources/&#34; title=&#34;自定义控制器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自定义控制器&lt;/a&gt;的概念，该功能可以让开发人员扩展添加新功能，更新现有的功能，并且可以自动执行一些管理任务，这些自定义的控制器就像 Kubernetes 原生的组件一样，Operator 直接使用 Kubernetes API 进行开发，也就是说它们可以根据这些控制器内部编写的自定义规则来监控集群、更改 Pods/Services、对正在运行的应用进行扩缩容。&lt;/p&gt;
&lt;p&gt;Operator 的本质是一种调节器模式（Reconciler Pattern）的应用，跟 Kubernetes 本身的实现模式是一样的，用于管理云原生应用，协调应用的实际状态达到预期状态。&lt;/p&gt;
&lt;p&gt;调节器模式的四个原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;所有的输入和输出都使用数据结构。&lt;/li&gt;
&lt;li&gt;确保数据结构是不可变的。&lt;/li&gt;
&lt;li&gt;保持资源映射简单。&lt;/li&gt;
&lt;li&gt;使实际状态符合预期状态。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;云原生应用走向碎片化&#34;&gt;云原生应用走向碎片化&lt;/h2&gt;
&lt;p&gt;利用声明式 API 及调节器模式，理论上可以在 Kubernetes 上部署任何可声明应用，但是在 Operator 出现之前，管理 Kubernetes 上的有状态应用一直是一个难题，随着 Operator 模式的确立，该难题已得以解决，并促进了 Kubernetes 生态的进一步发展。随着该生态的繁荣，有一种碎片化的特征正在显现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;云原生应用碎片化的体现&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Operator 模式将运维人员的反应式经验转化成基于 &lt;code&gt;Reconcile&lt;/code&gt; 模式的代码，统一了有状态应用的管理模式，极大得扩展了 Kubernetes 应用生态。&lt;/li&gt;
&lt;li&gt;开发者在引用 Operator 所提供的能力时没有统一的视图，加大了基础设施运维与开发者之间的沟通成本。&lt;/li&gt;
&lt;li&gt;Operator 总体上治理松散，没有统一的管控机制，在同时应用时可能导致互相冲突或无法预期的结果发生。&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;有状态应用管理难题&#34;&gt;有状态应用管理难题&lt;/h3&gt;
&lt;p&gt;Kubernetes 对于无状态应用的管理很出色，但是对于有状态应用就不是那么回事了。虽然 StatefulSet 可以帮助管理有状态应用，但是这还远远不够，有状态应用往往有复杂的依赖。声明式的 API 里往往要加载着大量的配置和启动脚本，才能实现一个复杂应用的 Kubernetes 化。&lt;/p&gt;
&lt;p&gt;例如在 2017 年初，Operator Framework 出现之前，需要使用大量的 &lt;code&gt;ConfigMap&lt;/code&gt;、复杂的启动脚本才能&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/guide/migrating-hadoop-yarn-to-kubernetes.html&#34; title=&#34;在 Kubernetes 上定义 Hadoop YARN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在 Kubernetes 上定义 Hadoop YARN&lt;/a&gt; 和&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/usecases/running-spark-with-kubernetes-native-scheduler.html&#34; title=&#34;运行 Spark&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运行 Spark&lt;/a&gt;。虽然 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34; title=&#34;&amp;lt;code&amp;gt;StatefulSet&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;StatefulSet&lt;/code&gt;&lt;/a&gt; 号称可以解决有状态应用的部署问题，但是它主要是保证了 Pod 的在启动、伸缩时的顺序和使 Pod 具有稳定的标识。但是很多分布式应用来说并不仅依靠启动顺序就可以保证其状态，根据其在分布式应用中的角色不同（master/worker）而需要有大量的自定义配置，在没有 Operator 之前这些配置通常是通过一些自定义脚本来实现，这些脚本可能存在于应用镜像中，也可以通过 &lt;code&gt;ConfigMap&lt;/code&gt; 挂在到容器运行时，但无论如何这些脚本都可能因为散落在各处，这些脚本还是面向过程的，跟在 Kubernetes 诞生之前的运维方式毫无二致，这极其不便于版本控制和运维管理。&lt;/p&gt;
&lt;h3 id=&#34;operator-统一了-kubernetes-应用运维框架&#34;&gt;Operator 统一了 Kubernetes 应用运维框架&lt;/h3&gt;
&lt;p&gt;Operator 大大增强了 Kubernetes 的可扩展性，丰富了以 Kubernetes 为基础的云原生生态，许多原先不是为 Kubernetes 而构建的应用纷纷通过&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54633203&#34; title=&#34;构建自己的 Operator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;构建自己的 Operator&lt;/a&gt; 迁移到 Kubernetes 上。还有一些直接基于 Kubernetes 构建的 Service Mesh、Serverless 框架，它们应用 Operator 模式（如 &lt;a href=&#34;https://istio.io&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;、&lt;a href=&#34;https://knative.dev&#34; title=&#34;Knative&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Knative&lt;/a&gt;），试图成为云原生应用的基础设施层，补齐 Kubernetes 在服务治理、无服务架构等方面的短板，随着大量的 CRD、Operator 控制器的出现，而 Kubernetes 却无法以应用的视角来管理这些能力及其背后零散的 CRD，这使得云原生应用碎片化。&lt;/p&gt;
&lt;p&gt;Operator 百花齐放，在没有一个大一统的视图之前，各个控制器之间存在着这样的关系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;独立&lt;/strong&gt;：互不干涉，比如 Controller 与服务发现之间就不存在冲突。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可组合&lt;/strong&gt;：例如 &lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt; 同属一类资源（可访问性与路由），就是可组合的（后两者是 Istio 中的 CRD，用于流量管理）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有冲突&lt;/strong&gt;：例如图中的 &lt;code&gt;CronHorizontalPodAutoscaler&lt;/code&gt;（CRD）、&lt;code&gt;HorizontalPodAutoscaler&lt;/code&gt;（Kubernetes 内置），同时使用可能导致无法意料的情况发生。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;正是以为这样复杂的关系，导致其无法做到开箱即用，还需要基础设施团队基于云原生社区和生态自己构建出来的，比如&lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/#application-delivery&#34; title=&#34;应用交付领域&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用交付领域&lt;/a&gt;的系列开源项目。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用管理工具-helm&#34;&gt;云原生应用管理工具 Helm&lt;/h2&gt;
&lt;p&gt;Kubernetes 之上有很多能力缺失，比如应用构建、发布、管理和运维等，Helm 的出现主要补偿了应用打包和版本管理的缺陷。其中云原生应用的配置包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序启动时加载的配置文件；&lt;/li&gt;
&lt;li&gt;应用程序的运维配置，如资源申请限额；&lt;/li&gt;
&lt;li&gt;应用程序的服务发现配置；&lt;/li&gt;
&lt;li&gt;应用程序的工作负载、发布策略、依赖等；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些配置可以存在于 &lt;code&gt;ConfigMap&lt;/code&gt;、&lt;code&gt;Deployment&lt;/code&gt;、&lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;Ingress&lt;/code&gt; 等 Kubernetes 的多个资源文件中，如何保证应用程序的复用性？应用程序之间有依赖该如何解决？这是时候你可能自然的想到了 Helm。&lt;/p&gt;
&lt;p&gt;云原生应用打包和发布管理&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Helm 通过 chart 模板，提高了应用程序的复用性并解决了部分依赖问题；&lt;/li&gt;
&lt;li&gt;Chart 仓库提供了云原生应用程序的统一管控视图；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Release&lt;/code&gt; 概念的引入，使得云原生应用版本化管理进一步加强；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Helm 主要关注的是 &lt;a href=&#34;https://12factor.net/zh_cn/&#34; title=&#34;12 因素应用&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;12 因素应用&lt;/a&gt;法则&lt;a href=&#34;https://12factor.net/zh_cn/build-release-run&#34; title=&#34;构建、发布、运行&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;构建、发布、运行&lt;/a&gt;这一原则中的”发布”这一环节。下图是 Helm v3 的架构图。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/post-kubernetes-era/helm-chart_hu9afbbdedb02edb818b6556857f76303a_42376_600x429_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/post-kubernetes-era/helm-chart.png&#34; data-img=&#34;/blog/post-kubernetes-era/helm-chart.png&#34; data-width=&#34;600&#34; data-height=&#34;429&#34; alt=&#34;image&#34; data-caption=&#34;Helm3 架构&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Helm3 架构&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;Helm 可以安装本地或者远程的 chart，当 chart 安装到 Kubernetes 中后就会创建一个 release，每次更新该 chart 的配置并执行 &lt;code&gt;helm upgrade&lt;/code&gt;，release 的版本数就会加 1，开发者可以升级 chart 或回滚到历史版本。&lt;/p&gt;
&lt;h3 id=&#34;打包配置和发布&#34;&gt;打包、配置和发布&lt;/h3&gt;
&lt;p&gt;Helm 和 chart 的主要作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序封装&lt;/li&gt;
&lt;li&gt;版本管理&lt;/li&gt;
&lt;li&gt;依赖检查&lt;/li&gt;
&lt;li&gt;便于应用程序分发&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;打包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Helm 采用 &lt;a href=&#34;https://helm.sh/docs/topics/charts/&#34; title=&#34;Chart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chart&lt;/a&gt; 的格式来标准化描述应用，可以将目录打包成版本化的压缩包进行部署理论上一个 Chart 是可以嵌套若干个 Chart 并定义依赖关系，组织形式非常灵活。Helm chart 用于打包 Kubernetes 原生应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;应用配置参数，在 Chart 中由 &lt;code&gt;values.yaml&lt;/code&gt; 和命令行参数组成。Chart 采用 Go Template 的特性和 &lt;code&gt;values.yaml&lt;/code&gt; 对部署的模板文件进行参数渲染，也可以通过 &lt;code&gt;helm&lt;/code&gt; 命令 &lt;code&gt;--set key=value&lt;/code&gt; 的方式进行参数赋值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;发布&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Release 代表 Chart 在集群中的运行实例，Helm 围绕 Release 对应用提供了强大的生命周期管理能力，包括 Release 的查询、安装、更新、删除、回滚等。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用&#34;&gt;云原生应用&lt;/h2&gt;
&lt;p&gt;以上关注的点都是基于 Kubernetes 原语的实现，虽然基于 Kubernetes 构建的 PaaS 平台部分屏蔽了底层基础设施的差异，但是仍有很多云服务是无法通过 Kubernetes 创建，或者需要提前创建供 Kubernetes 原生应用使用的，这些应用通常不运行在 Kubernetes 集群中。因此创建和管理一个云原生应用程序需要考虑以下方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运行时：ECS、Docker、KataContainer、gVisor 等；&lt;/li&gt;
&lt;li&gt;资源隔离性：多租户、VPC、Namespace、防火墙；&lt;/li&gt;
&lt;li&gt;资源调度：各种类型的 controller；&lt;/li&gt;
&lt;li&gt;网络可达性：Service、Ingress、Egress、Gateway、VirtualService、DestinationRule、LoadBalancer、ServiceEntry 等；&lt;/li&gt;
&lt;li&gt;可观测性：日志、分布式追踪、指标；&lt;/li&gt;
&lt;li&gt;安全性：SecurityPolicy、NetworkPolicy、AuthorizationPolicy；&lt;/li&gt;
&lt;li&gt;平台资源申请：数据库、存储等；&lt;/li&gt;
&lt;li&gt;运行与隔离：ECS、Docker、KataContainer 等；&lt;/li&gt;
&lt;li&gt;资源分配和调度：各种控制器；&lt;/li&gt;
&lt;li&gt;环境隔离：Namespace、多租户、VPC、防火墙、LimitRange、Resources；&lt;/li&gt;
&lt;li&gt;可访问性：Service、Ingress、Egress、Gateway、LoadBalancer、VirtualService、DestinationRule、ServiceEntry；&lt;/li&gt;
&lt;li&gt;状态管理：Operator；&lt;/li&gt;
&lt;li&gt;可观测性：日志、监控、指标；&lt;/li&gt;
&lt;li&gt;安全性：SecurityPolicy、ServiceAccount；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;云原生应用分层模型&#34;&gt;云原生应用分层模型&lt;/h3&gt;
&lt;p&gt;那么究竟如何来给云原生应用分层，化繁就简？近几年来，基于 Kubernetes 的应用呈爆炸式发展，光是在&lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/#application-delivery&#34; title=&#34;应用交付领域&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用交付领域&lt;/a&gt;的开源项目就达几十个之多。下图展示我根据这些项目的特性而绘制的 App Delivery Landscape。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/post-kubernetes-era/cloud-native-app_hu7d47b535d0003e689bf1fda99b24e11d_32198_1054x514_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/post-kubernetes-era/cloud-native-app.png&#34; data-img=&#34;/blog/post-kubernetes-era/cloud-native-app.png&#34; data-width=&#34;1054&#34; data-height=&#34;514&#34; alt=&#34;image&#34; data-caption=&#34;云原生应用的分层模型&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;云原生应用的分层模型&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;应用定义和包装&lt;/strong&gt;：云原生应用的最上层，直接定义云原生应用的组成形式，解决云原生应用之间的依赖关系，并封装成发布包，如 Helm、CNAB，还有云原生变成语言 Pulumi 和 Ballerina，基于 API 的方式来编排云原生应用；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;负载定义&lt;/strong&gt;：基于 Kubernetes Operator，大多是 Serverless 负载，既负责了负载的定义又负责了生命周期管理。&lt;a href=&#34;https://istio.io&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt; 是比较特殊的存在，它不仅管理服务间的流量，还负责安全性、可观测性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用发布和上线&lt;/strong&gt;：关注应用的构建和发布、GitOps、发布策略等，这也是云原生应用全景中最丰富的部分之一；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes 原语&lt;/strong&gt;：Kubernetes 本身提供的原语，Operator 基于此构建；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上为我个人分类的云原生应用全景模型，仅限于 Kubernetes 之上的应用，对于其他非 Kubernetes 应用非本文的考虑范围。另外，CNCF SIG App Delivery 中也给出的云原生应用的分层模型，其模型将非 Kubernetes 应用场景也纳入了考虑，详见：&lt;a href=&#34;https://docs.google.com/document/d/1gMhRz4vEwiHa3uD8DqFKHGTSxrVJNgkLG2WZWvi9lXo/edit#heading=h.h9so53gv5zen&#34; title=&#34;The Dictionary of Cloud-Native App Delivery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Dictionary of Cloud-Native App Delivery&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;Platform/Kuberntes，Kubernetes 仅仅是屏蔽了平台的一些差异，但是对于最上层的应用来说，没有涉及，用户需要自己来基于各种开源组件来搭积木。&lt;/p&gt;
&lt;h3 id=&#34;oam开放应用模型&#34;&gt;OAM（开放应用模型）&lt;/h3&gt;
&lt;p&gt;那么以上这么多应用有哪些共性，能不能再进一步抽象呢？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有应用是都以容器作为运行时环境（ContainerizedWorkload），这是 OAM 中的核心 Workload 类型；&lt;/li&gt;
&lt;li&gt;在应用发布和上线方面，有些是属于应用的运维特征，需要根据实际需求组合和变更，这些是持续变动的部分；&lt;/li&gt;
&lt;li&gt;要实现某些复杂的应用管控，需要使用到多个 CRD 的组合，比如 Istio 中的让流量根据百分比切分到不同的而服务，就需要部署 Istio Operator，并声明 &lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt;，二者同时使用；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个 &lt;code&gt;ApplicationConfiguration&lt;/code&gt; 的 Runtime 的正常流程应该是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用开发者创建自己的 &lt;code&gt;Component&lt;/code&gt;，在 &lt;code&gt;Component&lt;/code&gt; 中描述要应用相关的信息，如应用名称、镜像配置、环境变量等，应用到 Kubernetes cluster 中；&lt;/li&gt;
&lt;li&gt;运维创建各种运维策略，如发布策略、网络策略等等，发布时由 AppConfig 对象关联要发布的 &lt;code&gt;Component&lt;/code&gt; 和本次的运维策略，apply 到集群中，集群的 OAM operator watch 到一次 &lt;code&gt;ApplicationConfiguration&lt;/code&gt;的下发，生成 &lt;code&gt;Component&lt;/code&gt; 对应的 &lt;code&gt;Workload&lt;/code&gt; 和 &lt;code&gt;Trait&lt;/code&gt;，&lt;code&gt;Trait&lt;/code&gt; controller 将本次的 &lt;code&gt;Trait&lt;/code&gt; 策略应用到本次要管理的 &lt;code&gt;Workload&lt;/code&gt; 当中，最终到达终态，完成一次发布。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OAM 是对 Kubernetes 友好的，一样采用声明式 API 的理念开发。如果你已经编写了现成的 CRD Operator，可以平滑的接入到 OAM 体系中。OAM 以应用为中心，高度可扩展，扩展点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Workload：扩展各种运行时类型，不仅限于容器运行时，还可以定义更多其他运行时，比如 Serverless 负载、虚拟机、数据库、网络等；例如，Pod、无服务器函数、数据存储、消息队列或任何其他类型的工作负载，这些都是应用程序开发人员需要设计一个完整的应用程序所需要的，可以直接引用 Kubernetes 的 CRD；&lt;/li&gt;
&lt;li&gt;Trait：各种运维规则，比如扩缩容、流量控制、安全性；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;生态&#34;&gt;生态&lt;/h3&gt;
&lt;p&gt;以前 CNCF 的主要关注群体大多是基础设施领域的技术人员，但是自 2019 年 9 月，&lt;a href=&#34;https://www.infoq.cn/article/Cdw7ISlEqKilGyN9V3Pj&#34; title=&#34;CNCF 宣布成立 SIG App Delivery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 宣布成立 SIG App Delivery&lt;/a&gt; 后，CNCF 正在将应用开发者和运维人员更紧密的联系在一起。&lt;a href=&#34;https://github.com/cncf/sig-app-delivery&#34; title=&#34;应用交付 SIG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用交付 SIG&lt;/a&gt; 的使命是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在与开发、分发、部署、管理和运行安全的云原生应用相关的领域进行合作，目标是以云原生方式交付应用。&lt;/li&gt;
&lt;li&gt;发展信息资源，包括指南、教程和白皮书，让社区了解最佳实践和应用交付的价值。&lt;/li&gt;
&lt;li&gt;识别合适的项目和现状的差距，定期向 TOC 更新，并以结构化的方式向 TOC 提出行动建议。这包括帮助 TOC 评估和对潜在的新项目进行尽职调查。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前 OAM 定义的云原生应用模型已有以下项目支持。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://crossplane.io/&#34; title=&#34;Crossplane&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crossplane&lt;/a&gt;：这是一个开源的 Kubernetes 扩展组件，适用于主流公有云平台，使用 &lt;code&gt;kubectl&lt;/code&gt; 配置和管理基础架构、服务和应用。对于 OAM 的支持详见运行应用程序。&lt;/li&gt;
&lt;li&gt;KPT：Kpt（发音为 &amp;ldquo;keep&amp;rdquo;）是一个在资源配置之上构建声明性工作流的开源工具。它的 git + YAML 架构意味着它只需与现有的工具、框架和平台一起工作。Kpt 包括了获取、显示、自定义、更新、验证和应用 Kubernetes 配置的解决方案。对 OAM 的支持详见 使用 kpt 来管理由开放应用模型（OAM）定义的自定义 Kubernetes 应用程序。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应用交付领域相关的开源项目还有很多，详见 &lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/#application-delivery&#34; title=&#34;Awesome Cloud Native&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Cloud Native&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;基于 Kubernetes 的云原生生态发展至今已有 6 年时间，当前已步入了普及推广阶段。可以说谁云原生应用定义的制高点，就可以掌握云原生的未来。从前我们是新技术浪潮的追随者，现在我们抓住时代的基于，参与标准制定、引领云原生的浪潮！欢迎加入 &lt;a href=&#34;https://oam.dev/&#34; title=&#34;OAM 社区&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM 社区&lt;/a&gt;，一起参与进来，把国人参与指定的标准推向世界。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.ibm.com/technologies/containers/blogs/kubernetes-helm-3/&#34; title=&#34;Do you know what’s in Helm 3? - developer.ibm.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Do you know what’s in Helm 3? - developer.ibm.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.redhat.com/cms/managed-files/cm-oreilly-kubernetes-patterns-ebook-f19824-201910-en.pdf&#34; title=&#34;O’Reilly: Kubernetes patterns for designing cloud-native apps - redhat.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O’Reilly: Kubernetes patterns for designing cloud-native apps - redhat.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1gMhRz4vEwiHa3uD8DqFKHGTSxrVJNgkLG2WZWvi9lXo/edit#heading=h.h9so53gv5zen&#34; title=&#34;The Dictionary of Cloud-Native App Delivery - docs.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Dictionary of Cloud-Native App Delivery - docs.google.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/Cdw7ISlEqKilGyN9V3Pj&#34; title=&#34;CNCF 宣布成立应用交付领域小组，正式开启云原生应用时代 - infoq.cn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 宣布成立应用交付领域小组，正式开启云原生应用时代 - infoq.cn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/c7A8lOdAKkW25GoqmwOgWg&#34; title=&#34;OAM v1alpha2 新版发布：平衡标准与可扩展性，灵活接入 CRD operator - mp.weixin.qq.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM v1alpha2 新版发布：平衡标准与可扩展性，灵活接入 CRD operator - mp.weixin.qq.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54633203&#34; title=&#34;Kubernetes API 与 Operator，不为人知的开发者战争 - zhuanlan.zhihu.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes API 与 Operator，不为人知的开发者战争 - zhuanlan.zhihu.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/cloud-native-era/&#34; title=&#34;云原生时代——投资人视角下的云原生趋势思考 - cloudnative.to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生时代——投资人视角下的云原生趋势思考 - cloudnative.to&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>《Service Mesh 实战—基于 Linkerd 和 Kubernetes 的微服务实践》读后感</title>
      <link>https://jimmysong.io/blog/service-mesh-in-action-by-yangzhangxian-review/</link>
      <pubDate>Tue, 08 Jan 2019 20:50:44 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/service-mesh-in-action-by-yangzhangxian-review/</guid>
      <description>
        
        
        &lt;p&gt;最近在回顾 Service Mesh 技术在 2018 年的发展，想再看看 Linkerd，正好&lt;strong&gt;杨彰显&lt;/strong&gt;的这本《Service Mesh 实战——基于 Linkerd 和 Kubernetes 的微服务实践》上市发售了，&lt;strong&gt;机械工业出版社&lt;/strong&gt;的编辑送了我一本，🙏&lt;strong&gt;杨福川&lt;/strong&gt;编辑，我看了下抽空写了点读后感，我看了下抽空写了点读后感，其实也说不上是读后感，就当是自己的一点感悟吧，就当拿此书借题发挥吧，这个知识爆炸的年代，技术发展如此迅速，可以说是 IT 人员的幸运，也是不幸！有多少写开源软件的书推出一版后能撑过三年的？如果软件红得发紫，持续迭代 N 个版本，例如 Kubernetes，最近两年以每三个月一个版本的速度迭代，之前的书早就跟不上节奏，要么就要不断推出新版，直到软件稳定后不再有大的改动。还有种可能就是软件推广和发展的不理想，无人问津，写这样软件的书就不会有再版了。&lt;/p&gt;
&lt;p&gt;拿到本书后我的第一反应就是看看这本书定稿的时候 Istio 是什么版本，Linkerd 又是什么版本。因为在这一年内两款开源软件都有较大的版本变动，如果书籍定稿的时候基于的软件版本太低，软件架构可能会有较大的变化，影响书中示例和部分章节的时效性。这也是大多技术书籍名短的症结所在，技术发展是在太快，传统的书籍出版流程往往过于繁琐和冗长，等到书籍出版后所介绍的软件都出了好几个版本。例如 Kubernetes 这种的软件，每三个月一个版本，而写一般书从策划到发行少说半年，一般也要一年的时间。&lt;/p&gt;
&lt;h2 id=&#34;关于书籍定稿时的软件版本&#34;&gt;关于书籍定稿时的软件版本&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Istio 0.8&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本书第一章「Service Mesh 简介」对 Service Mesh 相关开源产品介绍时提到本书定稿时 Istio 是 0.8 版本，而 Istio 在 2018 年 7 月 31 日发布了 1.0 版本。&lt;/p&gt;
&lt;p&gt;这本书定稿时，Istio 的最新版本是 0.8。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Linkerd 1.3.6&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;本书从序言开始一直到第二章结束也没有提及写作时基于的 Linkerd 版本，我在第二章的安装步骤中看到了说明。&lt;/p&gt;
&lt;p&gt;可以看到本书写作时是基于 Linkerd 1.3.6 版本，而 Linkerd 在同年的 9 月 18 日发布了 &lt;a href=&#34;https://cloudnative.to/blog/linkerd-2-0-in-general-availability/&#34; title=&#34;2.0 GA&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2.0 GA&lt;/a&gt;，这一版本跟 1.x 版本相比有重大变化——它还将项目从集群范围的 service mesh 转换为可组合的 &lt;em&gt;service sidecar&lt;/em&gt; ，旨在为开发人员和服务所有者提供在云原生环境中成功所需的关键工具。&lt;/p&gt;
&lt;h2 id=&#34;linkerd-vs-envoy&#34;&gt;Linkerd vs Envoy&lt;/h2&gt;
&lt;p&gt;Linkerd 2.0 的 service sidecar 设计使开发人员和服务所有者能够在他们的服务上运行 Linkerd，提供自动可观测性、可靠性和运行时诊断，而无需更改配置或代码。通过提供轻量级的增量路径来获得平台范围的遥测、安全性和可靠性的传统 service mesh 功能，service sidecar 方法还降低了平台所有者和系统架构师的风险。该版本还用 Rust 重写了代理部分，在延迟，吞吐量和资源消耗方面产生了数量级的改进。&lt;/p&gt;
&lt;p&gt;而 Linkerd 1.x 继承自 Twitter 开源的 Finagle 高性能 RPC，所有想要深度学习 Linkerd 1.x 还需要了解 Finagle，这就跟 Istio 将 Envoy 作为默认的数据平面一样，要想深度学习 Istio 必须了解 Envoy。&lt;/p&gt;
&lt;p&gt;二者几乎使用了完全不同的术语，假如你已经了解了 &lt;a href=&#34;https://envoyproxy.io&#34; title=&#34;Envoy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Envoy&lt;/a&gt; 想要再切换到 Linkerd 上，那么就要再费很多心力来学习它的概念和原理，例如如下这些术语或配置（Linkerd 中独有的配置）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;dtab（委托表）&lt;/strong&gt;：由一系列路由组成，由一系列路由规则组成，以逻辑路径为输入，然后经过路由规则做一系列转换生成具体名字。这是 Linkerd 路由机制的根本，就像 Envoy 中的 &lt;a href=&#34;https://jimmysong.io/istio-handbook/data-plane/envoy-xds.html&#34; title=&#34;xDS 协议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS 协议&lt;/a&gt;一样，本书的第四章「深入 Linkerd 数据访问流」专门讲解了 dtab 的实现机制。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;dentry（委托表记录）&lt;/strong&gt;：委托表的每条路由规则称为 dentry，如 /consul =&amp;gt; /#/io.l5d.consul/dc1。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;namer&lt;/strong&gt;：配置 Linkerd 支持的服务发现工具。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;namerd&lt;/strong&gt;：Linkerd 的控制平面，相当于 Istio 中的 Pilot，对接各种服务发现。当然 Linkerd 也可以直接与某个服务发现平台对接如 consul，而不使用 namerd 这个集中路由和配置管理组件。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;interpreter&lt;/strong&gt;：interpreter 决定如何解析服务名字和客户端名字。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;虽然 Linkerd 也是 &lt;a href=&#34;https://www.cncf.io/projects/&#34; title=&#34;CNCF 中的项目&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 中的项目&lt;/a&gt;，但它目前还处于孵化阶段，而 Envoy 的 &lt;a href=&#34;https://jimmysong.io/istio-handbook/data-plane/envoy-xds.html&#34; title=&#34;xDS 协议&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xDS 协议&lt;/a&gt;已经被众多开源项目所支持，如 &lt;a href=&#34;https://istio.io/zh&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;、&lt;a href=&#34;https://github.com/alipay/sofa-mesh&#34; title=&#34;SOFAMesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SOFAMesh&lt;/a&gt;、&lt;a href=&#34;https://github.com/nginxinc/nginmesh&#34; title=&#34;NginxMesh&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NginxMesh&lt;/a&gt; 等，且 Envoy 已经从 CNCF 中毕业，以后可能成为 Service Mesh 领域的标准协议，Linkerd 的生存状况堪忧。&lt;/p&gt;
&lt;h2 id=&#34;关于本书&#34;&gt;关于本书&lt;/h2&gt;
&lt;p&gt;本书中所有示例都提供了虚拟机的快速上手环境，只要使用 Vagrant 即可创建虚拟机和应用，所以在本书的&lt;a href=&#34;https://github.com/yangzhares/linkerd-in-action&#34; title=&#34;示例代码&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;示例代码&lt;/a&gt;有大量的 Vagrantfile。&lt;/p&gt;
&lt;p&gt;本书第三部分「实战篇」花了大量篇幅（本书一半的页数）来讲解如何使用 Linkerd 和 Kubernetes 来管理微服务，可以参考我 2017 年 8 月 1 日写的这篇&lt;a href=&#34;https://jimmysong.io/posts/linkerd-user-guide/&#34; title=&#34;微服务管理框架 service mesh——Linkerd 安装试用笔记&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;微服务管理框架 service mesh——Linkerd 安装试用笔记&lt;/a&gt;，那时候还是基于 Linkerd 1.1.2，还有 &lt;a href=&#34;https://github.com/linkerd/linkerd-examples/&#34; title=&#34;Linkerd 官方示例&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linkerd 官方示例&lt;/a&gt;，这些示例基本都不怎么更新了。&lt;/p&gt;
&lt;p&gt;因为该书定稿时所基于的 Linkerd 版本距离本书发售时的 Linkerd 已经落后一个大版本（最新版本是 &lt;a href=&#34;https://blog.linkerd.io/2018/12/06/announcing-linkerd-2-1/&#34; title=&#34;Linkerd 2.1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Linkerd 2.1&lt;/a&gt;），所以读者一定要注意这一点，老实说我只花了两个夜晚快速过了一下本书，无法对本书内容给出具体评论，所以本书是否是你所需要的就要你自己去思考了。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>配置 Kubernetes DNS 服务 kube-dns</title>
      <link>https://jimmysong.io/blog/configuring-kubernetes-kube-dns/</link>
      <pubDate>Wed, 03 Jan 2018 16:16:01 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/configuring-kubernetes-kube-dns/</guid>
      <description>
        
        
        &lt;p&gt;在我们安装 Kubernetes 集群的时候就已经安装了 kube-dns 插件，这个插件也是官方推荐安装的。通过将 Service 注册到 DNS 中，Kuberentes 可以为我们提供一种简单的服务注册发现与负载均衡方式。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://coredns.io&#34; title=&#34;CoreDNS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CoreDNS&lt;/a&gt;作为 CNCF 中的托管的一个项目，在 Kuberentes1.9 版本中，使用 kubeadm 方式安装的集群可以通过以下命令直接安装 CoreDNS。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kubeadm init --feature-gates&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;CoreDNS&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;true&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;您也可以使用 CoreDNS 替换 Kubernetes 插件 kube-dns，可以使用 Pod 部署也可以独立部署，请参考&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/coredns/&#34; title=&#34;Using CoreDNS for Service Discovery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Using CoreDNS for Service Discovery&lt;/a&gt;，下文将介绍如何配置 kube-dns。&lt;/p&gt;
&lt;p&gt;本文已归档到&lt;a href=&#34;https://jimmysong.io/book/kubernetes-handbook&#34; title=&#34;kubernetes-handbook&#34;&gt;kubernetes-handbook&lt;/a&gt;中。&lt;/p&gt;
&lt;h2 id=&#34;kube-dns&#34;&gt;kube-dns&lt;/h2&gt;
&lt;p&gt;kube-dns 是 Kubernetes 中的一个内置插件，目前作为一个独立的开源项目维护，见 &lt;a href=&#34;https://github.com/kubernetes/dns&#34; title=&#34;https://github.com/kubernetes/dns&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/kubernetes/dns&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;下文中给出了配置 DNS Pod 的提示和定义 DNS 解析过程以及诊断 DNS 问题的指南。&lt;/p&gt;
&lt;h2 id=&#34;前提要求&#34;&gt;前提要求&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kubernetes 1.6 及以上版本。&lt;/li&gt;
&lt;li&gt;集群必须使用 &lt;code&gt;kube-dns&lt;/code&gt; 插件进行配置。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kube-dns-介绍&#34;&gt;kube-dns 介绍&lt;/h2&gt;
&lt;p&gt;从 Kubernetes v1.3 版本开始，使用 [cluster add-on 插件管理器回自动启动内置的 DNS。&lt;/p&gt;
&lt;p&gt;Kubernetes DNS pod 中包括 3 个容器：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;kubedns&lt;/code&gt;：&lt;code&gt;kubedns&lt;/code&gt; 进程监视 Kubernetes master 中的 Service 和 Endpoint 的变化，并维护内存查找结构来服务 DNS 请求。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dnsmasq&lt;/code&gt;：&lt;code&gt;dnsmasq&lt;/code&gt; 容器添加 DNS 缓存以提高性能。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sidecar&lt;/code&gt;：&lt;code&gt;sidecar&lt;/code&gt; 容器在执行双重健康检查（针对 &lt;code&gt;dnsmasq&lt;/code&gt; 和 &lt;code&gt;kubedns&lt;/code&gt;）时提供单个健康检查端点（监听在 10054 端口）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DNS  pod 具有静态 IP 并作为 Kubernetes 服务暴露出来。该静态 IP 分配后，kubelet 会将使用 &lt;code&gt;--cluster-dns = &amp;lt;dns-service-ip&amp;gt;&lt;/code&gt; 标志配置的 DNS 传递给每个容器。&lt;/p&gt;
&lt;p&gt;DNS 名称也需要域名。本地域可以使用标志 &lt;code&gt;--cluster-domain = &amp;lt;default-local-domain&amp;gt;&lt;/code&gt; 在 kubelet 中配置。&lt;/p&gt;
&lt;p&gt;Kubernetes 集群 DNS 服务器基于 &lt;a href=&#34;https://github.com/skynetservices/skydns&#34; title=&#34;SkyDNS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SkyDNS&lt;/a&gt; 库。它支持正向查找（A 记录），服务查找（SRV 记录）和反向 IP 地址查找（PTR 记录）&lt;/p&gt;
&lt;h2 id=&#34;kube-dns-支持的-dns-格式&#34;&gt;kube-dns 支持的 DNS 格式&lt;/h2&gt;
&lt;p&gt;kube-dns 将分别为 service 和 pod 生成不同格式的 DNS 记录。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Service&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A 记录：生成&lt;code&gt;my-svc.my-namespace.svc.cluster.local&lt;/code&gt;域名，解析成 IP 地址，分为两种情况：
&lt;ul&gt;
&lt;li&gt;普通 Service：解析成 ClusterIP&lt;/li&gt;
&lt;li&gt;Headless Service：解析为指定 Pod 的 IP 列表&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;SRV 记录：为命名的端口（普通 Service 或 Headless Service）生成 &lt;code&gt;_my-port-name._my-port-protocol.my-svc.my-namespace.svc.cluster.local&lt;/code&gt; 的域名&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Pod&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A 记录：生成域名 &lt;code&gt;pod-ip.my-namespace.pod.cluster.local&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kube-dns-存根域名&#34;&gt;kube-dns 存根域名&lt;/h2&gt;
&lt;p&gt;可以在 Pod 中指定 hostname 和 subdomain：&lt;code&gt;hostname.custom-subdomain.default.svc.cluster.local&lt;/code&gt;，例如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostname&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox-1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;subdomain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox-subdomain&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;3600&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该 Pod 的域名是 &lt;code&gt;busybox-1.busybox-subdomain.default.svc.cluster.local&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;继承节点的-dns&#34;&gt;继承节点的 DNS&lt;/h2&gt;
&lt;p&gt;运行 Pod 时，kubelet 将预先配置集群 DNS 服务器到 Pod 中，并搜索节点自己的 DNS 设置路径。如果节点能够解析特定于较大环境的 DNS 名称，那么 Pod 应该也能够解析。请参阅下面的&lt;a href=&#34;#known-issues&#34; title=&#34;已知问题&#34;&gt;已知问题&lt;/a&gt;以了解警告。&lt;/p&gt;
&lt;p&gt;如果您不想要这个，或者您想要为 Pod 设置不同的 DNS 配置，您可以给 kubelet 指定 &lt;code&gt;--resolv-conf&lt;/code&gt; 标志。将该值设置为 &amp;quot;&amp;quot; 意味着 Pod 不继承 DNS。将其设置为有效的文件路径意味着 kubelet 将使用此文件而不是 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 用于 DNS 继承。&lt;/p&gt;
&lt;h2 id=&#34;配置存根域和上游-dns-服务器&#34;&gt;配置存根域和上游 DNS 服务器&lt;/h2&gt;
&lt;p&gt;通过为 kube-dns（&lt;code&gt;kube-system:kube-dns&lt;/code&gt;）提供一个 ConfigMap，集群管理员能够指定自定义存根域和上游 nameserver。&lt;/p&gt;
&lt;p&gt;例如，下面的 ConfigMap 建立了一个 DNS 配置，它具有一个单独的存根域和两个上游 nameserver：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-dns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stubDomains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sd&#34;&gt;    {“acme.local”: [“1.2.3.4”]}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;upstreamNameservers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sd&#34;&gt;    [“8.8.8.8”, “8.8.4.4”]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如上面指定的那样，带有“.acme.local”后缀的 DNS 请求被转发到 1.2.3.4 处监听的 DNS。Google Public DNS 为上游查询提供服务。&lt;/p&gt;
&lt;p&gt;下表描述了如何将具有特定域名的查询映射到其目标 DNS 服务器：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;域名&lt;/th&gt;
&lt;th&gt;响应查询的服务器&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;kubernetes.default.svc.cluster.local&lt;/td&gt;
&lt;td&gt;kube-dns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;foo.acme.local&lt;/td&gt;
&lt;td&gt;自定义 DNS (1.2.3.4)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;widget.com&lt;/td&gt;
&lt;td&gt;上游 DNS (8.8.8.8 或 8.8.4.4)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;查看 &lt;a href=&#34;#configmap-options&#34; title=&#34;ConfigMap 选项&#34;&gt;ConfigMap 选项&lt;/a&gt; 获取更多关于配置选项格式的详细信息。&lt;/p&gt;
&lt;h3 id=&#34;对-pod-的影响&#34;&gt;对 Pod 的影响&lt;/h3&gt;
&lt;p&gt;自定义的上游名称服务器和存根域不会影响那些将自己的 &lt;code&gt;dnsPolicy&lt;/code&gt; 设置为 &lt;code&gt;Default&lt;/code&gt; 或者 &lt;code&gt;None&lt;/code&gt; 的 Pod。&lt;/p&gt;
&lt;p&gt;如果 Pod 的 &lt;code&gt;dnsPolicy&lt;/code&gt; 设置为“&lt;code&gt;ClusterFirst&lt;/code&gt;”，则其名称解析将按其他方式处理，具体取决于存根域和上游 DNS 服务器的配置。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;未进行自定义配置&lt;/strong&gt;：没有匹配上配置的集群域名后缀的任何请求，例如“www.kubernetes.io”，将会被转发到继承自节点的上游 nameserver。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;进行自定义配置&lt;/strong&gt;：如果配置了存根域和上游 DNS 服务器（和在 &lt;a href=&#34;#configuring-stub-domain-and-upstream-dns-servers&#34; title=&#34;前面例子&#34;&gt;前面例子&lt;/a&gt; 配置的一样），DNS 查询将根据下面的流程进行路由：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;查询首先被发送到 kube-dns 中的 DNS 缓存层。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;从缓存层，检查请求的后缀，并转发到合适的 DNS 上，基于如下的示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;具有集群后缀的名字&lt;/em&gt; （例如“.cluster.local”）：请求被发送到 kube-dns。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;具有存根域后缀的名字&lt;/em&gt; （例如“.acme.local”）：请求被发送到配置的自定义 DNS 解析器（例如：监听在 1.2.3.4）。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;不具有能匹配上后缀的名字&lt;/em&gt; （例如“widget.com”）：请求被转发到上游 DNS（例如：Google 公共 DNS 服务器，8.8.8.8 和 8.8.4.4）。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    &lt;img src=&#34;https://d33wubrfki0l68.cloudfront.net/340889cb80e81dcd19a16bc34697a7907e2b229a/24ad0/docs/tasks/administer-cluster/dns-custom-nameservers/dns.png&#34; data-img=&#34;https://d33wubrfki0l68.cloudfront.net/340889cb80e81dcd19a16bc34697a7907e2b229a/24ad0/docs/tasks/administer-cluster/dns-custom-nameservers/dns.png&#34; alt=&#34;image&#34; data-caption=&#34;DNS lookup flow&#34;&gt;
  
  
  &lt;figcaption&gt;DNS lookup flow&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;configmap-选项&#34;&gt;ConfigMap 选项&lt;/h2&gt;
&lt;p&gt;kube-dns &lt;code&gt;kube-system:kube-dns&lt;/code&gt; ConfigMap 的选项如下所示：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;格式&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;stubDomains&lt;/code&gt;（可选）&lt;/td&gt;
&lt;td&gt;使用 DNS 后缀 key 的 JSON map（例如“acme.local”），以及 DNS IP 的 JSON 数组作为 value。&lt;/td&gt;
&lt;td&gt;目标 nameserver 可能是一个 Kubernetes Service。例如，可以运行自己的 dnsmasq 副本，将 DNS 名字暴露到 ClusterDNS namespace 中。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;code&gt;upstreamNameservers&lt;/code&gt;（可选）&lt;/td&gt;
&lt;td&gt;DNS IP 的 JSON 数组。&lt;/td&gt;
&lt;td&gt;注意：如果指定，则指定的值会替换掉被默认从节点的 &lt;code&gt;/etc/resolv.conf&lt;/code&gt; 中获取到的 nameserver。限制：最多可以指定三个上游 nameserver。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;示例&#34;&gt;示例&lt;/h3&gt;
&lt;h4 id=&#34;示例存根域&#34;&gt;示例：存根域&lt;/h4&gt;
&lt;p&gt;在这个例子中，用户有一个 Consul DNS 服务发现系统，他们希望能够与 kube-dns 集成起来。Consul 域名服务器地址为 10.150.0.1，所有的 Consul 名字具有后缀“.consul.local”。要配置 Kubernetes，集群管理员只需要简单地创建一个 ConfigMap 对象，如下所示：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-dns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;stubDomains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sd&#34;&gt;    {“consul.local”: [“10.150.0.1”]}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;注意，集群管理员不希望覆盖节点的上游 nameserver，所以他们不会指定可选的 &lt;code&gt;upstreamNameservers&lt;/code&gt; 字段。&lt;/p&gt;
&lt;h4 id=&#34;示例上游-nameserver&#34;&gt;示例：上游 nameserver&lt;/h4&gt;
&lt;p&gt;在这个示例中，集群管理员不希望显式地强制所有非集群 DNS 查询进入到他们自己的 nameserver 172.16.0.1。而且这很容易实现：他们只需要创建一个 ConfigMap，&lt;code&gt;upstreamNameservers&lt;/code&gt; 字段指定期望的 nameserver 即可。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;ConfigMap&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-dns&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;kube-system&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;upstreamNameservers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;sd&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;sd&#34;&gt;    [“172.16.0.1”]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;调试-dns-解析&#34;&gt;调试 DNS 解析&lt;/h2&gt;
&lt;h3 id=&#34;创建一个简单的-pod-用作测试环境&#34;&gt;创建一个简单的 Pod 用作测试环境&lt;/h3&gt;
&lt;p&gt;创建一个名为 busybox.yaml 的文件，其中包括以下内容：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;namespace&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;busybox&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;command&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;l&#34;&gt;sleep&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;s2&#34;&gt;&amp;#34;3600&amp;#34;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;imagePullPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;IfNotPresent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;restartPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Always&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;使用该文件创建 Pod 并验证其状态：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f busybox.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;pod &lt;span class=&#34;s2&#34;&gt;&amp;#34;busybox&amp;#34;&lt;/span&gt; created
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl get pods busybox
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME      READY     STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;busybox   1/1       Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;          &amp;lt;some-time&amp;gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该 Pod 运行后，您可以在它的环境中执行 &lt;code&gt;nslookup&lt;/code&gt;。如果您看到类似如下的输出，表示 DNS 正在正确工作。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -ti busybox -- nslookup kubernetes.default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Server:    10.0.0.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Address 1: 10.0.0.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Name:      kubernetes.default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Address 1: 10.0.0.1
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果 &lt;code&gt;nslookup&lt;/code&gt; 命令失败，检查如下内容：&lt;/p&gt;
&lt;h3 id=&#34;首先检查本地-dns-配置&#34;&gt;首先检查本地 DNS 配置&lt;/h3&gt;
&lt;p&gt;查看下 resolv.conf 文件。（参考&lt;a href=&#34;#inheriting-dns-from-the-node&#34; title=&#34;集成节点的 DNS&#34;&gt;集成节点的 DNS&lt;/a&gt;和 下面的&lt;a href=&#34;#known-issues&#34; title=&#34;已知问题&#34;&gt;已知问题&lt;/a&gt;获取更多信息）&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; busybox cat /etc/resolv.conf
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;验证搜索路径和名称服务器设置如下（请注意，搜索路径可能因不同的云提供商而异）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;search default.svc.cluster.local svc.cluster.local cluster.local google.internal c.gce_project_id.internal
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nameserver 10.0.0.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;options ndots:5
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果看到如下错误表明错误来自 kube-dns 或相关服务：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -ti busybox -- nslookup kubernetes.default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Server:    10.0.0.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Address 1: 10.0.0.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nslookup: can&lt;span class=&#34;s1&#34;&gt;&amp;#39;t resolve &amp;#39;&lt;/span&gt;kubernetes.default&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;或者&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl &lt;span class=&#34;nb&#34;&gt;exec&lt;/span&gt; -ti busybox -- nslookup kubernetes.default
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Server:    10.0.0.10
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;Address 1: 10.0.0.10 kube-dns.kube-system.svc.cluster.local
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;nslookup: can&lt;span class=&#34;s1&#34;&gt;&amp;#39;t resolve &amp;#39;&lt;/span&gt;kubernetes.default&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;检查-dns-pod-是否在运行&#34;&gt;检查 DNS pod 是否在运行&lt;/h3&gt;
&lt;p&gt;使用 &lt;code&gt;kubectl get pods&lt;/code&gt; 命令验证 DNS pod 是否正在运行。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl get pods --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system -l k8s-app&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-dns
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME                    READY     STATUS    RESTARTS   AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-dns-v19-ezo1y      3/3       Running   &lt;span class=&#34;m&#34;&gt;0&lt;/span&gt;           1h
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果您看到没有 Pod 运行或者 Pod 处于 失败/完成 状态，DNS 插件可能没有部署到您的当前环境中，您需要手动部署。&lt;/p&gt;
&lt;h3 id=&#34;检查-dns-pod-中的错误&#34;&gt;检查 DNS pod 中的错误&lt;/h3&gt;
&lt;p&gt;使用 &lt;code&gt;kubectl logs&lt;/code&gt; 命令查看 DNS 守护进程的日志。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl logs --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get pods --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system -l k8s-app&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-dns -o name&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c kubedns
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl logs --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get pods --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system -l k8s-app&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-dns -o name&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c dnsmasq
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl logs --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system &lt;span class=&#34;k&#34;&gt;$(&lt;/span&gt;kubectl get pods --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system -l k8s-app&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-dns -o name&lt;span class=&#34;k&#34;&gt;)&lt;/span&gt; -c sidecar
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;看看有没有可疑的日志。以字母“&lt;code&gt;W&lt;/code&gt;”，“&lt;code&gt;E&lt;/code&gt;”，“&lt;code&gt;F&lt;/code&gt;”开头的代表警告、错误和失败。请搜索具有这些日志级别的条目，并使用 &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues&#34; title=&#34;kubernetes issues&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kubernetes issues&lt;/a&gt;来报告意外错误。&lt;/p&gt;
&lt;h3 id=&#34;dns-服务启动了吗&#34;&gt;DNS 服务启动了吗？&lt;/h3&gt;
&lt;p&gt;使用 &lt;code&gt;kubectl get service&lt;/code&gt; 命令验证 DNS 服务是否启动。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl get svc --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME          CLUSTER-IP     EXTERNAL-IP   PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;             AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-dns      10.0.0.10      &amp;lt;none&amp;gt;        53/UDP,53/TCP        1h
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;...
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果您已经创建了该服务或它本应该默认创建但没有出现，参考&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/&#34; title=&#34;调试服务&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;调试服务&lt;/a&gt;获取更多信息。&lt;/p&gt;
&lt;h3 id=&#34;dns-端点暴露出来了吗&#34;&gt;DNS 端点暴露出来了吗？&lt;/h3&gt;
&lt;p&gt;您可以使用&lt;code&gt;kubectl get endpoints&lt;/code&gt;命令验证 DNS 端点是否被暴露。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl get ep kube-dns --namespace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;kube-system
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME       ENDPOINTS                       AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;kube-dns   10.180.3.17:53,10.180.3.17:53    1h
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果您没有看到端点，查看&lt;a href=&#34;https://kubernetes.io/docs/tasks/debug-application-cluster/debug-service/&#34; title=&#34;调试服务&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;调试服务&lt;/a&gt;文档中的端点部分。&lt;/p&gt;
&lt;p&gt;获取更多的 Kubernetes DNS 示例，请参考 Kubernetes GitHub 仓库中的&lt;a href=&#34;https://github.com/kubernetes/examples/tree/master/staging/cluster-dns&#34; title=&#34;cluster-dns 示例&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cluster-dns 示例&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;已知问题&#34;&gt;已知问题&lt;/h2&gt;
&lt;p&gt;Kubernetes 安装时不会将节点的 resolv.conf 文件配置为默认使用集群 DNS，因为该过程本身是特定于发行版的。这一步应该放到最后实现。&lt;/p&gt;
&lt;p&gt;Linux 的 libc 不可思议的卡住（&lt;a href=&#34;https://bugzilla.redhat.com/show_bug.cgi?id=168253&#34; title=&#34;查看该 2005 年起暴出来的 bug&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;查看该 2005 年起暴出来的 bug&lt;/a&gt;）限制只能有 3 个 DNS &lt;code&gt;nameserver&lt;/code&gt; 记录和 6 个 DNS &lt;code&gt;search&lt;/code&gt; 记录。Kubernetes 需要消耗 1 个 &lt;code&gt;nameserver&lt;/code&gt; 记录和 3 个 &lt;code&gt;search&lt;/code&gt; 记录。这意味着如果本地安装已经使用 3 个 &lt;code&gt;nameserver&lt;/code&gt; 或使用 3 个以上的 &lt;code&gt;search&lt;/code&gt; 记录，那么其中一些设置将会丢失。有个部分解决该问题的方法，就是节点可以运行 &lt;code&gt;dnsmasq&lt;/code&gt;，它将提供更多的 &lt;code&gt;nameserver&lt;/code&gt; 条目，但不会有更多的 &lt;code&gt;search&lt;/code&gt; 条目。您也可以使用 kubelet 的 &lt;code&gt;--resolv-conf&lt;/code&gt; 标志。&lt;/p&gt;
&lt;p&gt;如果您使用的是 Alpine 3.3 或更低版本作为基础映像，由于已知的 Alpine 问题，DNS 可能无法正常工作。点击&lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/30215&#34; title=&#34;这里&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;这里&lt;/a&gt;查看更多信息。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-集群联邦多可用区支持&#34;&gt;Kubernetes 集群联邦（多可用区支持）&lt;/h2&gt;
&lt;p&gt;Kubernetes 1.3 版本起引入了支持多站点 Kubernetes 安装的集群联邦支持。这需要对 Kubernetes 集群 DNS 服务器处理 DNS 查询的方式进行一些小的（向后兼容的）更改，以便于查找联邦服务（跨多个 Kubernetes 集群）。有关集群联邦和多站点支持的更多详细信息，请参阅集群联邦管理员指南。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/dns-custom-nameservers/&#34; title=&#34;Configure DNS Service&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Configure DNS Service&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/&#34; title=&#34;Service 和 Pod 的 DNS&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Service 和 Pod 的 DNS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/&#34; title=&#34;自动扩容集群中的 DNS 服务&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自动扩容集群中的 DNS 服务&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kubernetes.io/docs/tasks/administer-cluster/coredns/&#34; title=&#34;Using CoreDNS for Service Discovery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Using CoreDNS for Service Discovery&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>从外部访问 Kubernetes 中的 Pod</title>
      <link>https://jimmysong.io/blog/accessing-kubernetes-pods-from-outside-of-the-cluster/</link>
      <pubDate>Tue, 21 Nov 2017 20:13:01 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/accessing-kubernetes-pods-from-outside-of-the-cluster/</guid>
      <description>
        
        
        &lt;p&gt;本文主要讲解访问 Kubernetes 中的 Pod 和 Service 的几种方式，包括如下几种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;hostNetwork&lt;/li&gt;
&lt;li&gt;hostPort&lt;/li&gt;
&lt;li&gt;NodePort&lt;/li&gt;
&lt;li&gt;LoadBalancer&lt;/li&gt;
&lt;li&gt;Ingress&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;说是暴露 Pod 其实跟暴露 Service 是一回事，因为 Pod 就是 Service 的 backend。&lt;/p&gt;
&lt;h2 id=&#34;hostnetwork-true&#34;&gt;hostNetwork: true&lt;/h2&gt;
&lt;p&gt;这是一种直接定义 Pod 网络的方式。&lt;/p&gt;
&lt;p&gt;如果在 Pod 中使用 &lt;code&gt;hostNetwork:true&lt;/code&gt; 配置的话，在这种 pod 中运行的应用程序可以直接看到 pod 启动的主机的网络接口。在主机的所有网络接口上都可以访问到该应用程序。以下是使用主机网络的 pod 的示例定义：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostNetwork&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;部署该 Pod：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f influxdb-hostnetwork.yml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;访问该 pod 所在主机的 8086 端口：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;curl -v http://&lt;span class=&#34;nv&#34;&gt;$POD_IP&lt;/span&gt;:8086/ping
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将看到 204 No Content 的 204 返回码，说明可以正常访问。&lt;/p&gt;
&lt;p&gt;注意每次启动这个 Pod 的时候都可能被调度到不同的节点上，所有外部访问 Pod 的 IP 也是变化的，而且调度 Pod 的时候还需要考虑是否与宿主机上的端口冲突，因此一般情况下除非您知道需要某个特定应用占用特定宿主机上的特定端口时才使用 &lt;code&gt;hostNetwork: true&lt;/code&gt; 的方式。&lt;/p&gt;
&lt;p&gt;这种 Pod 的网络模式有一个用处就是可以将网络插件包装在 Pod 中然后部署在每个宿主机上，这样该 Pod 就可以控制该宿主机上的所有网络。&lt;/p&gt;
&lt;h2 id=&#34;hostport&#34;&gt;hostPort&lt;/h2&gt;
&lt;p&gt;这是一种直接定义 Pod 网络的方式。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;hostPort&lt;/code&gt; 是直接将容器的端口与所调度的节点上的端口路由，这样用户就可以通过宿主机的 IP 加上来访问 Pod 了，如:。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8086&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;hostPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8086&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样做有个缺点，因为 Pod 重新调度的时候该 Pod 被调度到的宿主机可能会变动，这样就变化了，用户必须自己维护一个 Pod 与所在宿主机的对应关系。&lt;/p&gt;
&lt;p&gt;这种网络方式可以用来做 nginx &lt;a href=&#34;https://github.com/kubernetes/ingress/tree/master/controllers/nginx&#34; title=&#34;Ingress controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress controller&lt;/a&gt; 。外部流量都需要通过 Kubernetes node 节点的 80 和 443 端口。&lt;/p&gt;
&lt;h2 id=&#34;nodeport&#34;&gt;NodePort&lt;/h2&gt;
&lt;p&gt;NodePort 在 Kubernetes 里是一个广泛应用的服务暴露方式。Kubernetes 中的 service 默认情况下都是使用的 &lt;code&gt;ClusterIP&lt;/code&gt; 这种类型，这样的 service 会产生一个 ClusterIP，这个 IP 只能在集群内部访问，要想让外部能够直接访问 service，需要将 service type 修改为 &lt;code&gt;nodePort&lt;/code&gt;。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;labels&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;containers&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;containerPort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8086&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;同时还可以给 service 指定一个 &lt;code&gt;nodePort&lt;/code&gt; 值，范围是 30000-32767，这个值在 API server 的配置文件中，用 &lt;code&gt;--service-node-port-range&lt;/code&gt; 定义。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;NodePort&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8086&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;nodePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;30000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;集群外就可以使用 kubernetes 任意一个节点的 IP 加上 30000 端口访问该服务了。kube-proxy 会自动将流量以 round-robin 的方式转发给该 service 的每一个 pod。&lt;/p&gt;
&lt;p&gt;这种服务暴露方式，无法让你指定自己想要的应用常用端口，不过可以在集群上再部署一个反向代理作为流量入口。&lt;/p&gt;
&lt;h2 id=&#34;loadbalancer&#34;&gt;LoadBalancer&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;LoadBalancer&lt;/code&gt; 只能在 service 上定义。这是公有云提供的负载均衡器，如 AWS、Azure、CloudStack、GCE 等。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Service&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;type&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;LoadBalancer&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;ports&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;port&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8086&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;selector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;查看服务：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl get svc influxdb
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;NAME       CLUSTER-IP     EXTERNAL-IP     PORT&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;S&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;          AGE
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;influxdb   10.97.121.42   10.13.242.236   8086:30051/TCP   39s
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;内部可以使用 ClusterIP 加端口来访问服务，如 19.97.121.42:8086。&lt;/p&gt;
&lt;p&gt;外部可以用以下两种方式访问该服务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用任一节点的 IP 加 30051 端口访问该服务&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;EXTERNAL-IP&lt;/code&gt; 来访问，这是一个 VIP，是云供应商提供的负载均衡器 IP，如 10.13.242.236:8086。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ingress&#34;&gt;Ingress&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;Ingress&lt;/code&gt; 是自 kubernetes1.1 版本后引入的资源类型。必须要部署 &lt;a href=&#34;https://github.com/kubernetes/ingress/tree/master/controllers/nginx&#34; title=&#34;Ingress controller&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ingress controller&lt;/a&gt; 才能创建 Ingress 资源，Ingress controller 是以一种插件的形式提供。Ingress controller 是部署在 Kubernetes 之上的 Docker 容器。它的 Docker 镜像包含一个像 nginx 或 HAProxy 的负载均衡器和一个控制器守护进程。控制器守护程序从 Kubernetes 接收所需的 Ingress 配置。它会生成一个 nginx 或 HAProxy 配置文件，并重新启动负载平衡器进程以使更改生效。换句话说，Ingress controller 是由 Kubernetes 管理的负载均衡器。&lt;/p&gt;
&lt;p&gt;Kubernetes Ingress 提供了负载平衡器的典型特性：HTTP 路由，粘性会话，SSL 终止，SSL 直通，TCP 和 UDP 负载平衡等。目前并不是所有的 Ingress controller 都实现了这些功能，需要查看具体的 Ingress controller 文档。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;apiVersion&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;extensions/v1beta1&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;kind&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;Ingress&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;metadata&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;spec&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;rules&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb.kube.example.com&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;influxdb&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;              &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8086&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;外部访问 URL &lt;code&gt;http://influxdb.kube.example.com/ping&lt;/code&gt; 访问该服务，入口就是 80 端口，然后 Ingress controller 直接将流量转发给后端 Pod，不需再经过 kube-proxy 的转发，比 LoadBalancer 方式更高效。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;总的来说 Ingress 是一个非常灵活和越来越得到厂商支持的服务暴露方式，包括 Nginx、HAProxy、Traefik，还有各种 Service Mesh，而其它服务暴露方式可以更适用于服务调试、特殊应用的部署。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>适用于 Kubernetes 的应用开发与部署流程详解</title>
      <link>https://jimmysong.io/blog/deploy-applications-in-kubernetes/</link>
      <pubDate>Thu, 20 Jul 2017 19:41:53 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/deploy-applications-in-kubernetes/</guid>
      <description>
        
        
        &lt;p&gt;本文已归档在&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook&#34; title=&#34;kubernetes-handbook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kubernetes-handbook&lt;/a&gt;中的第 3 章【用户指南】中，一切更新以 kubernetes-handbook 中为准。&lt;/p&gt;
&lt;p&gt;为了详细说明，我特意写了两个示例程序放在 GitHub 中，模拟应用开发流程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-test&#34; title=&#34;k8s-app-monitor-test&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;k8s-app-monitor-test&lt;/a&gt;：生成模拟的监控数据，发送 http 请求，获取 json 返回值&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-agent&#34; title=&#34;K8s-app-monitor-agent&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;K8s-app-monitor-agent&lt;/a&gt;：获取监控数据并绘图，访问浏览器获取图表&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;API 文档见&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-test&#34; title=&#34;k8s-app-monitor-test&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;k8s-app-monitor-test&lt;/a&gt;中的&lt;code&gt;api.html&lt;/code&gt;文件，该文档在 API blueprint 中定义，使用&lt;a href=&#34;https://github.com/danielgtaylor/aglio&#34; title=&#34;aglio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;aglio&lt;/a&gt;生成，打开后如图所示：&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/deploy-applications-in-kubernetes/k8s-app-monitor-test-api-doc_hu73bc232b740be39d3b06697e0b199e1b_39338_958x941_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/deploy-applications-in-kubernetes/k8s-app-monitor-test-api-doc.jpg&#34; data-img=&#34;/blog/deploy-applications-in-kubernetes/k8s-app-monitor-test-api-doc.jpg&#34; data-width=&#34;958&#34; data-height=&#34;941&#34; alt=&#34;image&#34; data-caption=&#34;API 文档&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;API 文档&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;关于服务发现&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;K8s-app-monitor-agent&lt;/code&gt;服务需要访问&lt;code&gt;k8s-app-monitor-test&lt;/code&gt;服务，这就涉及到服务发现的问题，我们在代码中直接写死了要访问的服务的内网 DNS 地址（kubedns 中的地址，即&lt;code&gt;k8s-app-monitor-test.default.svc.cluster.local&lt;/code&gt;）。&lt;/p&gt;
&lt;p&gt;我们知道 Kubernetes 在启动 Pod 的时候为容器注入环境变量，这些环境变量在所有的 namespace 中共享（环境变量是不断追加的，新启动的 Pod 中将拥有老的 Pod 中所有的环境变量，而老的 Pod 中的环境变量不变）。但是既然使用这些环境变量就已经可以访问到对应的 service，那么获取应用的地址信息，究竟是使用变量呢？还是直接使用 DNS 解析来发现？&lt;/p&gt;
&lt;p&gt;答案是使用 DNS，详细说明见&lt;a href=&#34;https://jimmysong.io/blog/exploring-kubernetes-env-with-docker/&#34; title=&#34;Kubernetes 中的服务发现与 Docker 容器间的环境变量传递源码探究&#34;&gt;Kubernetes 中的服务发现与 Docker 容器间的环境变量传递源码探究&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;打包镜像&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因为我使用 wercker 自动构建，构建完成后自动打包成 docker 镜像并上传到 docker hub 中（需要提前在 docker hub 中创建 repo），如何使用 wercker 做持续构建与发布，并集成 docker hub 插件请参考&lt;a href=&#34;https://jimmysong.io/blog/continuous-integration-with-wercker/&#34; title=&#34;使用 Wercker 进行持续构建与发布&#34;&gt;使用 Wercker 进行持续构建与发布&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://app.wercker.com/jimmysong/k8s-app-monitor-agent/&#34; title=&#34;查看详细构建流程&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;查看详细构建流程&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/deploy-applications-in-kubernetes/k8s-app-monitor-agent-wercker_hub9c0e50fdb57d51b987a72e16255d0e2_82839_3316x1536_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/deploy-applications-in-kubernetes/k8s-app-monitor-agent-wercker.jpg&#34; data-img=&#34;/blog/deploy-applications-in-kubernetes/k8s-app-monitor-agent-wercker.jpg&#34; data-width=&#34;3316&#34; data-height=&#34;1536&#34; alt=&#34;image&#34; data-caption=&#34;wercker&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;wercker&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;生成了如下两个 docker 镜像：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;jimmysong/k8s-app-monitor-test:latest&lt;/li&gt;
&lt;li&gt;jimmysong/k8s-app-monitor-agent:latest&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;启动服务&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;所有的 kubernetes 应用启动所用的 yaml 配置文件都保存在那两个 GitHub 仓库的&lt;code&gt;manifest.yaml&lt;/code&gt;文件中。&lt;/p&gt;
&lt;p&gt;分别在两个 GitHub 目录下执行&lt;code&gt;kubectl create -f manifest.yaml&lt;/code&gt;即可启动服务。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;外部访问&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;服务启动后需要更新 ingress 配置，在&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook/blob/master/manifests/traefik-ingress/ingress.yaml&#34; title=&#34;ingress.yaml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ingress.yaml&lt;/a&gt;文件中增加以下几行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Yaml&#34; data-lang=&#34;Yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s-app-monitor-agent.jimmysong.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;k8s-app-monitor-agent&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8080&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;保存后，然后执行&lt;code&gt;kubectl replace -f ingress.yaml&lt;/code&gt;即可刷新 ingress。&lt;/p&gt;
&lt;p&gt;修改本机的&lt;code&gt;/etc/hosts&lt;/code&gt;文件，在其中加入以下一行：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;172.20.0.119 k8s-app-monitor-agent.jimmysong.io&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当然你也可以加入到 DNS 中，为了简单起见我使用 hosts。&lt;/p&gt;
&lt;p&gt;详见&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook/blob/master/practice/edge-node-configuration.md&#34; title=&#34;边缘节点配置&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;边缘节点配置&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在浏览器中访问 &lt;a href=&#34;http://k8s-app-monitor-agent.jimmysong.io&#34; title=&#34;http://k8s-app-monitor-agent.jimmysong.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://k8s-app-monitor-agent.jimmysong.io&lt;/a&gt;&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/deploy-applications-in-kubernetes/k8s-app-monitor-agent_hu578b91404b6091d13500e74302b80bca_56093_1015x579_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/deploy-applications-in-kubernetes/k8s-app-monitor-agent.jpg&#34; data-img=&#34;/blog/deploy-applications-in-kubernetes/k8s-app-monitor-agent.jpg&#34; data-width=&#34;1015&#34; data-height=&#34;579&#34; alt=&#34;image&#34; data-caption=&#34;图表&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;图表&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;刷新页面将获得新的图表。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/blog/continuous-integration-with-wercker/&#34; title=&#34;使用 Wercker 进行持续构建与发布&#34;&gt;使用 Wercker 进行持续构建与发布&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://app.wercker.com/jimmysong/k8s-app-monitor-agent/&#34; title=&#34;示例的项目代码服务器端&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;示例的项目代码服务器端&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-agent&#34; title=&#34;示例项目代码前端&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;示例项目代码前端&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/book/kubernetes-handbook/&#34; title=&#34;kubernetes-handbok&#34;&gt;kubernetes-handbok&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook/blob/master/practice/edge-node-configuration.md&#34; title=&#34;边缘节点配置&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;边缘节点配置&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
                           
    <item>
      <title>记一本关于 kubernetes management design patterns 的书</title>
      <link>https://jimmysong.io/blog/book-kubernetes-management-design-patterns/</link>
      <pubDate>Thu, 20 Jul 2017 18:21:18 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/book-kubernetes-management-design-patterns/</guid>
      <description>
        
        
        &lt;p&gt;下面是这本书的基本信息。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;书名：Kubernetes Management Design Patterns: With Docker, CoreOS Linux, and Other Platforms&lt;/li&gt;
&lt;li&gt;Amazon 购买链接：&lt;a href=&#34;https://www.amazon.com/Kubernetes-Management-Design-Patterns-Platforms-ebook/dp/B01MZDO0BD/ref=pd_sbs_351_4?_encoding=UTF8&amp;amp;psc=1&amp;amp;refRID=79F47CR67EEESD35S2VF&#34; title=&#34;链接&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;链接&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;作者：Deepak Vohra&lt;/li&gt;
&lt;li&gt;发行日期：2017 年 1 月 20 日&lt;/li&gt;
&lt;li&gt;出版社：Apress&lt;/li&gt;
&lt;li&gt;页数：399&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;简介&#34;&gt;简介&lt;/h3&gt;
&lt;p&gt;Kubernetes 引领容器集群管理进入一个全新的阶段；学习如何在 CoreOS 上配置和管理 kubernetes 集群；使用适当的管理模式，如 ConfigMaps、Autoscaling、弹性资源使用和高可用性配置。讨论了 kubernetes 的一些其他特性，如日志、调度、滚动升级、volume、服务类型和跨多个云供应商 zone。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的最小模块化单位是 Pod，它是拥有共同的文件系统和网络的系列容器的集合。Pod 的抽象层可以对容器使用设计模式，就像面向对象设计模式一样。容器能够提供与软件对象（如模块化或包装，抽象和重用）相同的优势。&lt;/p&gt;
&lt;p&gt;在大多数章节中使用的都是 CoreOS Linux，其他讨论的平台有 CentOS，OpenShift，Debian 8（jessie），AWS 和 Debian 7 for Google Container Engine。&lt;/p&gt;
&lt;p&gt;使用 CoreOS 主要是因为 Docker 已经在 CoreOS 上开箱即用。CoreOS：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;支持大多数云提供商（包括 Amazon AWS EC2 和 Google Cloud Platform）和虚拟化平台（如 VMWare 和 VirtualBox）&lt;/li&gt;
&lt;li&gt;提供 Cloud-Config，用于声明式配置 OS，如网络配置（flannel），存储（etcd）和用户帐户&lt;/li&gt;
&lt;li&gt;为容器化应用提供生产级基础架构，包括自动化，安全性和可扩展性&lt;/li&gt;
&lt;li&gt;引领容器行业标准，并建立了应用程序标准&lt;/li&gt;
&lt;li&gt;提供最先进的容器仓库，Quay&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Docker 于 2013 年 3 月开源，现已称为最流行的容器平台。kubernetes 于 2014 年 6 月开源，现在已经成为最流行的容器集群管理平台。第一个稳定版 CoreOS Linux 于 2014 年 7 月发行，现已成为最流行的容器操作系统之一。&lt;/p&gt;
&lt;h3 id=&#34;你将学到什么&#34;&gt;你将学到什么&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;使用 docker 和 kubernetes&lt;/li&gt;
&lt;li&gt;在 AWS 和 CoreOS 上创建 kubernetes 集群&lt;/li&gt;
&lt;li&gt;应用集群管理设计模式&lt;/li&gt;
&lt;li&gt;使用多个云供应商 zone&lt;/li&gt;
&lt;li&gt;使用 Ansible 管理 kubernetes&lt;/li&gt;
&lt;li&gt;基于 kubernetes 的 PAAS 平台 OpenShift&lt;/li&gt;
&lt;li&gt;创建高可用网站&lt;/li&gt;
&lt;li&gt;构建高可用用的 kubernetes master 集群&lt;/li&gt;
&lt;li&gt;使用 volume、configmap、Service、autoscaling 和 rolling update&lt;/li&gt;
&lt;li&gt;管理计算资源&lt;/li&gt;
&lt;li&gt;配置日志和调度&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;谁适合读这本书&#34;&gt;谁适合读这本书&lt;/h3&gt;
&lt;p&gt;Linux 管理员、CoreOS 管理员、应用程序开发者、容器即服务（CAAS）开发者。阅读这本书需要 Linux 和 Docker 的前置知识。介绍 Kubernetes 的知识，例如创建集群，创建 Pod，创建 service 以及创建和缩放 replication controller。还需要一些关于使用 Amazon Web Services（AWS）EC2，CloudFormation 和 VPC 的必备知识。&lt;/p&gt;
&lt;h3 id=&#34;关于作者&#34;&gt;关于作者&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Deepak Vohra&lt;/strong&gt; is an Oracle Certified Associate and a Sun Certified Java Programmer. Deepak has published in Oracle Magazine, OTN, IBM developerWorks, ONJava, DevSource,  WebLogic Developer’s Journal, XML Journal, Java Developer’s Journal, FTPOnline, and devx.&lt;/p&gt;
&lt;h3 id=&#34;目录&#34;&gt;目录&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;第一部分：平台
&lt;ul&gt;
&lt;li&gt;第 1 章：Kuberentes on AWS&lt;/li&gt;
&lt;li&gt;第 2 章：kubernetes on CoreOS on AWS&lt;/li&gt;
&lt;li&gt;第 3 章：kubernetes on Google Cloud Platform&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;第二部分：管理和配置
&lt;ul&gt;
&lt;li&gt;第 4 章：使用多个可用区&lt;/li&gt;
&lt;li&gt;第 5 章：使用 Tectonic Console&lt;/li&gt;
&lt;li&gt;第 6 章：使用 volume&lt;/li&gt;
&lt;li&gt;第 7 章：使用 service&lt;/li&gt;
&lt;li&gt;第 8 章：使用 Rolling updte&lt;/li&gt;
&lt;li&gt;第 9 章：在 node 上调度 pod&lt;/li&gt;
&lt;li&gt;第 10 章：配置计算资源&lt;/li&gt;
&lt;li&gt;第 11 章：使用 ConfigMap&lt;/li&gt;
&lt;li&gt;第 12 章：使用资源配额&lt;/li&gt;
&lt;li&gt;第 13 章：使用 Autoscaling&lt;/li&gt;
&lt;li&gt;第 14 章：配置 logging&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;第三部分：高可用
&lt;ul&gt;
&lt;li&gt;第 15 章：在 OpenShift 中使用 HA master&lt;/li&gt;
&lt;li&gt;第 16 章：开发高可用网站&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;个人评价&#34;&gt;个人评价&lt;/h3&gt;
&lt;p&gt;本书更像是一本参考手册，对于想在公有云中（如 AWS、Google Cloud Platform）中尝试 Kubernetes 的人会有所帮助，而对于想使用 kubernetes 进行自己的私有云建设，或想了解 kubernetes 的实现原理和技术细节的人来说，就不适合了。对我来说，本书中有个别几个章节可以参考，如高可用，但还是使用 OpenShift 实现的。总之，如果你使用 AWS 这样的公有云，对操作系统没有特别要求，可以接受 CoreOS 的话，那么可以看看这本书。本来本书会对 kubernetes 中的各种应用模式能够有个详解，但是从书中我并没有找到。&lt;/p&gt;
&lt;p&gt;本书有两个优点，一个是每个章节都给出了问题的起因和 kubernetes 的解决方案，二是几乎所有的命令和操作都附有截图，说明很详细。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>Kubernetes 中的服务发现与 docker 容器间的环境变量传递源码探究</title>
      <link>https://jimmysong.io/blog/exploring-kubernetes-env-with-docker/</link>
      <pubDate>Wed, 19 Jul 2017 23:15:01 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/exploring-kubernetes-env-with-docker/</guid>
      <description>
        
        
        &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;今天创建了两个 kubernetes 示例应用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-test&#34; title=&#34;k8s-app-monitor-test&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;k8s-app-monitor-test&lt;/a&gt;：启动 server 用来产生 metrics&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/rootsongjc/k8s-app-monitor-agent&#34; title=&#34;k8s-app-monitor-agent&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;k8s-app-monitor-agent&lt;/a&gt;：获取 metrics 并绘图，显示在 web 上&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;注：相关的 kubernetes 应用&lt;code&gt;manifest.yaml&lt;/code&gt;文件分别见以上两个应用的 GitHub。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当我查看 Pod 中的环境变量信息时，例如 kubernetes 中的 service &lt;code&gt;k8s-app-monitor-test&lt;/code&gt;注入的环境变量时，包括了以下变量：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_PORT_3000_TCP_ADDR&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;10.254.56.68&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;tcp://10.254.56.68:3000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_PORT_3000_TCP_PROTO&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;tcp&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_SERVICE_PORT_HTTP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;3000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_PORT_3000_TCP_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;3000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_PORT_3000_TCP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;tcp://10.254.56.68:3000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_SERVICE_HOST&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;10.254.56.68&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;K8S_APP_MONITOR_TEST_SERVICE_PORT&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;3000&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们知道 Kubernetes 在启动 Pod 的时候为容器注入环境变量，这些环境变量将在该 Pod 所在的 namespace 中共享。但是既然使用这些环境变量就已经可以访问到对应的 service，那么获取应用的地址信息，究竟是使用变量呢？还是直接使用 DNS 解析来发现？下面我们从代码中来寻求答案。&lt;/p&gt;
&lt;p&gt;如果不想看下面的文字，可以直接看图。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/exploring-kubernetes-env-with-docker/kubernetes-service-discovery-with-dns-or-env_hu35f0cd451eca7e3a74e5a1c51b166438_253406_1029x1127_resize_q75_h2_lanczos_3.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/exploring-kubernetes-env-with-docker/kubernetes-service-discovery-with-dns-or-env.png&#34; data-img=&#34;/blog/exploring-kubernetes-env-with-docker/kubernetes-service-discovery-with-dns-or-env.png&#34; data-width=&#34;1029&#34; data-height=&#34;1127&#34; alt=&#34;image&#34; data-caption=&#34;kubernetes 中传递 ENV 的探索过程&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;kubernetes 中传递 ENV 的探索过程&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;探索&#34;&gt;探索&lt;/h2&gt;
&lt;p&gt;docker 的&lt;code&gt;docker/engine-api/types/container/config.go&lt;/code&gt;中的&lt;code&gt;Config&lt;/code&gt;结构体中有对环境变量的定义：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Go&#34; data-lang=&#34;Go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Config contains the configuration data about a container.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// It should hold only portable information about the container.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Here, &amp;#34;portable&amp;#34; means &amp;#34;independent from the host we are running on&amp;#34;.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Non-portable information *should* appear in HostConfig.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// All fields added to this struct must be marked `omitempty` to keep getting
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// predictable hashes from the old `v1Compatibility` configuration.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Config&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nx&#34;&gt;Hostname&lt;/span&gt;        &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;                &lt;span class=&#34;c1&#34;&gt;// Hostname
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;Domainname&lt;/span&gt;      &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;                &lt;span class=&#34;c1&#34;&gt;// Domainname
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;User&lt;/span&gt;            &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;                &lt;span class=&#34;c1&#34;&gt;// User that will run the command(s) inside the container
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nx&#34;&gt;Env&lt;/span&gt;             &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;              &lt;span class=&#34;c1&#34;&gt;// List of environment variable to set in the container
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;Cmd&lt;/span&gt;             &lt;span class=&#34;nx&#34;&gt;strslice&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;StrSlice&lt;/span&gt;     &lt;span class=&#34;c1&#34;&gt;// Command to run when starting the container
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Kubernetes 中在&lt;code&gt;pkg/kubelet/container/runtime.go&lt;/code&gt;中的&lt;code&gt;RunContainerOptions&lt;/code&gt;结构体中定义：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// RunContainerOptions specify the options which are necessary for running containers
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;RunContainerOptions&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// The environment variables list.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;Envs&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;EnvVar&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;  	&lt;span class=&#34;c1&#34;&gt;// The mounts for the containers.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;Mounts&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Mount&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// The host devices mapped into the containers.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Kubelet 向容器中注入环境变量的配置是在下面的方法中定义：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-ini&#34; data-lang=&#34;ini&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;na&#34;&gt;pkg/kubelet/kuberuntime/kuberuntime_container.go&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Go&#34; data-lang=&#34;Go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// generateContainerConfig generates container config for kubelet runtime v1.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kubeGenericRuntimeManager&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;generateContainerConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;container&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Container&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;pod&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;restartCount&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;podIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;imageRef&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;runtimeapi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ContainerConfig&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;runtimeHelper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;GenerateRunContainerOptions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;container&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;podIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// set environment variables
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;envs&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;runtimeapi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;KeyValue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Envs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;idx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Envs&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nx&#34;&gt;e&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Envs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;nx&#34;&gt;envs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;runtimeapi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;KeyValue&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;nx&#34;&gt;Key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;   &lt;span class=&#34;nx&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;			&lt;span class=&#34;nx&#34;&gt;Value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;e&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;		&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nx&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Envs&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;envs&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;config&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;kubelet 的&lt;code&gt;pkg/kubelet/kubelet_pods.go&lt;/code&gt;的如下方法中生成了&lt;code&gt;RunContainerOptions&lt;/code&gt;：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Go&#34; data-lang=&#34;Go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// GenerateRunContainerOptions generates the RunContainerOptions, which can be used by
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// the container runtime to set parameters for launching a container.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Kubelet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GenerateRunContainerOptions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pod&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;container&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Container&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;podIP&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kubecontainer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;RunContainerOptions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kubecontainer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;RunContainerOptions&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;CgroupParent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cgroupParent&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Envs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;kl&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;makeEnvironmentVariables&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;container&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;podIP&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;    &lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;opts&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;useClusterFirstPolicy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们再看下&lt;code&gt;makeEnvironmentVariables(pod, container, podIP)&lt;/code&gt;方法中又做了什么（该方法也在&lt;code&gt;pkg/kubelet/kubelet_pods.go&lt;/code&gt;文件中）。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Go&#34; data-lang=&#34;Go&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Make the environment variables for a pod in the given namespace.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kl&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Kubelet&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;makeEnvironmentVariables&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pod&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pod&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;container&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Container&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;podIP&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;([]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kubecontainer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;EnvVar&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;result&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;kubecontainer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;EnvVar&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;	&lt;span class=&#34;c1&#34;&gt;// Note:  These are added to the docker Config, but are not included in the checksum computed
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// by dockertools.BuildDockerName(...).  That way, we can still determine whether an
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// v1.Container is already running by its hash. (We don&amp;#39;t want to restart a container just
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// because some service changed.)
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// Note that there is a race between Kubelet seeing the pod and kubelet seeing the service.
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// To avoid this users can: (1) wait between starting a service and starting; or (2) detect
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// missing service env var and exit and be restarted; or (3) use DNS instead of env vars
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// and keep trying to resolve the DNS name of the service (recommended).
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;o&#34;&gt;...&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;该代码段比较长，kubernetes 究竟如何将环境变量注入到 docker 容器中的奥秘就在这里，按图索骥到了这里，从代码注释中已经可以得出结论，使用 DNS 解析而不要使用环境变量来做服务发现，究竟为何这样做，改天我们再详细解读。&lt;/p&gt;

      </description>
    </item>
                           
    <item>
      <title>使用 Kubernetes 进行分布式负载测试</title>
      <link>https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/</link>
      <pubDate>Mon, 24 Apr 2017 21:32:52 +0800</pubDate>
      <author>rootsongjc@gmail.com (Jimmy Song)</author>
      <guid>https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/</guid>
      <description>
        
        
        &lt;h2 id=&#34;前言&#34;&gt;前言&lt;/h2&gt;
&lt;p&gt;本示例来自 &lt;a href=&#34;https://github.com/rootsongjc/distributed-load-testing-using-kubernetes&#34; title=&#34;GitHub - distributed-load-testing-using-kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub - distributed-load-testing-using-kubernetes&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;该教程描述如何在&lt;a href=&#34;http://kubernetes.io&#34; title=&#34;Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt;中进行分布式负载均衡测试，包括一个 web 应用、docker 镜像和 Kubernetes controllers/services。更多资料请查看&lt;a href=&#34;http://cloud.google.com/solutions/distributed-load-testing-using-kubernetes&#34; title=&#34;Distributed Load Testing Using Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Distributed Load Testing Using Kubernetes&lt;/a&gt; 。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：该测试是在我自己本地搭建的 kubernetes 集群上测试的，不需要使用 Google Cloud Platform。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;准备&#34;&gt;准备&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;不需要 GCE 及其他组件，你只需要有一个 kubernetes 集群即可。&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;部署-web-应用&#34;&gt;部署 Web 应用&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;sample-webapp&lt;/code&gt; 目录下包含一个简单的 web 测试应用。我们将其构建为 docker 镜像，在 kubernetes 中运行。你可以自己构建，也可以直接用这个我构建好的镜像&lt;code&gt;index.tenxcloud.com/jimmy/k8s-sample-webapp:latest&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;在 kubernetes 上部署 sample-webapp。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ &lt;span class=&#34;nb&#34;&gt;cd&lt;/span&gt; kubernetes-config
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f sample-webapp-controller.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f kubectl create -f sample-webapp-service.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;部署-locust-的-controller-和-service&#34;&gt;部署 Locust 的 Controller 和 Service&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;locust-master&lt;/code&gt;和&lt;code&gt;locust-work&lt;/code&gt;使用同样的 docker 镜像，修改 cotnroller 中&lt;code&gt;spec.template.spec.containers.env&lt;/code&gt;字段中的 value 为你&lt;code&gt;sample-webapp&lt;/code&gt; service 的名字。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;- &lt;span class=&#34;nt&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;TARGET_HOST&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;value&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;http://sample-webapp:8000&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;创建-controller-docker-镜像可选&#34;&gt;创建 Controller Docker 镜像（可选）&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;locust-master&lt;/code&gt;和&lt;code&gt;locust-work&lt;/code&gt; controller 使用的都是&lt;code&gt;locust-tasks&lt;/code&gt; docker 镜像。你可以直接下载，也可以自己编译。自己编译大概要花几分钟时间，镜像大小为 820M。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ docker build -t index.tenxcloud.com/jimmy/locust-tasks:latest .
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ docker push index.tenxcloud.com/jimmy/locust-tasks:latest
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：我使用的是时速云的镜像仓库。&lt;/p&gt;
&lt;p&gt;每个 controller 的 yaml 的&lt;code&gt;spec.template.spec.containers.image&lt;/code&gt; 字段指定的是我的镜像：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-yaml&#34; data-lang=&#34;yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;nt&#34;&gt;image&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;index.tenxcloud.com/jimmy/locust-tasks:latest&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;部署-locust-master&#34;&gt;部署 locust-master&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f locust-master-controller.yaml
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f locust-master-service.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;部署-locust-worker&#34;&gt;部署 locust-worker&lt;/h3&gt;
&lt;p&gt;Now deploy &lt;code&gt;locust-worker-controller&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl create -f locust-worker-controller.yaml
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;你可以很轻易的给 work 扩容，通过命令行方式：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;$ kubectl scale --replicas&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;20&lt;/span&gt; replicationcontrollers locust-worker
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当然你也可以通过 WebUI：Dashboard - Workloads - Replication Controllers - &lt;strong&gt;ServiceName&lt;/strong&gt; - Scale 来扩容。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/dashbaord-scale_hub9c0e50fdb57d51b987a72e16255d0e2_113043_3268x1896_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/dashbaord-scale.jpg&#34; data-img=&#34;/blog/distributed-load-testing-using-kubernetes/dashbaord-scale.jpg&#34; data-width=&#34;3268&#34; data-height=&#34;1896&#34; alt=&#34;image&#34; data-caption=&#34;Dashboard&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Dashboard&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h3 id=&#34;配置-traefik&#34;&gt;配置 Traefik&lt;/h3&gt;
&lt;p&gt;参考&lt;a href=&#34;https://jimmysong.io/posts/traefik-ingress-installation/&#34; title=&#34;kubernetes 的 traefik ingress 安装&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;kubernetes 的 traefik ingress 安装&lt;/a&gt;，在&lt;code&gt;ingress.yaml&lt;/code&gt;中加入如下配置：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-Yaml&#34; data-lang=&#34;Yaml&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;  &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;host&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;traefik.locust.io&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;paths&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;      &lt;/span&gt;- &lt;span class=&#34;nt&#34;&gt;path&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;backend&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;serviceName&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;l&#34;&gt;locust-master&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;w&#34;&gt;          &lt;/span&gt;&lt;span class=&#34;nt&#34;&gt;servicePort&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;m&#34;&gt;8089&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;然后执行&lt;code&gt;kubectl replace -f ingress.yaml&lt;/code&gt;即可更新 traefik。&lt;/p&gt;
&lt;p&gt;通过 Traefik 的 dashboard 就可以看到刚增加的&lt;code&gt;traefik.locust.io&lt;/code&gt;节点。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/traefik-dashboard-locust_hub9c0e50fdb57d51b987a72e16255d0e2_114844_2300x1898_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/traefik-dashboard-locust.jpg&#34; data-img=&#34;/blog/distributed-load-testing-using-kubernetes/traefik-dashboard-locust.jpg&#34; data-width=&#34;2300&#34; data-height=&#34;1898&#34; alt=&#34;image&#34; data-caption=&#34;Traefik dashboard&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Traefik dashboard&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;执行测试&#34;&gt;执行测试&lt;/h2&gt;
&lt;p&gt;打开&lt;code&gt;http://traefik.locust.io&lt;/code&gt;页面，点击&lt;code&gt;Edit&lt;/code&gt;输入伪造的用户数和用户每秒发送的请求个数，点击&lt;code&gt;Start Swarming&lt;/code&gt;就可以开始测试了。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/locust-start-swarming_hub9c0e50fdb57d51b987a72e16255d0e2_67927_2050x1166_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/locust-start-swarming.jpg&#34; data-img=&#34;/blog/distributed-load-testing-using-kubernetes/locust-start-swarming.jpg&#34; data-width=&#34;2050&#34; data-height=&#34;1166&#34; alt=&#34;image&#34; data-caption=&#34;启动 locust&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;启动 locust&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;在测试过程中调整&lt;code&gt;sample-webapp&lt;/code&gt;的 pod 个数（默认设置了 1 个 pod），观察 pod 的负载变化情况。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/sample-webapp-rc_hub9c0e50fdb57d51b987a72e16255d0e2_155374_3252x1906_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/sample-webapp-rc.jpg&#34; data-img=&#34;/blog/distributed-load-testing-using-kubernetes/sample-webapp-rc.jpg&#34; data-width=&#34;3252&#34; data-height=&#34;1906&#34; alt=&#34;image&#34; data-caption=&#34;示例 Web 应用&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;示例 Web 应用&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;p&gt;从一段时间的观察中可以看到负载被平均分配给了 3 个 pod。&lt;/p&gt;
&lt;p&gt;在 locust 的页面中可以实时观察也可以下载测试结果。&lt;/p&gt;
&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
    
      
        
          
          &lt;picture&gt;
           &lt;source srcset=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/locust-dashboard_hub9c0e50fdb57d51b987a72e16255d0e2_48053_2086x784_resize_q75_h2_lanczos.webp&#34; type=&#34;image/webp&#34;&gt;
           &lt;img src=&#34;https://jimmysong.io/blog/distributed-load-testing-using-kubernetes/locust-dashboard.jpg&#34; data-img=&#34;/blog/distributed-load-testing-using-kubernetes/locust-dashboard.jpg&#34; data-width=&#34;2086&#34; data-height=&#34;784&#34; alt=&#34;image&#34; data-caption=&#34;Locust dashboard&#34;&gt;
          &lt;/picture&gt;
        
      
    
  
  
  &lt;figcaption&gt;Locust dashboard&lt;/figcaption&gt;
  
&lt;/figure&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloud.google.com/solutions/distributed-load-testing-using-kubernetes&#34; title=&#34;Distributed Load Testing Using Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Distributed Load Testing Using Kubernetes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.csdn.net/article/2015-07-07/2825155&#34; title=&#34;运用 Kubernetes 进行分布式负载测试&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运用 Kubernetes 进行分布式负载测试&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
  </channel>
</rss>
