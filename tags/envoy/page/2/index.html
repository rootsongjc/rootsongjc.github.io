<!DOCTYPE html>
<html lang="zh"><head>
  <meta charset="utf-8">
  
  <title>Envoy - Jimmy Song</title>
  

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5">
  <meta name="description" content="宋净超的博客">
  <meta name="author" content="Jimmy Song">
  <meta name="generator" content="Hugo 0.136.0">

  <!-- CSS plugins -->
  
  
    
    
      
    
  
    
    
      
    
  
    
    
      
    
  
    
    
      
    
  
    
    
      
    
  
  
  <link rel="preload" href="/css/combined.7ac6b2864cb09c5595ac8ca79f8ca0db6c69a657edac885ba2c2412080d68da0.css" as="style">
  <link rel="stylesheet" href="/css/combined.7ac6b2864cb09c5595ac8ca79f8ca0db6c69a657edac885ba2c2412080d68da0.css" media="screen">
  

  <!-- Main Stylesheet -->
  
  <link rel="preload" href="/scss/style.min.784204edcd29c092198e88494fa2ae755eba9ae231d6fa7faf8e7da3207b4623.css" as="style">
  <link rel="stylesheet" href="/scss/style.min.784204edcd29c092198e88494fa2ae755eba9ae231d6fa7faf8e7da3207b4623.css" media="screen">

  <!-- Bigger picture css -->
  
  <link rel="stylesheet" href="/plugins/bigger-picture/bigger-picture.min.css" media="print" onload="this.media='all'">
  <!--Favicon generate by https://realfavicongenerator.net-->
  <link rel="icon" href="/favicon.png" type="image/png">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  <link rel="apple-touch-icon" sizes="200x200" href="/images/favicon.png" />
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">

  <link href='/opensearchdescription.xml' rel='search' title='Content search' type='application/opensearchdescription+xml'/>

  <!--Twitter card-->
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:site" content="jimmysong.io" />
  <meta name="twitter:creator" content="@jimmysongio" />
  <meta property="og:url" content="https://jimmysong.io/tags/envoy/" />
  <meta property="og:title" content="Envoy | Jimmy Song" />
  <meta property="twitter:title" content="Envoy | Jimmy Song" />

  
  <meta property="og:description" content="宋净超的博客" />
  <meta property="twitter:description" content="宋净超的博客" />

  
  <meta property="og:image" content="https://jimmysong.io/images/banner/default.jpg" />
  <meta property="twitter:image" content="https://jimmysong.io/images/banner/default.jpg" />

  
  
</head>
<body>
<header class="fixed-top header">
  
  
  <button onclick="topFunction()" id="backTopBtn" title="Go to top"><i class="fa fa-arrow-circle-up" aria-hidden="true"></i></button>
  
  <div class="navigation w-100 ">
    <div class="container-xl">
      <nav class="navbar navbar-expand-lg navbar-light p-0">
        <a class="navbar-brand" href="/">
            
            <b>JIMMY SONG</b>
            
        </a>
        <button class="navbar-toggler rounded-0" type="button" data-toggle="collapse" data-target="#navigation"
          aria-controls="navigation" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse text-center" id="navigation">
          <ul class="navbar-nav ml-auto">
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/blog">博客</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/book">资料</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/tags">标签</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/notice">公告</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/contact">联系</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/about">关于</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="/community/">社区</a>
              
            </li>
            
            
            
            <li class="nav-item">
              
              <a class="nav-link" href="https://space.bilibili.com/515485124" target="_blank" rel="noopener">视频 <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i></a>
              
            </li>
            
            

          
          
          <li class="nav-item">
            
            
            
              
              
                
                
                
                  
                    
                    <a class="nav-link" href="/en/tags/envoy/">English</a>
                    
                  
                
              
              
              
                
                  
                    
                    
                  
                
                
                
              
          </li>
          
          
          <!-- search -->
           <button type="button" class="search-btn js-search" id="searchOpen" aria-label="Search">
              <div class="search-container d-flex justify-content-center">
              <span class="search-content">
                  <i class="fa fa-search"></i>
                  <span>搜索</span>
              </span>
              <span class="search-shortcuts d-none d-sm-block">
                  <kbd class="cmd-key">⌘</kbd>
                  <kbd class="k-key">K</kbd>
              </span>
              </div>
          </button>
          
          </ul>
        </div>
      </nav>
    </div>
  </div>
</header>


            <aside class="search-modal" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between">
        <div class="col-6 search-title">
          <p>站内搜索</p> 
        </div>
        <div class="col-6 col-search-close">
          <div class="js-search" aria-label="关闭"><i class="fa-solid fa-circle-xmark text-muted" aria-hidden="true"></i></div>
        </div>
      </div>

      <div id="search-box">
        <i class="fa-solid fa-magnifying-glass" id="search-icon" aria-hidden="true"></i>
        <input name="q" id="search-query" placeholder="请输入搜索词" autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control" aria-label="请输入搜索词">
        
        <div class="mt-4">
          <span>搜索类型: </span>
          <span>
            <input type="radio" id="all" name="search_type" value="all" checked>
            <label for="all">所有</label>
            
              <input type="radio" id="blog" name="search_type" value="blog">
              <label for="blog">原创</label>
              <input type="radio" id="trans" name="search_type" value="trans">
              <label for="trans">译文</label>
            
            <input type="radio" id="book" name="search_type" value="book">
            <label for="book">资料</label>
            <input type="radio" id="notice" name="search_type" value="notice">
            <label for="notice">公告</label>
          </span>
        </div>
      </div>
      
    </section>
    <section class="section-search-results">
      <div id="search-results-count" class="search-results-count"></div>
      <div id="search-hits">
        
      </div>
    </section>
  </div>
</aside>

        
        
            

<section class="bg-cover page-title-section overlay" style="background-image: url('/images/backgrounds/circle.svg'),url('/images/backgrounds/page-title.webp');background-size: cover;">
    <div class="container-xl">
        <div class="row">
            <div class="col-12">
                <p class="h1">
                    Envoy
                </p>
                <p class="page-description">
                    
                </p>
                
            </div>
        </div>
    </div>
</section>

        


<section class="section-sm book-list-section bg-gray">
  <div class="container-xl">
    <div class="row">
      <div class="col-lg-8 order-2 order-lg-1">
        <div class="row">
          
          
          
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/preserve-source-ip-in-istio/">维持请求的透明度：在 Istio 中保留客户端请求的源 IP</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2024/01/29</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/istio"> 
             Istio
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('维持请求的透明度：在 Istio 中保留客户端请求的源 IP', '本文专注于如何在 Istio 服务网格中保持客户端源 IP 的透明性。', '\n本博文解析了在 Istio 服务网格中服务端获取客户端源 IP 的挑战，并提供了解决方案。将探讨以下问题：\n\n- 数据包传输中源 IP 丢失的原因；\n- 如何确定客户端源 IP；\n- 在南北向和东西向请求中传递源 IP 的策略；\n- 针对 HTTP 和 TCP 协议的处理方法。\n\n## 源 IP 保留的重要性\n\n保留客户端源 IP 的主要理由包括：\n\n- **访问控制策略**：基于源 IP 执行身份验证或安全策略；\n- **负载均衡**：实现基于客户端 IP 的请求路由；\n- **数据分析**：包含真实源地址的访问日志和监控指标，助力开发人员进行分析。\n\n## 保留源 IP 的含义\n\n保留源 IP 指的是在请求从客户端发出、经过负载均衡器或反向代理后，避免真实的客户端源 IP 被替换的情况。\n\n以下是源 IP 地址丢失的流程示例：\n\n\u0060\u0060\u0060mermaid \u0022源 IP 地址丢失的流程\u0022\nsequenceDiagram\n    participant C as Client\n    participant LB as Load Balancer\n    participant IG as Ingress Gateway\n    participant S as Server\n    C-\u003e\u003eLB: Initial Request\n    LB-\u003e\u003eIG: Altered Request (IP Changed)\n    IG-\u003e\u003eS: Forwarded Request\n    Note over IG,S: Source IP Lost\n\u0060\u0060\u0060\n\n![源 IP 地址丢失的流程](9a331cc374c51421ecb64e58b25a6c4d.svg)\n\n\n\n上面图只是最常见的一种情况。本文考虑到以下几种情况：\n\n1. 南北向流量：客户端通过负载均衡器（网关）访问服务端\n   1. 只有一层网关\n   2. 两层或两层以上网关\n2. 东西向流量：网格内部的服务间访问\n3. 协议：HTTP 和 TCP\n\n## 如何确认客户端源 IP？\n\n在 Istio 服务网格中，Envoy 代理通常会将客户端 IP 添加到 HTTP 请求的 \u0022X-Forwarded-For\u0022 头部中。以下是确认客户端 IP 的步骤：\n\n1. **检查 x-forwarded-for 头部**：包含请求路径上各代理的 IP 地址。\n2. **选择最后一个 IP**：通常，最后一个 IP 是最接近服务器的客户端 IP。\n3. **验证 IP 的可信性**：检查代理服务器的信任度。\n4. **使用 x-envoy-external-address**：Envoy 可以设置此头部，包含客户端真实 IP。\n\n详情请见 Envoy 文档中对 [\u0060x-forwarded-for\u0060 标头](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/http\/http_conn_man\/headers#config-http-conn-man-headers-x-forwarded-for)的说明。对于 TCP\/IP 连接，可以通过协议字段解析客户端 IP。\n\n## 测试环境\n\n**GKE**\n\n- Client Version: v1.28.4\n- Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3\n- Server Version: v1.27.7-gke.1121000\n\n**Istio**\n\n- client version: 1.20.1\n- control plane version: 1.20.1\n- data plane version: 1.20.1 (12 proxies)\n\n**CNI**\n\n我们使用了 Cilium CNI，但是没有开启无 kube-proxy 模式。\n\n- cilium-cli: v0.15.18 compiled with go1.21.5 on darwin\/amd64\n- cilium image (default): v1.14.4\n- cilium image (stable): unknown\n- cilium image (running): 1.14.5\n\n**Node**\n\n| 节点名称                                | 内部 IP     | 备注                         |\n| --------------------------------------- | ----------- | ---------------------------- |\n| gke-cluster1-default-pool-5e4152ba-t5h3 | 10.128.0.53 |                              |\n| gke-cluster1-default-pool-5e4152ba-ubc9 | 10.128.0.52 |                              |\n| gke-cluster1-default-pool-5e4152ba-yzbg | 10.128.0.54 | Ingress Gateway Pod 所在节点 |\n\n执行测试的本地客户端电脑的公网 IP：123.120.247.15\n\n## 部署测试示例\n\n下图展示了测试方式：\n\n\u0060\u0060\u0060mermaid \u0022测试方式\u0022\nsequenceDiagram\n    participant C as Client\n    participant LB as Load Balancer\n    participant IG as Ingress Gateway\n    participant S as Source IP App\n    C-\u003e\u003eLB: Initial Request\n    LB-\u003e\u003eIG: Forward Request \n    IG-\u003e\u003eS: Forwarded Request\n\u0060\u0060\u0060\n\n![测试方式](8cd62d9391e2e4fb0b4b257075c64426.svg)\n\n\n\n首先参考 [Istio 文档](https:\/\/istio.io\/latest\/docs\/setup\/install\/)部署 Istio，然后为 default 命名空间开启 sidecar 自动注入：\n\n\u0060\u0060\u0060bash\nkubectl label namespace default istio-injection=enabled\n\u0060\u0060\u0060\n\n在 Istio 中部署 echo-server 应用测试。echo-server 是一个基于 Nginx 的服务器，用于回显客户端发送的请求信息，例如请求头、客户端地址、请求方法等。\n\n\u0060\u0060\u0060bash\nkubectl create deployment echo-server --image=registry.k8s.io\/echoserver:1.4\nkubectl expose deployment echo-server --name=clusterip --port=80 --target-port=8080\n\u0060\u0060\u0060\n\n创建 Ingress Gateway：\n\n\u0060\u0060\u0060bash\ncat\u003econfig.yaml\u003c\u003cEOF\napiVersion: networking.istio.io\/v1beta1\nkind: Gateway\nmetadata:\n  name: clusterip-gateway\nspec:\n  selector:\n    istio: ingressgateway # 根据你的环境选择适当的 selector\n  servers:\n    - port:\n        number: 80\n        name: http\n        protocol: HTTP\n      hosts:\n        - \u0022clusterip.jimmysong.io\u0022 # 替换成你想要使用的主机名\n---\napiVersion:  networking.istio.io\/v1beta1\nkind: VirtualService\nmetadata:\n  name: clusterip-virtualservice\nspec:\n  hosts:\n    - \u0022clusterip.jimmysong.io\u0022 # 替换成与 Gateway 中相同的主机名\n  gateways:\n    - clusterip-gateway # 这里使用 Gateway 的名称\n  http:\n    - route:\n        - destination:\n            host: clusterip.default.svc.cluster.local # 替换成你的 Service 的实际主机名\n            port:\n              number: 80 # Service 的端口\nEOF\nkubectl apply -f config.yaml\n\u0060\u0060\u0060\n\n查看 Ingress Gateway 中的 Envoy 日志：\n\n\u0060\u0060\u0060bash\nkubectl logs -f deployment\/istio-ingressgateway -n istio-system\n\u0060\u0060\u0060\n\n查看 Sleep Pod 中的 Envoy 日志：\n\n\u0060\u0060\u0060bash\nkubectl logs -f deployment\/sleep -n default -c istio-proxy\n\u0060\u0060\u0060\n\n查看 Source IP App 中的 Envoy 日志：\n\n\u0060\u0060\u0060bash\nkubectl logs -f deployment\/echo-server -n default -c istio-proxy\n\u0060\u0060\u0060\n\n获取网关公网 IP：\n\n\u0060\u0060\u0060bash\nexport GATEWAY_IP=$(kubectl -n istio-system get service istio-ingressgateway -o jsonpath=\u0027{.status.loadBalancer.ingress[0].ip}\u0027)\n\u0060\u0060\u0060\n\n在本地使用 curl 测试：\n\n\u0060\u0060\u0060bash\ncurl -H \u0022Host: clusterip.jimmysong.io\u0022 $GATEWAY_IP\n\u0060\u0060\u0060\n\n### 资源 IP\n\n当部署好测试应用后，你需要获取与以下资源的 IP 地址。在接下来的实验环节中将会用到。\n\n**Pod**\n\n下面是初始状况下的 Pod IP，随着对 Deployment 的补丁，Pod 会重建，名称和 IP 地址都会变。\n\n| Pod 名称                              | Pod IP      |\n| ------------------------------------- | ----------- |\n| echo-server-6d9f5d97d7-fznrq          | 10.32.1.205 |\n| sleep-9454cc476-2dskx                 | 10.32.3.202 |\n| istio-ingressgateway-6c96bdcd74-zh46d | 10.32.1.221 |\n\n**Service**\n\n| Service 名称         | Cluster IP  | External IP   |\n| -------------------- | ----------- | ------------- |\n| clusterip            | 10.36.8.86  | -             |\n| sleep                | 10.36.14.12 | -             |\n| istio-ingressgateway | 10.36.4.127 | 35.188.212.88 |\n\n## 南北向流量\n\n我们首先考虑客户端位于 Kubernetes 集群外，通过负载均衡器来访问集群内部服务的情况。\n\n### 测试 1：Cluster 流量策略、iptables 流量劫持\n\n这是通过以上步骤部署完测试应用后的默认情况，也是大家遇到的所谓的源 IP 地址丢失的情况。\n\ncurl 测试：\n\n\u0060\u0060\u0060bash\ncurl -H \u0022Host: clusterip.jimmysong.io\u0022 $GATEWAY_IP\n\u0060\u0060\u0060\n\n{{\u003cdetail \u0022查看结果\u0022\u003e}}\n\n{{\u003chighlight text \u0022linenos=table,hl_lines=2 21 23\u0022\u003e}}\nCLIENT VALUES:\nclient_address=127.0.0.6\ncommand=GET\nreal path=\/\nquery=nil\nrequest_version=1.1\nrequest_uri=http:\/\/clusterip.jimmysong.io:8080\/\n\nSERVER VALUES:\nserver_version=nginx: 1.10.0 - lua: 10001\n\nHEADERS RECEIVED:\naccept=*\/*\nhost=clusterip.jimmysong.io\nuser-agent=curl\/8.4.0\nx-b3-parentspanid=03c124c5f910001a\nx-b3-sampled=1\nx-b3-spanid=103dc912ec14f3b4\nx-b3-traceid=140ffa034822077f03c124c5f910001a\nx-envoy-attempt-count=1\nx-envoy-internal=true\nx-forwarded-client-cert=By=spiffe:\/\/cluster.local\/ns\/default\/sa\/default;Hash=79253e34e1c28d389e9bfb1a62ffe8944b2c3c369b46bf4a9faf055b55dedb7f;Subject=\u0022\u0022;URI=spiffe:\/\/cluster.local\/ns\/istio-system\/sa\/istio-ingressgateway-service-account\nx-forwarded-for=10.128.0.54\nx-forwarded-proto=http\nx-request-id=b3c05e22-594e-98da-ab23-da711a8f53ec\nBODY:\n-no body in request-\n{{\u003c\/highlight\u003e}}\n\n{{\u003c\/detail\u003e}}\n\n你只需要关注 \u0060client_address\u0060 和 \u0060x-forwarded-for\u0060 这两个结果即可。下文的 curl 测试结果中将省略其他信息。\n\n{{\u003ccallout note 说明\u003e}}\n\n该结果中字段的含义：\n\n- \u0060client_address\u0060：通过解析 TCP\/IP 协议而获取的客户端 IP 地址，在 Envoy 中称为 remote address。\n- \u0060x-forwarded-for\u0060：\u0060x-forwarded-for\u0060 (XFF) 是一个标准的代理头部，用于指示请求在从客户端到服务器的过程中经过的 IP 地址。一个合规的代理会在代理请求之前将最近客户端的 IP 地址添加到 XFF 列表中。详见 [Envoy 文档](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/http\/http_conn_man\/headers#x-forwarded-for)。\n\n{{\u003c\/callout\u003e}}\n\n从测试结果中我们可以看出，源 IP 地址变成了 Ingress  Gateway  Pod 所在节点的 IP 地址（\u006010.128.0.54\u0060）。\n\n下图展示是两个 Pod 中的数据包流量路径。\n\n\u0060\u0060\u0060mermaid \u0022两个 Pod 中的数据包流量路径\u0022\ngraph LR\nsubgraph IngressGatewayPod[Ingress Gateway Pod]\nA[\u0022Downstream Remote (Ingress Gateway Node)\u003cbr\u003e10.128.0.54:56532\u0022] --\u003e B\n    B[\u0022Downstream Local (Ingresss Gateway Pod)\u003cbr\u003e10.32.1.221:8080\u0022]--\u003eC\n    C[\u0022Upstream Local (Ingress Gateway Pod)\u003cbr\u003e10.32.1.221:59842\u0022]\n    C --\u003e D[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.205:8080\u0022]\nend\nsubgraph SourceIPAppPod[Source IP App Pod]\n    E[\u0022Downstream Remote (Ingress Gateway Pod)\u003cbr\u003e10.128.0.54:0\u0022] --\u003e F\n    F[\u0022Downstream Local (Source IP App Pod)\u003cbr\u003e10.32.1.205:8080\u0022]\n    G[\u0022Upstream Local (InboundPassthroughClusterIpv4)\u003cbr\u003e127.0.0.6:60481\u0022]\n    H[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.205:8080\u0022]\n    F --\u003e G\n    G --\u003e H\nend\nIngressGatewayPod--\u003eSourceIPAppPod\n\u0060\u0060\u0060\n\n![两个 Pod 中的数据包流量路径](80963dcc68a315cb631ee687bb10a409.svg)\n\n\n\n对于这种情况，要想保留源 IP 其实很简单，而且也是 Kubernetes 提供的标准选项。\n\n### 源 IP 地址是如何丢失的？\n\n下图展示客户端的源 IP 是如何在请求过程中丢失的。\n\n\u0060\u0060\u0060mermaid \u0022客户端的源 IP 是如何在请求过程中丢失的\u0022\nsequenceDiagram\n    participant C as Client\u003cbr\u003e123.120.247.15\n    participant LB as Load Balancer\u003cbr\u003e35.188.212.88\n    box Node \u003cbr\u003e10.128.0.54\n    participant IG as Ingress Gateway\u003cbr\u003e10.32.1.221\n    end\n    participant S as Source IP App Pod\u003cbr\u003e10.32.1.205\n    C-\u003e\u003eLB: Initial Request\n    LB-\u003e\u003eIG: Altered Request (IP Changed)\u003cbr\u003eSNAT: 123.120.234.15 -\u003e 10.128.0.54\n    IG-\u003e\u003eS: Forwarded Request\n    Note over IG,S: Source IP Lost\n\u0060\u0060\u0060\n\n![客户端的源 IP 是如何在请求过程中丢失的](3aeef9eef475587bbca6edb88a134f69.svg)\n\n\n\n因为负载均衡器将数据包发送到 Kubernetes 集群中的任意节点，在此过程中会进行 SNAT，导致最终发送到 Server Pod 中的客户端源 IP 丢失。\n\n### 如何保留客户端源 IP\n\n你可以通过设置 service 中的 \u0060externalTrafficPolicy\u0060 字段为 \u0060Local\u0060 控制负载均衡器保留源 IP。\n\n**externalTrafficPolicy**\n\n\u0060externalTrafficPolicy\u0060 是一个[标准 Service 选项](https:\/\/kubernetes.io\/docs\/tasks\/access-application-cluster\/create-external-load-balancer\/#preserving-the-client-source-ip)，用于定义传入 Kubernetes 节点的流量是否进行负载均衡以及如何进行负载均衡。\u0060Cluster\u0060 是默认策略，但 \u0060Local\u0060 通常用于保留传入集群节点的流量的来源 IP。\u0060Local\u0060 会在集群节点上有效停用负载均衡，以使本地 Pod 接收的流量看到原始来源 IP 地址。\n\n\u0060\u0060\u0060mermaid \u0022externalTrafficPolicy\u0022\ngraph TD;\n    A[Client Request] --\u003e|Sent to Service| B[Load Balancer]\n    B --\u003e|externalTrafficPolicy: Local| C[Node with Service Endpoint]\n    C --\u003e|Source IP Preserved| D[Service Handling Request]\n    B --\u003e|\u0022externalTrafficPolicy: Cluster (Default)\u0022| E[Any Node in Cluster]\n    E --\u003e|Source IP Altered| D\n\u0060\u0060\u0060\n\n![externalTrafficPolicy](02f4d9919bbd6f3d5fc5682c3793896a.svg)\n\n\n\n也就是说将 \u0060externalTrafficPolicy\u0060 设置为 \u0060Local\u0060 就可以让数据包绕过节点上的 kube-proxy，而直达目标 Pod。但是大多数人在 Kubernetes 中创建 Service 时都没有设置 \u0060externalTrafficPolicy\u0060，所以使用了默认的 \u0060Cluster\u0060 策略。\n\n既然 Service 采用 Local 外部流量策略可以保留客户端的源 IP 地址，那为什么 Kubernetes 不默认采用呢？\n\n{{\u003ccallout note 说明\u003e}}\n\n通过 Local 模式暴露服务以获取客户端源 IP 是一种对可靠性的妥协，如果大家有更好的方案欢迎推荐给我。\n\n{{\u003c\/callout\u003e}}\n\nKubernetes 默认将 Service 的 \u0060externalTrafficPolicy\u0060 设置为 \u0060Cluster\u0060 而非 \u0060Local\u0060，主要是基于以下考虑：\n\n1. **负载均衡**：确保流量在所有节点之间平均分配，避免单个节点过载。\n2. **高可用性**：允许流量被集群中任何节点接收，提高服务的可用性。\n3. **简化配置**：\u0060Cluster\u0060 模式降低了网络配置的复杂性。\n4. **性能优化**：避免由于保留客户端源 IP 而引起的潜在性能问题。\n5. **通用性**：兼容多种网络环境和集群配置，适应更广泛的使用场景。\n\n### 测试 2：Local 流量策略、iptables 流量劫持\n\n将 Ingress Gateway Service  设置为 Local 外部流量策略：\n\n\u0060\u0060\u0060bash\nkubectl patch svc istio-ingressgateway -p \u0027{\u0022spec\u0022:{\u0022externalTrafficPolicy\u0022:\u0022Local\u0022}}\u0027 -n istio-system\n\u0060\u0060\u0060\n\nCurl 测试：\n\n\u0060\u0060\u0060bash\ncurl -H \u0022Host: clusterip.jimmysong.io\u0022 $GATEWAY_IP\n\u0060\u0060\u0060\n\n{{\u003cdetail \u0022查看结果\u0022\u003e}}\n\n{{\u003chighlight text \u0022linenos=table,hl_lines=2 21 23\u0022\u003e}}\nCLIENT VALUES:\nclient_address=127.0.0.6\ncommand=GET\nreal path=\/\nquery=nil\nrequest_version=1.1\nrequest_uri=http:\/\/clusterip.jimmysong.io:8080\/\n\nSERVER VALUES:\nserver_version=nginx: 1.10.0 - lua: 10001\n\nHEADERS RECEIVED:\naccept=*\/*\nhost=clusterip.jimmysong.io\nuser-agent=curl\/8.4.0\nx-b3-parentspanid=060c393adb561603\nx-b3-sampled=1\nx-b3-spanid=8df3e10078cc826b\nx-b3-traceid=cf26040ae9536702060c393adb561603\nx-envoy-attempt-count=1\nx-envoy-external-address=123.120.247.15\nx-forwarded-client-cert=By=spiffe:\/\/cluster.local\/ns\/default\/sa\/default;Hash=79253e34e1c28d389e9bfb1a62ffe8944b2c3c369b46bf4a9faf055b55dedb7f;Subject=\u0022\u0022;URI=spiffe:\/\/cluster.local\/ns\/istio-system\/sa\/istio-ingressgateway-service-account\nx-forwarded-for=123.120.247.15\nx-forwarded-proto=http\nx-request-id=35bc2123-0971-9a9c-84c1-2aeee233a268\nBODY:\n-no body in request-\n{{\u003c\/highlight\u003e}}\n{{\u003c\/detail\u003e}}\n\n通过 Envoy 日志可以得出现在的数据包路径：\n\n\u0060\u0060\u0060mermaid \u0022数据包路径 1\u0022\ngraph LR\nsubgraph IngressGatewayPod[Ingress Gateway Pod]\n    B[\u0022Downstream Local (Ingress Gateway Pod)\u003cbr\u003e10.32.1.221:8080\u0022]\n    C[\u0022Upstream Local (Ingress Gateway Pod)\u003cbr\u003e10.32.1.221:59842\u0022]\nA[\u0022Downstream Remote (Client)\u003cbr\u003e123.120.247.15:62650\u0022] --\u003e B\nB --\u003e C\nC --\u003e D[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.205:8080\u0022]\nend\nsubgraph SourceIPAppPod[Source IP App Pod]\n    F[\u0022Downstream Local (Source IP App Pod)\u003cbr\u003e10.32.1.205:8080\u0022]\n    G[\u0022Upstream Local (InboundPassthroughClusterIpv4)\u003cbr\u003e127.0.0.6:58639\u0022]\n    H[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.205:8080\u0022]\nE[\u0022Downstream Remote (Client)\u003cbr\u003e123.120.247.15:0\u0022] --\u003e F\nF --\u003e G\nG --\u003e H\nend\nIngressGatewayPod--\u003eSourceIPAppPod\n\u0060\u0060\u0060\n\n![数据包路径 1](566a610667551fdcd025fc541c3d1fe7.svg)\n\n客户端源 IP 被正确识别为 \u0060123.120.247.15\u0060。\n\n## 东西向流量\n\n在 Istio 默认配置的情况下，对于东西向流量，服务端也无法获取正确的客户端源 IP。\n\n### 测试 3：Local 流量策略、tproxy 流量劫持\n\n将 Source IP App 中的流量拦截方式从 iptables 修改为 [tproxy](\/blog\/what-is-tproxy\/)：\n\n\u0060\u0060\u0060bash\nkubectl patch deployment -n default echo-server -p \u0027{\u0022spec\u0022:{\u0022template\u0022:{\u0022metadata\u0022:{\u0022annotations\u0022:{\u0022sidecar.istio.io\/interceptionMode\u0022:\u0022TPROXY\u0022}}}}}\u0027\n\u0060\u0060\u0060\n\n注意：此时 Source IP App 的 Pod 将会重建，新的 Pod 名称是 \u0060echo-server-686d564647-r7nlq\u0060，IP 地址是 10.32.1.140。\n\nCurl 测试：\n\n\u0060\u0060\u0060bash\nkubectl exec -it deployment\/sleep -it -- curl clusterip\n\u0060\u0060\u0060\n\n{{\u003cdetail \u0022查看结果\u0022\u003e}}\n{{\u003chighlight text \u0022linenos=table,hl_lines=2\u0022\u003e}}\nCLIENT VALUES:\nclient_address=10.32.3.202\ncommand=GET\nreal path=\/\nquery=nil\nrequest_version=1.1\nrequest_uri=http:\/\/clusterip:8080\/\n\nSERVER VALUES:\nserver_version=nginx: 1.10.0 - lua: 10001\n\nHEADERS RECEIVED:\naccept=*\/*\nhost=clusterip\nuser-agent=curl\/8.5.0\nx-b3-parentspanid=3c07f3b87cc547dd\nx-b3-sampled=1\nx-b3-spanid=97844ebdde748bfc\nx-b3-traceid=90f57b0fb260dfbf3c07f3b87cc547dd\nx-envoy-attempt-count=1\nx-forwarded-client-cert=By=spiffe:\/\/cluster.local\/ns\/default\/sa\/default;Hash=25af59fcf9fbe745eb75a318c47d55059d75914632d2536a43a80d342eaed27c;Subject=\u0022\u0022;URI=spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\nx-forwarded-proto=http\nx-request-id=e9b27bde-3cf6-9d8b-8f23-1cb0fa35d405\nBODY:\n-no body in request-\n{{\u003c\/highlight\u003e}}\n{{\u003c\/detail\u003e}}\n\n下图展示了数据包路径：\n\n\u0060\u0060\u0060mermaid \u0022数据包路径 2\u0022\ngraph LR\nsubgraph SleepPod[Sleep Pod]\nA[\u0022Downstream Remote (Sleep Pod)\u003cbr\u003e10.32.3.202:38394\u0022] --\u003e B\nB[\u0022Downstream Local (Clusterip Service)\u003cbr\u003e10.36.8.86:80\u0022] --\u003e C\nC[\u0022Upstream Local (Sleep Pod)\u003cbr\u003e10.32.3.202:33786\u0022] --\u003e D[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.140:8080\u0022]\nend\nsubgraph SourceIPAppPod[Source IP App Pod]\nE[\u0022Downstream Remote (Sleep Pod)\u003cbr\u003e10.32.3.202:33786\u0022] --\u003e F\nF[\u0022Downstream Local (Source IP App Pod)\u003cbr\u003e10.32.1.140:8080\u0022] --\u003e G\nG[\u0022Upstream Local (Sleep Pod)\u003cbr\u003e10.32.3.202:34173\u0022] --\u003e H[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.140:8080\u0022]\nend\nSleepPod--\u003eSourceIPAppPod\n\u0060\u0060\u0060\n\n![数据包路径 2](72c7107f23253c70fabc41ed04a0140f.svg)\n\n客户端 IP 被正确识别为 \u006010.32.3.202\u0060。\n\n### 测试 4：Local 流量策略、iptables 流量劫持\n\n将 Source IP App 中的流量拦截方式恢复为 redirect：\n\n\u0060\u0060\u0060bash\nkubectl patch deployment -n default echo-server -p \u0027{\u0022spec\u0022:{\u0022template\u0022:{\u0022metadata\u0022:{\u0022annotations\u0022:{\u0022sidecar.istio.io\/interceptionMode\u0022:\u0022REDIRECT\u0022}}}}}\u0027\n\u0060\u0060\u0060\n\n注意：此时 Source IP App 的 Pod 将会重建，新的 Pod 名称是 \u0060echo-server-6d9f5d97d7-bgpk6\u0060，IP 地址是 10.32.1.123。\n\nCurl 测试：\n\n\u0060\u0060\u0060bash\nkubectl exec -it deployment\/sleep -it -- curl clusterip\n\u0060\u0060\u0060\n\n{{\u003cdetail \u0022查看结果\u0022\u003e}}\n{{\u003chighlight text \u0022linenos=table,hl_lines=2\u0022\u003e}}\nCLIENT VALUES:\nclient_address=127.0.0.6\ncommand=GET\nreal path=\/\nquery=nil\nrequest_version=1.1\nrequest_uri=http:\/\/clusterip:8080\/\n\nSERVER VALUES:\nserver_version=nginx: 1.10.0 - lua: 10001\n\nHEADERS RECEIVED:\naccept=*\/*\nhost=clusterip\nuser-agent=curl\/8.5.0\nx-b3-parentspanid=6123380e58ca0ce7\nx-b3-sampled=1\nx-b3-spanid=633848c0065ec91e\nx-b3-traceid=dbcda8b3673e70a46123380e58ca0ce7\nx-envoy-attempt-count=1\nx-forwarded-client-cert=By=spiffe:\/\/cluster.local\/ns\/default\/sa\/default;Hash=25af59fcf9fbe745eb75a318c47d55059d75914632d2536a43a80d342eaed27c;Subject=\u0022\u0022;URI=spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\nx-forwarded-proto=http\nx-request-id=b05e07e1-08ba-9449-90a9-a4a98277a8c0\nBODY:\n-no body in request-\n{{\u003c\/highlight\u003e}}\n{{\u003c\/detail\u003e}}\n\n下图展示了数据包路径：\n\n\u0060\u0060\u0060mermaid \u0022数据包路径 3\u0022\ngraph LR\nsubgraph Sleep[Sleep Pod]\nA[\u0022Downstream Remote (Sleep Pod)\u003cbr\u003e10.32.3.202:34238\u0022] --\u003e B\nB[\u0022Downstream Local (Clusterip Service)\u003cbr\u003e10.36.8.86:80\u0022] --\u003e C\nC[\u0022Upstream Local (Sleep Pod)\u003cbr\u003e10.32.3.202:52776\u0022] --\u003e D[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.123:8080\u0022]\nend\nsubgraph SourceIPApp[Source IP App Pod]\nE[\u0022Downstream Remote (Sleep Pod)\u003cbr\u003e10.32.3.202:52776\u0022] --\u003e F\nF[\u0022Downstream Local (Source IP App Pod)\u003cbr\u003e10.32.1.123:8080\u0022] --\u003e G\nG[\u0022Upstream Local (InboundPassthroughClusterIpv4)\u003cbr\u003e127.0.0.6:49803\u0022] --\u003e H[\u0022Upstream Host (Source IP App Pod)\u003cbr\u003e10.32.1.123:8080\u0022]\nend\nSleep --\u003eSourceIPApp\n\u0060\u0060\u0060\n\n![数据包路径 3](8993fe075c1e3ecc7c42eefb98fccb21.svg)\n\n客户端源 IP 被识别为 \u0060127.0.0.6\u0060。\n\n## 单层代理场景总结\n\n在单层代理的情况下，只需要将 Ingress Gateway 的 Service 的 \u0060externalTrafficPolicy\u0060 设置为 \u0060Local\u0060 即可保留客户端源 IP。将目标服务的流量拦截模式修改为 \u0060TPROXY\u0060 即可以保留东西向请求中的源 IP。\n\n## 多层代理\n\n如果流量在进入 Istio Mesh 前已经经过的多层代理转发，每次流量经过代理时，代理解析 HTTP 流量并将其自身的 IP 地址追加到 \u0060x-forwarded-for\u0060 标头中。那么可以使用 \u0060numTrustedProxies\u0060 配置您信任的代理跳数，请参考 [Envoy 文档](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/http\/http_conn_man\/headers#x-forwarded-for) 了解如何确定 \u0060X-Forwarded-For\u0060 标头和受信任的客户端地址。\n\n实际上我们很难确定流量在到达 Istio Mesh 时究竟经过了几层代理，但你可以根据 \u0060x-forwarded-for\u0060 标头了解流量的转发路径。\n\n下图展示了 Envoy 如何根据 \u0060x-forwarded-for\u0060 标头和 \u0060xff_num_trusted_hops\u0060（对应 Istio 中的 \u0060numTrustedProxies\u0060 配置）来确认源 IP 的流程。详见 [Envoy 文档](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/http\/http_conn_man\/headers#x-forwarded-for)。\n\n\u0060\u0060\u0060mermaid \u0022多层代理\u0022\ngraph TD\n    A[Start] --\u003e|use_remote_address is false| B[Check XFF]\n    A --\u003e|use_remote_address is true| G[Check xff_num_trusted_hops]\n    B --\u003e|XFF contains at least one IP| C[Use last IP in XFF]\n    B --\u003e|XFF is empty| D[Use immediate downstream IP]\n    G --\u003e|xff_num_trusted_hops \u003e 0| H[\u0022Use (N)th IP from right in XFF\u0022]\n    G --\u003e|xff_num_trusted_hops \u003c= 0| D\n    H --\u003e|XFF contains \u003e= N addresses| I[Use Nth address from right]\n    H --\u003e|XFF contains \u003c N addresses| D\n\u0060\u0060\u0060\n\n![多层代理](b82caafefa304b53c996da072373043a.svg)\n\n\n\n执行下面的命令为入口网关开启受信代理数量配置：\n\n\u0060\u0060\u0060bash\nkubectl patch deployment istio-ingressgateway -n istio-system -p \u0027{\u0022spec\u0022:{\u0022template\u0022:{\u0022metadata\u0022:{\u0022annotations\u0022:{\u0022proxy.istio.io\/config\u0022:\u0022{\\\u0022gatewayTopology\\\u0022:{\\\u0022numTrustedProxies\\\u0022: 2,\\\u0022forwardClientCertDetails\\\u0022:\\\u0022SANITIZE_SET\\\u0022}}\u0022}}}}}\u0027\n\u0060\u0060\u0060\n\n当 Istio Gateway 收到这个请求时，它将 \u0060X-Envoy-External-Address\u0060 头设置为您 curl 命令中 \u0060X-Forwarded-For\u0060 头中的倒数第二个地址（\u0060numTrustedProxies: 2\u0060）。根据 Istio 的文档，Gateway 在将其转发到服务端负载之前，会将自己的 IP 附加到 \u0060X-Forwarded-For\u0060 头中。但实际情况是标头中只有客户端源 IP 和 External Gateway Pod IP。\n\n你可以执行下面的命令取消这个补丁：\n\n\u0060\u0060\u0060bash\nkubectl patch deployment istio-ingressgateway -n istio-system -p \u0027{\u0022spec\u0022:{\u0022template\u0022:{\u0022metadata\u0022:{\u0022annotations\u0022:{\u0022proxy.istio.io\/config\u0022:\u0022{}\u0022}}}}}\u0027\n\u0060\u0060\u0060\n\n## TCP 流量\n\n上文所说的使用标头获取客户端源 IP 的方式只适用于 L7 网络，对于 L4 网络的 TCP 流量可以使用 Proxy 协议。\n\nProxy 协议是一种网络协议，它在 TCP 连接的起始处添加了一个协议头部，用于传递连接过程中的一些元数据，如客户端的真实 IP 地址和端口号。这对于在负载均衡器（LB）后部署的应用程序非常有用，因为负载均衡器通常会更改客户端的原始 IP 地址成 LB 的地址，导致服务端无法知晓客户端的真实 IP。很多代理软件都支持 Proxy Protocol，比如 [Envoy](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/listeners\/listener_filters\/proxy_protocol) 和 HAProxy、NGINX 等。\n\n你可以使用下面的命令为 Ingress Gateway 打上补丁，以支持 Proxy 协议：\n\n\u0060\u0060\u0060\nkubectl patch deployment istio-ingressgateway -n istio-system -p \u0027{\u0022spec\u0022:{\u0022template\u0022:{\u0022metadata\u0022:{\u0022annotations\u0022:{\u0022proxy.istio.io\/config\u0022:\u0022{\\\\\u0022gatewayTopology\\\\\u0022:{\\\\\u0022proxyProtocol\\\\\u0022:{}}}\u0022}}}}}\u0027\n\u0060\u0060\u0060\n\n注意：不是所有的公有云中的 Kubernetes  中 \u0060LoadBalancer\u0060 类型的 Service 创建的的负载均衡器都支持该配置。比如 GKE 中就不支持。在 AWS NLB 中开启 Proxy 协议请参考[该博客](https:\/\/istio.io\/latest\/blog\/2020\/show-source-ip\/)。\n\nEnvoy 并不建议使用 Proxy 协议，因为它：\n\n- 只支持 TCP 协议\n- 必须上游主机支持\n- 可能影响性能\n\n关于 Envoy 对 Proxy 协议的支持请参考[该文档](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/other_features\/ip_transparency#proxy-protocol)。\n\n## 应用场景示例\n\n下面是常见的两个源 IP 地址的应用场景。\n\n### 基于源 IP 地址的访问控制\n\n在 Istio 的入口网关配置基于源 IP 的访问控制策略。这通过设置入口网关的授权策略，根据源 IP 地址实现访问限制。\n\n下图展示了基于源 IP 地址的访问控制流程图。\n\n\u0060\u0060\u0060mermaid \u0022基于源 IP 地址的访问控制流程图\u0022\nsequenceDiagram\n    participant C as Client\n    participant P1 as Proxy 1\n    participant P2 as Proxy 2\n    participant Pn as Proxy N\n    participant IG as Ingress Gateway\n    participant S as Service\n\n    C-\u003e\u003e\u002bP1: Request with Source IP\n    P1-\u003e\u003e\u002bP2: Forward Request\n    P2-\u003e\u003e\u002bPn: Forward Request\n    Pn-\u003e\u003e\u002bIG: Forward Request\n    Note over IG: numTrustedProxies Set\n    IG-\u003e\u003e\u002bS: Forwarded Request\n    Note over IG: Authorization Policy Based on Source IP\n\u0060\u0060\u0060\n\n![基于源 IP 地址的访问控制流程图](635bc14feb9b6939b3319929849cd0b5.svg)\n\n\n\n#### 场景假设\n\n假设请求经过三个代理，其 IP 地址分别为 \u00601.1.1.1\u0060、\u00602.2.2.2\u0060 和 \u00603.3.3.3\u0060。在 Ingress Gateway 中，\u0060numTrustedProxies\u0060 被设置为 2，因此 Istio 信任的源 IP 为 \u00602.2.2.2\u0060（即 \u0060x-envoy-external-address\u0060）。\n\n\u0060\u0060\u0060bash\ncurl -H \u0022Host: clusterip.jimmysong.io\u0022 -H \u0027X-Forwarded-For: 1.1.1.1,2.2.2.2,3.3.3.3\u0027 $GATEWAY_IP\n\u0060\u0060\u0060\n\n#### 屏蔽特定源 IP\n\n若需屏蔽来自 \u00602.2.2.2\u0060 的请求，可以使用以下授权策略：\n\n\u0060\u0060\u0060yaml\napiVersion: security.istio.io\/v1\nkind: AuthorizationPolicy\nmetadata:\n  name: ingress-policy\n  namespace: istio-system\nspec:\n  selector:\n    matchLabels:\n      app: istio-ingressgateway\n  action: DENY\n  rules:\n    - from:\n        - source:\n            remoteIpBlocks:\n            - \u00222.2.2.2\/24\u0022\n\u0060\u0060\u0060\n\n#### 使用最终客户端 IP\n\n如果希望识别与 Istio Mesh 直连的客户端 IP（即 \u0060x-forwarded-for\u0060 中的最后一个 IP，例如 \u0060123.120.234.15\u0060），则需要用 \u0060ipBlocks\u0060 配置：\n\n\u0060\u0060\u0060yaml\napiVersion: security.istio.io\/v1\nkind: AuthorizationPolicy\nmetadata:\n  name: ingress-policy\n  namespace: istio-system\nspec:\n  selector:\n    matchLabels:\n      app: istio-ingressgateway\n  action: DENY\n  rules:\n    - from:\n        - source:\n            ipBlocks:\n            - \u0022123.120.234.15\/24\u0022\n\u0060\u0060\u0060\n\n这种方法通过配置 Istio 的入口网关授权策略，可以有效地实现基于源 IP 的访问控制。它允许管理员根据不同的需求（如屏蔽特定 IP 或信任最终客户端 IP）灵活设定规则，从而增强了服务的安全性和灵活性。\n\n### 基于源 IP 地址的负载均衡\n\n要在 Istio 中根据源 IP 地址配置负载均衡策略，你需要使用 \u0060DestinationRule\u0060 资源，并指定 \u0060LOAD_BALANCER_POLICY_CONSISTENT_HASH\u0060 策略。这种策略允许您根据一致性哈希算法为流量分配目标，可以基于源 IP 地址来实现会话亲和性（session affinity），确保来自同一源 IP 的请求被路由到相同的目标。\n\n#### 源 IP 地址负载均衡示例\n\n下面是一个示例配置，展示了如何使用 \u0060DestinationRule\u0060 来根据源 IP 地址实现负载均衡：\n\n\u0060\u0060\u0060yaml\napiVersion: networking.istio.io\/v1alpha3\nkind: DestinationRule\nmetadata:\n  name: example-destination-rule\nspec:\n  host: example-service\n  trafficPolicy:\n    loadBalancer:\n      consistentHash:\n        httpHeaderName: x-forwarded-for # 这通常包含源 IP 地址，适用于经过代理或负载均衡器转发的流量。\n\u0060\u0060\u0060\n\n注意，如果直接连接到 Istio Ingress Gateway 而不经过其他代理，你可能需要根据实际情况调整 \u0060httpHeaderName\u0060 或使用其他哈希键，例如 \u0060useSourceIp\u0060，如下所示：\n\n\u0060\u0060\u0060yaml\nspec:\n  trafficPolicy:\n    loadBalancer:\n      consistentHash:\n        useSourceIp: true\n\u0060\u0060\u0060\n\n{{\u003ccallout note 注意\u003e}}\n\n- 使用源 IP 地址作为负载均衡的键时，请确保您理解这可能如何影响流量分布，特别是在源 IP 地址分布不均匀的情况下。\n- 正如上文所述，在某些环境中，原始的源 IP 可能会被网络设备（如负载均衡器或 NAT 设备）修改，需要确保 \u0060x-forwarded-for\u0060 头或其他相应机制能准确反映原始的客户端 IP。\n\n{{\u003c\/callout\u003e}}\n\n## 总结\n\n- 保留源 IP 对于实施访问控制、负载均衡和数据分析至关重要。\n- Envoy 代理使用 \u0060X-Forwarded-For\u0060 头部来处理 HTTP 请求中的客户端源 IP。\n- 通过设置 \u0060externalTrafficPolicy\u0060 和选择合适的流量劫持方式（\u0060REDIRECT\u0060 或 \u0060TPROXY\u0060），可以在南北向和东西向流量中正确获取客户端源 IP。\n- 处理经过多层代理的流量时，\u0060numTrustedProxies\u0060 配置是关键。\n- 对于 TCP 流量，Proxy 协议是一个有效的解决方案。\n\n## 参考\n\n- [x-forwarded-for - envoyproxy.io](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/http\/http_conn_man\/headers#x-forwarded-for)\n- [Proxy protocol on AWS NLB and Istio ingress gateway - istio.io](https:\/\/istio.io\/latest\/blog\/2020\/show-source-ip\/)\n- [Configuring Gateway Network Topology - istio.io](https:\/\/istio.io\/latest\/docs\/ops\/configuration\/traffic-management\/network-topologies\/)\n- [IP Transparency - envoyproxy.io](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/other_features\/ip_transparency)\n- [Using Source IP - kubernetes.io](https:\/\/kubernetes.io\/docs\/tutorials\/services\/source-ip\/)\n- [Proxy Protocol - github.com](https:\/\/github.com\/haproxy\/haproxy\/blob\/master\/doc\/proxy-protocol.txt)\n', '\/blog\/preserve-source-ip-in-istio\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文专注于如何在 Istio 服务网格中保持客户端源 IP 的透明性。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/matt-created-bitdrift/">[译] Envoy 创始人 Matt Klein 领衔 Bitdrift 创业，推出创新移动可观测性产品并获得 1500 万美元 A 轮融资</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/12/05</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/%e4%b8%9a%e6%80%81"> 
             业态
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Envoy 创始人 Matt Klein 领衔 Bitdrift 创业，推出创新移动可观测性产品并获得 1500 万美元 A 轮融资', 'Envoy 创始人 Matt Klein 领导的 Bitdrift 宣布推出首款产品 Capture，并完成 1500 万美元 A 轮融资。Capture 旨在革新移动端可观测性，允许动态实时控制遥测数据，大幅提高移动开发者的调试效率。这标志着 Bitdrift 在提升移动和服务器端可观测性方面迈出了重要一步，预示着可观测性生态系统的未来发展方向。', '\n![Matt Klein 的推文宣布推出公司第一个产品及完成 A 轮融资](image-20231205162037349.png)\n\n云原生社区报道：\n\n近期，Matt Klein——Envoy 代理的创造者——领导下的创业公司 Bitdrift 发布了他们的首款产品：Capture。这款专注于移动端可观测性的产品获得了 1500 万美元 A 轮融资，由 Amplify Partners 领投。这标志着 Bitdrift 在解决移动和服务器端可观测性问题方面迈出了重要的一步。\n\n![Bitdrift 初创团队](team-photo.jpg)\n\nBitdrift 的创始缘起于团队在规模化构建互联网基础设施时的挑战和挫折。公司团队来自 Twitter、AWS、Square、Google、Microsoft、Netflix 等知名企业，他们认为当前的可观测性生态系统存在供应商和消费者之间的不匹配问题。Bitdrift 旨在通过实时动态控制，仅发出可能用于解决客户问题的遥测数据，以改变这一现状。\n\n目前，移动端可观测性被认为是浪费、无序且远落后于服务器端。大约 95% 用于监控系统健康的数据从未被阅读。与此同时，移动工程师在生产中拥有的分析事件集合通常是静态的，而且调整这些事件以调试正在进行的问题可能需要数周甚至数月的时间。\n\n![Capture workflow](workflows.png)\n\nCapture 通过在 iOS 和 Android 上实现发出会话遥测数据的动态实时控制，改变了可观测性游戏的规则。这个系统允许对设备进行即时定位，从所有客户端到特定群体，甚至个别设备。结合先进的本地存储和实时配置，Capture 支持分布式搜索和遥测数据，使得数据仅在解决客户问题时才被请求和发送。\n\n![Ring buffer](ring_buffer.png)\n\nCapture 的本地存储解决方案核心是所谓的“环形缓冲区”，一种高性能的子系统，使用有界且实时可配置的 RAM 和磁盘空间。数据首先被刷新到 RAM，然后在后台级联到磁盘。Capture 还包括高效且注重隐私的会话回放实现，可以捕获移动屏幕状态的 2D 和 3D 表示。\n\nCapture 已在 Lyft 应用中部署到数百万设备上，并在大规模下经过战斗测试。它已准备好为全球的组织解决现实世界的挑战【18†source】。\n\nBitdrift 的愿景是开创可观测性的未来。通过 Capture，Bitdrift 开始了一段旅程，将本地遥测存储与实时控制和分布式搜索相结合，这不仅适用于移动端，而且适用于整个分布式系统——从每个服务器到移动边缘。\n\n作为云原生社区，我们对 Matt Klein 和 Bitdrift 团队在改善可观测性生态系统方面的努力表示赞赏。他们的创新不仅对移动工程师，而且对整个分布式系统的健康和效率具有深远影响。欢迎来到可观测性的未来。\n\n## 参考\n\n- [Bitdrift 介绍](https:\/\/bitdrift.io\/about)\n- [Honey, I shrunk the telemetry](https:\/\/blog.bitdrift.io\/post\/honey-i-shrunk-the-telemetry)\n', '\/trans\/matt-created-bitdrift\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">Envoy 创始人 Matt Klein 领导的 Bitdrift 宣布推出首款产品 Capture，并完成 1500 万美元 A 轮融资。Capture 旨在革新移动端可观测性，允许动态实时控制遥测数据，大幅提高移动开发者的调试效率。这标志着 Bitdrift 在提升移动和服务器端可观测性方面迈出了重要一步，预示着可观测性生态系统的未来发展方向。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/envoy-gateway-customization/">Envoy Gateway 0.4.0 发布：自定义 API 扩展</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2023/05/16</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/envoy"> 
             Envoy
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Envoy Gateway 0.4.0 发布：自定义 API 扩展', 'Envoy Gateway 是一款基于 Envoy 代理和 Kubernetes Gateway API 开发的开源 API 网关，最近发布了 0.4.0 版本。此次发布的版本着重于自定义功能，旨在为最终用户提供更多的用例。在本文中，我们将讨论此版本中可用的新自定义选项及其对用户的重要性。', '\n[Envoy Gateway](https:\/\/github.com\/envoyproxy\/gateway) 是一款基于 Envoy 代理和 [Kubernetes Gateway API](https:\/\/gateway-api.sigs.k8s.io\/) 开发的开源 API 网关，最近发布了 0.4.0 版本。此次发布的版本着重于自定义功能，旨在为最终用户提供更多的用例。在本文中，我们将讨论此版本中可用的新自定义选项及其对用户的重要性。\n\n## 自定义 Envoy 代理架构 {#customization}\n\n此次版本中最主要的自定义功能之一是配置 EnvoyProxy（Envoy Gateway 定义的 CRD）部署的确切类型。你可以定义 EnvoyProxy 部署的副本数、镜像和资源限制。还可以向 EnvoyProxy 部署和服务添加注解（Annotation）。这使得不同的用例成为可能，例如：\n\n- 将 Envoy Gateway 与 AWS、NLB、ELB 和 GCP 等外部负载均衡器链接起来。\n- 在 EnvoyProxy 旁边注入 Sidecar，这对于 Ingress 层管理南北向流量的 Envoy Gateway 和服务网格层用于管理东西向流量互联 TLS（mTLS）的 Envoy Sidecar 非常有用。此自定义功能消除了用户创建自己证书的需要，因为它基于历史的证书管理。\n\n{{\u003ccallout note 注意\u003e}}\n关于 Envoy Gateway 的更多自定义功能请参考 Envoy Gateway 文档。\n{{\u003c\/callout\u003e}}\n\n此外，Envoy Gateway 除了默认的 Kubernetes 单租户模式以外还新增其他部署模式支持，例如多租户，如下图所示。\n\n![Envoy Gateway 的多租户模式示意图](eg-multi-tenancy.svg)\n\n分别在每个租户的 namespace 部署一个 Envoy Gateway Controller，它们监视 Kubernetes 中的 HTTPRoute 和 Service 资源，并在各自的 namespace 中创建和管理 EnvoyProxy 部署。\n\n## 自定义 Envoy xDS 引导程序 {#bootstrap}\n\n此版本中的另一个重要自定义功能是自定义 Envoy xDS 引导程序。使用此功能，用户可以提供引导配置，在启动 EnvoyProxy 时配置一些静态资源。例如配置访问日志记录、跟踪和指标以发送到 SkyWalking（可以作为 APM）非常有用。此外，此版本添加了大量 CLI 工具，以帮助验证用户配置。用户可以将 CLI 用作干运行以更改引导程序中的特定字段，如果配置在语法上不正确，则将失败。\n\n## 扩展控制平面 {#extend-control-plane}\n\nEnvoy Gateway 现在允许供应商和扩展开发人员在 Envoy Gateway 管道的不同阶段添加 gRPC 钩子，以进一步扩展其功能，允许用户做一些事情，比如增强发送给 EnvoyProxy 的 xDS 配置，这在以前是不可能的。\n\n## 总结 {#summary}\n\n最后，Envoy Gateway 0.4.0 扩展了自定义 API，并为最终用户提供了更多用例。新的自定义功能包括自定义 Envoy 部署、Envoy xDS 引导程序以及扩展控制平面。这些新功能消除了用户创建自己的证书的需要，配置访问日志记录、跟踪和指标，并使供应商能够扩展 XDS 翻译用例。通过此版本的发布，Envoy Gateway 正变得更加用户友好，成为 Istio 的绝佳替代品。\n', '\/blog\/envoy-gateway-customization\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">Envoy Gateway 是一款基于 Envoy 代理和 Kubernetes Gateway API 开发的开源 API 网关，最近发布了 0.4.0 版本。此次发布的版本着重于自定义功能，旨在为最终用户提供更多的用例。在本文中，我们将讨论此版本中可用的新自定义选项及其对用户的重要性。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/ambient-mesh-l7-traffic-path/">Istio Ambient 模式中的七层流量路由路径详解</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2022/11/17</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/istio"> 
             Istio
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Istio Ambient 模式中的七层流量路由路径详解', '本文以图示和实际操作的形式详细介绍了 Ambient Mesh 中的七层（L7）流量路径。', '\n在[上一篇博客中](\/blog\/ambient-mesh-l4-traffic-path\/)我介绍了 Ambient 模式中的透明流量劫持和四层流量路由，在这一篇博客中，我将向你介绍在 Istio 的 Ambient 模式中，七层流量是如何路由的。\n\n下图展示了 Ambient 模式中七层网络流量路径。\n\n![Ambient Mesh 中的七层网络流量路径](ambient-mesh-l7-traffic-path.svg)\n\n注意：Waypoint Proxy 可以位于应用程序所在节点，甚至图中的服务 A、服务 B 和 Waypoint Proxy 都可以位于同一个节点，之所以将它们画在三个节点上是为了方便展示，但是对于实际的流量路径没有大的影响，只不过是不再通过 eth0 发送到另外一个节点。\n\n下文我们将从手操作探究图中过程。\n\n## 环境说明 {#environment}\n\n我们继续使用上一篇博客中部署的 Ambient 模式的 Istio，[查看环境说明](\/blog\/ambient-mesh-l4-traffic-path\/#environment)。为了说明七层网路路由，我们需要在此基础上再创建一个 Gateway：\n\n\u0060\u0060\u0060bash\nkubectl apply -f - \u003c\u003cEOF\napiVersion: gateway.networking.k8s.io\/v1alpha2\nkind: Gateway\nmetadata:\n name: productpage\n annotations:\n   istio.io\/service-account: bookinfo-productpage\nspec:\n gatewayClassName: istio-mesh\nEOF\n\u0060\u0060\u0060\n\n执行完该命令后，\u0060default\u0060 命名空间下会创建了一个 Waypoint proxy，在我的环境中这个 pod 的名字是 \u0060bookinfo-productpage-waypoint-proxy-6f88c55d59-4dzdx\u0060，专门用于处理发往 productpage 服务（服务 B）的 L7 流量，我将它称之为 Waypoint Proxy B。\n\nWaypoint 代理可以位于与工作负载相同或者不同的节点上，它也可以部署在独立的命名空间中，不论它位于哪个节点，对于 L7 流量路径没有影响。\n\nAmbient mesh 中透明流量的方式在 L4 和 L7 网络中没有什么不同，因此在这篇博客中我们将略过 Inbound 和 Outbound 流量劫持部分，你可以查看[上一篇博客](\/blog\/ambient-mesh-l4-traffic-path\/)了解详情。\n\n下面我们将直接从流量被劫持到 Ztunnel A 后，被转发到 Envoy 的 15006 端口开始。\n\n## Ztunnel A 上的出站流量路由 {#ztunel-a-outbound}\n\n使用下面的命令导出 Ztunnel A 上的 Envoy 代理配置：\n\n\u0060\u0060\u0060bash\nkubectl exec -n istio-system ztunnel-hptxk -c istio-proxy -- curl \u0022127.0.0.1:15000\/config_dump?include_eds\u0022\u003eztunnel-a-all-include-eds.json\n\u0060\u0060\u0060\n\n查看 \u0060ztunnel-a-all-include-eds.json\u0060 文件中的 Listener 配置部分，根据目的端口和来源 IP 的匹配关系，你将看到 \u0060ztunnel_outbound\u0060 监听器中有如下配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=2 12 18\u0022\u003e}}\n{\n  \u002210.8.14.226\u0022: {\n    \u0022matcher\u0022: {\n    \u0022matcher_tree\u0022: {\n      \u0022input\u0022: {\n      \u0022name\u0022: \u0022port\u0022,\n      \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.matching.common_inputs.network.v3.DestinationPortInput\u0022\n      }\n      },\n      \u0022exact_match_map\u0022: {\n      \u0022map\u0022: {\n        \u00229080\u0022: {\n        \u0022action\u0022: {\n          \u0022name\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_server_waypoint_proxy_spiffe:\/\/cluster.local\/ns\/default\/sa\/bookinfo-productpage\u0022,\n          \u0022typed_config\u0022: {\n          \u0022@type\u0022: \u0022type.googleapis.com\/google.protobuf.StringValue\u0022,\n          \u0022value\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_server_waypoint_proxy_spiffe:\/\/cluster.local\/ns\/default\/sa\/bookinfo-productpage\u0022\n          }\n        }\n        }\n      }\n      }\n    }\n    }\n  }\n}\n{{\u003c\/highlight\u003e}}\n\n\u006010.8.14.226\u0060 是目标服务的 Cluster  IP，服务端口是 9080。流量将被路由到 \u0060spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_server_waypoint_proxy_spiffe:\/\/cluster.local\/ns\/default\/sa\/bookinfo-productpage\u0060 集群，查看该集群的配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=6\u0022\u003e}}\n{\n \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_server_waypoint_proxy_spiffe:\/\/cluster.local\/ns\/default\/sa\/bookinfo-productpage\u0022,\n  \u0022type\u0022: \u0022EDS\u0022,\n  \u0022eds_cluster_config\u0022: {\n   \u0022eds_config\u0022: {\n    \u0022ads\u0022: {},\n    \u0022initial_fetch_timeout\u0022: \u00220s\u0022,\n    \u0022resource_api_version\u0022: \u0022V3\u0022\n   }\n  },\n  \/* 省略 *\/\n}\n{{\u003c\/highlight\u003e}}\n\n该集群使用 EDS 服务发现。查看该集群的 EDS 信息：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=11 12\u0022\u003e}}\n{ \n \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.endpoint.v3.ClusterLoadAssignment\u0022,\n \u0022endpoints\u0022: [\n  {\n   \u0022locality\u0022: {},\n   \u0022lb_endpoints\u0022: [\n    {\n     \u0022endpoint\u0022: {\n      \u0022address\u0022: {\n       \u0022socket_address\u0022: {\n        \u0022address\u0022: \u002210.4.3.14\u0022,\n        \u0022port_value\u0022: 15006\n       }\n      },\n      \u0022health_check_config\u0022: {}\n     },\n     \u0022health_status\u0022: \u0022HEALTHY\u0022,\n     \u0022load_balancing_weight\u0022: 1\n    }\n   ]\n  }\n ],\n \u0022policy\u0022: {\n  \u0022overprovisioning_factor\u0022: 140\n }\n}\n{{\u003c\/highlight\u003e}}\n\n注意：这里还是缺少输出 \u0060cluster_name\u0060 字段。\n\n在这里直接将流量转发给 Waypoint Proxy 的端点 \u006010.4.3.14:15006\u0060。\n\n## Waypoint Proxy B 上的流量转发 {#waypoint-proxy-b}\n\n我们再导出 Waypoint Proxy B 中的 Envoy 配置：\n\n\u0060\u0060\u0060bash\nkubectl exec -n default bookinfo-productpage-waypoint-proxy-6f88c55d59-4dzdx -c istio-proxy -- curl \u0022127.0.0.1:15000\/config_dump?include_eds\u0022\u003ewaypoint-a-all-include-eds.json\n\u0060\u0060\u0060\n\n查看 \u0060inbound_CONNECT_terminate\u0060 监听器的配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=7 10 11 39 44 58 62\u0022\u003e}}\n{\n  \u0022name\u0022: \u0022inbound_CONNECT_terminate\u0022,\n  \u0022active_state\u0022: {\n    \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n    \u0022listener\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n    \u0022name\u0022: \u0022inbound_CONNECT_terminate\u0022,\n    \u0022address\u0022: {\n      \u0022socket_address\u0022: {\n      \u0022address\u0022: \u00220.0.0.0\u0022,\n      \u0022port_value\u0022: 15006\n      }\n    },\n    \u0022filter_chains\u0022: [{\n      \u0022filters\u0022: [{\n        \u0022name\u0022: \u0022capture_tls\u0022,\n        \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/udpa.type.v1.TypedStruct\u0022,\n        \u0022type_url\u0022: \u0022type.googleapis.com\/istio.tls_passthrough.v1.CaptureTLS\u0022\n        }\n      },\n      {\n        \u0022name\u0022: \u0022envoy.filters.network.http_connection_manager\u0022,\n        \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\u0022,\n        \u0022stat_prefix\u0022: \u0022inbound_hcm\u0022,\n        \u0022route_config\u0022: {\n          \u0022name\u0022: \u0022local_route\u0022,\n          \u0022virtual_hosts\u0022: [{\n          \u0022name\u0022: \u0022connect\u0022,\n          \u0022domains\u0022: [\n            \u0022*\u0022\n          ],\n          \u0022routes\u0022: [{...},\n            {\n            \u0022match\u0022: {\n              \u0022headers\u0022: [{\n              \u0022name\u0022: \u0022:authority\u0022,\n              \u0022exact_match\u0022: \u002210.8.14.226:9080\u0022\n              }],\n              \u0022connect_matcher\u0022: {}\n            },\n            \u0022route\u0022: {\n              \u0022cluster\u0022: \u0022inbound-vip|9080|internal|productpage.default.svc.cluster.local\u0022,\n              \u0022upgrade_configs\u0022: [{\n              \u0022upgrade_type\u0022: \u0022CONNECT\u0022,\n              \u0022connect_config\u0022: {}\n              }]\n            }\n            }\n          ]\n          }],\n          \u0022validate_clusters\u0022: false\n        },\n        \u0022http_filters\u0022: [...],\n        \u0022tracing\u0022: {...},\n        \u0022http2_protocol_options\u0022: {\n          \u0022allow_connect\u0022: true\n        },\n        \u0022use_remote_address\u0022: false,\n        \u0022upgrade_configs\u0022: [{\n          \u0022upgrade_type\u0022: \u0022CONNECT\u0022\n        }],\n        \u0022stream_idle_timeout\u0022: \u00220s\u0022,\n        \u0022normalize_path\u0022: true,\n        \u0022request_id_extension\u0022: {...},\n        \u0022path_with_escaped_slashes_action\u0022: \u0022KEEP_UNCHANGED\u0022\n        }\n      }\n      ],\n      \u0022transport_socket\u0022: {...},\n      \u0022name\u0022: \u0022inbound_CONNECT_terminate\u0022\n    }]\n    },\n    \u0022last_updated\u0022: \u00222022-11-17T06:24:51.467Z\u0022\n  }\n}\n{{\u003c\/highlight\u003e}}\n\n目的地为 \u006010.8.14.226:9080\u0060 的 TCP 流量将被转发到 \u0060inbound-vip|9080|internal|productpage.default.svc.cluster.local\u0060，并将 HTTP 类型修改为 \u0060CONNECT\u0060，查看该集群的配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=6 37\u0022\u003e}}\n{\n \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022inbound-vip|9080|internal|productpage.default.svc.cluster.local\u0022,\n  \u0022type\u0022: \u0022STATIC\u0022,\n  \u0022transport_socket\u0022: {\n   \u0022name\u0022: \u0022envoy.transport_sockets.internal_upstream\u0022,\n   \u0022typed_config\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.internal_upstream.v3.InternalUpstreamTransport\u0022,\n    \u0022passthrough_metadata\u0022: [\n     {\n      \u0022kind\u0022: {\n       \u0022cluster\u0022: {}\n      },\n      \u0022name\u0022: \u0022istio\u0022\n     }\n    ],\n    \u0022transport_socket\u0022: {\n     \u0022name\u0022: \u0022envoy.transport_sockets.raw_buffer\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.raw_buffer.v3.RawBuffer\u0022\n     }\n    }\n   }\n  },\n  \u0022common_lb_config\u0022: {},\n  \u0022load_assignment\u0022: {\n   \u0022cluster_name\u0022: \u0022inbound-vip|9080|internal|productpage.default.svc.cluster.local\u0022,\n   \u0022endpoints\u0022: [\n    {\n     \u0022lb_endpoints\u0022: [\n      {\n       \u0022endpoint\u0022: {\n        \u0022address\u0022: {\n         \u0022envoy_internal_address\u0022: {\n          \u0022server_listener_name\u0022: \u0022inbound-vip|9080||productpage.default.svc.cluster.local\u0022\n         }\n        }\n       }\n      }\n     ]\n    }\n   ]\n  }\n },\n \u0022last_updated\u0022: \u00222022-11-17T03:27:46.137Z\u0022\n}\n{{\u003c\/highlight\u003e}}\n\n该集群的端点是一个内部监听器 \u0060inbound-vip|9080||productpage.default.svc.cluster.local\u0060：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=21-47 73-80\u0022\u003e}}\n{\n \u0022name\u0022: \u0022inbound-vip|9080||productpage.default.svc.cluster.local\u0022,\n \u0022active_state\u0022: {\n  \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n  \u0022listener\u0022: {\n   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n   \u0022name\u0022: \u0022inbound-vip|9080||productpage.default.svc.cluster.local\u0022,\n   \u0022filter_chains\u0022: [{\n    \u0022filters\u0022: [{\n      \u0022name\u0022: \u0022restore_tls\u0022,\n      \u0022typed_config\u0022: {\n       \u0022@type\u0022: \u0022type.googleapis.com\/udpa.type.v1.TypedStruct\u0022,\n       \u0022type_url\u0022: \u0022type.googleapis.com\/istio.tls_passthrough.v1.RestoreTLS\u0022\n      }\n     },\n     {\n      \u0022name\u0022: \u0022envoy.filters.network.http_connection_manager\u0022,\n      \u0022typed_config\u0022: {\n       \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\u0022,\n       \u0022stat_prefix\u0022: \u0022inbound_0.0.0.0_9080\u0022,\n       \u0022route_config\u0022: {\n        \u0022name\u0022: \u0022inbound-vip|9080|http|productpage.default.svc.cluster.local\u0022,\n        \u0022virtual_hosts\u0022: [{\n         \u0022name\u0022: \u0022inbound|http|9080\u0022,\n         \u0022domains\u0022: [\n          \u0022*\u0022\n         ],\n         \u0022routes\u0022: [{\n          \u0022match\u0022: {\n           \u0022prefix\u0022: \u0022\/\u0022\n          },\n          \u0022route\u0022: {\n           \u0022cluster\u0022: \u0022inbound-vip|9080|http|productpage.default.svc.cluster.local\u0022,\n           \u0022timeout\u0022: \u00220s\u0022,\n           \u0022max_stream_duration\u0022: {\n            \u0022max_stream_duration\u0022: \u00220s\u0022,\n            \u0022grpc_timeout_header_max\u0022: \u00220s\u0022\n           }\n          },\n          \u0022decorator\u0022: {\n           \u0022operation\u0022: \u0022:9080\/*\u0022\n          },\n          \u0022name\u0022: \u0022default\u0022\n         }]\n        }],\n        \u0022validate_clusters\u0022: false\n       }\n      },\n      \u0022server_name\u0022: \u0022istio-envoy\u0022,\n      \u0022use_remote_address\u0022: false,\n      \u0022forward_client_cert_details\u0022: \u0022APPEND_FORWARD\u0022,\n      \u0022set_current_client_cert_details\u0022: {\n       \u0022subject\u0022: true,\n       \u0022dns\u0022: true,\n       \u0022uri\u0022: true\n      },\n      \u0022upgrade_configs\u0022: [{\n       \u0022upgrade_type\u0022: \u0022websocket\u0022\n      }],\n      \u0022stream_idle_timeout\u0022: \u00220s\u0022,\n      \u0022normalize_path\u0022: true,\n      \u0022request_id_extension\u0022: {\n       \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.request_id.uuid.v3.UuidRequestIdConfig\u0022,\n        \u0022use_request_id_for_trace_sampling\u0022: true\n       }\n      },\n      \u0022path_with_escaped_slashes_action\u0022: \u0022KEEP_UNCHANGED\u0022\n     }\n    ],\n    \u0022name\u0022: \u0022inbound-vip|9080||productpage.default.svc.cluster.local-http\u0022\n   }],\n   \u0022listener_filters\u0022: [{\n     \u0022name\u0022: \u0022set_dst_address\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/xds.type.v3.TypedStruct\u0022,\n      \u0022type_url\u0022: \u0022type.googleapis.com\/istio.set_internal_dst_address.v1.Config\u0022,\n      \u0022value\u0022: {}\n     }\n    },\n    {\n     \u0022name\u0022: \u0022envoy.filters.listener.metadata_to_peer_node\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/udpa.type.v1.TypedStruct\u0022,\n      \u0022type_url\u0022: \u0022type.googleapis.com\/istio.telemetry.metadatatopeernode.v1.Config\u0022\n     }\n    }\n   ],\n   \u0022traffic_direction\u0022: \u0022INBOUND\u0022,\n   \u0022internal_listener\u0022: {}\n  },\n  \u0022last_updated\u0022: \u00222022-11-17T03:27:46.300Z\u0022\n }\n}\n{{\u003c\/highlight\u003e}}\n\n数据包被转发到 \u0060inbound-vip|9080|http|productpage.default.svc.cluster.local\u0060 集群：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=6\u0022\u003e}}\n{\n \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022inbound-vip|9080|http|productpage.default.svc.cluster.local\u0022,\n  \u0022type\u0022: \u0022EDS\u0022,\n  \u0022eds_cluster_config\u0022: {\n   \u0022eds_config\u0022: {\n    \u0022ads\u0022: {},\n    \u0022initial_fetch_timeout\u0022: \u00220s\u0022,\n    \u0022resource_api_version\u0022: \u0022V3\u0022\n   },\n   \u0022service_name\u0022: \u0022inbound-vip|9080|http|productpage.default.svc.cluster.local\u0022\n  },\n  \u0022transport_socket\u0022: {\n   \u0022name\u0022: \u0022envoy.transport_sockets.internal_upstream\u0022,\n   \u0022typed_config\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.internal_upstream.v3.InternalUpstreamTransport\u0022,\n    \u0022transport_socket\u0022: {\n     \u0022name\u0022: \u0022envoy.transport_sockets.raw_buffer\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.raw_buffer.v3.RawBuffer\u0022\n     }\n    }\n   }\n  },\n  \u0022metadata\u0022: {\n   \u0022filter_metadata\u0022: {\n    \u0022istio\u0022: {\n     \u0022services\u0022: [{\n      \u0022namespace\u0022: \u0022default\u0022,\n      \u0022name\u0022: \u0022productpage\u0022,\n      \u0022host\u0022: \u0022productpage.default.svc.cluster.local\u0022\n     }]\n    }\n   }\n  },\n  \u0022common_lb_config\u0022: {}\n },\n \u0022last_updated\u0022: \u00222022-11-17T03:27:46.138Z\u0022\n}\n{{\u003c\/highlight\u003e}}\n\n该集群是 EDS 类型，查看 Endpoint 配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=14\u0022\u003e}}\n{\n \u0022endpoint_config\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.endpoint.v3.ClusterLoadAssignment\u0022,\n  \u0022cluster_name\u0022: \u0022inbound-vip|9080|http|productpage.default.svc.cluster.local\u0022,\n  \u0022endpoints\u0022: [{\n   \u0022locality\u0022: {\n    \u0022region\u0022: \u0022us-west2\u0022,\n    \u0022zone\u0022: \u0022us-west2-a\u0022\n   },\n   \u0022lb_endpoints\u0022: [{\n    \u0022endpoint\u0022: {\n     \u0022address\u0022: {\n      \u0022envoy_internal_address\u0022: {\n       \u0022server_listener_name\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022\n      }\n     },\n     \u0022health_check_config\u0022: {}\n    },\n    \u0022health_status\u0022: \u0022HEALTHY\u0022,\n    \u0022metadata\u0022: {\n     \u0022filter_metadata\u0022: {\n      \u0022istio\u0022: {\n       \u0022workload\u0022: \u0022productpage-v1;default;productpage;v1;Kubernetes\u0022\n      }\n     }\n    },\n    \u0022load_balancing_weight\u0022: 1\n   }]\n  }],\n  \u0022policy\u0022: {\n   \u0022overprovisioning_factor\u0022: 140\n  }\n }\n}\n{{\u003c\/highlight\u003e}}\n\n数据包被转发到 \u0060inbound-pod|9080||10.4.0.5\u0060 监听器：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=33\u0022\u003e}}\n\n{\n \u0022name\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022,\n \u0022active_state\u0022: {\n  \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n  \u0022listener\u0022: {\n   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n   \u0022name\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022,\n   \u0022filter_chains\u0022: [{\n    \u0022filters\u0022: [{\n      \u0022name\u0022: \u0022restore_tls\u0022,\n      \u0022typed_config\u0022: {\n       \u0022@type\u0022: \u0022type.googleapis.com\/udpa.type.v1.TypedStruct\u0022,\n       \u0022type_url\u0022: \u0022type.googleapis.com\/istio.tls_passthrough.v1.RestoreTLS\u0022\n      }\n     },\n     {\n      \u0022name\u0022: \u0022envoy.filters.network.http_connection_manager\u0022,\n      \u0022typed_config\u0022: {\n       \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\u0022,\n       \u0022stat_prefix\u0022: \u0022inbound_0.0.0.0_9080\u0022,\n       \u0022route_config\u0022: {\n        \u0022name\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022,\n        \u0022virtual_hosts\u0022: [{\n         \u0022name\u0022: \u0022inbound|http|9080\u0022,\n         \u0022domains\u0022: [\n          \u0022*\u0022\n         ],\n         \u0022routes\u0022: [{\n          \u0022match\u0022: {\n           \u0022prefix\u0022: \u0022\/\u0022\n          },\n          \u0022route\u0022: {\n           \u0022cluster\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022,\n           \u0022timeout\u0022: \u00220s\u0022,\n           \u0022max_stream_duration\u0022: {\n            \u0022max_stream_duration\u0022: \u00220s\u0022,\n            \u0022grpc_timeout_header_max\u0022: \u00220s\u0022\n           }\n          },\n          \u0022decorator\u0022: {\n           \u0022operation\u0022: \u0022:9080\/*\u0022\n          },\n          \u0022name\u0022: \u0022default\u0022\n         }]\n        }],\n        \u0022validate_clusters\u0022: false\n       },\n       \u0022http_filters\u0022: [{\n        \u0022name\u0022: \u0022envoy.filters.http.rbac\u0022,\n        \u0022typed_config\u0022: {\n         \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.http.rbac.v3.RBAC\u0022,\n         \u0022rules\u0022: {\n          \u0022policies\u0022: {\n           \u0022ns[default]-policy[productpage-viewer]-rule[0]\u0022: {\n            \u0022permissions\u0022: [{\n             \u0022and_rules\u0022: {\n              \u0022rules\u0022: [{\n               \u0022any\u0022: true\n              }]\n             }\n            }],\n            \u0022principals\u0022: [{\n             \u0022and_ids\u0022: {\n              \u0022ids\u0022: [{\n               \u0022or_ids\u0022: {\n                \u0022ids\u0022: [{\n                  \u0022authenticated\u0022: {\n                   \u0022principal_name\u0022: {\n                    \u0022exact\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022\n                   }\n                  }\n                 },\n                 {\n                  \u0022authenticated\u0022: {\n                   \u0022principal_name\u0022: {\n                    \u0022exact\u0022: \u0022spiffe:\/\/cluster.local\/ns\/istio-system\/sa\/istio-ingressgateway-service-account\u0022\n                   }\n                  }\n                 }\n                ]\n               }\n              }]\n             }\n            }]\n           }\n          }\n         },\n         \u0022shadow_rules_stat_prefix\u0022: \u0022istio_dry_run_allow_\u0022\n        }\n       }],\n       \u0022server_name\u0022: \u0022istio-envoy\u0022,\n       \u0022use_remote_address\u0022: false,\n       \u0022forward_client_cert_details\u0022: \u0022APPEND_FORWARD\u0022,\n       \u0022set_current_client_cert_details\u0022: {\n        \u0022subject\u0022: true,\n        \u0022dns\u0022: true,\n        \u0022uri\u0022: true\n       },\n       \u0022upgrade_configs\u0022: [{\n        \u0022upgrade_type\u0022: \u0022websocket\u0022\n       }],\n       \u0022stream_idle_timeout\u0022: \u00220s\u0022,\n       \u0022normalize_path\u0022: true,\n       \u0022request_id_extension\u0022: {\n        \u0022typed_config\u0022: {\n         \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.request_id.uuid.v3.UuidRequestIdConfig\u0022,\n         \u0022use_request_id_for_trace_sampling\u0022: true\n        }\n       },\n       \u0022path_with_escaped_slashes_action\u0022: \u0022KEEP_UNCHANGED\u0022\n      }\n     }\n    ],\n    \u0022name\u0022: \u0022inbound-pod|9080||10.4.0.5-http\u0022\n   }],\n   \u0022listener_filters\u0022: [{\n    \u0022name\u0022: \u0022set_dst_address\u0022,\n    \u0022typed_config\u0022: {\n     \u0022@type\u0022: \u0022type.googleapis.com\/xds.type.v3.TypedStruct\u0022,\n     \u0022type_url\u0022: \u0022type.googleapis.com\/istio.set_internal_dst_address.v1.Config\u0022,\n     \u0022value\u0022: {}\n    }\n   }],\n   \u0022traffic_direction\u0022: \u0022INBOUND\u0022,\n   \u0022internal_listener\u0022: {}\n  },\n  \u0022last_updated\u0022: \u00222022-11-17T03:27:46.339Z\u0022\n }\n}\n\n{{\u003c\/highlight\u003e}}\n\n数据包被转发到 \u0060inbound-pod|9080||10.4.0.5\u0060 集群：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=6 43 48-55\u0022\u003e}}\n{\n \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022,\n  \u0022type\u0022: \u0022STATIC\u0022,\n  \u0022transport_socket\u0022: {\n   \u0022name\u0022: \u0022envoy.transport_sockets.internal_upstream\u0022,\n   \u0022typed_config\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.internal_upstream.v3.InternalUpstreamTransport\u0022,\n    \u0022passthrough_metadata\u0022: [\n     {\n      \u0022kind\u0022: {\n       \u0022host\u0022: {}\n      },\n      \u0022name\u0022: \u0022tunnel\u0022\n     },\n     {\n      \u0022kind\u0022: {\n       \u0022host\u0022: {}\n      },\n      \u0022name\u0022: \u0022istio\u0022\n     }\n    ],\n    \u0022transport_socket\u0022: {\n     \u0022name\u0022: \u0022envoy.transport_sockets.raw_buffer\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.raw_buffer.v3.RawBuffer\u0022\n     }\n    }\n   }\n  },\n  \u0022common_lb_config\u0022: {},\n  \u0022load_assignment\u0022: {\n   \u0022cluster_name\u0022: \u0022inbound-pod|9080||10.4.0.5\u0022,\n   \u0022endpoints\u0022: [\n    {\n     \u0022lb_endpoints\u0022: [\n      {\n       \u0022endpoint\u0022: {\n        \u0022address\u0022: {\n         \u0022envoy_internal_address\u0022: {\n          \u0022server_listener_name\u0022: \u0022inbound_CONNECT_originate\u0022,\n          \u0022endpoint_id\u0022: \u002210.4.0.5:9080\u0022\n         }\n        }\n       },\n       \u0022metadata\u0022: {\n        \u0022filter_metadata\u0022: {\n         \u0022tunnel\u0022: {\n          \u0022destination\u0022: \u002210.4.0.5:9080\u0022,\n          \u0022address\u0022: \u002210.4.0.5:15008\u0022\n         }\n        }\n       }\n      }\n     ]\n    }\n   ]\n  }\n },\n \u0022last_updated\u0022: \u00222022-11-17T03:27:46.139Z\u0022\n}\n{{\u003c\/highlight\u003e}}\n\n该集群是 \u0060STATIC\u0060 类型，其中包含了 HBONE 隧道配置（HTTP\/2 CONNECT 地址是 \u006010.4.0.15008\u0060），端点是 Envoy 内部监听器 \u0060inbound_CONNECT_originate\u0060：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=16-27 33 36\u0022\u003e}}\n{\n \u0022name\u0022: \u0022inbound_CONNECT_originate\u0022,\n \u0022active_state\u0022: {\n  \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n  \u0022listener\u0022: {\n   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n   \u0022name\u0022: \u0022inbound_CONNECT_originate\u0022,\n   \u0022filter_chains\u0022: [\n    {\n     \u0022filters\u0022: [\n      {\n       \u0022name\u0022: \u0022envoy.filters.network.tcp_proxy\u0022,\n       \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy\u0022,\n        \u0022stat_prefix\u0022: \u0022inbound_CONNECT_originate\u0022,\n        \u0022cluster\u0022: \u0022inbound_CONNECT_originate\u0022,\n        \u0022tunneling_config\u0022: {\n         \u0022hostname\u0022: \u0022%DYNAMIC_METADATA(tunnel:destination)%\u0022,\n         \u0022headers_to_add\u0022: [\n          {\n           \u0022header\u0022: {\n            \u0022key\u0022: \u0022x-envoy-original-dst-host\u0022,\n            \u0022value\u0022: \u0022%DYNAMIC_METADATA([\\\u0022tunnel\\\u0022, \\\u0022destination\\\u0022])%\u0022\n           }\n          }\n         ]\n        }\n       }\n      }\n     ]\n    }\n   ],\n   \u0022use_original_dst\u0022: false,\n   \u0022listener_filters\u0022: [\n    {\n     \u0022name\u0022: \u0022set_dst_address\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/xds.type.v3.TypedStruct\u0022,\n      \u0022type_url\u0022: \u0022type.googleapis.com\/istio.set_internal_dst_address.v1.Config\u0022,\n      \u0022value\u0022: {}\n     }\n    }\n   ],\n   \u0022internal_listener\u0022: {}\n  },\n  \u0022last_updated\u0022: \u00222022-11-17T03:27:46.339Z\u0022\n }\n}\n{{\u003c\/highlight\u003e}}\n\n说明：\n\n- \u0060listener_filters\u0060 中的 \u0060set_dst_address\u0060 将目的地地址设置为 \u006010.4.0.5.15008\u0060；\n- 在隧道中新增了一个 Header：\u0060x-envoy-original-dst-host\u0060，它的值是 \u006010.4.0.5:9080\u0060；\n- 该集群的端点是 \u0060inbound_CONNECT_originate\u0060 集群；\n\n查看 \u0060inbound_CONNECT_originate\u0060 集群：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=6\u0022\u003e}}\n{\n \u0022version_info\u0022: \u00222022-11-17T03:27:45Z\/82\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022inbound_CONNECT_originate\u0022,\n  \u0022type\u0022: \u0022ORIGINAL_DST\u0022,\n  \u0022connect_timeout\u0022: \u00222s\u0022,\n  \u0022lb_policy\u0022: \u0022CLUSTER_PROVIDED\u0022,\n  \u0022cleanup_interval\u0022: \u002260s\u0022,\n  \u0022transport_socket\u0022: {\n   \u0022name\u0022: \u0022envoy.transport_sockets.tls\u0022,\n   \u0022typed_config\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\u0022,\n    \u0022common_tls_context\u0022: {\n     \u0022tls_params\u0022: {\n      \u0022tls_minimum_protocol_version\u0022: \u0022TLSv1_3\u0022,\n      \u0022tls_maximum_protocol_version\u0022: \u0022TLSv1_3\u0022\n     },\n     \u0022alpn_protocols\u0022: [\n      \u0022h2\u0022\n     ],\n     \u0022tls_certificate_sds_secret_configs\u0022: [\n      {\n       \u0022name\u0022: \u0022default\u0022,\n       \u0022sds_config\u0022: {\n        \u0022api_config_source\u0022: {\n         \u0022api_type\u0022: \u0022GRPC\u0022,\n         \u0022grpc_services\u0022: [\n          {\n           \u0022envoy_grpc\u0022: {\n            \u0022cluster_name\u0022: \u0022sds-grpc\u0022\n           }\n          }\n         ],\n         \u0022set_node_on_first_message_only\u0022: true,\n         \u0022transport_api_version\u0022: \u0022V3\u0022\n        },\n        \u0022initial_fetch_timeout\u0022: \u00220s\u0022,\n        \u0022resource_api_version\u0022: \u0022V3\u0022\n       }\n      }\n     ],\n     \u0022combined_validation_context\u0022: {\n      \u0022default_validation_context\u0022: {\n       \u0022match_subject_alt_names\u0022: [\n        {\n         \u0022prefix\u0022: \u0022spiffe:\/\/cluster.local\/\u0022\n        }\n       ]\n      },\n      \u0022validation_context_sds_secret_config\u0022: {\n       \u0022name\u0022: \u0022ROOTCA\u0022,\n       \u0022sds_config\u0022: {\n        \u0022api_config_source\u0022: {\n         \u0022api_type\u0022: \u0022GRPC\u0022,\n         \u0022grpc_services\u0022: [\n          {\n           \u0022envoy_grpc\u0022: {\n            \u0022cluster_name\u0022: \u0022sds-grpc\u0022\n           }\n          }\n         ],\n         \u0022set_node_on_first_message_only\u0022: true,\n         \u0022transport_api_version\u0022: \u0022V3\u0022\n        },\n        \u0022initial_fetch_timeout\u0022: \u00220s\u0022,\n        \u0022resource_api_version\u0022: \u0022V3\u0022\n       }\n      }\n     }\n    }\n   }\n  },\n  \u0022typed_extension_protocol_options\u0022: {\n   \u0022envoy.extensions.upstreams.http.v3.HttpProtocolOptions\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\u0022,\n    \u0022explicit_http_config\u0022: {\n     \u0022http2_protocol_options\u0022: {\n      \u0022allow_connect\u0022: true\n     }\n    }\n   }\n  }\n },\n \u0022last_updated\u0022: \u00222022-11-17T03:27:46.140Z\u0022\n}\n{{\u003c\/highlight\u003e}}\n\n该集群的类型是 \u0060ORIGINAL_DST\u0060，直接与上游建立 HBONE 隧道，将数据包发送到 Pod B 的 15008 端口。在节点 B 的 Ztunnel 的流量劫持和路由方式就跟 L4 是一样的了，在这里不再赘述。\n\n## 总结 {#summary}\n\nL7 流量路由是在 L4 的基础上增加了 Waypoint 代理，该代理中 Envoy 处理比较复杂。Waypoint 代理使用 Gateway API 生成基于 Deployment 部署的，我们可以根据个别服务的负载情况，单独扩缩容其 Waypoint 代理，也可以创建 HPA 来动态扩容。\n\n## 参考 {#reference}\n\n- [Original destination - envoyproxy.io](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/upstream\/service_discovery#arch-overview-service-discovery-types-original-destination)\n- [一文读懂 Ambient Mesh 七层服务治理 - mp.weixin.qq.com](https:\/\/mp.weixin.qq.com\/s\/TXMyxbzBSfuYNquOZJmZTg)\n', '\/blog\/ambient-mesh-l7-traffic-path\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文以图示和实际操作的形式详细介绍了 Ambient Mesh 中的七层（L7）流量路径。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/ambient-mesh-l4-traffic-path/">Istio Ambient 模式中的透明流量劫持四层网络路由路径详解</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2022/11/14</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/istio"> 
             Istio
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Istio Ambient 模式中的透明流量劫持四层网络路由路径详解', '本文以图示和实际操作的形式详细介绍了 Ambient Mesh 中的透明流量劫持和四层（L4）流量路径。', '\n本文通过动手操作，带领读者一步步了解 Istio ambient 模式中的四层流量路径。如果你还不了解什么是 Ambient 模式，以下文章可以帮助你了解：\n\n- [关于 Istio 推出 Ambient 数据平面模式的看法](\/blog\/istio-ambient-mode\/)\n- [Istio 无 sidecar 代理数据平面 ambient 模式简介](https:\/\/cloudnative.to\/blog\/introducing-ambient-mesh\/)\n- [Istio 服务网格 ambient 模式安全详解](https:\/\/cloudnative.to\/blog\/ambient-security\/)\n- [什么是 Ambient Mesh，它与 sidecar 模式有什么区别？](https:\/\/cloudnative.to\/blog\/what-is-ambient-mesh\/)\n\n如果你想略过实际动手步骤，只是想知道 Ambient 模式中的四层流量路径，请看下面服务 A 的一个 Pod 访问不同节点上服务 B 的 Pod 的四层流量路径图。\n\n![Ambient 模式中的四层流量路径](ambient-mesh-l4-traffic-path.svg)\n\n## 原理 {#principles}\n\nAmbient 模式使用 **tproxy** 和 **HBONE** 这两个关键技术实现透明流量劫持和路由的：\n\n- 使用 tproxy 将主机 Pod 中的流量劫持到 Ztunnel（Envoy Proxy）中，实现透明流量劫持；\n- 使用 HBONE 建立在 Ztunnel 之间传递 TCP 数据流隧道；\n\n### 什么是 tproxy？{#what-is-tproxy}\n\n\u0060tproxy\u0060 是 Linux 内核自 2.2 版本以来支持的透明代理（Transparent proxy），其中的 t 代表 transparent，即透明。你需要在内核配置中启用 \u0060NETFILTER_TPROXY\u0060 和策略路由。通过 tproxy，Linux 内核就可以作为一个路由器，将数据包重定向到用户空间。详见 [tproxy 文档](http:\/\/lxr.linux.no\/linux\u002bv3.10\/Documentation\/networking\/tproxy.txt) 。\n\n### 什么是 HBONE？{#what-is-hbone}\n\nHBONE 是 HTTP-Based Overlay Network Environment 的缩写，是一种使用 HTTP 协议提供隧道能力的方法。客户端向 HTTP 代理服务器发送 HTTP CONNECT 请求（其中包含了目的地址）以建立隧道，代理服务器代表客户端与目的地建立 TCP 连接，然后客户端就可以通过代理服务器透明的传输 TCP 数据流到目的服务器。在 Ambient 模式中，Ztunnel（其中的 Envoy）实际上是充当了透明代理，它使用 [Envoy Internal Listener](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/other_features\/internal_listener) 来接收 HTTP CONNECT 请求和传递 TCP 流给上游集群。\n\n## 环境说明 {#environment}\n\n在开始动手操作之前，需要先说明一下笔者的演示环境，本文中对应的对象名称：\n\n| 代号           | 名称                                         | IP            |\n| -------------- | -------------------------------------------- | ------------- |\n| 服务 A Pod     | sleep-5644bdc767-2dfg7                       | 10.4.4.19     |\n| 服务 B Pod     | productpage-v1-5586c4d4ff-qxz9f              | 10.4.3.20     |\n| Ztunnel A Pod  | ztunnel-rts54                                | 10.4.4.18     |\n| Ztunnel B Pod  | ztunnel-z4qmh                                | 10.4.3.14     |\n| 节点 A         | gke-jimmy-cluster-default-pool-d5041909-d10i | 10.168.15.222 |\n| 节点 B         | gke-jimmy-cluster-default-pool-d5041909-c1da | 10.168.15.224 |\n| 服务 B Cluster | productpage                                  | 10.8.14.226   |\n\n注意：因为这些名称将在后续的命令行中用到，文中将使用代称，以便你在自己的环境中实验。\n\n笔者在 GKE 中安装了 Ambient 模式的 Istio，请参考[该步骤](\/blog\/istio-ambient-mode\/#setup)安装，注意不要安装 Gateway，以免启用 L7 功能，否则流量路径将于 L4 流量不同。\n\n下面我们将动手实验，深入探究 \u0060sleep\u0060 服务的 Pod 访问不同节点上 \u0060productpage\u0060 服务的 Pod 的四层流量路径。我们将分别检视 Pod 的 outbound 和 inbound 流量。\n\n## Outbound 流量劫持 {#outbound}\n\nAmbient mesh 的 pod 出站流量的透明流量劫持流程如下：\n\n1. Istio CNI 在节点上创建 \u0060istioout\u0060 网卡和 iptables 规则，将 Ambient mesh 中的 Pod IP 加入 [IP 集](https:\/\/ipset.netfilter.org\/)，并通过 netfilter \u0060nfmark\u0060 标记和路由规则，将 Ambient mesh 中的出站流量通过 Geneve 隧道透明劫持到 \u0060pistioout\u0060 虚拟网卡；\n2. ztunnel 中的 init 容器创建 iptables 规则，将 \u0060pistioout\u0060 网卡中的所有流量转发到 ztunnel 中的 Envoy 代理的 15001 端口；\n3. Envoy 对数据包进行处理，并与上游端点建立 HBONE 隧道（HTTP CONNECT），将数据包转发到上游。\n\n### 检查节点 A 上的路由规则 {#node-a-rules}\n\n登录到服务 A 所在的节点 A，使用 \u0060iptables-save\u0060 查看规则：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=3 4 6 35\u0022\u003e}}\n$ iptables-save\n\/* 省略 *\/\n-A PREROUTING -j ztunnel-PREROUTING\n-A PREROUTING -m comment --comment \u0022kubernetes service portals\u0022 -j KUBE-SERVICES\n-A ztunnel-POSTROUTING -m mark --mark 0x100\/0x100 -j ACCEPT\n-A ztunnel-PREROUTING -m mark --mark 0x100\/0x100 -j ACCEPT\n\/* 省略 *\/\n*mangle\n\/* 省略 *\/\n-A PREROUTING -j ztunnel-PREROUTING\n-A INPUT -j ztunnel-INPUT\n-A FORWARD -j ztunnel-FORWARD\n-A OUTPUT -j ztunnel-OUTPUT\n-A OUTPUT -s 169.254.169.254\/32 -j DROP\n-A POSTROUTING -j ztunnel-POSTROUTING\n-A ztunnel-FORWARD -m mark --mark 0x220\/0x220 -j CONNMARK --save-mark --nfmask 0x220 --ctmask 0x220\n-A ztunnel-FORWARD -m mark --mark 0x210\/0x210 -j CONNMARK --save-mark --nfmask 0x210 --ctmask 0x210\n-A ztunnel-INPUT -m mark --mark 0x220\/0x220 -j CONNMARK --save-mark --nfmask 0x220 --ctmask 0x220\n-A ztunnel-INPUT -m mark --mark 0x210\/0x210 -j CONNMARK --save-mark --nfmask 0x210 --ctmask 0x210\n-A ztunnel-OUTPUT -s 10.4.4.1\/32 -j MARK --set-xmark 0x220\/0xffffffff\n-A ztunnel-PREROUTING -i istioin -j MARK --set-xmark 0x200\/0x200\n-A ztunnel-PREROUTING -i istioin -j RETURN\n-A ztunnel-PREROUTING -i istioout -j MARK --set-xmark 0x200\/0x200\n-A ztunnel-PREROUTING -i istioout -j RETURN\n-A ztunnel-PREROUTING -p udp -m udp --dport 6081 -j RETURN\n-A ztunnel-PREROUTING -m connmark --mark 0x220\/0x220 -j MARK --set-xmark 0x200\/0x200\n-A ztunnel-PREROUTING -m mark --mark 0x200\/0x200 -j RETURN\n-A ztunnel-PREROUTING ! -i veth300a1d80 -m connmark --mark 0x210\/0x210 -j MARK --set-xmark 0x40\/0x40\n-A ztunnel-PREROUTING -m mark --mark 0x40\/0x40 -j RETURN\n-A ztunnel-PREROUTING ! -s 10.4.4.18\/32 -i veth300a1d80 -j MARK --set-xmark 0x210\/0x210\n-A ztunnel-PREROUTING -m mark --mark 0x200\/0x200 -j RETURN\n-A ztunnel-PREROUTING -i veth300a1d80 -j MARK --set-xmark 0x220\/0x220\n-A ztunnel-PREROUTING -p udp -j MARK --set-xmark 0x220\/0x220\n-A ztunnel-PREROUTING -m mark --mark 0x200\/0x200 -j RETURN\n-A ztunnel-PREROUTING -p tcp -m set --match-set ztunnel-pods-ips src -j MARK --set-xmark 0x100\/0x100\n{{\u003c\/highlight\u003e}}\n\niptables 规则说明：\n\n- 第 3 行：PREROUTING 链是最先运行的，所有数据包将先进入 \u0060ztunnel-PREROUTING\u0060 链；\n- 第 4 行：将数据包发往 \u0060KUBE-SERVICES\u0060 链，在那里将 Kubernetes Service 的 Cluster IP 进行 DNAT 转换为 Pod IP；\n- 第 6 行：带有 \u00600x100\/0x100\u0060 标记的数据包通过 PREROUTING 链，不再经过 \u0060KUBE-SERVICES\u0060 链；\n- 第 35 行：这是添加到 \u0060ztunnel-PREROUTING\u0060 链上的最后一条规则，进入 \u0060ztunnel-PREROUTING\u0060 链中的在 \u0060ztunnel-pods-ips\u0060 IP 集中的所有 TCP 数据包都会被打上 \u00600x100\/0x100\u0060 的标记，它将覆盖前面的所有标记；\n\n{{\u003ccallout note \u0022关于 iptables 设置 mark 和 xmark 标记\u0022\u003e}}\n\n\u0060MARK\u0060 这个扩展目标可以用来给数据包打标记，标记分两种：一种是用于标记链接的 \u0060ctmark\u0060，一种是用于标记数据包的 \u0060nfmark\u0060 。\u0060nfmark\u0060占四个字节共 32 位，我们可以把它看成是一个长度为 32 位的无符号整数，一般用 16 进制来表示。\n\nMark 的设置一共有五个选项，分别是 \u0060--set-xmark\u0060、\u0060--set-mark\u0060、\u0060--and-mark\u0060、\u0060--and-mark\u0060、\u0060--or-mark\u0060 和 \u0060--xor-mark\u0060。在本文用到了前两种，下面将分别为大家介绍。\n\n**\u0060--set-xmark value[\/mask]\u0060**\n\n上面的 \u0060value\u0060 和掩码 \u0060mask\u0060 都是 32 位无符号整数，一般用 16 进制表示。内核设置数据包 nfmark 值的流程分为两步：\n\n1. 首先，内核会先用 mask 预处理数据包原来的 nfmark，处理方法是：如果 mask 的第 N 位（二进制）为 1，则将数据包的 nfmark 第的 N 位（二进制）清零（Zero out） ，如果 mask 的第 N 位为 0，那么数据包的 nfmark 位保持不变\n2. 再用上面预处理后的 nfmark 和 value 做异或运算，得到数据包最后的 nfmark 值。\n\n举个例子：假设我们设置了 \u0060--set-xmark 0x4000\/0xffffffff\u0060，掩码为 \u00600xffffffff\u0060，掩码表示为二进制的话 32 位每一位都是 \u00601\u0060，那么内核首先会将数据包原来的 \u0060nfmark\u0060 所有的位都清零（异或运算，相当于是先把 \u0060nfmark\u0060 置 0），然后再和 value 做异或操作，那么得到的最后的 \u0060nfmark\u0060 值就是 \u00600x4000\u0060。所以，数据包经过这条规则后，它的 nfmark 值就是 \u00600x4000\u0060。\n\n上面的掩码 \u0060mask\u0060 是个可选项，如果没有设置的话，默认为 \u00600xffffffff\u0060。\n\n根据上面的规则，省略 \u0060mask\u0060 的值或者将 \u0060mask\u0060 和 \u0060value\u0060 的值设置成一样可以快速设置数据包的 \u0060nfmark\u0060 值为 \u0060value\u0060。读者可以自己推导一下：\u0060value XOR 0xFFFFFFFF XOR value =value\u0060，\u0060value XOR value XOR value = value\u0060。\n\n**\u0060--set-mark value[\/mask]\u0060**\n\n设置步骤与上文类似。第一步预处理也是将原来的 \u0060nfmark\u0060 与 mask 进行异或运算，第二步不同，该方法是将预处理的 nfmark 和 value 做或（OR）运算。\n\n根据上面的规则，省略 \u0060mask\u0060 的值，或者将 \u0060mask\u0060 与 \u0060value\u0060 值设置成一样可以快速设置数据包的 \u0060nfmark\u0060 值为 \u0060value\u0060。读者可以自己推导一下：\u0060value XOR 0xFFFFFFFF OR value = value\u0060，\u00600 OR value = value\u0060）。\n\n查看 [netfilter 文档](https:\/\/ipset.netfilter.org\/iptables-extensions.man.html#lbDD) 了解详情。\n\n{{\u003c\/callout\u003e}}\n\n通过执行以上 iptables 规则，可以确保 Ambient Mesh 仅拦截 \u0060ztunnel-pods-ips\u0060 IP 集 Pod 中的数据包并给数据包打上 \u00600x100\/0x100\u0060 标记（\u0060nfmark\u0060，格式为 \u0060值\/掩码\u0060，值和掩码都是 32 位的二进制整数，），而不影响其他 Pod。\n\n{{\u003ccallout note \u0022关于 ztunnel-pods-ips IP 集\u0022\u003e}}\n\n\u0060ztunnel-pods-ips\u0060 是由 Istio CNI 创建的 [IP 集（IP Set）](https:\/\/ipset.netfilter.org\/)，这里面保存着该节点上 Ambient Mesh 中的所有 Pod 的 IP 地址。IP 集是 Linux 内核中的一个框架，可由 [ipset](https:\/\/ipset.netfilter.org\/ipset.man.html) 实用程序管理。IP 集可以存储不同类型的数据，例如 IP 地址、网络、（TCP\/UDP）端口号、MAC 地址、接口名称或它们的组合，从而确保在条目与集合匹配时具有闪电般的速度。\n\n{{\u003c\/callout\u003e}}\n\n{{\u003cdetail \u0022用 \u0060iptables -t nat -L\u0060 按顺序查看 iptables 规则，将可以更明显的看到路由路径。\u0022\u003e}}\n\n\u0060\u0060\u0060bash\n$ iptables -t nat -L\nChain PREROUTING (policy ACCEPT)\ntarget     prot opt source               destination\n# 数据包首先进入 ztunnel-PREROUTING 链处理\nztunnel-PREROUTING  all  --  anywhere             anywhere\n# 然后进入 KUBE-SERVICES 链处理\nKUBE-SERVICES  all  --  anywhere             anywhere             \/* kubernetes service portals *\/\n\nChain INPUT (policy ACCEPT)\ntarget     prot opt source               destination         \n\nChain OUTPUT (policy ACCEPT)\ntarget     prot opt source               destination         \nKUBE-SERVICES  all  --  anywhere             anywhere             \/* kubernetes service portals *\/\n\nChain POSTROUTING (policy ACCEPT)\ntarget     prot opt source               destination         \nztunnel-POSTROUTING  all  --  anywhere             anywhere            \nKUBE-POSTROUTING  all  --  anywhere             anywhere             \/* kubernetes postrouting rules *\/\nIP-MASQ    all  --  anywhere             anywhere             \/* ip-masq: ensure nat POSTROUTING directs all non-LOCAL destination traffic to our custom IP-MASQ chain *\/ ADDRTYPE match dst-type !LOCAL\n\n\/* Omit KUBE-SVC chains *\/\n\nChain ztunnel-POSTROUTING (1 references)\ntarget     prot opt source               destination         \nACCEPT     all  --  anywhere             anywhere             mark match 0x100\/0x100\n\nChain ztunnel-PREROUTING (1 references)\ntarget     prot opt source               destination   \n# 通过所有被打上 0x100\/0x100 标记的数据包\nACCEPT     all  --  anywhere             anywhere             mark match 0x100\/0x100\n\u0060\u0060\u0060\n\n{{\u003c\/detail\u003e}}\n\n我们再查看一下该节点的路由规则：\n\n\u0060\u0060\u0060bash\n$ ip rule\n0:      from all lookup local\n100:    from all fwmark 0x200\/0x200 goto 32766\n101:    from all fwmark 0x100\/0x100 lookup 101\n102:    from all fwmark 0x40\/0x40 lookup 102\n103:    from all lookup 100\n32766:  from all lookup main\n32767:  from all lookup default\n\u0060\u0060\u0060\n\n路由表将按顺序执行，第一列表示的是路由表的优先级，第二列表示要查找或跳转的路由表。你会看到所有带有 \u00600x100\/0x100\u0060 标记的数据包将查找 101 路由表。我们再查看一下该路由表：\n\n\u0060\u0060\u0060bash\n$ ip route show table 101\ndefault via 192.168.127.2 dev istioout \n10.4.4.18 dev veth52b75946 scope link \n\u0060\u0060\u0060\n\n你会看到 \u0060101\u0060 路由表中带有关键字 \u0060via\u0060 ，这表示数据包将通过网关传输，查看 [ip route 命令的用法](http:\/\/linux-ip.net\/html\/tools-ip-route.html#tools-ip-route-show)。所有数据包被通过 \u0060istioout\u0060 网卡发送到网关（IP 是 \u0060192.168.127.2\u0060）。另一行表示是当前节点上 ztunnel pod 的路由链路。\n\n{{\u003ccallout note  \u0022关于 101 路由表\u0022\u003e}}\n所谓路由表（Routing Table），指的是路由器或者其他互联网网络设备上存储的表，该表中存有到达特定网络终端的路径。路由器的主要工作就是为经过路由器的每个数据包寻找一条最佳的传输路径，并将该数据有效地传送到目的站点。为了完成这项工作，在路由器中保存着各种传输路径的相关数据，供路由选择时使用，表中包含的信息决定了数据转发的策略。路由表根据其建立的方法，可以分为**动态路由表**和**静态路由表**。\n\n101 路由表是由 Istio CNI 创建的，它的作用是将带有 \u00600x100\/0x00\u0060 fwmark 的数据包转发到 ztunnel 中。\n\n在 Linux 系统中，用户可以自定义编号 1 到 252 的路由表，Linux 系统维护了 4 个路由表：\n\n- 0：系统保留表\n- 253：defulte 表，没特别指定的默认路由都放在改表\n- 254：main 表，没指明路由表的所有路由放在该表，默认表，我们使用 \u0060ip route list\u0060 或 \u0060route -n\u0060 或 \u0060netstat -rn\u0060 查看的路由记录即为 main 表中的记录\n- 255：locale 表，保存本地接口地址，广播地址、NAT 地址 由系统维护，用户不得更改\n\n{{\u003c\/callout\u003e}}\n\n我们再查看一下 \u0060istioout\u0060 网卡的详细信息：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=4 5\u0022\u003e}}\n$ ip -d addr show istioout\n24: istioout: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1410 qdisc noqueue state UNKNOWN group default \n    link\/ether 62:59:1b:ad:79:01 brd ff:ff:ff:ff:ff:ff\n    geneve id 1001 remote 10.4.4.18 ttl auto dstport 6081 noudpcsum udp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535\n    inet 192.168.127.1\/30 brd 192.168.127.3 scope global istioout\n       valid_lft forever preferred_lft forever\n    inet6 fe80::6059:1bff:fead:7901\/64 scope link \n       valid_lft forever preferred_lft forever\n{{\u003c\/highlight\u003e}}\n\nPod A 中的 \u0060istioout\u0060 网卡通过 Geneve tunnel 与 ztunnel A 中的 \u0060pstioout\u0060 网卡连通。\n\n{{\u003ccallout note \u0022关于 istioout 网卡\u0022\u003e}}\n\n\u0060istioout\u0060 是一个 [Geneve（Generic Network Virtualization Encapsulation）](https:\/\/datatracker.ietf.org\/doc\/html\/draft-gross-geneve-00)类型的虚拟网卡，它的 IP 是 \u0060192.168.127.1\u0060，远端是 \u006010.4.2.19\u0060（节点 A 上的 ztunnel Pod 的 IP），网关是 \u0060192.168.127.2\u0060（节点 A 上 ztunnel Pod 中 \u0060pistioout\u0060 网卡的 IP，在下文会看到）。\n\n{{\u003c\/callout\u003e}}\n\n### 检查 Ztunnel A 上的路由规则 {#ztunnel-a-rules}\n\n进入 Ztunnel A Pod，使用 \u0060ip -d a\u0060 命令检查它的网卡信息：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=11-20\u0022\u003e}}\n$ ip -d a\n1: lo: \u003cLOOPBACK,UP,LOWER_UP\u003e mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link\/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 promiscuity 0 minmtu 0 maxmtu 0 numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n    inet 127.0.0.1\/8 scope host lo\n       valid_lft forever preferred_lft forever\n2: eth0@if16: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1460 qdisc noqueue state UP group default \n    link\/ether 06:3e:d1:5d:95:16 brd ff:ff:ff:ff:ff:ff link-netnsid 0 promiscuity 0 minmtu 68 maxmtu 65535 \n    veth numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n    inet 10.4.2.1\/24 brd 10.4.4.255 scope global eth0\n       valid_lft forever preferred_lft forever\n3: pistioin: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1410 qdisc noqueue state UNKNOWN group default qlen 1000\n    link\/ether 06:18:ee:29:7e:e4 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65485 \n    geneve id 1000 remote 10.4.2.1 ttl auto dstport 6081 noudpcsum udp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n    inet 192.168.126.2\/30 scope global pistioin\n       valid_lft forever preferred_lft forever\n4: pistioout: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1410 qdisc noqueue state UNKNOWN group default qlen 1000\n    link\/ether aa:40:40:7c:07:b2 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65485 \n    geneve id 1001 remote 10.4.2.1 ttl auto dstport 6081 noudpcsum udp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n    inet 192.168.127.2\/30 scope global pistioout\n       valid_lft forever preferred_lft forever\n{{\u003c\/highlight\u003e}}\n\n你将发现其中有两个网卡：\n\n- \u0060pistioin\u0060 ：IP 为 \u0060192.168.126.2\u0060\n- \u0060pistioout\u0060：IP 为 \u0060192.168.127.2\u0060\n\n{{\u003ccallout note \u0022关于 pistioin 和 pistioout 网卡\u0022\u003e}}\n\n这两个网卡都是由 ztunnel 中的 init 容器创建的 Geneve 类型的虚拟网卡，其 IP 地址也是固定的，如果你查看 ztunnel 的 YAML 配置将发现其中的网卡创建命令，在此我们按下不表，因为 Ambient 模式还在开发初期，这些启动命令未来可能有很大变化，感兴趣的读者可以自行查阅。\n\n{{\u003c\/callout\u003e}}\n\n自 Pod A 的流量进入 ztunnel 之后，如何对流量进行处理呢？答案是 iptables，查看 ztunnel A 中的 iptables 规则：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=11\u0022\u003e}}\n$ iptables-save\n\/* 省略 *\/\n*mangle\n:PREROUTING ACCEPT [185880:96984381]\n:INPUT ACCEPT [185886:96984813]\n:FORWARD ACCEPT [0:0]\n:OUTPUT ACCEPT [167491:24099839]\n:POSTROUTING ACCEPT [167491:24099839]\n-A PREROUTING -j LOG --log-prefix \u0022mangle pre [ ztunnel-rts54] \u0022\n-A PREROUTING -i pistioin -p tcp -m tcp --dport 15008 -j TPROXY --on-port 15008 --on-ip 127.0.0.1 --tproxy-mark 0x400\/0xfff\n-A PREROUTING -i pistioout -p tcp -j TPROXY --on-port 15001 --on-ip 127.0.0.1 --tproxy-mark 0x400\/0xfff\n-A PREROUTING -i pistioin -p tcp -j TPROXY --on-port 15006 --on-ip 127.0.0.1 --tproxy-mark 0x400\/0xfff\n\/* 省略 *\/\n{{\u003c\/highlight\u003e}}\n\n可以看到 ztunnel A 中的所有发往 \u0060pistioin\u0060 网卡的 TCP 流量透明转发到 \u006015001\u0060 端口（Envoy 的 outbound 端口），并打上了 \u00600x400\/0xfff\u0060 的标记。这个标记可以保证数据包发往正确的网卡。\n\n{{\u003ccallout note \u0022关于 tproxy\u0022\u003e}}\n\n\u0060tproxy\u0060 是 Linux 内核自 2.2 版本以来支持的透明代理（Transparent proxy），其中的 t 代表 transparent，即透明。你需要在内核配置中启用 \u0060NETFILTER_TPROXY\u0060 和策略路由。通过 tproxy，Linux 内核就可以作为一个路由器，将数据包重定向到用户空间。详见 [tproxy 文档](http:\/\/lxr.linux.no\/linux\u002bv3.10\/Documentation\/networking\/tproxy.txt)。\n\n{{\u003c\/callout\u003e}}\n\n查看 Ztunnel A 中的路由表。\n\n\u0060\u0060\u0060bash\n$ ip rule\n0:      from all lookup local\n20000:  from all fwmark 0x400\/0xfff lookup 100\n20001:  from all fwmark 0x401\/0xfff lookup 101\n20002:  from all fwmark 0x402\/0xfff lookup 102\n20003:  from all fwmark 0x4d3\/0xfff lookup 100\n32766:  from all lookup main\n32767:  from all lookup default\n\u0060\u0060\u0060\n\n你会看到所有标记 \u00600x400\/0xfff\u0060 的数据包应用 101 路由表，我们查看该路由表详情：\n\n\u0060\u0060\u0060bash\n$ ip route show table 100\nlocal default dev lo scope host \n\u0060\u0060\u0060\n\n你会看到这是一条本地路由，数据包发送到本地的回环网卡，即 \u0060127.0.0.1\u0060。\n\n以上就是 Pod 中出站流量的透明劫持过程。\n\n## Ztunnel A 上的出站流量路由 {#ztunnel-a-outbound}\n\n出站流量在被劫持到 Ztunnel 上，进入 Envoy 的 15001 端口处理。下面我们来查看 Ztunnel 如何路由出站流量。\n\n注意：Ztunnel 中的 Envoy 过滤器规则与 Sidecar 模式中的 Envoy 过滤器规则完全不同，我们不使用 \u0060istioctl proxy-config\u0060 命令来检视 Listener、Cluster、Endpoint 等配置，而是直接导出 ztunnel 中的 Envoy 完整配置。 \n\n我们直接在自己的本地机器上远程获取 ztunnel A 中的 Envoy 配置：\n\n\u0060\u0060\u0060bash\nkubectl exec -n istio-system ztunnel-hptxk -c istio-proxy -- curl \u0022127.0.0.1:15000\/config_dump?include_eds\u0022\u003eztunnel-a-all-include-eds.json\n\u0060\u0060\u0060\n\n注意：不要使用 \u0060istioctl proxy-config all ztunnel-rts54 -n istio-system\u0060 命令来获取 Envoy 配置，因为这样获取的配置中不包含 EDS 部分。导出的 Json 文件将有上万行，为了便于阅读，建议使用 [fx](https:\/\/github.com\/antonmedv\/fx) 或其他工具来解析该文件。\n\n### ztunnel_outbound 监听器 {#ztunnel_outbound-listener}\n\n在这个 Envoy 配置中包含了该节点上的所有 Pod 访问的流量规则配置，查看 \u0060ztunnel_outbound\u0060 Listener 部分配置（因配置太多，省略部分内容）：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=7 10 11 14 43 59 62 64 69 76 82 85 88-123\u0022\u003e}}\n{\n \u0022name\u0022: \u0022ztunnel_outbound\u0022,\n \u0022active_state\u0022: {\n  \u0022version_info\u0022: \u00222022-11-11T07:10:40Z\/13\u0022,\n  \u0022listener\u0022: {\n   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n   \u0022name\u0022: \u0022ztunnel_outbound\u0022,\n   \u0022address\u0022: {\n    \u0022socket_address\u0022: {\n     \u0022address\u0022: \u00220.0.0.0\u0022,\n     \u0022port_value\u0022: 15001\n    }\n   },\n   \u0022filter_chains\u0022: [{...},...],\n   \u0022use_original_dst\u0022: true,\n   \u0022listener_filters\u0022: [\n    {\n     \u0022name\u0022: \u0022envoy.filters.listener.original_dst\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.listener.original_dst.v3.OriginalDst\u0022\n     }\n    },\n    {\n     \u0022name\u0022: \u0022envoy.filters.listener.original_src\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.listener.original_src.v3.OriginalSrc\u0022,\n      \u0022mark\u0022: 1234\n     }\n    },\n    {\n     \u0022name\u0022: \u0022envoy.filters.listener.workload_metadata\u0022,\n     \u0022config_discovery\u0022: {\n      \u0022config_source\u0022: {\n       \u0022ads\u0022: {},\n       \u0022initial_fetch_timeout\u0022: \u002230s\u0022\n      },\n      \u0022type_urls\u0022: [\n       \u0022type.googleapis.com\/istio.telemetry.workloadmetadata.v1.WorkloadMetadataResources\u0022\n      ]\n     }\n    }\n   ],\n   \u0022transparent\u0022: true,\n   \u0022socket_options\u0022: [\n    {\n     \u0022description\u0022: \u0022Set socket mark to packets coming back from outbound listener\u0022,\n     \u0022level\u0022: \u00221\u0022,\n     \u0022name\u0022: \u002236\u0022,\n     \u0022int_value\u0022: \u00221025\u0022\n    }\n   ],\n   \u0022access_log\u0022: [{...}],\n   \u0022default_filter_chain\u0022: {\u0022filters\u0022: [...], ...},\n   \u0022filter_chain_matcher\u0022: {\n    \u0022matcher_tree\u0022: {\n     \u0022input\u0022: {\n      \u0022name\u0022: \u0022port\u0022,\n      \u0022typed_config\u0022: {\n       \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.matching.common_inputs.network.v3.DestinationPortInput\u0022\n      }\n     },\n     \u0022exact_match_map\u0022: {\n      \u0022map\u0022: {\n       \u002215001\u0022: {\n        \u0022action\u0022: {\n         \u0022name\u0022: \u0022BlackHoleCluster\u0022,\n         \u0022typed_config\u0022: {\n          \u0022@type\u0022: \u0022type.googleapis.com\/google.protobuf.StringValue\u0022,\n          \u0022value\u0022: \u0022BlackHoleCluster\u0022\n         }\n        }\n       }\n      }\n     }\n    },\n    \u0022on_no_match\u0022: {\n     \u0022matcher\u0022: {\n      \u0022matcher_tree\u0022: {\n       \u0022input\u0022: {\n        \u0022name\u0022: \u0022source-ip\u0022,\n        \u0022typed_config\u0022: {\n         \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.matching.common_inputs.network.v3.SourceIPInput\u0022\n        }\n       },\n       \u0022exact_match_map\u0022: {\n        \u0022map\u0022: {\n         \u002210.168.15.222\u0022: {...},\n         \u002210.4.4.19\u0022: {\n          \u0022matcher\u0022: {\n           \u0022matcher_tree\u0022: {\n            \u0022input\u0022: {\n             \u0022name\u0022: \u0022ip\u0022,\n             \u0022typed_config\u0022: {\n              \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.matching.common_inputs.network.v3.DestinationIPInput\u0022\n             }\n            },\n            \u0022exact_match_map\u0022: {\n             \u0022map\u0022: {\n              \u002210.8.4.226\u0022: {\n               \u0022matcher\u0022: {\n                \u0022matcher_tree\u0022: {\n                 \u0022input\u0022: {\n                  \u0022name\u0022: \u0022port\u0022,\n                  \u0022typed_config\u0022: {\n                   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.matching.common_inputs.network.v3.DestinationPortInput\u0022\n                  }\n                 },\n                 \u0022exact_match_map\u0022: {\n                  \u0022map\u0022: {\n                   \u00229080\u0022: {\n                    \u0022action\u0022: {\n                     \u0022name\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_http_productpage.default.svc.cluster.local_outbound_internal\u0022,\n                     \u0022typed_config\u0022: {\n                      \u0022@type\u0022: \u0022type.googleapis.com\/google.protobuf.StringValue\u0022,\n                      \u0022value\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_http_productpage.default.svc.cluster.local_outbound_internal\u0022\n                     }\n                    }\n                   }\n                  }\n                 }\n                }\n               }\n              },\n              {...}\n             }\n            }\n           }\n          }\n         },\n         \u002210.4.4.7\u0022: {...},\n         \u002210.4.4.11\u0022: {...},\n        }\n       }\n      },\n      \u0022on_no_match\u0022: {\n       \u0022action\u0022: {\n        \u0022name\u0022: \u0022PassthroughFilterChain\u0022,\n        \u0022typed_config\u0022: {\n         \u0022@type\u0022: \u0022type.googleapis.com\/google.protobuf.StringValue\u0022,\n         \u0022value\u0022: \u0022PassthroughFilterChain\u0022\n        }\n       }\n      }\n     }\n    }\n   }\n  },\n  \u0022last_updated\u0022: \u00222022-11-11T07:33:10.485Z\u0022\n }\n}\n{{\u003c\/highlight\u003e}}\n\n说明：\n- 第 10、11、59、62、64、69、76、82、85 行：Envoy 监听 15001 端口，处理内核中使用 tproxy 转发的流量；对于目的地是 15001 端口的数据包直接抛弃，对于目的地是其他端口的流量再根据源 IP 地址匹配决定数据包去向；\n- 第 43 行：使用 \u0060IP_TRANSPARENT\u0060 套接字选项，开启 tproxy 透明代理，转发目的地非 ztunnel IP 的流量包；\n-  第 88 到 123 行：根据源 IP（\u006010.4.4.19\u0060 是 Pod A 的 IP）、目的 IP（\u006010.8.14.226\u0060 是服务 B 的 Cluster IP）和端口（9080）规则匹配，数据包将被发往 \u0060spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_http_productpage.default.svc.cluster.local_outbound_internal\u0060 集群。\n\n### Sleep 集群\n\n我们再查看一下该集群的配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=5 6 18 23-37\u0022\u003e}}\n{\n \u0022version_info\u0022: \u00222022-11-08T06:40:06Z\/63\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_http_productpage.default.svc.cluster.local_outbound_internal\u0022,\n  \u0022type\u0022: \u0022EDS\u0022,\n  \u0022eds_cluster_config\u0022: {\n   \u0022eds_config\u0022: {\n    \u0022ads\u0022: {},\n    \u0022initial_fetch_timeout\u0022: \u00220s\u0022,\n    \u0022resource_api_version\u0022: \u0022V3\u0022\n   }\n  },\n  \u0022transport_socket_matches\u0022: [\n   {\n    \u0022name\u0022: \u0022internal_upstream\u0022,\n    \u0022match\u0022: {\n     \u0022tunnel\u0022: \u0022h2\u0022\n    },\n    \u0022transport_socket\u0022: {\n     \u0022name\u0022: \u0022envoy.transport_sockets.internal_upstream\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.internal_upstream.v3.InternalUpstreamTransport\u0022,\n      \u0022passthrough_metadata\u0022: [\n       {\n        \u0022kind\u0022: {\n         \u0022host\u0022: {}\n        },\n        \u0022name\u0022: \u0022tunnel\u0022\n       },\n       {\n        \u0022kind\u0022: {\n         \u0022host\u0022: {}\n        },\n        \u0022name\u0022: \u0022istio\u0022\n       }\n      ],\n      \u0022transport_socket\u0022: {\n       \u0022name\u0022: \u0022envoy.transport_sockets.raw_buffer\u0022,\n       \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.raw_buffer.v3.RawBuffer\u0022\n       }\n      }\n     }\n    }\n   },\n   {\n    \u0022name\u0022: \u0022tlsMode-disabled\u0022,\n    \u0022match\u0022: {},\n    \u0022transport_socket\u0022: {\n     \u0022name\u0022: \u0022envoy.transport_sockets.raw_buffer\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.raw_buffer.v3.RawBuffer\u0022\n     }\n    }\n   }\n  ]\n },\n \u0022last_updated\u0022: \u00222022-11-08T06:40:06.619Z\u0022\n}\n{{\u003c\/highlight\u003e}}\n\n说明：\n\n- 第 6 行：该 Cluster 配置使用 EDS 获取端点\n- 第 18 行：对所有具有 \u0060tunnel: h2\u0060 元数据的字节流应用 [\u0060InternalUpstreamTransport\u0060](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/api-v3\/extensions\/transport_sockets\/internal_upstream\/v3\/internal_upstream.proto#envoy-v3-api-msg-extensions-transport-sockets-internal-upstream-v3-internalupstreamtransport)，用于内部地址，定义位于同一代理实例中的环回用户空间 socket。除了常规字节流之外，该扩展还允许跨用户空间 socket 传递额外的结构化状态（\u0060passthrough_metadata\u0060）。目的是促进下游过滤器和上游内部连接之间的通信。与上游连接共享的所有过滤器状态对象也通过此传输 socket 与下游内部连接共享。\n- 第 23 到 37 行：向上游传递的结构化数据；\n\n### Sleep 集群的端点 {#sleep-endpoints}\n\n我们再检查下 EDS，你会发现在众多的 \u0060endpoint_config\u0060 中有这样一条：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=4 13 20-30\u0022\u003e}}\n{\n \u0022endpoint_config\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.endpoint.v3.ClusterLoadAssignment\u0022,\n  \u0022cluster_name\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep_to_http_productpage.default.svc.cluster.local_outbound_internal\u0022,\n  \u0022endpoints\u0022: [\n   {\n    \u0022locality\u0022: {},\n    \u0022lb_endpoints\u0022: [\n     {\n      \u0022endpoint\u0022: {\n       \u0022address\u0022: {\n        \u0022envoy_internal_address\u0022: {\n         \u0022server_listener_name\u0022: \u0022outbound_tunnel_lis_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022,\n         \u0022endpoint_id\u0022: \u002210.4.3.20:9080\u0022\n        }\n       },\n       \u0022health_check_config\u0022: {}\n      },\n      \u0022health_status\u0022: \u0022HEALTHY\u0022,\n      \u0022metadata\u0022: {\n       \u0022filter_metadata\u0022: {\n        \u0022envoy.transport_socket_match\u0022: {\n         \u0022tunnel\u0022: \u0022h2\u0022\n        },\n        \u0022tunnel\u0022: {\n         \u0022address\u0022: \u002210.4.3.20:15008\u0022,\n         \u0022destination\u0022: \u002210.4.3.20:9080\u0022\n        }\n       }\n      },\n      \u0022load_balancing_weight\u0022: 1\n     }\n    ]\n   }\n  ],\n  \u0022policy\u0022: {\n   \u0022overprovisioning_factor\u0022: 140\n  }\n }\n}\n{{\u003c\/highlight\u003e}}\n\n说明：\n\n- 第 4 行：截止 2022 年 11 月 14 日，实际在导出 Envoy 配置的时候并没有该字段，但是理应有这个字段，否则无法判断 Endpoint 属于哪个 Cluster；\n- 第 13 行：该端点的地址是一个 \u0060envoy_internal_address\u0060，Envoy 内部监听器 \u0060outbound_tunnel_lis_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0060；\n- 第 20 - 30 行：定义过滤器元数据，使用 HBONE 隧道传递给 Envoy 内部监听器；\n\n{{\u003ccallout warning \u0022关于 endpoint_config 中未显示 cluster_name 字段的问题\u0022\u003e}}\n\n这里的 [\u0060endpoint_config\u0060](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/api-v3\/config\/endpoint\/v3\/endpoint.proto) 中缺少了必选的 \u0060cluster_name\u0060 字段，这可能是 Ambient 模式的一个 bug 导致了在导出 Envoy 的配置时缺少了该字段。我在 GItHub 上创建了一个 Issue 来追踪这个问题，详见 [Istio Issue-42022](https:\/\/github.com\/istio\/istio\/issues\/42022)。\n\n{{\u003c\/callout\u003e}}\n\n### 通过 Envoy 内部监听器建立 HBONE 隧道 {#sleep-internal-upstream}\n\n我们再看下这个监听器 \u0060outbound_tunnel_lis_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0060：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=16 18-28 40\u0022\u003e}}\n{\n \u0022name\u0022: \u0022outbound_tunnel_lis_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022,\n \u0022active_state\u0022: {\n  \u0022version_info\u0022: \u00222022-11-08T06:40:06Z\/63\u0022,\n  \u0022listener\u0022: {\n   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n   \u0022name\u0022: \u0022outbound_tunnel_lis_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022,\n   \u0022filter_chains\u0022: [\n    {\n     \u0022filters\u0022: [\n      {\n       \u0022name\u0022: \u0022envoy.filters.network.tcp_proxy\u0022,\n       \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.tcp_proxy.v3.TcpProxy\u0022,\n        \u0022stat_prefix\u0022: \u0022outbound_tunnel_lis_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022,\n        \u0022cluster\u0022: \u0022outbound_tunnel_clus_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022,\n        \u0022access_log\u0022: [{...}, ...],\n        \u0022tunneling_config\u0022: {\n         \u0022hostname\u0022: \u0022%DYNAMIC_METADATA(tunnel:destination)%\u0022,\n         \u0022headers_to_add\u0022: [\n          {\n           \u0022header\u0022: {\n            \u0022key\u0022: \u0022x-envoy-original-dst-host\u0022,\n            \u0022value\u0022: \u0022%DYNAMIC_METADATA([\\\u0022tunnel\\\u0022, \\\u0022destination\\\u0022])%\u0022\n           }\n          }\n         ]\n        }\n       }\n      }\n     ]\n    }\n   ],\n   \u0022use_original_dst\u0022: false,\n   \u0022listener_filters\u0022: [\n    {\n     \u0022name\u0022: \u0022set_dst_address\u0022,\n     \u0022typed_config\u0022: {\n      \u0022@type\u0022: \u0022type.googleapis.com\/xds.type.v3.TypedStruct\u0022,\n      \u0022type_url\u0022: \u0022type.googleapis.com\/istio.set_internal_dst_address.v1.Config\u0022,\n      \u0022value\u0022: {}\n     }\n    }\n   ],\n   \u0022internal_listener\u0022: {}\n  },\n  \u0022last_updated\u0022: \u00222022-11-08T06:40:06.750Z\u0022\n }\n}\n{{\u003c\/highlight\u003e}}\n\n说明：\n\n- 第 14 行：数据包将被转发到 \u0060outbound_tunnel_clus_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0060 集群；\n- 第 18 - 28 行： [\u0060tunneling_config\u0060](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/api-v3\/extensions\/filters\/network\/tcp_proxy\/v3\/tcp_proxy.proto#envoy-v3-api-msg-extensions-filters-network-tcp-proxy-v3-tcpproxy-tunnelingconfig) ，用来配置上游 HTTP CONNECT 隧道。另外该监听器中的 \u0060TcpProxy\u0060 过滤器将流量传给上游 \u0060outbound_tunnel_clus_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0060 集群。TCP 过滤器上设置了 HTTP CONNECT 隧道（承载发送到 \u006010.4.3.20:9080\u0060 的流量），供 \u0060productpage\u0060 所在节点的 ztunnel 使用。有多少个端点，就会创建多少条隧道。HTTP 隧道是 Ambient 组件之间安全通信的承载协议。同时在隧道中的数据包添加了 \u0060x-envoy-original-dst-host\u0060 header，根据上一步 EDS 中选择的端点的 \u0060metadata\u0060 里的参数设置目的地址。前面 EDS  选择的端点是 \u006010.4.3.20:9080\u0060 ，那么这里的 tunnel 监听器就会 header 的值设置为 \u006010.4.3.20:9080\u0060，请留意这个 header，它会在隧道的另一端被用到；\n- 第 40 行：监听器中首先执行监听器过滤器，\u0060set_dst_address\u0060 过滤器将上游地址设置为下游的目的地址。\n\n{{\u003ccallout note \u0022关于 HBONE 隧道\u0022\u003e}}\n\nHBONE 是 HTTP-Based Overlay Network Environment 的缩写，是一种使用 HTTP 协议提供隧道能力的方法。客户端向 HTTP 代理服务器发送 HTTP CONNECT 请求（其中包含了目的地址）以建立隧道，代理服务器代表客户端与目的地建立 TCP 连接，然后客户端就可以通过代理服务器透明的传输 TCP 数据流到目的服务器。在 Ambient 模式中，Ztunnel（其中的 Envoy）实际上是充当了透明代理，它使用 [Envoy Internal Listener](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/other_features\/internal_listener) 来接收 HTTP CONNECT 请求和传递 TCP 流给上游集群。\n\n{{\u003c\/callout\u003e}}\n\n### Sleep 集群的 HBONE 隧道端点 {#sleep-tunnel-cluster}\n\n我们再查看一下 \u0060outbound_tunnel_clus_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0060 集群的配置：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=6 22-41 45-47\u0022\u003e}}\n {\n \u0022version_info\u0022: \u00222022-11-11T07:30:10Z\/37\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022outbound_pod_tunnel_clus_spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep\u0022,\n  \u0022type\u0022: \u0022ORIGINAL_DST\u0022,\n  \u0022connect_timeout\u0022: \u00222s\u0022,\n  \u0022lb_policy\u0022: \u0022CLUSTER_PROVIDED\u0022,\n  \u0022cleanup_interval\u0022: \u002260s\u0022,\n  \u0022transport_socket\u0022: {\n   \u0022name\u0022: \u0022envoy.transport_sockets.tls\u0022,\n   \u0022typed_config\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.transport_sockets.tls.v3.UpstreamTlsContext\u0022,\n    \u0022common_tls_context\u0022: {\n     \u0022tls_params\u0022: {\n      \u0022tls_minimum_protocol_version\u0022: \u0022TLSv1_3\u0022,\n      \u0022tls_maximum_protocol_version\u0022: \u0022TLSv1_3\u0022\n     },\n     \u0022alpn_protocols\u0022: [\n      \u0022h2\u0022\n     ],\n     \u0022tls_certificate_sds_secret_configs\u0022: [\n      {\n       \u0022name\u0022: \u0022spiffe:\/\/cluster.local\/ns\/default\/sa\/sleep~sleep-5644bdc767-2dfg7~85c8c34e-7ae3-4d29-9582-0819e2b10c69\u0022,\n       \u0022sds_config\u0022: {\n        \u0022api_config_source\u0022: {\n         \u0022api_type\u0022: \u0022GRPC\u0022,\n         \u0022grpc_services\u0022: [\n          {\n           \u0022envoy_grpc\u0022: {\n            \u0022cluster_name\u0022: \u0022sds-grpc\u0022\n           }\n          }\n         ],\n         \u0022set_node_on_first_message_only\u0022: true,\n         \u0022transport_api_version\u0022: \u0022V3\u0022\n        },\n        \u0022resource_api_version\u0022: \u0022V3\u0022\n       }\n      }\n     ]\n    }\n   }\n  },\n  \u0022original_dst_lb_config\u0022: {\n   \u0022upstream_port_override\u0022: 15008\n  },\n  \u0022typed_extension_protocol_options\u0022: {\n   \u0022envoy.extensions.upstreams.http.v3.HttpProtocolOptions\u0022: {\n    \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.upstreams.http.v3.HttpProtocolOptions\u0022,\n    \u0022explicit_http_config\u0022: {\n     \u0022http2_protocol_options\u0022: {\n      \u0022allow_connect\u0022: true\n     }\n    }\n   }\n  }\n },\n \u0022last_updated\u0022: \u00222022-11-11T07:30:10.754Z\u0022\n}\n{{\u003c\/highlight\u003e}}\n\n说明：\n\n- 第 6 行：该集群的类型是 \u0060ORIGINAL_DST\u0060，即前文中 EDS 获取到的地址 \u006010.4.3.20:9080\u0060；\n- 第 22 - 41 行：配置了上游的 TLS 证书；\n- 第 45 - 48 行：将上游端口修改为 15008；\n\n以上就是使用 tproxy 和 HBONE 隧道实现的出站流量透明劫持的全过程。\n\n## Inbound 流量劫持 {#inbound}\n\n节点 B 接收节点 A 对 \u006010.4.3.20:15008\u0060 的请求。Ambient 模式的入站流量劫持与出站流量类似，同样使用 tproxy 和 HBONE 实现透明流量劫持。\n\nAmbient mesh 的 pod 入站流量的透明流量劫持流程如下：\n\n1. Istio CNI 在节点上创建 \u0060istioin\u0060 网卡和 iptables 规则，将 Ambient mesh 中的 Pod IP 加入 IP 集，并通过 netfilter \u0060nfmark\u0060 标记和路由规则，将 Ambient mesh 中的出站流量通过 Geneve 隧道透明劫持到 \u0060pistioin\u0060 虚拟机网卡；\n2. ztunnel 中的 init 容器创建 iptables 规则，将 \u0060pistioin\u0060 网卡中的所有流量转发到 ztunnel 中的 Envoy 代理的 15008 端口；\n3. Envoy 对数据包进行处理后转发给 Pod B。\n\n因为操作步骤与上文中的检查出站流量时相同，因此下文将省略部分输出。\n\n### 检查节点 B 上的路由规则 {#node-b-rules}\n\n登录到服务 B 所在的节点 B，查看节点上的 iptables：\n\n\u0060\u0060\u0060bash\n$ iptables-save\n\/* 省略 *\/\n-A ztunnel-PREROUTING -m mark --mark 0x200\/0x200 -j RETURN\n-A ztunnel-PREROUTING -p tcp -m set --match-set ztunnel-pods-ips src -j MARK --set-xmark 0x100\/0x100\n\/* 省略 *\/\n\u0060\u0060\u0060\n\n你将看到在前文中提到的给所有 \u0060ztunnel-pods-ips\u0060 IP 集中 Pod 发送的数据包打上 \u00600x100\/0x100\u0060 标记的上一条命令：给所有数据包打上 \u00600x200\/0x200\u0060 标记，然后继续执行 iptables。\n\n查看节点 B 上的路由表：\n\n\u0060\u0060\u0060bash\n0:      from all lookup local\n100:    from all fwmark 0x200\/0x200 goto 32766\n101:    from all fwmark 0x100\/0x100 lookup 101\n102:    from all fwmark 0x40\/0x40 lookup 102\n103:    from all lookup 100\n32766:  from all lookup main\n32767:  from all lookup default\n\u0060\u0060\u0060\n\n所有 Ambient Mesh 节点中的路由表数量和规则是一样的，路由表规则将按顺序执行，首先查找 \u0060local\u0060 表，然后所有带有 \u00600x200\/0x200\u0060 标记的数据包将首先跳转到 \u0060main\u0060 表（其中定义了 veth 路由），然后查找 \u0060100\u0060 表，在 \u0060100\u0060 表中有以下规则：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=8\u0022\u003e}}\n$ ip route show table 100\n10.4.3.14 dev veth28865c45 scope link \n10.4.3.15 via 192.168.126.2 dev istioin src 10.4.3.1\n10.4.3.16 via 192.168.126.2 dev istioin src 10.4.3.1\n10.4.3.17 via 192.168.126.2 dev istioin src 10.4.3. \n10.4.3.18 via 192.168.126.2 dev istioin src 10.4.3. \n10.4.3.19 via 192.168.126.2 dev istioin src 10.4.3.1\n10.4.3.20 via 192.168.126.2 dev istioin src 10.4.3.1\n{{\u003c\/highlight\u003e}}\n\n你会看到发往 \u006010.4.3.20\u0060 的数据包将被路由到 \u0060istioin\u0060 网卡上的 \u0060192.168.126.2\u0060 网关。\n\n查看 \u0060istioin\u0060 网卡的详细信息：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=4 5\u0022\u003e}}\n$ ip -d addr show istioin \n17: istioin: \u003cBROADCAST,MULTICAST,UP,LOWER_UP\u003e mtu 1410 qdisc noqueue state UNKNOWN group default \n    link\/ether 36:2a:2f:f1:5c:97 brd ff:ff:ff:ff:ff:ff promiscuity 0 minmtu 68 maxmtu 65485 \n    geneve id 1000 remote 10.4.3.14 ttl auto dstport 6081 noudpcsum udp6zerocsumrx numtxqueues 1 numrxqueues 1 gso_max_size 65536 gso_max_segs 65535 \n    inet 192.168.126.1\/30 brd 192.168.126.3 scope global istioin\n       valid_lft forever preferred_lft forever\n    inet6 fe80::342a:2fff:fef1:5c97\/64 scope link \n       valid_lft forever preferred_lft forever\n{{\u003c\/highlight\u003e}}\n\n从输出中可以看到，\u0060istioin\u0060 是一个 Geneve 类型虚拟网卡，它创建了一个 Geneve 隧道，远端的 IP 是 \u006010.4.3.14 \u0060，这是 Ztunnel B 的 Pod IP。\n\n### 检查 Ztunnel B Pod 上的路由规则 {#ztunnel-b-rules}\n\n进入 Ztunnel B Pod，使用 \u0060ip -d a\u0060 命令检查它的网卡信息，你会看到有一个 \u0060pistioout\u0060 网卡，它的 IP 为 \u0060192.168.127.2\u0060，这正是与 \u0060istioout\u0060 虚拟网卡建立的 Geneve 隧道的远端。\n\n使用 \u0060iptables-save\u0060 查看 Pod 内的 iptables 规则，你会看到：\n\n\u0060\u0060\u0060bash\n-A PREROUTING -i pistioin -p tcp -m tcp --dport 15008 -j TPROXY --on-port 15008 --on-ip 127.0.0.1 --tproxy-mark 0x400\/0xfff\n-A PREROUTING -i pistioin -p tcp -j TPROXY --on-port 15006 --on-ip 127.0.0.1 --tproxy-mark 0x400\/0xfff\n\u0060\u0060\u0060\n\n所有发往 \u006010.4.3.20:15008\u0060 的流量将使用 tproxy 被路由到 15008 端口。\n\n{{\u003ccallout note \u0022关于 15006 和 15008 端口\u0022\u003e}}\n\n- 15006 端口用于处理非加密的（plain）TCP 数据包。\n- 15008 端口用于处理加密的（TLS）TCP 数据包。\n\n{{\u003c\/callout\u003e}}\n\n以上就是 Pod 中入站流量的透明劫持过程。\n\n## Ztunnel B 上的入站流量路由 {#ztunnel-b-inbound}\n\n出站的 TLS 加密流量在被劫持到 Ztunnel 上，进入 Envoy 的 15008 端口处理。下面我们来查看 Ztunnel 如何路由入站流量。\n\n我们直接在自己的本地机器上远程获取 ztunnel B 中的 Envoy 配置：\n\n\u0060\u0060\u0060bash\nkubectl exec -n istio-system \tztunnel-z4qmh -c istio-proxy -- curl \u0022127.0.0.1:15000\/config_dump?include_eds\u0022\u003eztunnel-b-all-include-eds.json\n\u0060\u0060\u0060\n\n### ztunnel_inbound 监听器 {#ztunnel_inbound-listener}\n\n查看 \u0060ztunnel_inbound\u0060 监听器的详细信息：\n\n{{\u003chighlight json \u0022linenos=table,hl_lines=7 10 11 17-22 39-65 78-82\u0022\u003e}}\n\n{\n \u0022name\u0022: \u0022ztunnel_inbound\u0022,\n \u0022active_state\u0022: {\n  \u0022version_info\u0022: \u00222022-11-11T07:12:01Z\/16\u0022,\n  \u0022listener\u0022: {\n   \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.listener.v3.Listener\u0022,\n   \u0022name\u0022: \u0022ztunnel_inbound\u0022,\n   \u0022address\u0022: {\n    \u0022socket_address\u0022: {\n     \u0022address\u0022: \u00220.0.0.0\u0022,\n     \u0022port_value\u0022: 15008\n    }\n   },\n   \u0022filter_chains\u0022: [\n    {\n     \u0022filter_chain_match\u0022: {\n      \u0022prefix_ranges\u0022: [\n       {\n        \u0022address_prefix\u0022: \u002210.4.3.20\u0022,\n        \u0022prefix_len\u0022: 32\n       }\n      ]\n     },\n     \u0022filters\u0022: [\n      {\n       \u0022name\u0022: \u0022envoy.filters.network.rbac\u0022,\n       \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.rbac.v3.RBAC\u0022,\n        \u0022rules\u0022: {...},\n        \u0022stat_prefix\u0022: \u0022tcp.\u0022,\n        \u0022shadow_rules_stat_prefix\u0022: \u0022istio_dry_run_allow_\u0022\n       }\n      },\n      {\n       \u0022name\u0022: \u0022envoy.filters.network.http_connection_manager\u0022,\n       \u0022typed_config\u0022: {\n        \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\u0022,\n        \u0022stat_prefix\u0022: \u0022inbound_hcm\u0022,\n        \u0022route_config\u0022: {\n         \u0022name\u0022: \u0022local_route\u0022,\n         \u0022virtual_hosts\u0022: [\n          {\n           \u0022name\u0022: \u0022local_service\u0022,\n           \u0022domains\u0022: [\n            \u0022*\u0022\n           ],\n           \u0022routes\u0022: [\n            {\n             \u0022match\u0022: {\n              \u0022connect_matcher\u0022: {}\n             },\n             \u0022route\u0022: {\n              \u0022cluster\u0022: \u0022virtual_inbound\u0022,\n              \u0022upgrade_configs\u0022: [\n               {\n                \u0022upgrade_type\u0022: \u0022CONNECT\u0022,\n                \u0022connect_config\u0022: {}\n               }\n              ]\n             }\n            }\n           ]\n          }\n         ]\n        },\n        \u0022http_filters\u0022: [\n         {\n          \u0022name\u0022: \u0022envoy.filters.http.router\u0022,\n          \u0022typed_config\u0022: {\n           \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.http.router.v3.Router\u0022\n          }\n         }\n        ],\n        \u0022http2_protocol_options\u0022: {\n         \u0022allow_connect\u0022: true\n        },\n        \u0022access_log\u0022: [{...}],\n        \u0022upgrade_configs\u0022: [\n         {\n          \u0022upgrade_type\u0022: \u0022CONNECT\u0022\n         }\n        ]\n       }\n      }\n     ],\n     \u0022transport_socket\u0022: {\n      \u0022name\u0022: \u0022envoy.transport_sockets.tls\u0022,\n      \u0022typed_config\u0022: {...} \n     },\n     \u0022name\u0022: \u0022inbound_10.4.3.20\u0022\n    },\n    {...}\n   ],\n   \u0022use_original_dst\u0022: true,\n   \u0022listener_filters\u0022: [{},...],\n   \u0022transparent\u0022: true,\n   \u0022socket_options\u0022: [{...}}],\n   \u0022access_log\u0022: [{...} ]\n  },\n  \u0022last_updated\u0022: \u00222022-11-14T03:54:07.040Z\u0022\n }\n}\n\n{{\u003c\/highlight\u003e}}\n\n从上面的配置中可以看出：\n\n- 发往 \u006010.4.3.20\u0060 的流量将被路由到 \u0060virtual_inbound\u0060 集群；\n- 第 78 - 82 行：[\u0060upgrade_type: \u0022CONNECT\u0022\u0060](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/api-v3\/config\/route\/v3\/route_components.proto#config-route-v3-routeaction-upgradeconfig) 为 Envoy 的 HCM 启用 HTTP Connect 隧道，将该隧道中的 TCP 数据发送到上游；\n\n### virtual_inbound 集群 {#virtual_inbound-cluster}\n\n查看 \u0060virtual_inbound\u0060 集群的信息：\n\n{{\u003chighlight bash \u0022linenos=table,hl_lines=6 9\u0022\u003e}}\n\n{\n \u0022version_info\u0022: \u00222022-11-11T07:10:40Z\/13\u0022,\n \u0022cluster\u0022: {\n  \u0022@type\u0022: \u0022type.googleapis.com\/envoy.config.cluster.v3.Cluster\u0022,\n  \u0022name\u0022: \u0022virtual_inbound\u0022,\n  \u0022type\u0022: \u0022ORIGINAL_DST\u0022,\n  \u0022lb_policy\u0022: \u0022CLUSTER_PROVIDED\u0022,\n  \u0022original_dst_lb_config\u0022: {\n   \u0022use_http_header\u0022: true\n  }\n },\n \u0022last_updated\u0022: \u00222022-11-11T07:10:42.111Z\u0022\n}\n\n{{\u003c\/highlight\u003e}}\n\n说明：\n\n- 第 7 行：该集群的类型是 \u0060ORIGINAL_DST\u0060，表示使用下游的原始目的地作为路由目的地，即 \u006010.4.3.20:15008\u0060，显然这个地址中的端口不正确；\n- 第 9 行：[\u0060use_http_header\u0060](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/api-v3\/config\/cluster\/v3\/cluster.proto#config-cluster-v3-cluster-originaldstlbconfig) 为 \u0060true\u0060 时将使用 HTTP header [\u0060x-envoy-original-dst-host\u0060](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/configuration\/http\/http_conn_man\/headers#config-http-conn-man-headers-x-envoy-original-dst-host) 作为目的地址，而这个 header [在出站的 Ztunnel 中已设置](\/#sleep-internal-upstream)为 \u006010.4.3.20:9080\u0060，它将覆盖之前设置的目的地址；\n\n至此，入站流量被 ztunnel 准确地路由到了目的地。以上就是 Ambient 模式中不同节点间 L4 流量劫持和路由流程。\n\n## 总结 {#summary}\n\n为了方便演示，本文中展示的是不同节点上的服务 L4 网络访问数据包的路径，即使两个服务在同一个节点上路径也是类似的。根据本文中提供的操作说明，读者可以在自己的环境中尝试。Istio 的 Ambient 模式还在初级阶段，在笔者测试过程中，也发现导出的 Envoy 配置中 EDS 缺少 \u0060cluster_name\u0060 字段的问题（[Issue Istio-42022](https:\/\/github.com\/istio\/istio\/issues\/42022)）。另外 Ambient 模式使用 Istio CNI 在节点中注入 iptables 规则，通过设置 \u0060nfmark\u0060 的方式拦截 Pod 的流量到 Ztunnel 中，这种方式可能造成对其他 CNI 的兼容性问题，[Merbridge](https:\/\/merbridge.io\/zh\/blog\/2022\/11\/11\/ambient-mesh-support\/) 项目正在寻求使用 eBPF 来绕过 IPtables，从而无需安装 Istio CNI，这样也就不会存在 CNI 兼容性问题。\n\n在了解了 L4 流量路径之后，今后笔者会再分享 Ambient 模式中的 L7 流量路径，欢迎关注。\n\n## 参考{#reference}\n\n- [安装 Ambient Mesh - istio.io](https:\/\/istio.io\/latest\/blog\/2022\/get-started-ambient\/)\n- [深入 Ambient Mesh - 流量路径 - mp.weixin.qq.com](https:\/\/mp.weixin.qq.com\/s\/PpP0pmxdJR8PknHeR-pVHQ)\n- [一文读懂 Ambient Mesh 七层服务治理 - mp.weixin.qq.com](https:\/\/mp.weixin.qq.com\/s\/TXMyxbzBSfuYNquOZJmZTg)\n- [深度剖析！Istio 共享代理新模式 Ambient Mesh - mp.weixin.qq.com](https:\/\/mp.weixin.qq.com\/s\/B0q73ACAvmY4SjW42A2GVw)\n- [Istio Ambient 模式流量管理实现机制详解（一）- zhaohuabing.com](https:\/\/www.zhaohuabing.com\/post\/2022-09-11-ambient-deep-dive-1\/)\n- [Istio Ambient 模式流量管理实现机制详解（二） - zhaohuabing.com](https:\/\/www.zhaohuabing.com\/post\/2022-09-11-ambient-deep-dive-2\/)\n- [Istio Ambient 模式流量管理实现机制详解（三）- zhaohuabing.com](https:\/\/www.zhaohuabing.com\/post\/2022-10-17-ambient-deep-dive-3\/)\n- [Merbridge 支持 Ambient Mesh，无惧 CNI 兼容性！- merbridge.io](https:\/\/merbridge.io\/zh\/blog\/2022\/11\/11\/ambient-mesh-support\/)\n', '\/blog\/ambient-mesh-l4-traffic-path\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文以图示和实际操作的形式详细介绍了 Ambient Mesh 中的透明流量劫持和四层（L4）流量路径。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/envoy-gateway-release/">Envoy Gateway 首个正式开源版本介绍</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2022/10/21</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/envoy"> 
             Envoy
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Envoy Gateway 首个正式开源版本介绍', '今天 Envoy Gateway v0.2 发布，本文将为你介绍什么是 Envoy Gateway，它的架构、快速入门和使用指南。', '\n今年五月 Envoy 社区宣布成立一个新的项目 [Envoy Gateway](https:\/\/github.com\/envoyproxy\/gateway)，经过五个月时间的开发，今天它的首个开源版本 v0.2 发布，本文将为你介绍什么是 Envoy Gateway，它的架构、快速入门和使用指南。\n\n## 什么是 Envoy Gateway？{#what-is-envoy-gateway}\n\nEnvoy Gateway 是一个用于管理 Envoy Proxy 的开源项目，可单独使用或作为 Kubernetes 中应用的网关。它通过了 Gateway API 核心一致性测试，使用 [Gateway API](https:\/\/gateway-api.sigs.k8s.io\/) 作为其唯一的配置语言来管理 Envoy 代理，支持 \u0060GatewayClass\u0060、Gateway、\u0060HTTPRoute\u0060 和 \u0060TLSRoute\u0060 资源。\n\nEnvoy Gateway 的目标是降低用户采用 Envoy 作为 API 网关的障碍，以吸引更多用户采用 Envoy。它通过入口和 L4\/L7 流量路由，表达式、可扩展、面向角色的 API 设计，使其成为供应商建立 API 网关增值产品的基础。\n\nEnvoy Gateway 的核心优势是轻量级、开放、可动态编程，尤其是为后端增加了安全功能，这些优势使得它很适合作为后端 API 网关。\n\n## 架构 {#architecture}\n\n下图展示的是 Envoy Gateway 的架构，图中的阴影部分表示是 Envoy Gateway。你可以通过静态和动态两种方式来配置它，其中的 Provider 是针对不同的供应商开发的。\n\n![Envoy Gateway 架构图](envoy-gateway-arch.svg)\n\n该架构图参考了 [Envoy Gateway 文档](https:\/\/gateway.envoyproxy.io\/contributions\/design\/system-design\/#architecture)。\n\n## 配置流程\n\n下面是配置 Envoy Gateway 的流程：\n\n1. 你可以通过配置文件为其 Provider 提供静态配置（目前仅支持 Kubernetes 和文件方式，将来有可能支持更多不同平台供应商），在 Envoy Gateway 启动后，你还可以通过 Kubernetes 动态配置 Provider；\n2. 这些配置会被 Provider 中的资源监视器看到后应用到 Envoy Gateway 的资源转义器上；\n3. 资源转义器将配置分别转义为针对不同 Provider 开发的基础设施管理器的中间表示（Infra IR）和 xDS 中间表示（xDS IR）；\n4. 两种中间表示（IR）分别应用到其对应的基础设施管理器和 xDS 转义上；\n5. 基础设施通过增删改查（CRDU）Kubernetes Deployment、Service 等资源来运行 Envoy，xDS 管理器通过将 xDS 协议配置 xDS Server 的方式配置 Envoy 代理；\n6. 对于 Envoy 代理的流量请求将应用以上配置并转发到对应的后端；\n\n以上就是对 Envoy Gateway 配置的流程，关于 Envoy 代理设计的更多细节请参考 [Envoy Gateway 文档](https:\/\/gateway.envoyproxy.io\/contributions\/design\/system-design\/)。\n\n## 快速开始 {#quick-start}\n\n下面我们将在 Kubernetes 集群中安装 Envoy Gateway 并部署一个测试网站来看看它是否可以正常运行。\n\n### 前提 {#prerequisites}\n\n在使用 Envoy Gateway 前，请注意它的兼容性问题，参考兼容性矩阵。\n\n| Envoy Gateway 版本 | Envoy 代理版本   | Gateway API 版本 | Kubernetes 最低版本 |\n| ------------------ | ---------------- | ---------------- | ------------------- |\n| v0.2.0             | **v1.23 - 最新** | **v0.5.1**       | v1.24               |\n\n### 安装 {#setup}\n\n因为在 Kubernetes 集群中 Gateway API 不是默认安装的，因此你需要手动安装 Gateway CRD。执行下面的命令安装 Gateway CRD 和 Envoy Gateway：\n\n\u0060\u0060\u0060bash\nkubectl apply -f https:\/\/github.com\/envoyproxy\/gateway\/releases\/download\/v0.2.0\/install.yaml\n\u0060\u0060\u0060\n\n该命令将为你创建 \u0060envoy-gateway-system\u0060、\u0060gateway-system\u0060 两个命令空间，同时创了一系列 CRD。还有一些 Envoy Gateway 运行所需要的 ConfigMap、服务账户、RBAC、角色等。\n\n### 测试 {#test}\n\n执行下面的命令安装 GatewayClass、Gateway、HTTPRoute 和示例应用程序：\n\n\u0060\u0060\u0060 bash\nkubectl apply -f https:\/\/github.com\/envoyproxy\/gateway\/releases\/download\/v0.2.0\/quickstart.yaml\n\u0060\u0060\u0060\n\n端口转发到 Envoy 服务：\n\n\u0060\u0060\u0060bash\nkubectl -n envoy-gateway-system port-forward service\/${ENVOY_SERVICE} 8888:8080 \u0026\n\u0060\u0060\u0060\n\n通过 Envoy 代理 curl 示例应用程序：\n\n\u0060\u0060\u0060bash\ncurl --verbose --header \u0022Host: www.example.com\u0022 http:\/\/localhost:8888\/get\n\u0060\u0060\u0060\n\n你将看到如下输出：\n\n\u0060\u0060\u0060\n*   Trying 127.0.0.1:8888...\n* Connected to localhost (127.0.0.1) port 8888 (#0)\n\u003e GET \/get HTTP\/1.1\n\u003e Host: www.example.com\n\u003e User-Agent: curl\/7.79.1\n\u003e Accept: *\/*\n\u003e\n* Mark bundle as not supporting multiuse\n\u003c HTTP\/1.1 200 OK\n\u003c content-type: application\/json\n\u003c x-content-type-options: nosniff\n\u003c date: Sat, 22 Oct 2022 07:10:34 GMT\n\u003c content-length: 513\n\u003c x-envoy-upstream-service-time: 22\n\u003c server: envoy\n\u003c x-envoy-decorator-operation: backend.default.svc.cluster.local:3000\/*\n\u003c\n{\n \u0022path\u0022: \u0022\/get\u0022,\n \u0022host\u0022: \u0022www.example.com\u0022,\n \u0022method\u0022: \u0022GET\u0022,\n \u0022proto\u0022: \u0022HTTP\/1.1\u0022,\n \u0022headers\u0022: {\n  \u0022Accept\u0022: [\n   \u0022*\/*\u0022\n  ],\n  \u0022User-Agent\u0022: [\n   \u0022curl\/7.79.1\u0022\n  \/\/内容省略...\n },\n \u0022namespace\u0022: \u0022default\u0022,\n \u0022ingress\u0022: \u0022\u0022,\n \u0022service\u0022: \u0022\u0022,\n \u0022pod\u0022: \u0022backend-764c65b4dd-lp6jw\u0022\n* Connection #0 to host localhost left intact\n}\n\u0060\u0060\u0060\n\n如果你看到以上输出就证明你的 Envoy Gateway 安装成功并可正常运行。\n\n如果你的 Kubernetes 集群部署在云上，可以使用云负载均衡器的 IP 地址来访问测试：\n\n\u0060\u0060\u0060bash\nexport GATEWAY_HOST=$(kubectl get svc\/${ENVOY_SERVICE} -n envoy-gateway-system -o jsonpath=\u0027{.status.loadBalancer.ingress[0].ip}\u0027)\ncurl --verbose --header \u0022Host: www.example.com\u0022 http:\/\/$GATEWAY_HOST:8080\/get\n\u0060\u0060\u0060\n\n笔者使用的 GKE，运行上面的命令，\u0060GATEWAY_HOST\u0060 环境变量的值几位负载均衡器的 IP 地址，最后同样可以类似上文的 \u0060curl\u0060 输出。\n\n## Envoy Gateway 中使用的 CRD 简介 {#isito-gateway-crd}\n\n上文说到安装 Envoy Gateway 的时候创建了一系列 CRD，在此我们将简要介绍一下这些 CRD：\n\n- \u0060envoyproxies.config.gateway.envoyproxy.io\u0060：Envoy Proxy API 的 Schema。\n- \u0060gatewayclasses.gateway.networking.k8s.io\u0060：GatewayClass 描述了用户可用于创建 Gateway 资源的一类 Gateways。建议将该资源作为 Gateway 的模板。这意味着一个 Gateway 是基于创建时 GatewayClass 的状态，对 GatewayClass 或相关参数的改变不会向下传播到现有的 Gateway。这项建议的目的是限制 GatewayClass 或相关参数的变化的爆炸半径。如果实现者选择将 GatewayClass 的变化传播给现有 Gateway，实现者必须清楚地记录这一点。每当一个或多个 Gateway 使用一个 GatewayClass 时，实现必须在相关的 GatewayClass 上添加 \u0060gateway-exists-finalizer.gateway.networking.k8s.io\u0060 finalizer。这可以确保与 Gateway 相关的 GatewayClass 在使用中不会被删除。GatewayClass 是一个集群级的资源。\n- \u0060gateways.gateway.networking.k8s.io\u0060：Gateway 通过将 Listener 与一组 IP 地址绑定，代表了一个服务流量处理基础设施的实例。\n- \u0060httproutes.gateway.networking.k8s.io\u0060：HTTPRoute 提供了一种路由 HTTP 请求的方法。这包括通过主机名、路径、标头或查询参数来匹配请求的能力。过滤器可以用来指定额外的处理步骤。后端指定匹配的请求应该被路由到哪里。\n- \u0060referencegrants.gateway.networking.k8s.io\u0060：\u0060ReferenceGrant\u0060 标识了其他命名空间中的资源种类，这些资源被信任为引用与策略相同的名称空间中的指定资源种类。每个 \u0060ReferenceGrant\u0060 都可以用来代表一个独特的信任关系。额外的引用授权可以用来添加到它们所定义的命名空间的入站引用的信任源集合中。Gateway API 中的所有跨命名空间引用（除了跨命名空间的 Gateway-route 附件）都需要一个 \u0060ReferenceGrant\u0060。\n- \u0060referencepolicies.gateway.networking.k8s.io\u0060：该资源已被重新命名为 ReferenceGrant，且将在 Gateway API v0.6.0 中被删除，而采用相同的 ReferenceGrant 资源。\n- \u0060tcproutes.gateway.networking.k8s.io\u0060：TCPRoute 提供了一种路由 TCP 请求的方法。当与 Gateway 监听器结合使用时，它可以用来将监听器指定的端口上的连接转发到 TCPRoute 指定的一组后端。\n- \u0060tlsroutes.gateway.networking.k8s.io\u0060：TLSRoute 资源与 TCPRoute 类似，但可以配置为与 TLS 特定的元数据相匹配。这使得为特定的 TLS 监听器匹配数据流时有更大的灵活性。如果你需要将流量转发到一个 TLS 监听器的单一目标，你可以选择同时使用 TCPRoute 和 TLS 监听器。\n- \u0060udproutes.gateway.networking.k8s.io\u0060：UDPRoute 提供了一种路由 UDP 流量的方法。当与网关监听器结合使用时，它可以用来将监听器指定的端口上的流量转发到 UDPRoute 指定的一组后端。\n\n关于这些 CRD 的具体用法以及 Envoy Gateway 的用户指南，将在以后的文章中分享。\n\n下面两篇我同事写的关于 Envoy Gateway 的文章推荐给大家阅读：\n\n- [使用 Envoy Gateway 0.2 体验新的 Kubernetes Gateway API](https:\/\/cloudnative.to\/blog\/hands-on-with-envoy-gateway\/)\n- [面向未来的网关：新的 Kubernetes Gateway API 和 Envoy Gateway 0.2 介绍](https:\/\/cloudnative.to\/blog\/envoy-gateway-to-the-future\/)\n\n## 参考 {#reference}\n\n- [开源项目 Envoy Gateway 简介 - cloudnative.to](https:\/\/cloudnative.to\/blog\/introducing-envoy-gateway\/)\n- [Envoy API Gateway—— 推动网关的进一步发展 - cloudnative.to](https:\/\/cloudnative.to\/blog\/the-gateway-to-a-new-frontier\/)\n- [Envoy Gateway 官方网站 - gateway.envoyproxy.io](https:\/\/gateway.envoyproxy.io\/)\n', '\/blog\/envoy-gateway-release\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">今天 Envoy Gateway v0.2 发布，本文将为你介绍什么是 Envoy Gateway，它的架构、快速入门和使用指南。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/validating-a-request-payload-with-wasm/">[译] 使用 WebAssembly 验证请求负载</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2022/05/13</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/service-mesh"> 
             Service Mesh
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://www.tetrate.io/blog/validating-a-request-payload-with-wasm/" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('使用 WebAssembly 验证请求负载', '本文是一个开发 Wasm 插件验证请求负载的教程。', '\n## 什么是 Wasm 插件？\n\n你可以使用 Wasm 插件在数据路径上添加自定义代码，轻松地扩展服务网格的功能。可以用你选择的语言编写插件。目前，有 AssemblyScript（TypeScript-ish）、C\u002b\u002b、Rust、Zig 和 Go 语言的 Proxy-Wasm SDK。\n\n在这篇博文中，我们描述了如何使用 Wasm 插件来验证一个请求的有效载荷。这是 Wasm 与 Istio 的一个重要用例，也是你可以使用 Wasm 扩展 Istio 的许多方法的一个例子。您可能有兴趣阅读我们关于[在 Istio 中使用 Wasm 的博文](https:\/\/www.tetrate.io\/blog\/category\/wasm\/)，并观看我们关于在 Istio 和 Envoy 中使用 Wasm 的免费研讨会的录音。\n\n## 何时使用 Wasm 插件？\n\n当你需要添加 Envoy 或 Istio 不支持的自定义功能时，你应该使用 Wasm 插件。使用 Wasm 插件来添加自定义验证、认证、日志或管理配额。\n\n在这个例子中，我们将构建和运行一个 Wasm 插件，验证请求 body 是 JSON，并包含两个必要的键 ——\u0060id\u0060 和 \u0060token\u0060。\n\n## 编写 Wasm 插件\n\n这个示例使用 [tinygo](https:\/\/tinygo.org\/) 来编译成 Wasm。确保你已经安装了 [tinygo 编译器](https:\/\/tinygo.org\/getting-started\/install\/)。\n\n### 配置 Wasm 上下文\n\n首先配置 Wasm 上下文，这样 tinygo 文件才能操作 HTTP 请求：\n\n\u0060\u0060\u0060go\npackage main\n\nimport (\n\t\u0022github.com\/tetratelabs\/proxy-wasm-go-sdk\/proxywasm\u0022\n\t\u0022github.com\/tetratelabs\/proxy-wasm-go-sdk\/proxywasm\/types\u0022\n\t\u0022github.com\/tidwall\/gjson\u0022\n)\n\nfunc main() {\n\t\/\/ SetVMContext 是配置整个 Wasm VM 的入口。请确保该入口在 main 函数中调用，否则 VM 将启动失败。\n\tproxywasm.SetVMContext(\u0026vmContext{})\n}\n\n\/\/ vmContext 实现 proxy-wasm-go SDK 的 types.VMContext 接口。\ntype vmContext struct {\n\t\/\/ 在这里嵌入默认的虚拟机环境，我们不需要实现所有方法。\n\ttypes.DefaultVMContext\n}\n\n\/\/ 复写 types.DefaultVMContext\nfunc (*vmContext) NewPluginContext(contextID uint32) types.PluginContext {\n\treturn \u0026pluginContext{}\n}\n\n\/\/ pluginContext 实现 proxy-wasm-go SDK 的 types.PluginContext 接口\ntype pluginContext struct {\n\t\/\/ 在这里侵入默认的插件上下文，我们不需要实现所有方法。\n\ttypes.DefaultPluginContext\n}\n\n\/\/ 复写 types.DefaultPluginContext\nfunc (ctx *pluginContext) NewHttpContext(contextID uint32) types.HttpContext {\n\treturn \u0026payloadValidationContext{}\n}\n\n\/\/ payloadValidationContext 实现 proxy-wasm-go SDK 的 types.HttpContext 接口\ntype payloadValidationContext struct {\n\t\/\/ 在这里嵌入默认的根 http 上下文，我们不需要实现所有方法。\n\ttypes.DefaultHttpContext\n\ttotalRequestBodySize int\n}\n\u0060\u0060\u0060\n\n### 验证负载\n\n内容类型头是通过实现 \u0060OnHttpRequestHeaders\u0060 来验证的，一旦从客户端收到请求头，就会调用该头。\n\n\u0060proxywasm.SendHttpResponse\u0060 用于响应 403 forbidden 的错误代码和信息，如果内容类型丢失的话。\n\n\u0060\u0060\u0060go\nfunc (ctx *payloadValidationContext) OnHttpRequestHeaders(numHeaders int, endOfStream bool) types.Action {\n\tcontentType, err := proxywasm.GetHttpRequestHeader(\u0022content-type\u0022)\n\tif err != nil || contentType != \u0022application\/json\u0022 {\n\t\t\/\/ 如果 header 没有期望的 content type，返回 403 响应\n\t\tif err := proxywasm.SendHttpResponse(403, nil, []byte(\u0022content-type must be provided\u0022), -1); err != nil {\n\t\t\tproxywasm.LogErrorf(\u0022failed to send the 403 response: %v\u0022, err)\n\t\t}\n\t\t\/\/ 终止 ActionPause 对流量的进一步处理\n\t\treturn types.ActionPause\n\t}\n\n\t\/\/ ActionContinue 让主机继续处理 body\n\treturn types.ActionContinue\n}\n\u0060\u0060\u0060\n\n请求主体是通过实现 \u0060OnHttpRequestBody\u0060 来验证的，每次从客户端接收到请求的一个块时，都会调用该请求。这是通过等待直到 \u0060endOfStream\u0060 为真并记录所有收到的块的总大小来完成的。一旦收到整个主体，就会使用 \u0060proxywasm.GetHttpRequestBody\u0060 读取，然后可以使用 golang 进行验证。\n\n这个例子使用 \u0060gjson\u0060，因为 tinygo 不支持 golang 的默认 JSON 库。它检查有效载荷是否是有效的 JSON，以及键 \u0060id\u0060 和 \u0060token\u0060 是否存在。\n\n\u0060\u0060\u0060go\nfunc (ctx *payloadValidationContext) OnHttpRequestBody(bodySize int, endOfStream bool) types.Action {\n\tctx.totalRequestBodySize \u002b= bodySize\n\tif !endOfStream {\n\t\t\/\/ OnHttpRequestBody 等待收到到 body 的全部才开始处理。\n\t\treturn types.ActionPause\n\t}\n\n\tbody, err := proxywasm.GetHttpRequestBody(0, ctx.totalRequestBodySize)\n\tif err != nil {\n\t\tproxywasm.LogErrorf(\u0022failed to get request body: %v\u0022, err)\n\t\treturn types.ActionContinue\n\t}\n\n\tif !validatePayload(body) {\n\t\t\/\/ 如果验证失败，发送 403 响应。\n\t\tif err := proxywasm.SendHttpResponse(403, nil, []byte(\u0022invalid payload\u0022), -1); err != nil {\n\t\t\tproxywasm.LogErrorf(\u0022failed to send the 403 response: %v\u0022, err)\n\t\t}\n\t\t\/\/ 终止流量\n\t\treturn types.ActionPause\n\t}\n\n\treturn types.ActionContinue\n}\n\n\/\/ validatePayload 验证给定的 json 负载\n\/\/ 注意该函数使用 gjson 解析 json，因为 TinyGo 不支持 encoding\/json\nfunc validatePayload(body []byte) bool {\n\tif !gjson.ValidBytes(body) {\n\t\tproxywasm.LogErrorf(\u0022body is not a valid json: %v\u0022, body)\n\t\treturn false\n\t}\n\tjsonData := gjson.ParseBytes(body)\n\n\t\/\/ 验证 json。检查示例中是否存在必须的键\n\tfor _, requiredKey := range []string{\u0022id\u0022, \u0022token\u0022} {\n\t\tif !jsonData.Get(requiredKey).Exists() {\n\t\t\tproxywasm.LogErrorf(\u0022required key (%v) is missing: %v\u0022, requiredKey, jsonData)\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\u0060\u0060\u0060\n\n### 编译成 Wasm\n\n使用 tinygo 编译器编译成 Wasm：\n\n\u0060\u0060\u0060bash\ntinygo build -o main.wasm -scheduler=none -target=wasi main.go\n\u0060\u0060\u0060\n\n## 部署 Wasm 插件\n\n### 打包到 Docker 中部署到 Envoy\n\n对于开发，这个插件可以在 Docker 中部署到 Envoy。下面的 Envoy 配置文件将设置 Envoy 监听 \u0060localhost:18000\u0060，运行所提供的 Wasm 插件，并在成功后响应 HTTP 200 和文本 \u0060hello from server\u0060。突出显示的部分是配置 Wasm 插件。\n\n\u0060\u0060\u0060yaml\nstatic_resources:\n  listeners:\n    - name: main\n      address:\n        socket_address:\n          address: 0.0.0.0\n          port_value: 18000\n      filter_chains:\n        - filters:\n            - name: envoy.http_connection_manager\n              typed_config:\n                \u0022@type\u0022: type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\n                stat_prefix: ingress_http\n                codec_type: auto\n                route_config:\n                  name: local_route\n                  virtual_hosts:\n                    - name: local_service\n                      domains:\n                        - \u0022*\u0022\n                      routes:\n                        - match:\n                            prefix: \u0022\/\u0022\n                          route:\n                            cluster: web_service\n \n                http_filters:\n                 - name: envoy.filters.http.wasm\n                    typed_config:\n                      \u0022@type\u0022: type.googleapis.com\/udpa.type.v1.TypedStruct\n                      type_url: type.googleapis.com\/envoy.extensions.filters.http.wasm.v3.Wasm\n                      value:\n                        config:\n                          vm_config:\n                            runtime: \u0022envoy.wasm.runtime.v8\u0022\n                            code:\n                              local:\n                                filename: \u0022.\/main.wasm\u0022\n                  - name: envoy.filters.http.router\n\n    - name: staticreply\n      address:\n        socket_address:\n          address: 127.0.0.1\n          port_value: 8099\n      filter_chains:\n        - filters:\n            - name: envoy.http_connection_manager\n              typed_config:\n                \u0022@type\u0022: type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\n                stat_prefix: ingress_http\n                codec_type: auto\n                route_config:\n                  name: local_route\n                  virtual_hosts:\n                    - name: local_service\n                      domains:\n                        - \u0022*\u0022\n                      routes:\n                        - match:\n                            prefix: \u0022\/\u0022\n                          direct_response:\n                            status: 200\n                            body:\n                              inline_string: \u0022hello from the server\\n\u0022\n                http_filters:\n                  - name: envoy.filters.http.router\n                    typed_config: {}\n\n  clusters:\n    - name: web_service\n      connect_timeout: 0.25s\n      type: STATIC\n      lb_policy: ROUND_ROBIN\n      load_assignment:\n        cluster_name: mock_service\n        endpoints:\n          - lb_endpoints:\n              - endpoint:\n                  address:\n                    socket_address:\n                      address: 127.0.0.1\n                      port_value: 8099\n\nadmin:\n  access_log_path: \u0022\/dev\/null\u0022\n  address:\n    socket_address:\n      address: 0.0.0.0\n      port_value: 8001\n\u0060\u0060\u0060\n\n运行 Docker 容器：\n\n\u0060\u0060\u0060bash\ndocker run --rm -p 18000:18000 \\\n  -v $PWD\/envoy.yaml:\/envoy.yaml \\\n  -v $PWD\/main.wasm:\/main.wasm \\\n  --entrypoint envoy containers.istio.tetratelabs.com\/proxyv2:1.9.7-tetrate-v0 \\\n  -l debug \\\n  -c \/envoy.yaml\n\u0060\u0060\u0060\n\n通过 curl 测试。首先，没有设置内容类型，将返回 403：\n\n\u0060\u0060\u0060bash\n% curl -i -X POST localhost:18000\nHTTP\/1.1 403 Forbidden\ncontent-length: 29\ncontent-type: text\/plain\ndate: Sun, 13 Mar 2022 22:13:37 GMT\nserver: envoy\n\ncontent-type must be provided\n\u0060\u0060\u0060\n\n然后，请求 body 不是 JSON，同样返回 403。\n\n\u0060\u0060\u0060bash\n% curl -i -X POST localhost:18000 -H \u0027Content-Type: application\/json\u0027 --data \u0027not JSON\u0027\nHTTP\/1.1 403 Forbidden\ncontent-length: 15\ncontent-type: text\/plain\ndate: Sun, 13 Mar 2022 22:15:53 GMT\nserver: envoy\n\ninvalid payload\n\u0060\u0060\u0060\n\nJSON 负载中没有 \u0060token\u0060 字段，还是返回 403。\n\n\u0060\u0060\u0060bash\n% curl -i -X POST localhost:18000 -H \u0027Content-Type: application\/json\u0027 --data \u0027{\u0022id\u0022: \u0022xxx\u0022}\u0027\nHTTP\/1.1 403 Forbidden\ncontent-length: 15\ncontent-type: text\/plain\ndate: Sun, 13 Mar 2022 22:17:18 GMT\nserver: envoy\n\ninvalid payload\n\u0060\u0060\u0060\n\n当 id 和 token 字段都被提供时，将返回一个成功的响应。\n\n\u0060\u0060\u0060bash\n% curl -i -X POST localhost:18000 -H \u0027Content-Type: application\/json\u0027 --data \u0027{\u0022id\u0022: \u0022xxx\u0022, \u0022token\u0022: \u0022xxx\u0022, \u0022anotherField\u0022: \u0022yyy\u0022}\u0027\nHTTP\/1.1 200 OK\ncontent-length: 22\ncontent-type: text\/plain\ndate: Sun, 13 Mar 2022 22:18:37 GMT\nserver: envoy\nx-envoy-upstream-service-time: 1\n\nhello from the server\n\u0060\u0060\u0060\n\n## 部署到 Istio\n\n### 部署 Istio 和 httpbin 示例应用\n\n我们使用 [kind](https:\/\/kind.sigs.k8s.io\/) 来创建测试集群，对于其他方式创建的 Kubernetes 集群同样适用。\n\n\u0060\u0060\u0060bash\nkind create cluster\n\u0060\u0060\u0060\n\n集群创建完毕后，安装 Istio，我们使用的是 Istio 1.12.3，安装 [Istio httpbin 示例应用](https:\/\/github.com\/istio\/istio\/tree\/master\/samples\/httpbin)。\n\n\u0060\u0060\u0060bash\nistioctl install --set profile=demo\nkubectl label namespace default istio-injection=enabled\nkubectl apply -f https:\/\/raw.githubusercontent.com\/istio\/istio\/release-1.12\/samples\/httpbin\/httpbin.yaml\nkubectl apply -f https:\/\/raw.githubusercontent.com\/istio\/istio\/release-1.12\/samples\/httpbin\/httpbin-gateway.yaml\n\u0060\u0060\u0060\n\n在另一个终端中，将 Ingress 网关的 80 端口转发到你本地机器的 8080 端口上。\n\n\u0060\u0060\u0060bash\nkubectl port-forward -n istio-system svc\/istio-ingressgateway 8080:80\n\u0060\u0060\u0060\n\n发送 curl 请求，检查服务是否正常启动，你应该应该看到成功的响应。\n\n\u0060\u0060\u0060bash\ncurl -X POST -i http:\/\/localhost:8080\/post\n\u0060\u0060\u0060\n\n有两种方式在 Istio 中安装 Wasm 模块：\n\n1. 对于 Istio 1.12 和更新版本的 Istio，支持 [WasmPlugin](https:\/\/istio.io\/latest\/docs\/reference\/config\/proxy_extensions\/wasm-plugin\/) 资源\n2. 对于老版本的 Istio，可以使用 [EnvoyFilter](https:\/\/istio.io\/latest\/docs\/reference\/config\/networking\/envoy-filter\/)\n\n### 使用 WasmPlugin 安装\n\nWasmPlugin 资源从镜像仓库中提取 wasm 模块。因此，让我们首先为我们的 wasm 模块构建并推送一个 Docker 镜像。下面的 Docker 文件允许从你的 wasm 模块建立一个 Docker 镜像。\n\n\u0060\u0060\u0060Docker\nFROM scratch\n\nCOPY main.wasm .\/\n\u0060\u0060\u0060\n\n构建镜像，推送到镜像仓库。\n\n\u0060\u0060\u0060bash\nexport HUB=your_registry # e.g. docker.io\/tetrate\ndocker build . -t $HUB\/json-validation:v1\ndocker push $HUB\/json-validation:v1\n\u0060\u0060\u0060\n\n现在我们创建 [WasmPlugin](https:\/\/istio.io\/latest\/docs\/reference\/config\/proxy_extensions\/wasm-plugin\/) 资源。这将适用于所有通过 Istio Ingress 网关暴露的路由，并对其应用我们的验证。确保你把 \u0060{your_registry}\u0060 替换为你上传 wasm 镜像的镜像仓库。\n\n\u0060\u0060\u0060yaml\napiVersion: extensions.istio.io\/v1alpha1\nkind: WasmPlugin\nmetadata:\n  name: json-validation\n  namespace: istio-system\nspec:\n  selector:\n    matchLabels:\n      istio: ingressgateway\n  url: oci:\/\/{your_registry}\/json-validation:v3\n  imagePullPolicy: IfNotPresent\n  phase: AUTHN\n\u0060\u0060\u0060\n\n### 使用 EnvoyFilter 安装\n\n为了使用 EnvoyFilter，我们创建一个包含已编译的 Wasm 插件的 ConfigMap，将 ConfigMap 挂载到网关 pod 中，然后通过 EnvoyFilter 配置 Envoy，从本地文件加载 Wasm 插件。这种方法的限制是，更大和更复杂的 Wasm 模块可能超出 ConfigMap 1MB 的大小限制。\n\n首先，创建一个包含编译好的 Wasm 模块的 ConfigMap：\n\n\u0060\u0060\u0060bash\nkubectl -n istio-system create configmap wasm-plugins --from-file=main.wasm\n\u0060\u0060\u0060\n\n然后在 Istio Ingress 网关部署中打补丁，挂载这个 ConfigMap。\n\n\u0060\u0060\u0060bash\nkubectl -n istio-system patch deployment istio-ingressgateway --patch=\u0027\nspec:\n  template:\n    spec:\n      containers:\n        - name: istio-proxy\n          volumeMounts:\n            - name: wasm-plugins\n              mountPath: \/var\/local\/lib\/wasm-plugins\n              readOnly: true\n      volumes:\n        - name: wasm-plugins\n          configMap:\n            name: wasm-plugins\u0027\n\u0060\u0060\u0060\n\n现在 Wasm 模块就挂载到了网关 Pod 中，应用这个 EnvoyFilter。\n\n\u0060\u0060\u0060yaml\napiVersion: networking.istio.io\/v1alpha3\nkind: EnvoyFilter\nmetadata:\n  name: json-validation\n  namespace: istio-system\nspec:\n  configPatches:\n  - applyTo: HTTP_FILTER\n    match:\n      context: GATEWAY\n    patch:\n      operation: INSERT_BEFORE\n      value:\n        name: json-validation\n        typed_config:\n          \u0027@type\u0027: type.googleapis.com\/envoy.extensions.filters.http.wasm.v3.Wasm\n          config:\n            vm_config:\n              code:\n                local:\n                  filename: \/var\/local\/lib\/wasm-plugins\/main.wasm\n              runtime: envoy.wasm.runtime.v8\n              vm_id: json-validation\n\u0060\u0060\u0060\n\n### 测试 Wasm 插件\n\n重复之前的 curl 请求。\n\n\u0060\u0060\u0060bash\n% curl -X POST -i http:\/\/localhost:8080\/post\nHTTP\/1.1 403 Forbidden\ncontent-length: 29\ncontent-type: text\/plain\ndate: Tue, 15 Mar 2022 22:04:35 GMT\nserver: istio-envoy\n\ncontent-type must be provided\n\u0060\u0060\u0060\n\n如果提供了内容类型和 json 负载的话，请求将会成功。\n\n\u0060\u0060\u0060bash\ncurl -i http:\/\/localhost:8080\/post  -H \u0027Content-Type: application\/json\u0027 --data \u0027{\u0022id\u0022: \u0022xxx\u0022, \u0022token\u0022: \u0022xxx\u0022}\u0027\n\u0060\u0060\u0060\n\n## 让必填字段可配置\n\n与其在编译的 golang 代码中硬编码所需的 JSON 字段，不如允许通过 Envoy 配置来配置这些字段。\n\n当在 Docker 中运行 Envoy 时，可以通过向之前创建的 Wasm \u0060http_filter\u0060 添加配置来实现。\n\n\u0060\u0060\u0060yaml\n  http_filters:\n                  - name: envoy.filters.http.wasm\n                    typed_config:\n                      \u0022@type\u0022: type.googleapis.com\/udpa.type.v1.TypedStruct\n                      type_url: type.googleapis.com\/envoy.extensions.filters.http.wasm.v3.Wasm\n                      value:\n                        config:\n                          configuration:\n                            \u0022@type\u0022: type.googleapis.com\/google.protobuf.StringValue\n                            value: |\n                                                            { \u0022requiredKeys\u0022: [\u0022id\u0022, \u0022token\u0022] }\n                          vm_config:\n                            runtime: \u0022envoy.wasm.runtime.v8\u0022\n                            code:\n                              local:\n                                filename: \u0022.\/main.wasm\u0022\n\u0060\u0060\u0060\n\n当使用 WasmPlugin，在 \u0060pluginConfig\u0060 字段中配置。\n\n\u0060\u0060\u0060yaml\napiVersion: extensions.istio.io\/v1alpha1\nkind: WasmPlugin\nmetadata:\n  name: json-validation\n  namespace: istio-system\nspec:\n  selector:\n    matchLabels:\n      istio: ingressgateway\n  url: oci:\/\/{your_registry}\/json-validation:v3\n  imagePullPolicy: IfNotPresent\n  phase: AUTHN\n  pluginConfig:\n    requiredKeys: [\u0022id\u0022, \u0022token\u0022]\n\u0060\u0060\u0060\n\n最后，当使用 EnvoyFilter 时，将它添加到 filter 配置中。\n\n\u0060\u0060\u0060yaml\n   value:\n        name: json-validation\n        typed_config:\n          \u0027@type\u0027: type.googleapis.com\/envoy.extensions.filters.http.wasm.v3.Wasm\n          config:\n            configuration:\n              \u0022@type\u0022: type.googleapis.com\/google.protobuf.StringValue\n              value: |\n                                { \u0022requiredKeys\u0022: [\u0022id\u0022, \u0022token\u0022] }\n            vm_config:\n              code:\n                local:\n                  filename: \/var\/local\/lib\/wasm-plugins\/main.wasm\n              runtime: envoy.wasm.runtime.v8\n              vm_id: json-validation\n\u0060\u0060\u0060\n\n在代码中，实现 \u0060OnPluginStart\u0060，使用 \u0060proxywasm.GetPluginConfiguration\u0060 加载。\n\n\u0060\u0060\u0060go\n\/\/ pluginContext 实现 proxy-wasm-go SDK 中的 types.PluginContext 接口\ntype pluginContext struct {\n\t\/\/ 在这里嵌入默认的 plugin 上下文，这样就不用实现所有方法\n\ttypes.DefaultPluginContext\n\tconfiguration *pluginConfiguration\n}\n\n\/\/ pluginConfiguration 代表这个 wasm 插件中的示例配置\ntype pluginConfiguration struct {\n\t\/\/ 示例配置字段，插件将验证 json 负载中是否存在这些字段。\n\trequiredKeys []string\n}\n\n\/\/ 复写 types.DefaultPluginContext\nfunc (ctx *pluginContext) OnPluginStart(pluginConfigurationSize int) types.OnPluginStartStatus {\n\tdata, err := proxywasm.GetPluginConfiguration()\n\tif err != nil {\n\t\tproxywasm.LogCriticalf(\u0022error reading plugin configuration: %v\u0022, err)\n\t\treturn types.OnPluginStartStatusFailed\n\t}\n\tconfig, err := parsePluginConfiguration(data)\n\tif err != nil {\n\t\tproxywasm.LogCriticalf(\u0022error parsing plugin configuration: %v\u0022, err)\n\t\treturn types.OnPluginStartStatusFailed\n\t}\n\tctx.configuration = config\n\treturn types.OnPluginStartStatusOK\n}\n\n\/\/ parsePluginConfiguration 解析 json 插件配置并返回 pluginConfiguration\n\/\/ 注意使用 gjson 解析 json，因为 TinyGo 不支持 encoding\/json\n\/\/ 你也可以使用 https:\/\/github.com\/mailru\/easyjson，支持解析为结构体\nfunc parsePluginConfiguration(data []byte) (*pluginConfiguration, error) {\n\tconfig := \u0026pluginConfiguration{}\n\tif !gjson.ValidBytes(data) {\n\t\treturn nil, fmt.Errorf(\u0022the plugin configuration is not a valid json: %v\u0022, data)\n\t}\n\n\tjsonData := gjson.ParseBytes(data)\n\trequiredKeys := jsonData.Get(\u0022requiredKeys\u0022).Array()\n\tfor _, requiredKey := range requiredKeys {\n\t\tconfig.requiredKeys = append(config.requiredKeys, requiredKey.Str)\n\t}\n\n\treturn config, nil\n}\n\u0060\u0060\u0060\n\n现在它们被包含在 \u0060pluginConfiguration\u0060 结构中，它们可以像其他字段一样在验证过程中被使用。\n\n\u0060\u0060\u0060go\n\/\/ validatePayload 验证给定的 json 负载\n\/\/ 注意该函数使用 gjson 解析 json，因为 TinyGo 不支持 encoding\/json\nfunc (ctx *payloadValidationContext) validatePayload(body []byte) bool {\n\tif !gjson.ValidBytes(body) {\n\t\tproxywasm.LogErrorf(\u0022body is not a valid json: %v\u0022, body)\n\t\treturn false\n\t}\n\tjsonData := gjson.ParseBytes(body)\n\n\t\/\/ 验证 json。检查示例中是否包含必须的键。\n\t\/\/ 必须的键通过插件配置。\n\tfor _, requiredKey := range ctx.requiredKeys {\n\t\tif !jsonData.Get(requiredKey).Exists() {\n\t\t\tproxywasm.LogErrorf(\u0022required key (%v) is missing: %v\u0022, requiredKey, jsonData)\n\t\t\treturn false\n\t\t}\n\t}\n\n\treturn true\n}\n\u0060\u0060\u0060\n\n然后可以使用与之前相同的命令对其进行编译和测试。\n\n## 总结\n\n总而言之，要在 Istio 1.12 和更新的版本上使用 Wasm 插件，需要三个步骤：\n\n1. 在你选择的语言中实现插件的功能。我在本教程中使用 Golang。\n2. 编译 Wasm 插件并推送到镜像仓库。\n3. 配置 Istio 以加载和使用镜像仓库中的插件。\n\n该教程还详细介绍了如何使用 Docker 在 Envoy 容器中运行 Wasm 插件，以加快开发速度，以及如何将其部署到旧的 Istio 版本。\n', '\/trans\/validating-a-request-payload-with-wasm\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文是一个开发 Wasm 插件验证请求负载的教程。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/sidecar-injection-iptables-and-traffic-routing/">Istio 中的 Sidecar 注入、透明流量劫持及流量路由过程详解</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2022/05/12</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/istio"> 
             Istio
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Istio 中的 Sidecar 注入、透明流量劫持及流量路由过程详解', '本文基于 Istio 1.13 版本，介绍了 sidecar 模式及其优势 sidecar 如何注入到数据平面，Envoy 如何做流量劫持和路由转发的，包括 Inbound 流量和 Outbound 流量。', '\n本文最早是基于 Istio 1.11 撰写，之后随着 Istio 的版本陆续更新，最新更新时间为 2022 年 5 月 12 日，关于本文历史版本的更新说明请见文章最后。本文记录了详细的实践过程，力图能够让读者复现，因此事无巨细，想要理解某个部分过程的读者可以使用目录跳转到对应的小节阅读。\n\n为了使读者能够更加直观的了解本文中执行的操作，在阅读本文前你也可以先观看下 [Istio Workshop 第八讲视频](https:\/\/bilibili.com\/video\/BV1cF411T72o\/)。\n\n{{\u003cfigure title=\u0022观看视频\u0022 alt=\u0022图片\u0022 attr=\u0022[点击观看](https:\/\/bilibili.com\/video\/BV1cF411T72o\/)\u0022 src=\u0022bilibili.jpg\u0022 link=\u0022https:\/\/bilibili.com\/video\/BV1cF411T72o\/\u0022\u003e}}\n\n为了理解本文希望你先阅读以下内容：\n\n- [理解 iptables](\/blog\/understanding-iptables\/)\n- [Istio 数据平面 Pod 启动过程详解](\/blog\/istio-pod-process-lifecycle\/)\n\n## 内容介绍\n\n本文基于 Istio 1.13 版本，将为大家介绍以下内容：\n\n- 什么是 sidecar 模式和它的优势在哪里。\n- Istio 中是如何做 sidecar 注入的。\n- Sidecar 代理是如何做透明流量劫持的。\n- iptables 的路由规则。\n- Envoy 代理是如何路由流量到上游的。\n\n请大家结合下图理解本文中的内容，本图基于 Istio 官方提供的 Bookinfo 示例绘制，展示的是 \u0060reviews\u0060 Pod 的内部结构，包括 Linux Kernel 空间中的 iptables 规则、Sidecar 容器、应用容器。\n\n![Istio 流量劫持示意图](istio-iptables.svg)\n\n\u0060productpage\u0060 访问 \u0060reviews\u0060 Pod，入站流量处理过程对应于图示上的步骤：1、2、3、4、Envoy Inbound Handler、5、6、7、8、应用容器。\n\n\u0060reviews\u0060 Pod 访问 \u0060rating\u0060 服务的出站流量处理过程对应于图示上的步骤是：9、10、11、12、Envoy Outbound Handler、13、14、15。\n\n注意：图中的路径 16 近用于路由规则说明，它不不出现在当前示例中。实际上仅当 Pod 内发出的对当前 Pod 内的服务访问的时候才会途径它。\n\n上图中关于流量路由部分，包含：\n\n-  \u0060productpage\u0060 服务请求访问 \u0060http:\/\/reviews.default.svc.cluster.local:9080\/\u0060，当流量进入 \u0060reviews\u0060 Pod 内部时，流量是如何被 iptables 劫持到 Envoy 代理被 Inbound Handler 处理的；\n- \u0060reviews\u0060 请求访问 \u0060ratings\u0060 服务的 Pod，应用程序发出的出站流量被 iptables 劫持到 Envoy 代理的 Outbound Handler 的处理。\n\n在阅读下文时，请大家确立以下已知点：\n\n- 首先，\u0060productpage\u0060 发出的对 \u0060reivews\u0060 的访问流量，是在 Envoy 已经通过 EDS 选择出了要请求的 \u0060reviews\u0060 服务的某个 Pod，知晓了其 IP 地址，直接向该 IP 发送的 TCP 连接请求。\n- \u0060reviews\u0060 服务有三个版本，每个版本有一个实例，三个版本中的 sidecar 工作步骤类似，下文只以其中一个 Pod 中的 sidecar 流量转发步骤来说明。\n- 所有进入 \u0060reviews\u0060 Pod 的 TCP 流量都根据 Pod 中的 iptables 规则转发到了 Envoy 代理的 15006 端口，然后经过 Envoy 的处理确定转发给 Pod 内的应用容器还是透传。\n\n## Sidecar 模式\n\n将应用程序的功能划分为单独的进程运行在同一个最小调度单元中（例如 Kubernetes 中的 Pod）可以被视为 **sidecar 模式**。如下图所示，sidecar 模式允许您在应用程序旁边添加更多功能，而无需额外第三方组件配置或修改应用程序代码。\n\n![Sidecar 模式示意图](sidecar-pattern.svg)\n\n就像连接了 Sidecar 的三轮摩托车一样，在软件架构中，Sidecar 连接到父应用并且为其添加扩展或者增强功能。Sidecar 应用与主应用程序松散耦合。它可以屏蔽不同编程语言的差异，统一实现微服务的可观测性、监控、日志记录、配置、断路器等功能。\n\n### 使用 Sidecar 模式的优势\n\n使用 sidecar 模式部署服务网格时，无需在节点上运行代理，但是集群中将运行多个相同的 sidecar 副本。在 sidecar 部署方式中，每个应用的容器旁都会部署一个伴生容器（如 Envoy 或 MOSN），这个容器称之为 sidecar 容器。Sidecar 接管进出应用容器的所有流量。在 Kubernetes 的 Pod 中，在原有的应用容器旁边注入一个 Sidecar 容器，两个容器共享存储、网络等资源，可以广义的将这个包含了 sidecar 容器的 Pod 理解为一台主机，两个容器共享主机资源。\n\n因其独特的部署结构，使得 sidecar 模式具有以下优势：\n\n- 将与应用业务逻辑无关的功能抽象到共同基础设施，降低了微服务代码的复杂度。\n- 因为不再需要编写相同的第三方组件配置文件和代码，所以能够降低微服务架构中的代码重复度。\n- Sidecar 可独立升级，降低应用程序代码和底层平台的耦合度。\n\n## Sidecar 注入示例分析\n\n以 Istio 官方提供的 \u0060bookinfo\u0060 中 \u0060productpage\u0060 的 YAML 为例，关于 \u0060bookinfo\u0060 应用的详细 YAML 配置请参考 [bookinfo.yaml](https:\/\/github.com\/istio\/istio\/blob\/master\/samples\/bookinfo\/platform\/kube\/bookinfo.yaml)。\n\n下文将从以下几个方面讲解：\n\n- Sidecar 容器的注入\n- iptables 规则的创建\n- 路由的详细过程\n\n\u0060\u0060\u0060yaml\napiVersion: apps\/v1\nkind: Deployment\nmetadata:\n  name: productpage-v1\n  labels:\n    app: productpage\n    version: v1\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: productpage\n      version: v1\n  template:\n    metadata:\n      labels:\n        app: productpage\n        version: v1\n    spec:\n      serviceAccountName: bookinfo-productpage\n      containers:\n      - name: productpage\n        image: docker.io\/istio\/examples-bookinfo-productpage-v1:1.15.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 9080\n        volumeMounts:\n        - name: tmp\n          mountPath: \/tmp\n      volumes:\n      - name: tmp\n        emptyDir: {}\n\u0060\u0060\u0060\n\n再查看下 \u0060productpage\u0060 容器的 [Dockerfile](https:\/\/github.com\/istio\/istio\/blob\/master\/samples\/bookinfo\/src\/productpage\/Dockerfile)。\n\n\u0060\u0060\u0060docker\nFROM python:3.7.4-slim\n\nCOPY requirements.txt .\/\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY test-requirements.txt .\/\nRUN pip install --no-cache-dir -r test-requirements.txt\n\nCOPY productpage.py \/opt\/microservices\/\nCOPY tests\/unit\/* \/opt\/microservices\/\nCOPY templates \/opt\/microservices\/templates\nCOPY static \/opt\/microservices\/static\nCOPY requirements.txt \/opt\/microservices\/\n\nARG flood_factor\nENV FLOOD_FACTOR ${flood_factor:-0}\n\nEXPOSE 9080\nWORKDIR \/opt\/microservices\nRUN python -m unittest discover\n\nUSER 1\n\nCMD [\u0022python\u0022, \u0022productpage.py\u0022, \u00229080\u0022]\n\u0060\u0060\u0060\n\n我们看到 \u0060Dockerfile\u0060 中没有配置 \u0060ENTRYPOINT\u0060，所以 \u0060CMD\u0060 的配置 \u0060python productpage.py 9080\u0060 将作为默认的 \u0060ENTRYPOINT\u0060，记住这一点，再看下注入 sidecar 之后的配置。\n\n\u0060\u0060\u0060bash\n$ istioctl kube-inject -f samples\/bookinfo\/platform\/kube\/bookinfo.yaml\n\u0060\u0060\u0060\n\n我们只截取其中与 \u0060productpage\u0060 相关的 \u0060Deployment\u0060 配置中的部分 YAML 配置。\n\n\u0060\u0060\u0060yaml\n      containers:\n      - image: docker.io\/istio\/examples-bookinfo-productpage-v1:1.15.0 # 应用镜像\n        name: productpage\n        ports:\n        - containerPort: 9080\n      - args:\n        - proxy\n        - sidecar\n        - --domain\n        - $(POD_NAMESPACE).svc.cluster.local\n        - --configPath\n        - \/etc\/istio\/proxy\n        - --binaryPath\n        - \/usr\/local\/bin\/envoy\n        - --serviceCluster\n        - productpage.$(POD_NAMESPACE)\n        - --drainDuration\n        - 45s\n        - --parentShutdownDuration\n        - 1m0s\n        - --discoveryAddress\n        - istiod.istio-system.svc:15012\n        - --zipkinAddress\n        - zipkin.istio-system:9411\n        - --proxyLogLevel=warning\n        - --proxyComponentLogLevel=misc:error\n        - --connectTimeout\n        - 10s\n        - --proxyAdminPort\n        - \u002215000\u0022\n        - --concurrency\n        - \u00222\u0022\n        - --controlPlaneAuthPolicy\n        - NONE\n        - --dnsRefreshRate\n        - 300s\n        - --statusPort\n        - \u002215020\u0022\n        - --trust-domain=cluster.local\n        - --controlPlaneBootstrap=false\n        image: docker.io\/istio\/proxyv2:1.5.1 # sidecar proxy\n        name: istio-proxy\n        ports:\n        - containerPort: 15090\n          name: http-envoy-prom\n          protocol: TCP\n      initContainers:\n      - command:\n        - istio-iptables\n        - -p\n        - \u002215001\u0022\n        - -z\n        - \u002215006\u0022\n        - -u\n        - \u00221337\u0022\n        - -m\n        - REDIRECT\n        - -i\n        - \u0027*\u0027\n        - -x\n        - \u0022\u0022\n        - -b\n        - \u0027*\u0027\n        - -d\n        - 15090,15020\n        image: docker.io\/istio\/proxyv2:1.5.1 # init 容器\n        name: istio-init\n\u0060\u0060\u0060\n\nIstio 给应用 Pod 注入的配置主要包括：\n\n- Init 容器 \u0060istio-init\u0060：用于 pod 中设置 iptables 端口转发\n- Sidecar 容器 \u0060istio-proxy\u0060：运行 sidecar 代理，如 Envoy 或 MOSN。\n\n## iptables 规则注入解析\n\n为了查看 iptables 配置，我们需要登陆到 sidecar 容器中使用 root 用户来查看，因为 \u0060kubectl\u0060 无法使用特权模式来远程操作 docker 容器，所以我们需要登陆到 \u0060productpage\u0060 pod 所在的主机上使用 \u0060docker\u0060 命令登陆容器中查看。\n\n如果您使用 minikube 部署的 Kubernetes，可以直接登录到 minikube 的虚拟机中并切换为 root 用户。查看 iptables 配置，列出 NAT（网络地址转换）表的所有规则，因为在 Init 容器启动的时候选择给 \u0060istio-iptables\u0060 传递的参数中指定将入站流量重定向到 sidecar 的模式为 \u0060REDIRECT\u0060，因此在 iptables 中将只有 NAT 表的规格配置，如果选择 \u0060TPROXY\u0060 还会有 \u0060mangle\u0060 表配置。\u0060iptables\u0060 命令的详细用法请参考 [iptables](https:\/\/wangchujiang.com\/linux-command\/c\/iptables.html) 命令。\n\n我们仅查看与 \u0060productpage\u0060 有关的 iptables 规则如下，因为这些规则是运行在该容器特定的网络空间下，因此需要使用 \u0060nsenter\u0060 命令进入其网络空间。进入的时候需要指定进程 ID（PID），因此首先我们需要找到 \u0060productpage\u0060 容器的 PID。对于在不同平台上安装的 Kubernetes，查找容器的方式会略有不同，例如在 GKE 上，执行 \u0060docker ps -a\u0060 命令是查看不到任何容器进程的。下面已 minikube 和 GKE 两个典型的平台为例，指导你如何进入容器的网络空间。\n\n### 在 minikube 中查看容器中的 iptabes 规则\n\n对于 minikube，因为所有的进程都运行在单个节点上，因此你只需要登录到 minikube 虚拟机，切换为 root 用户然后查找 \u0060productpage\u0060 进程即可，参考下面的步骤。\n\n\u0060\u0060\u0060bash\n# 进入 minikube 并切换为 root 用户，minikube 默认用户为 docker\n$ minikube ssh\n$ sudo -i\n\n# 查看 productpage pod 的 istio-proxy 容器中的进程\n$ docker top \u0060docker ps|grep \u0022istio-proxy_productpage\u0022|cut -d \u0022 \u0022 -f1\u0060\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\n1337                10576               10517               0                   08:09               ?                   00:00:07            \/usr\/local\/bin\/pilot-agent proxy sidecar --domain default.svc.cluster.local --configPath \/etc\/istio\/proxy --binaryPath \/usr\/local\/bin\/envoy --serviceCluster productpage.default --drainDuration 45s --parentShutdownDuration 1m0s --discoveryAddress istiod.istio-system.svc:15012 --zipkinAddress zipkin.istio-system:9411 --proxyLogLevel=warning --proxyComponentLogLevel=misc:error --connectTimeout 10s --proxyAdminPort 15000 --concurrency 2 --controlPlaneAuthPolicy NONE --dnsRefreshRate 300s --statusPort 15020 --trust-domain=cluster.local --controlPlaneBootstrap=false\n1337                10660               10576               0                   08:09               ?                   00:00:33            \/usr\/local\/bin\/envoy -c \/etc\/istio\/proxy\/envoy-rev0.json --restart-epoch 0 --drain-time-s 45 --parent-shutdown-time-s 60 --service-cluster productpage.default --service-node sidecar~172.17.0.16~productpage-v1-7f44c4d57c-ksf9b.default~default.svc.cluster.local --max-obj-name-len 189 --local-address-ip-version v4 --log-format [Envoy (Epoch 0)] [%Y-%m-%d %T.%e][%t][%l][%n] %v -l warning --component-log-level misc:error --concurrency 2\n\n# 使用 nsenter 进入 sidecar 容器的命名空间（以上任何一个都可以）\n$ nsenter -n --target 10660\n\n# 查看 NAT 表中规则配置的详细信息。\n$ iptables -t nat -L\n\u0060\u0060\u0060\n\n### 在 GKE 中查看容器的 iptables 规则\n\n如果你在 GKE 中安装的多节点的 Kubernetes 集群，首先你需要确定这个 Pod 运行在哪个节点上，然后登陆到那台主机，使用下面的命令查找进程的 PID，你会得到类似下面的输出。\n\n\u0060\u0060\u0060bash\n$ ps aux|grep \u0022productpage\u0022\nchronos     4268  0.0  0.6  43796 24856 ?        Ss   Apr22   0:00 python productpage.py 9080\nchronos     4329  0.9  0.6 117524 24616 ?        Sl   Apr22  13:43 \/usr\/local\/bin\/python \/opt\/microservices\/productpage.py 9080\nroot      361903  0.0  0.0   4536   812 pts\/0    S\u002b   01:54   0:00 grep --colour=auto productpage\n\u0060\u0060\u0060\n\n在本示例中，productpage 进程的 PID 是 \u00604329\u0060，使用 \u0060nsenter -n --target 4329\u0060 进入该进程的命名空间，然后在终端中输入 \u0060iptables -t nat -L\u0060 即可查看 iptables 规则。\n\n## iptables 流量劫持过程详解\n\n经过上面的步骤，你已经可以查看到 init 容器向 Pod 中注入的 iptables 规则，如下所示。\n\n\u0060\u0060\u0060bash\n# PREROUTING 链：用于目标地址转换（DNAT），将所有入站 TCP 流量跳转到 ISTIO_INBOUND 链上。\nChain PREROUTING (policy ACCEPT 2701 packets, 162K bytes)\n pkts bytes target     prot opt in     out     source               destination\n 2701  162K ISTIO_INBOUND  tcp  --  any    any     anywhere             anywhere\n\n# INPUT 链：处理输入数据包，非 TCP 流量将继续 OUTPUT 链。\nChain INPUT (policy ACCEPT 2701 packets, 162K bytes)\n pkts bytes target     prot opt in     out     source               destination\n\n# OUTPUT 链：将所有出站数据包跳转到 ISTIO_OUTPUT 链上。\nChain OUTPUT (policy ACCEPT 79 packets, 6761 bytes)\n pkts bytes target     prot opt in     out     source               destination\n   15   900 ISTIO_OUTPUT  tcp  --  any    any     anywhere             anywhere\n\n# POSTROUTING 链：所有数据包流出网卡时都要先进入 POSTROUTING 链，内核根据数据包目的地判断是否需要转发出去，我们看到此处未做任何处理。\nChain POSTROUTING (policy ACCEPT 79 packets, 6761 bytes)\n pkts bytes target     prot opt in     out     source               destination\n\n# ISTIO_INBOUND 链：将所有入站流量重定向到 ISTIO_IN_REDIRECT 链上。目的地为 15090（Prometheus 使用）和 15020（Ingress gateway 使用，用于 Pilot 健康检查）端口的流量除外，发送到以上两个端口的流量将返回 iptables 规则链的调用点，即 PREROUTING 链的后继 INPUT 后直接调用原始目的地。\nChain ISTIO_INBOUND (1 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 RETURN     tcp  --  any    any     anywhere             anywhere             tcp dpt:ssh\n    2   120 RETURN     tcp  --  any    any     anywhere             anywhere             tcp dpt:15090\n 2699  162K RETURN     tcp  --  any    any     anywhere             anywhere             tcp dpt:15020\n    0     0 ISTIO_IN_REDIRECT  tcp  --  any    any     anywhere             anywhere\n\n# ISTIO_IN_REDIRECT 链：将所有的入站流量跳转到本地的 15006 端口，至此成功的拦截了流量到 sidecar 代理的 Inbound Handler 中。\nChain ISTIO_IN_REDIRECT (3 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 REDIRECT   tcp  --  any    any     anywhere             anywhere             redir ports 15006\n\n# ISTIO_OUTPUT 链：规则比较复杂，将在下文解释\nChain ISTIO_OUTPUT (1 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 RETURN     all  --  any    lo      127.0.0.6            anywhere #规则1\n    0     0 ISTIO_IN_REDIRECT  all  --  any    lo      anywhere            !localhost            owner UID match 1337 #规则2\n    0     0 RETURN     all  --  any    lo      anywhere             anywhere             ! owner UID match 1337 #规则3\n   15   900 RETURN     all  --  any    any     anywhere             anywhere             owner UID match 1337 #规则4\n    0     0 ISTIO_IN_REDIRECT  all  --  any    lo      anywhere            !localhost            owner GID match 1337 #规则5\n    0     0 RETURN     all  --  any    lo      anywhere             anywhere             ! owner GID match 1337 #规则6\n    0     0 RETURN     all  --  any    any     anywhere             anywhere             owner GID match 1337 #规则7\n    0     0 RETURN     all  --  any    any     anywhere             localhost #规则8\n    0     0 ISTIO_REDIRECT  all  --  any    any     anywhere             anywhere #规则9\n\n# ISTIO_REDIRECT 链：将所有流量重定向到 Envoy 代理的 15001 端口。\nChain ISTIO_REDIRECT (1 references)\n pkts bytes target     prot opt in     out     source               destination\n    0     0 REDIRECT   tcp  --  any    any     anywhere             anywhere             redir ports 15001\n\u0060\u0060\u0060\n\n这里着重需要解释的是 \u0060ISTIO_OUTPUT\u0060 链中的 9 条规则，为了便于阅读，我将以上规则中的部分内容使用表格的形式来展示如下：\n\n{{\u003ctable \u0022ISTIO_OUTPUT 链中的路由规则\u0022\u003e}}\n| **规则** | **target**        | **in** | **out** | **source** | **destination**                 |\n| -------- | ----------------- | ------ | ------- | ---------- | ------------------------------- |\n| 1        | RETURN            | any    | lo      | 127.0.0.6  | anywhere                        |\n| 2        | ISTIO_IN_REDIRECT | any    | lo      | anywhere   | !localhost owner UID match 1337 |\n| 3        | RETURN            | any    | lo      | anywhere   | anywhere !owner UID match 1337  |\n| 4        | RETURN            | any    | any     | anywhere   | anywhere owner UID match 1337   |\n| 5        | ISTIO_IN_REDIRECT | any    | lo      | anywhere   | !localhost owner GID match 1337 |\n| 6        | RETURN            | any    | lo      | anywhere   | anywhere !owner GID match 1337  |\n| 7        | RETURN            | any    | any     | anywhere   | anywhere owner GID match 1337   |\n| 8        | RETURN            | any    | any     | anywhere   | localhost                       |\n| 9        | ISTIO_REDIRECT    | any    | any     | anywhere   | anywhere                        |\n{{\u003c\/table\u003e}}\n\n下图展示了 \u0060ISTIO_ROUTE\u0060 规则的详细流程。\n\n![Istio_ROUTE iptalbes 规则判断流程图](istio-route-iptables.svg)\n\n我将按照规则的出现顺序来解释每条规则的目的、对应文章开头图示中的步骤及详情。其中规则 5、6、7 是分别对规则 2、3、4 的应用范围扩大（从 UID 扩大为 GID），作用是类似的，将合并解释。注意，其中的规则是按顺序执行的，也就是说排序越靠后的规则将作为默认值。出站网卡（out）为 \u0060lo\u0060 （本地回环地址，loopback 接口）时，表示流量的目的地是本地 Pod，对于 Pod 向外部发送的流量就不会经过这个接口。所有 \u0060review\u0060 Pod 的出站流量只适用于规则 4、7、8、9。\n\n**规则 1**\n\n- 目的：**透传** Envoy 代理发送到本地应用容器的流量，使其绕过 Envoy 代理，直达应用容器。\n- 对应图示中的步骤：6 到 7。\n- 详情：该规则使得所有来自 \u0060127.0.0.6\u0060（该 IP 地址将在下文解释）的请求，跳出该链，返回 iptables 的调用点（即 \u0060OUTPUT\u0060）后继续执行其余路由规则，即 \u0060POSTROUTING\u0060 规则，把流量发送到任意目的地址，如本地 Pod 内的应用容器。如果没有这条规则，由 Pod 内 Envoy 代理发出的对 Pod 内容器访问的流量将会执行下一条规则，即规则 2，流量将再次进入到了 Inbound Handler 中，从而形成了死循环。将这条规则放在第一位可以避免流量在 Inbound Handler 中死循环的问题。\n\n**规则 2、5**\n\n- 目的：处理 Envoy 代理发出的站内流量（Pod 内部的流量），但不是对 localhost 的请求，通过后续规则将其转发给 Envoy 代理的 Inbound Handler。该规则适用于 Pod 对自身 IP 地址调用的场景，即 Pod 内服务之间的访问。\n- 详情：如果流量的目的地非 localhost，且数据包是由 1337 UID（即 \u0060istio-proxy\u0060 用户，Envoy 代理）发出的，流量将被经过 \u0060ISTIO_IN_REDIRECT\u0060 最终转发到 Envoy 的 Inbound Handler。\n\n**规则 3、6**\n\n- 目的：**透传** Pod 内的应用容器的站内流量。该规则适用于容器内部的流量。例如在 Pod 内对 Pod IP 或 localhost 的访问。\n- 对应图示中的步骤：6 到 7。\n- 详情：如果流量不是由 Envoy 用户发出的，那么就跳出该链，返回 \u0060OUTPUT\u0060 调用 \u0060POSTROUTING\u0060，直达目的地。\n\n**规则 4、7**\n\n- 目的：**透传**  Envoy 代理发出的出站请求。\n- 对应图示中的步骤：14 到 15。\n- 详情：如果请求是由 Envoy 代理发出的，则返回 \u0060OUTPUT\u0060 继续调用 \u0060POSTROUTING\u0060 规则，最终直接访问目的地。\n\n**规则 8**\n\n- 目的：**透传** Pod 内部对 localhost 的请求。\n- 详情：如果请求的目的地是 localhost，则返回 OUTPUT 调用 \u0060POSTROUTING\u0060，直接访问 localhost。\n\n**规则 9**\n\n- 目的：所有其他的流量将被转发到 \u0060ISTIO_REDIRECT\u0060 后，最终达到 Envoy 代理的 Outbound Handler。\n- 对应图示中的步骤：10 到 11。\n\n以上规则避免了 Envoy 代理到应用程序的路由在 iptables 规则中的死循环，保障了流量可以被正确的路由到 Envoy 代理上，也可以发出真正的出站请求。\n\n**关于 RETURN target**\n\n你可能留意到上述规则中有很多 RETURN target，它的意思是，指定到这条规则时，跳出该规则链，返回 iptables 的调用点（在我们的例子中即 \u0060OUTPUT\u0060）后继续执行其余路由规则，在我们的例子中即 \u0060POSTROUTING\u0060 规则，把流量发送到任意目的地址，你可以把它直观的理解为**透传**。\n\n**关于 127.0.0.6 IP 地址**\n\n127.0.0.6 这个 IP 是 Istio 中默认的 \u0060InboundPassthroughClusterIpv4\u0060，在 Istio 的代码中指定。即流量在进入 Envoy 代理后被绑定的 IP 地址，作用是让 Outbound 流量重新发送到  Pod 中的应用容器，即 **Passthought（透传），绕过 Outbound Handler**。该流量是对 Pod 自身的访问，而不是真正的对外流量。至于为什么选择这个 IP 作为流量透传，请参考 [Istio Issue-29603](https:\/\/github.com\/istio\/istio\/issues\/29603)。\n\n## 流量路由过程详解\n\n通过上文，你已经了解了 Istio 是如何在 Pod 中做透明流量劫持的，那么流量被劫持到 Envoy 代理中之后是如何被处理的呢？流量路由分为 Inbound 和 Outbound 两个过程，下面将根据上文中的示例及 sidecar 的配置为读者详细分析此过程。\n\n### 理解 Inbound Handler\n\nInbound Handler 的作用是将 iptables 拦截到的 downstream 的流量转发给 Pod 内的应用程序容器。在我们的实例中，假设其中一个 Pod 的名字是 \u0060reviews-v1-545db77b95-jkgv2\u0060，运行 \u0060istioctl proxy-config listener reviews-v1-545db77b95-jkgv2 --port 15006\u0060 查看该 Pod 中 15006 端口上的监听器情况，你将看到下面的输出。\n\n\u0060\u0060\u0060ini\nADDRESS PORT  MATCH                                                                                           DESTINATION\n0.0.0.0 15006 Addr: *:15006                                                                                   Non-HTTP\/Non-TCP\n0.0.0.0 15006 Trans: tls; App: istio-http\/1.0,istio-http\/1.1,istio-h2; Addr: 0.0.0.0\/0                        InboundPassthroughClusterIpv4\n0.0.0.0 15006 Trans: raw_buffer; App: http\/1.1,h2c; Addr: 0.0.0.0\/0                                           InboundPassthroughClusterIpv4\n0.0.0.0 15006 Trans: tls; App: TCP TLS; Addr: 0.0.0.0\/0                                                       InboundPassthroughClusterIpv4\n0.0.0.0 15006 Trans: raw_buffer; Addr: 0.0.0.0\/0                                                              InboundPassthroughClusterIpv4\n0.0.0.0 15006 Trans: tls; Addr: 0.0.0.0\/0                                                                     InboundPassthroughClusterIpv4\n0.0.0.0 15006 Trans: tls; App: istio,istio-peer-exchange,istio-http\/1.0,istio-http\/1.1,istio-h2; Addr: *:9080 Cluster: inbound|9080||\n0.0.0.0 15006 Trans: raw_buffer; Addr: *:9080                                                                 Cluster: inbound|9080||\n\u0060\u0060\u0060\n\n下面列出了以上输出中各字段的含义：\n\n- ADDRESS：下游地址\n- PORT：Envoy 监听器监听的端口\n- MATCH：请求使用的传输协议或匹配的下游地址\n- DESTINATION：路由目的地\n\n\u0060reviews\u0060 Pod 中的 Iptables 将入站流量劫持到 15006 端口上，从上面的输出我们可以看到 Envoy 的 Inbound Handler 在 15006 端口上监听，对目的地为任何 IP 的 9080 端口的请求将路由到 \u0060inbound|9080||\u0060 Cluster 上。\n\n从该 Pod 的 Listener 列表的最后两行中可以看到，\u00600.0.0.0:15006\/TCP\u0060 的 Listener（其实际名字是 \u0060virtualInbound\u0060）监听所有的 Inbound 流量，其中包含了匹配规则，来自任意 IP 的对 \u00609080\u0060 端口的访问流量，将会路由到 \u0060inbound|9080||\u0060 Cluster，如果你想以 Json 格式查看该 Listener 的详细配置，可以执行 \u0060istioctl proxy-config listeners reviews-v1-545db77b95-jkgv2 --port 15006 -o json\u0060 命令，你将获得类似下面的输出。\n\n\u0060\u0060\u0060json\n[\n    \/*省略部分内容*\/\n    {\n        \u0022name\u0022: \u0022virtualInbound\u0022,\n        \u0022address\u0022: {\n            \u0022socketAddress\u0022: {\n                \u0022address\u0022: \u00220.0.0.0\u0022,\n                \u0022portValue\u0022: 15006\n            }\n        },\n        \u0022filterChains\u0022: [\n            \/*省略部分内容*\/\n            {\n                \u0022filterChainMatch\u0022: {\n                    \u0022destinationPort\u0022: 9080,\n                    \u0022transportProtocol\u0022: \u0022tls\u0022,\n                    \u0022applicationProtocols\u0022: [\n                        \u0022istio\u0022,\n                        \u0022istio-peer-exchange\u0022,\n                        \u0022istio-http\/1.0\u0022,\n                        \u0022istio-http\/1.1\u0022,\n                        \u0022istio-h2\u0022\n                    ]\n                },\n                \u0022filters\u0022: [\n                    \/*省略部分内容*\/\n                    {\n                        \u0022name\u0022: \u0022envoy.filters.network.http_connection_manager\u0022,\n                        \u0022typedConfig\u0022: {\n                            \u0022@type\u0022: \u0022type.googleapis.com\/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\u0022,\n                            \u0022statPrefix\u0022: \u0022inbound_0.0.0.0_9080\u0022,\n                            \u0022routeConfig\u0022: {\n                                \u0022name\u0022: \u0022inbound|9080||\u0022,\n                                \u0022virtualHosts\u0022: [\n                                    {\n                                        \u0022name\u0022: \u0022inbound|http|9080\u0022,\n                                        \u0022domains\u0022: [\n                                            \u0022*\u0022\n                                        ],\n                                        \u0022routes\u0022: [\n                                            {\n                                                \u0022name\u0022: \u0022default\u0022,\n                                                \u0022match\u0022: {\n                                                    \u0022prefix\u0022: \u0022\/\u0022\n                                                },\n                                                \u0022route\u0022: {\n                                                    \u0022cluster\u0022: \u0022inbound|9080||\u0022,\n                                                    \u0022timeout\u0022: \u00220s\u0022,\n                                                    \u0022maxStreamDuration\u0022: {\n                                                        \u0022maxStreamDuration\u0022: \u00220s\u0022,\n                                                        \u0022grpcTimeoutHeaderMax\u0022: \u00220s\u0022\n                                                    }\n                                                },\n                                                \u0022decorator\u0022: {\n                                                    \u0022operation\u0022: \u0022reviews.default.svc.cluster.local:9080\/*\u0022\n                                                }\n                                            }\n                                        ]\n                                    }\n                                ],\n                                \u0022validateClusters\u0022: false\n                            },\n                            \/*省略部分内容*\/\n                        }\n                    }\n                ],\n            \/*省略部分内容*\/\n        ],\n        \u0022listenerFilters\u0022: [\n        \/*省略部分内容*\/\n        ],\n        \u0022listenerFiltersTimeout\u0022: \u00220s\u0022,\n        \u0022continueOnListenerFiltersTimeout\u0022: true,\n        \u0022trafficDirection\u0022: \u0022INBOUND\u0022\n    }\n]\n\u0060\u0060\u0060\n\n既然 Inbound Handler 的流量中将来自任意地址的对该 Pod \u00609080\u0060 端口的流量路由到 \u0060inbound|9080||\u0060 Cluster，那么我们运行 \u0060istioctl pc cluster reviews-v1-545db77b95-jkgv2 --port 9080 --direction inbound -o json\u0060 查看下该 Cluster 配置，你将获得类似下面的输出。\n\n\u0060\u0060\u0060json\n[\n    {\n        \u0022name\u0022: \u0022inbound|9080||\u0022,\n        \u0022type\u0022: \u0022ORIGINAL_DST\u0022,\n        \u0022connectTimeout\u0022: \u002210s\u0022,\n        \u0022lbPolicy\u0022: \u0022CLUSTER_PROVIDED\u0022,\n        \u0022circuitBreakers\u0022: {\n            \u0022thresholds\u0022: [\n                {\n                    \u0022maxConnections\u0022: 4294967295,\n                    \u0022maxPendingRequests\u0022: 4294967295,\n                    \u0022maxRequests\u0022: 4294967295,\n                    \u0022maxRetries\u0022: 4294967295,\n                    \u0022trackRemaining\u0022: true\n                }\n            ]\n        },\n        \u0022cleanupInterval\u0022: \u002260s\u0022,\n        \u0022upstreamBindConfig\u0022: {\n            \u0022sourceAddress\u0022: {\n                \u0022address\u0022: \u0022127.0.0.6\u0022,\n                \u0022portValue\u0022: 0\n            }\n        },\n        \u0022metadata\u0022: {\n            \u0022filterMetadata\u0022: {\n                \u0022istio\u0022: {\n                    \u0022services\u0022: [\n                        {\n                            \u0022host\u0022: \u0022reviews.default.svc.cluster.local\u0022,\n                            \u0022name\u0022: \u0022reviews\u0022,\n                            \u0022namespace\u0022: \u0022default\u0022\n                        }\n                    ]\n                }\n            }\n        }\n    }\n]\n\u0060\u0060\u0060\n\n我们看其中的 \u0060TYPE\u0060 为 \u0060ORIGINAL_DST\u0060，将流量发送到原始目标地址（Pod IP），因为原始目标地址即当前 Pod，你还应该注意到 \u0060upstreamBindConfig.sourceAddress.address\u0060 的值被改写为了 \u0060127.0.0.6\u0060，而且对于 Pod 内流量是通过 \u0060lo\u0060 网卡发送的，这刚好呼应了上文中的 iptables \u0060ISTIO_OUTPUT\u0060 链中的第一条规则，根据该规则，流量将被透传到 Pod 内的应用容器。\n\n### 理解 Outbound Handler\n\n在本示例中 \u0060reviews\u0060 会向 \u0060ratings\u0060 服务发送 HTTP 请求，请求的地址是：\u0060http:\/\/ratings.default.svc.cluster.local:9080\/\u0060，Outbound Handler 的作用是将 iptables 拦截到的本地应用程序向外发出的流量，经由 Envoy 代理路由到上游。\n\nEnvoy 监听在 15001 端口上监听所有 Outbound 流量，Outbound Handler 处理，然后经过 \u0060virtualOutbound\u0060 Listener、\u00600.0.0.0_9080\u0060 Listener，然后通过 Route 9080 找到上游的 cluster，进而通过 EDS 找到 Endpoint 执行路由动作。\n\n**\u0060ratings.default.svc.cluster.local:9080\u0060 路由**\n\n运行 \u0060istioctl proxy-config routes reviews-v1-545db77b95-jkgv2 --name 9080 -o json\u0060 查看 route 配置，因为 sidecar 会根据 HTTP header 中的 domains 来匹配 VirtualHost，所以下面只列举了 \u0060ratings.default.svc.cluster.local:9080\u0060 这一个 VirtualHost。\n\n\u0060\u0060\u0060json\n[\n  {\n    \u0022name\u0022: \u00229080\u0022,\n    \u0022virtualHosts\u0022: [\n       {\n           \u0022name\u0022: \u0022ratings.default.svc.cluster.local:9080\u0022,\n           \u0022domains\u0022: [\n               \u0022ratings.default.svc.cluster.local\u0022,\n               \u0022ratings.default.svc.cluster.local:9080\u0022,\n               \u0022ratings\u0022,\n               \u0022ratings:9080\u0022,\n               \u0022ratings.default.svc\u0022,\n               \u0022ratings.default.svc:9080\u0022,\n               \u0022ratings.default\u0022,\n               \u0022ratings.default:9080\u0022,\n               \u002210.8.8.106\u0022,\n               \u002210.8.8.106:9080\u0022\n           ],\n           \u0022routes\u0022: [\n               {\n                   \u0022name\u0022: \u0022default\u0022,\n                   \u0022match\u0022: {\n                       \u0022prefix\u0022: \u0022\/\u0022\n                   },\n                   \u0022route\u0022: {\n                       \u0022cluster\u0022: \u0022outbound|9080||ratings.default.svc.cluster.local\u0022,\n                       \u0022timeout\u0022: \u00220s\u0022,\n                       \u0022retryPolicy\u0022: {\n                           \u0022retryOn\u0022: \u0022connect-failure,refused-stream,unavailable,cancelled,retriable-status-codes\u0022,\n                           \u0022numRetries\u0022: 2,\n                           \u0022retryHostPredicate\u0022: [\n                               {\n                                   \u0022name\u0022: \u0022envoy.retry_host_predicates.previous_hosts\u0022\n                               }\n                           ],\n                           \u0022hostSelectionRetryMaxAttempts\u0022: \u00225\u0022,\n                           \u0022retriableStatusCodes\u0022: [\n                               503\n                           ]\n                       },\n                       \u0022maxStreamDuration\u0022: {\n                           \u0022maxStreamDuration\u0022: \u00220s\u0022,\n                           \u0022grpcTimeoutHeaderMax\u0022: \u00220s\u0022\n                       }\n                   },\n                   \u0022decorator\u0022: {\n                       \u0022operation\u0022: \u0022ratings.default.svc.cluster.local:9080\/*\u0022\n                   }\n               }\n           ],\n           \u0022includeRequestAttemptCount\u0022: true\n       },\n       \/*省略部分内容*\/\n     ],\n     \u0022validateClusters\u0022: false\n    }\n]\n\u0060\u0060\u0060\n\n从该 Virtual Host 配置中可以看到将流量路由到\u0060outbound|9080||ratings.default.svc.cluster.local\u0060 集群。\n\n**\u0060outbound|9080||ratings.default.svc.cluster.local\u0060 集群的端点**\n\n运行 \u0060istioctl proxy-config endpoint reviews-v1-545db77b95-jkgv2 --port 9080 -o json --cluster \u0022outbound|9080||ratings.default.svc.cluster.local\u0022\u0060 查看集群的 Endpoint 配置，结果如下。\n\n\u0060\u0060\u0060json\n[\n    {\n        \u0022name\u0022: \u0022outbound|9080||ratings.default.svc.cluster.local\u0022,\n        \u0022addedViaApi\u0022: true,\n        \u0022hostStatuses\u0022: [\n            {\n                \u0022address\u0022: {\n                    \u0022socketAddress\u0022: {\n                        \u0022address\u0022: \u002210.4.1.12\u0022,\n                        \u0022portValue\u0022: 9080\n                    }\n                },\n                \u0022stats\u0022: [\n                    {\n                        \u0022name\u0022: \u0022cx_connect_fail\u0022\n                    },\n                    {\n                        \u0022name\u0022: \u0022cx_total\u0022\n                    },\n                    {\n                        \u0022name\u0022: \u0022rq_error\u0022\n                    },\n                    {\n                        \u0022name\u0022: \u0022rq_success\u0022\n                    },\n                    {\n                        \u0022name\u0022: \u0022rq_timeout\u0022\n                    },\n                    {\n                        \u0022name\u0022: \u0022rq_total\u0022\n                    },\n                    {\n                        \u0022type\u0022: \u0022GAUGE\u0022,\n                        \u0022name\u0022: \u0022cx_active\u0022\n                    },\n                    {\n                        \u0022type\u0022: \u0022GAUGE\u0022,\n                        \u0022name\u0022: \u0022rq_active\u0022\n                    }\n                ],\n                \u0022healthStatus\u0022: {\n                    \u0022edsHealthStatus\u0022: \u0022HEALTHY\u0022\n                },\n                \u0022weight\u0022: 1,\n                \u0022locality\u0022: {\n                    \u0022region\u0022: \u0022us-west2\u0022,\n                    \u0022zone\u0022: \u0022us-west2-a\u0022\n                }\n            }\n        ],\n        \u0022circuitBreakers\u0022: {\n            \u0022thresholds\u0022: [\n                {\n                    \u0022maxConnections\u0022: 4294967295,\n                    \u0022maxPendingRequests\u0022: 4294967295,\n                    \u0022maxRequests\u0022: 4294967295,\n                    \u0022maxRetries\u0022: 4294967295\n                },\n                {\n                    \u0022priority\u0022: \u0022HIGH\u0022,\n                    \u0022maxConnections\u0022: 1024,\n                    \u0022maxPendingRequests\u0022: 1024,\n                    \u0022maxRequests\u0022: 1024,\n                    \u0022maxRetries\u0022: 3\n                }\n            ]\n        },\n        \u0022observabilityName\u0022: \u0022outbound|9080||ratings.default.svc.cluster.local\u0022\n    }\n]\n\u0060\u0060\u0060\n\n我们看到端点的地址是 \u006010.4.1.12\u0060。实际上，Endpoint 可以是一个或多个，sidecar 将根据一定规则选择适当的 Endpoint 来路由。至此 \u0060review\u0060 Pod 找到了它上游服务 \u0060rating\u0060 的 Endpoint。\n\n## 小结\n\n本文使用了 Istio 官方提供的 bookinfo 示例，按图索骥得带领读者了解了 sidecar 注入、iptables 透明流量劫持及 sidecar 中流量路由背后的实现细节。Sidecar 模式和流量透明劫持是 Istio 服务网格的特色和基础功能，理解该功能的背后过程及实现细节，将有助于大家理解 Service Mesh 的原理，因此希望读者可以在自己的环境中从头来试验一遍以加深理解。\n\n使用 iptables 做流量劫持只是 service mesh 的数据平面中做流量劫持的方式之一，还有更多的流量劫持方案，下面引用自 [云原生网络代理 MOSN 官网中给出的流量劫持](https:\/\/mosn.io\/docs\/products\/structure\/traffic-hijack\/)部分的描述。\n\n### 使用 iptables 做流量劫持时存在的问题\n\n目前 Istio 使用 iptables 实现透明劫持，主要存在以下三个问题：\n\n1. 需要借助于 conntrack 模块实现连接跟踪，在连接数较多的情况下，会造成较大的消耗，同时可能会造成 track 表满的情况，为了避免这个问题，业内有关闭 conntrack 的做法。\n1. iptables 属于常用模块，全局生效，不能显式的禁止相关联的修改，可管控性比较差。\n1. iptables 重定向流量本质上是通过 loopback 交换数据，outbond 流量将两次穿越协议栈，在大并发场景下会损失转发性能。\n\n上述几个问题并非在所有场景中都存在，比方说某些场景下，连接数并不多，且 NAT 表未被使用到的情况下，iptables 是一个满足要求的简单方案。为了适配更加广泛的场景，透明劫持需要解决上述三个问题。\n\n### 透明劫持方案优化\n\n为了优化 Istio 中的透明流量劫持的性能，业界提出了以下方案。\n\n**使用 Merbridge 开源项目利用 eBPF 劫持流量**\n\n[Merbridge](https:\/\/github.com\/merbridge\/merbridge) 是由 DaoCloud 在 2022 年初开源的的一款利用 eBPF 加速 Istio 服务网格的插件。使用 Merbridge 可以在一定程度上优化数据平面的网络性能。\n\nMerbridge 利用 eBPF 的 \u0060sockops\u0060 和 \u0060redir\u0060 能力，可以直接将数据包从 inbound socket 传输到 outbound socket。eBPF 提供了 \u0060bpf_msg_redirect_hash\u0060 函数可以直接转发应用程序的数据包。\n\n详见 [Istio 服务网格 —— 云原生应用网络构建指南](https:\/\/jimmysong.io\/istio-handbook\/ecosystem\/merbridge.html)。\n\n**使用 tproxy 处理 inbound 流量**\n\ntproxy 可以用于 inbound 流量的重定向，且无需改变报文中的目的 IP\/端口，不需要执行连接跟踪，不会出现 conntrack 模块创建大量连接的问题。受限于内核版本，tproxy 应用于 outbound 存在一定缺陷。目前 Istio 支持通过 tproxy 处理 inbound 流量。\n\n**使用 hook connect 处理 outbound 流量**\n\n为了适配更多应用场景，outbound 方向通过 hook connect 来实现，实现原理如下：\n\n![hook-connect 原理示意图](hook-connect.svg)\n\n无论采用哪种透明劫持方案，均需要解决获取真实目的 IP\/端口的问题，使用 iptables 方案通过 getsockopt 方式获取，tproxy 可以直接读取目的地址，通过修改调用接口，hook connect 方案读取方式类似于 tproxy。\n\n实现透明劫持后，在内核版本满足要求（4.16 以上）的前提下，通过 sockmap 可以缩短报文穿越路径，进而改善 outbound 方向的转发性能。\n\n## 更新说明\n\n下面是本文的几次更新说明。\n\n**2020 年 4 月 27 日，第一版，基于 Istio 1.5**\n\n本文的第一版，基于 Istio 1.5 创作，在此之前，我曾写过基于 Istio 1.1 版本的[理解 Istio Service Mesh 中 Envoy 代理 Sidecar 注入及流量劫持](\/blog\/envoy-sidecar-injection-in-istio-service-mesh-deep-dive\/)，为了更细致的理解 Istio 中透明流量劫持的全过程，专门创作本文。\n\n**2022 年  1 月 17 日，第二版，基于 Istio 1.11**\n\n本文第一版发布后，在社区里获得了比较大的反响，收到了很多读者的评论和留言。基于这些评论，我也发现了第一版中的很多错误，在加上 Istio 版本发布频繁，在近两年的时间内，Istio 已经作出了众多更新，其中不乏重大更新。因此笔者撰写了本文的第二版，修改了之前版本中的纰漏并根据时下 Istio 的最新版本更新了本文。\n\nIstio 1.11 与 Istio 1.1 中的 sidecar 注入和流量劫持环节最大的变化是：\n\n- iptables 改用命令行工具，不再使用 shell 脚本。\n- sidecar inbound 和 outbound 分别指定了端口，而之前是使用同一个端口（15001）。\n\n**2022 年 4 月 24，第三版，基于 Istio  1.13**\n\n这个版本的文章主要是根据当时 Istio 的最新版本更新了文章的部分内容，并重新排版，增加更新说明。\n\nIstio 1.13 相比 Istio 1.11 的变化是 \u0060istioctl proxy-config\u0060 命令的输出有了较大变化。\n\n**2022 年 5 月 6 日，第四版，基于 Istio 1.13**\n\n- 修改了对 \u0060ISTIO_ROUTE\u0060 iptables 规则 2、5 的解释\n- 在示意图中增加了路径 16\n\n**2022 年 5 月 12 日，第五版，基于 Istio 1.13**\n\n- 将 iptables 说明和 sidecar 注入、init 容器部分独立成了两篇单独的博客，以缩减博客的篇幅，见 [Istio 数据平面 Pod 启动过程详解](\/blog\/istio-pod-process-lifecycle\/)和[理解 iptables](\/blog\/understanding-iptables\/)。\n\n**2023 年 7 月 17 日，第六版，基于 Istio 1.13**\n\n- 修改了对 ISTIO_INBOUND 链的说明\n\n## 参考\n\n- [Debugging Envoy and Istiod - istio.io](https:\/\/istio.io\/latest\/docs\/ops\/diagnostic-tools\/proxy-cmd\/)\n- [揭开 Istio Sidecar 注入模型的神秘面纱 - istio.io](https:\/\/istio.io\/latest\/zh\/blog\/2019\/data-plane-setup\/)\n- [MOSN 作为 Sidecar 使用时的流量劫持方案 - mosn.io](https:\/\/mosn.io\/docs\/products\/structure\/traffic-hijack\/)\n', '\/blog\/sidecar-injection-iptables-and-traffic-routing\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文基于 Istio 1.13 版本，介绍了 sidecar 模式及其优势 sidecar 如何注入到数据平面，Envoy 如何做流量劫持和路由转发的，包括 Inbound 流量和 Outbound 流量。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/trans/migrating-millions-of-concurrent-websockets-to-envoy/">[译] Slack 将数百万个并发的 Websockets 迁移到 Envoy 上经验分享</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2022/04/08</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/envoy"> 
             Envoy
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fas fa-language"></i>
              <a href="https://slack.engineering/migrating-millions-of-concurrent-websockets-to-envoy/" target="_blank" rel="noopener">原文</a>
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('Slack 将数百万个并发的 Websockets 迁移到 Envoy 上经验分享', '本文是 Slack 花半年时间从 HAProxy 迁移到 Envoy 上的经验分享。', '本文译自 [Migrating Millions of Concurrent Websockets to Envoy](https:\/\/slack.engineering\/migrating-millions-of-concurrent-websockets-to-envoy\/)，原文发布于 2021 年。作者是 **Ariane van der Steldt** Staff Software Engineer, Site Reliability，**Radha Kumari** Sr. Software Engineer, Site Reliability。\n\nSlack 有一个全球客户群，在高峰期有数百万同时连接的用户。用户之间的大部分通信涉及到向对方发送大量的微小信息。在 Slack 的大部分历史中，我们一直使用 [HAProxy](https:\/\/www.haproxy.com\/) 作为所有传入流量的负载均衡器。今天，我们将讨论我们在使用 HAProxy 时所面临的问题，我们如何用 [Envoy Proxy](https:\/\/www.envoyproxy.io\/) 来解决这些问题，迁移所涉及的步骤，以及结果是什么。让我们开始吧！\n\n## **Slack 的 Websockets**\n\n为了即时传递信息，我们使用 [websocket 连接](https:\/\/tools.ietf.org\/html\/rfc6455)，这是一种双向的通信链接，负责让你看到 \u0022有几个人在打字......\u0022，然后是他们打的东西，速度几乎是光速的。websocket 连接被摄取到一个叫做 \u0022wss\u0022（WebSocket 服务）的系统中，可以通过 \u0060wss-primary.slack.com\u0060 和 \u0060wss-backup.slack.com\u0060（这不是网站，如果去访问，只会得到一个 HTTP 404）从互联网上访问。\n\n![显示 websockets 工作原理的图表](e6c9d24ely1h1277posyqj20cg0b8dfz.jpg)\n\nWebsocket 连接一开始是普通的 HTTPS 连接，然后客户端发出协议切换请求，将连接升级为 Websocket。在 Slack，我们有不同的 websocket 服务，专门用于消息、在线（列出哪些联系人在线）和其他服务。其中一个 websocket 端点是专门为需要与 Slack 互动的应用程序制作的（因为应用程序也想要实时通信）。\n\n![解释流量如何被路由到后端服务的流程图](e6c9d24ely1h1277nk5l3j20hr0bbq3e.jpg)\n\n过去，我们在多个 [AWS](https:\/\/aws.amazon.com\/) Region 有一组专门用于 websockets 的 HAProxy 实例，以终止靠近用户的 websocket 连接，并将请求转发给相应的后端服务。\n\n## **迁移到 Envoy Proxy 的动机**\n\n虽然我们从 Slack 开始就一直在使用 HAproxy，并且知道如何大规模地操作它，但有一些操作上的挑战让我们考虑替代方案，比如 Envoy Proxy。\n\n### **热重启**\n\n在 Slack，后端服务端点列表的变化是一个常见的事件（由于实例被添加或删除）。HAProxy 提供两种方法来更新其配置，以适应端点列表的变化。一种是使用 HAProxy Runtime API。我们在其中一套 HAProxy 实例中使用了这种方法，我们的经验在另一篇博文中有所描述 —— [在 Slack 的可怕的、恐怖的、没有好处的、非常糟糕的一天](https:\/\/slack.engineering\/a-terrible-horrible-no-good-very-bad-day-at-slack\/)。另一种方法，我们用于 websockets 负载均衡器（LB），是将后端渲染到 HAProxy 配置文件中，然后重新加载 HAProxy。\n\n每次 HAProxy 重载时，都会创建一组新的进程来处理新进入的连接。我们会让旧的进程持续运行很多小时，以便让长寿的 websocket 连接耗尽，避免用户频繁断开连接。然而，我们不能有太多的 HAProxy 进程，每个进程都运行着它自己 \u0022当时\u0022 的配置副本 —— 我们希望实例能更快地汇聚到新版本的配置上。我们不得不定期收割旧的 HAProxy 进程，并限制 HAProxy 重新加载的频率，以防底层后端出现混乱。\n\n无论我们使用哪种方法，都需要一些额外的基础设施来管理 HAProxy 的重新加载。\n\nEnvoy 允许我们使用[动态配置的集群和端点](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/upstream\/service_discovery#arch-overview-service-discovery-types-eds)，这意味着如果端点列表发生变化，它不需要重新加载。如果代码或配置确实发生了变化，Envoy 有能力在不放弃任何连接的情况下[热重启](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/operations\/hot_restart)自己。Envoy 通过 [inotify](https:\/\/en.wikipedia.org\/wiki\/Inotify) 观察文件系统配置的更新。在热重启过程中，Envoy 还将统计数据从父进程复制到子进程中，因此仪表和计数器不会被重置。\n\n这一切都使 Envoy 的运营开销大大减少，而且不需要额外的服务来管理配置变化或重新启动。\n\n### **负载均衡功能**\n\nEnvoy 提供了一些先进的负载均衡功能，如：\n\n- 内置支持区域感知路由的功能\n- 通过[异常值检测](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/upstream\/outlier#arch-overview-outlier-detection)进行被动健康检查\n- [恐慌路由](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/upstream\/load_balancing\/panic_threshold)：Envoy 通常只将流量路由到健康的后端，但是如果健康主机的百分比低于某个阈值，它可以被配置为将流量发送到所有的后端，不管是健康的还是不健康的。这在我们 [2021 年 1 月 4 日的故障](https:\/\/slack.engineering\/slacks-outage-on-january-4th-2021\/)中非常有帮助，这次故障是由我们基础设施中的一个广泛的网络问题引起的。\n\n由于上述原因，在 2019 年，我们决定将我们的入口负载均衡层从 HAproxy 迁移到 Envoy Proxy，从 websockets 堆栈开始。迁移的主要目标是提高可操作性，获得 Envoy 提供的新功能，以及更加标准化。通过在整个 Slack 中从 HAProxy 迁移到 Envoy，我们的团队将不再需要了解两个软件的怪异之处，不再需要维护两种不同的配置，不再需要管理两个构建和发布管道，诸如此类。那时，我们已经在使用 Envoy Proxy 作为我们服务网格中的[数据平面](https:\/\/blog.envoyproxy.io\/service-mesh-data-plane-vs-control-plane-2774e720f7fc)。我们内部也有经验丰富的 Envoy 开发人员，所以我们可以随时获得 Envoy 的专业知识。\n\n## 生成 Envoy 配置\n\n这次迁移的第一步是审查我们现有的 websocket 层配置，并生成一个同等的 Envoy 配置。在迁移过程中，管理 Envoy 配置是我们最大的挑战之一。Envoy 有丰富的功能集，其配置与 HAProxy 的配置有很大的不同。Envoy 配置涉及四个主要概念：\n\n- **Listener**，接收请求，又称 TCP 套接字、SSL 套接字或 unix 域套接字。\n- **Cluster**，代表我们发送请求的内部服务，如消息服务器和存在服务器\n- **Route**，将 Listener 和 Cluster 连接在一起\n- **Filter**，它对请求进行操作\n\nSlack 的配置管理主要是通过 [Chef](https:\/\/www.chef.io\/) 完成的。当我们开始使用 Envoy 时，我们把 Envoy 配置作为 [chef 模板文件](https:\/\/docs.chef.io\/resources\/template\/)来部署，但它的管理变得很麻烦，而且容易出错。为了解决这个问题，我们建立了 chef 库和[自定义资源](https:\/\/docs.chef.io\/custom_resources_notes\/)来生成 Envoy 配置。\n\n![Chef 资源的结构和流程图](e6c9d24ely1h1277ob5drj20hs07wq2z.jpg)\n\n在 Chef 内部，配置是一个[单例](https:\/\/en.wikipedia.org\/wiki\/Singleton_pattern)，模拟了每个主机只有一个 Envoy 配置的情况。所有的 Chef 资源都在这个单例上操作，添加监听器、路由或集群。在 Chef 运行的最后，\u0060envoy.yaml\u0060 被生成、验证，然后安装 —— 我们从不写中间配置，因为这些配置可能是无效的。\n\n这个例子展示了我们如何创建一个有两条路由的 HTTP 监听器，将流量路由到两个[动态](https:\/\/www.envoyproxy.io\/docs\/envoy\/latest\/intro\/arch_overview\/upstream\/service_discovery#endpoint-discovery-service-eds)集群。\n\n![调用 Chef 资源以创建带有集群和路由的监听器的例子](e6c9d24ely1h1277otk25j20hs0ao74o.jpg)\n\n要在 Envoy 中复制我们复杂的 HAProxy 配置需要一些努力。大部分需要的功能在 Envoy 中已经有了，所以只需要在 chef 库中加入对它的支持就可以了。我们实现了一些缺失的 Envoy 功能（有些是[上游](https:\/\/github.com\/envoyproxy\/envoy\/pull\/12206)贡献的，有些是内部维护的扩展）。\n\n## 对我们的新配置进行测试和验证\n\n测试新的 Envoy websockets 层是一个迭代的过程。我们经常用手工编码的 Envoy 配置做原型，并在本地的开发机器上测试，每个监听器、路由和集群都有一个。手工编码的修改一旦成功，就会被移到 chef 库中。\n\nHTTP 路由是用 [curl](https:\/\/curl.se\/docs\/manpage.html) 测试的：\n\n- 基于头和 cookie 的特定路由到特定后端\n- 基于路径、前缀和查询参数的路由到特定后端\n- SSL 证书\n\n当事情没有达到预期效果时，我们在机器上使用 Envoy 调试日志。调试日志清楚地解释了为什么 Envoy 选择将一个特定的请求路由到一个特定的集群。Envoy 的调试日志非常有用，但也很冗长，而且很昂贵（你真的不想在生产环境中启用这个功能）。调试日志可以通过 Curl 启用，如下所示。\n\n\u0060\u0060\u0060bash\ncurl -X POST http:\/\/localhost:\u003cenvoy_admin_port\u003e\/logging?level=debug\n\u0060\u0060\u0060\n\nEnvoy 管理接口在初始调试时也很有用，特别是这些端点：\n\n- **clusters**：显示所有配置的集群，包括每个集群中所有上游主机的信息以及每个主机的统计数据。\n- **\/certs**：以 JSON 格式显示所有加载的 TLS 证书，包括文件名、序列号、主体替代名称和到期前的天数。\n- **\/listeners**：显示所有配置的监听器及其名称和地址。\n\n我们的 Chef 库使用 \u0060-mode validate\u0060 命令行选项运行 Envoy，作为一个验证步骤，以防止安装无效的配置。这也可以手动完成。\n\n\u0060\u0060\u0060bash\nsudo \/path\/to\/envoy\/binary -c \u003c\/path\/to\/envoy.yaml\u003e --mode validate\n\u0060\u0060\u0060\n\nEnvoy 提供 JSON 格式的监听器日志。我们将这些日志录入我们的日志管道（当然是在对日志进行 [PII](https:\/\/en.wikipedia.org\/wiki\/Personal_data) 处理后），这对调试工作经常很有帮助。\n\n一旦对开发环境中的配置有信心，我们就准备做一些更多的测试 -- 在生产中！\u0022。\n\n## 迁移至生产\n\n为了将迁移过程中的风险降到最低，我们建立了一个新的 Envoy websocket 栈，其配置与现有的 HAProxy 层相当。这意味着我们可以逐步、有控制地将流量转移到新的 Envoy 堆栈，并且在必要时可以快速切换回 HAProxy。缺点是我们的 AWS 成本 —— 我们在迁移过程中使用了双倍的资源，但我们愿意花费时间和资源为我们的客户透明地进行迁移。\n\n我们通过 [NS1](https:\/\/ns1.com\/) 管理我们的 DNS 记录 **wss-primary.slack.com** 和 **wss-backup.slack.com**。我们使用加权路由将流量从 **haproxy-wss** 转移到 **envoy-wss** [NLB](https:\/\/docs.aws.amazon.com\/elasticloadbalancing\/latest\/network\/introduction.html) DNS 名称。第一批区域是以 10%、25%、50%、75% 和 100% 的步骤单独上线的。由于我们对新的 Envoy 层和上线过程有信心，所以最后的区域上线速度更快（25%、50%、75%、100% 只需两天，而之前的一个区域需要一周的时间）。\n\n尽管迁移工作很顺利，没有出现故障，但还是出现了一些小问题，比如超时值和 header 的差异。在迁移过程中，我们多次恢复、修复，并再次上线。\n\n![流程图显示 DNS 迁移过程中涉及的组件和步骤](e6c9d24ely1h1277p8k19j20hs07c3yp.jpg)\n\n经过漫长而激动人心的 6 个月，迁移完成了，整个 HAProxy websocket 堆栈在全球范围内被 Envoy Proxy 取代，对客户的**影响为零**。\n\n## 哪些进展顺利，哪些不顺利\n\n迁移本身是相对平淡和无聊的。**枯燥是一件好事**：刺激意味着事情的中断，枯燥意味着一切顺利。\n\n我们发现，旧的 HAProxy 配置随着时间的推移而有机地增长。它在很大程度上是由 HAProxy 使用的模型形成的 —— 一个包括所有监听器的大型配置。Envoy 的配置模型比 HAProxy 的模型使用更多的定义范围。一旦一个监听器被输入，只有该监听器内的规则适用于请求。一旦输入一个路由，只有该路由上的规则适用。这使得将规则与相关的请求联系起来更加容易。\n\n我们花了很长时间从旧的 HAProxy 配置中提取重要的东西，这实际上是技术债务。通常很难弄清楚为什么会有某个规则，哪些是有意的，哪些是无意的，以及其他服务所依赖的行为是什么。例如，有些服务应该只在两个虚拟主机（vhosts）中的一个下，但实际上在 HAProxy 的两个 vhosts 下都可用。我们不得不复制这个错误，因为现有的代码依赖于这种行为。\n\n我们在 HAProxy 堆栈中错过了一些细微的东西。有时这些是很重要的 —— 我们破坏了 Slack 的每日活跃用户（DAU）指标（哎呀！）。也有很多小问题需要解决。负载均衡器的行为很复杂，除了花时间调试外，没有真正的办法解决这个问题。\n\n我们开始迁移时，没有为负载均衡器的配置提供测试框架。我们没有自动测试来验证测试的 URL 路由到正确的端点以及与请求和响应头相关的行为，而是有...... 一个 HAProxy 配置。在迁移过程中，测试是很有帮助的，因为它们可以提供很多关于预期行为的原因的背景。因为我们缺乏测试，所以我们经常不得不向服务所有者询问，以了解他们所依赖的行为。\n\n我们建立的 Chef 资源有意只支持 Envoy 功能的一个子集。这使我们的库更简单 —— 我们只需要考虑我们实际使用的功能。缺点是，每次我们想使用新的 Envoy 功能时，都必须在我们的 Chef 库中添加对这些功能的支持。例如，[SNI](https:\/\/en.wikipedia.org\/wiki\/Server_Name_Indication)（https）监听器是在开发过程中编写的，当时我们认为这比向现有的监听器添加支持更简单。然而，当涉及到 vhost 支持时，我们已经开发了很多代码并在使用中，重构整个公司其他地方正在使用的资源将花费很长时间。我们的 Chef 库中的 vhost 支持是一个 hack（很快有一天我们会修复它）。\n\n为了使改变 Envoy 资源 Chef 库更加安全，换句话说，确保我们不会破坏其他使用我们库的团队，我们引入了一套全面的测试，生成这些团队的整个配置。这使得我们可以很容易地知道，当我们更新 Envoy Chef 资源时，我们生成的所有 Envoy 配置会（或不会）受到什么影响。\n\n这次迁移（和其他迁移一样）的关键事项之一是沟通。我们努力让每个人都了解并配合我们正在进行的改变。我们的客户体验（CE）团队是一个很好的合作伙伴 —— 他们能够监控传入的工单，以发现任何可能表明用户因这次迁移而受到影响的情况。\n\n## 下一步是什么？\n\n尽管偶尔会遇到一些小挫折，但 envoy websocket 的迁移还是非常成功的。我们已经跟进，将另一个关键的 Slack 服务，即我们的软件客户端指标摄取管道 —— 与我们的其他入口负载均衡器隔离 —— 迁移到 Envoy Proxy。我们几乎已经完成了将我们的网络和 API 流量的内部负载均衡器迁移到 Envoy。这场史诗般的迁移的最后一部分是将我们的（常规的、非 websocket 的）HTTP 堆栈从 HAProxy 迁移到 Envoy，这也是正在进行的。\n\n我们的最终目标是在入口负载均衡器和服务网格数据平面上实现 Envoy Proxy 的标准化，这将大大降低团队的认知负荷和操作复杂性，并使 Envoy 的先进功能在我们的负载均衡基础设施中得到应用。自从迁移到 Envoy 后，我们已经大大超过了以前的峰值负载，没有任何问题。\n', '\/trans\/migrating-millions-of-concurrent-websockets-to-envoy\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文是 Slack 花半年时间从 HAProxy 迁移到 Envoy 上的经验分享。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
              <div class="col-sm-6 mb-3">
  <article class="card rounded-0 border-bottom border-primary border-top-0 border-left-0 border-right-0 hover-shadow">
    
    
    <div class="card-body blog-list-card-body">
      <p class="card-title"><a href="/blog/slime-intro/">网易开源 Istio 扩展项目 Slime 简介——基于 Istio 的智能服务网格管理器</a></p>
      
      <div class="blog-list-metadata">
          <ul class="list-inline">
             
             <li class="list-inline-item mr-2 mb-md-0"><i class="fa-regular fa-calendar"></i>
               2021/11/24</li>
             <li class="list-inline-item mr-2 md-md-0"><i class="fa-regular fa-folder-open"></i>
             
             <a href="/categories/service-mesh"> 
             Service Mesh
             </a>
             
             </li>
             
             <li class="list-inline-item mr-2 mb-md-0">
              

             </li>
             
             <li class="list-inline-item mr-2 mb-md-0 export-button" style="display: none;">
              <a href="#" onclick="exportToMarkdown('网易开源 Istio 扩展项目 Slime 简介——基于 Istio 的智能服务网格管理器', '本文介绍的是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器 Slime。', '\n最近我在研究 Istio 生态中的开源项目，[Slime](https:\/\/github.com\/slime-io\/slime\/) 这个项目开源与 2021 年初，是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器。Slime 基于 Kubernetes Operator 实现，可作为 Istio 的 CRD 管理器，无须对 Istio 做任何定制化改造，就可以定义动态的服务治理策略，从而达到自动便捷使用 Istio 和 Envoy 高阶功能的目的。\n\n## Slime 试图解决的问题\n\nSlime 项目的诞生主要为了解决以下问题：\n\n1. 网格内所有服务配置全量下到所有 Sidecar Proxy，导致其消耗大量资源使得应用性能变差的问题\n2. 如何在 Istio 中实现高阶扩展的问题：比如扩展 HTTP 插件；根据服务的资源使用率做到自适应限流\n\nSlime 解决以上问题的答案是构建 Istio 的控制平面，具体做法是：\n\n- 构建可拔插控制器\n- 数据平面监控\n- CRD 转换\n\n通过以上方式 Slime 可以实现**配置懒加载**和**插件管理器**。\n\n## Slime 架构\n\nSlime 内部分为三大模块，其架构图如下所示。\n\n![Slime 内部架构图](slime-internal-arch.jpg)\n\nSlime 内部三大组件为：\n\n1. \u0060slime-boot\u0060：在 Kubernetes 上部署 Slime 模块的 operator。\n2. \u0060slime-controller\u0060：Slime 的核心组件，监听 Slime CRD 并将其转换为 Istio CRD。\n3. \u0060slime-metric\u0060：用于获取服务 metrics 信息的组件，\u0060slime-controller\u0060 会根据其获取的信息动态调整服务治理规则。\n\n目前 Slime 内置了三个控制器子模块：\n\n1. **配置懒加载（按需加载）**：用户无须手动配置 \u0060SidecarScope\u0060，Istio 可以按需加载服务配置和服务发现信息；\n2. **HTTP 插件管理**：使用新的 CRD——\u0060pluginmanager\/envoyplugin\u0060 包装了可读性，摒弃了可维护性较差的 \u0060envoyfilter\u0060，使得插件扩展更为便捷；\n3. **自适应限流**：结合监控信息自动调整限流策略；\n\n\u003e **什么是 SidecarScope？**\n\u003e\n\u003e SidecarScope 是在 Istio 1.1 版本中引入的，它并不是一个直接面向用户的配置项，而是 Sidecar 资源的包装器，具体来说就是 Sidecar 资源中的 \u0060egress\u0060 选项。通过该配置可以减少 Istio 向 Sidecar 下发的数据量，例如只向某个命名空间中的某些服务下发某些 hosts 的访问配置，从而提高应用提高性能。\n\n## 使用 Slime 作为 Istio 的控制平面\n\n为了解决这些问题，Slime 在 Istio 之上构建了更高层次的抽象，相当于为 Istio 构建了一层管理平面，其工作流程图如下所示。\n\n![Slime 工作流程图](slime-flow-chart.jpg)\n\n具体步骤如下：\n\n1. Slime Operator 根据管理员的配置在 Kubernetes 中完成 Slime 组件的初始化；\n2. 开发者创建符合 Slime CRD 规范的配置并应用到 Kubernetes 集群中；\n3. Slime 查询 Prometheus 中保存的相关服务的监控数据，结合 Slime CRD 中自适应部分的配置，将 Slime CRD 转换为 Istio CRD，同时将其推送到 Global Proxy 中；\n4. Istio 监听 Istio CRD 的创建；\n5. Istio 将 Sidecar Proxy 的配置信息推送到数据平面相应的 Sidecar Proxy 中；\n\n以上只是一个对 Slime 工作流程的一个笼统的介绍，更多详细信息请参考 [Slime GitHub](https:\/\/github.com\/slime-io\/slime\/)。\n\n## 配置懒加载\n\n为了解决数据平面中 Sidecar Proxy 资源消耗过大及网络延迟问题，Slime 使用了配置懒加载（按需加载 Sidecar 配置）的方案。该方案的核心思想是向每个 Sidecar Proxy 中只下发其所 Pod 中服务所需的配置，而不是将网格中的所有服务信息全量下发。所以 Slime 需要获取每个服务的调用关系这样才能得到其所需的 Sidecar Proxy 配置。\n\nSlime 实现 Sidecar Proxy 配置懒加载的方法是：\n\n- 让数据平面中的所有服务的首次调用都通过一个 Global Proxy，该 Proxy 可以记录所有服务的调用和依赖信息，根据该依赖信息更新 Istio 中 Sidecar 资源的配置；\n- 当某个服务的调用链被 VirtualService 中的路由信息重新定义时，Global Proxy 原有记录就失效了，需要一个新的数据结构来维护该服务的调用关系。Slime 创建了名为 \u0060ServiceFence\u0060  的 CRD 来维护服务调用关系以解决服务信息缺失问题。\n\n### 使用 Global Proxy 初始化服务调用拓扑\n\nSlime 在数据平面中部署 Global Proxy（也叫做 Global Sidecar，但其与应用的 Pod 不是一对一的关系，笔者更倾向于称其为 Global Proxy），该代理同样使用 Envoy 构建，在每个需要启动配置懒加载的命名空间中部署一个或在整个网格中只部署一个，所有缺失服务发现信息的调用（你也可以手动配置服务调用关系），都会被兜底路由劫持到 Global Proxy，经过其首次转发后，Slime 便可感知到被调用方的信息，然后根据其对应服务的 VirtualService，找到服务名和真实后端的映射关系，将两者的都加入 SidecarScope，以后该服务的调用就不再需要经过 Global Proxy 了。\n\n### 使用 ServiceFence 维护服务调用拓扑\n\n在使用 Global Proxy 初始化服务调用拓扑后，一旦服务调用链有变动的话怎么办？对此 Slime 创建了 ServiceFence 的 CRD。使用 ServiceFence 可以维护服务名和后端服务的映射关系。Slime 根据其对应服务的 VirtualService，找到 Kubernetes 服务名和真实后端（host）的映射关系，将两者的都加入 Sidecar 的配置中。ServiceFence 管理生成的 SidecarScope 的生命周期，自动清理长时间不用的调用关系，从而避免上述问题。\n\n### 如何开启配置懒加载\n\n配置懒加载功能对于终端用户是透明的，只需要 Kubernetes  Service 上打上 \u0060istio.dependency.servicefence\/status:\u0022true\u0022\u0060 的标签，表明该服务需要开启配置懒加载，剩下的事情交给 Slime Operator 来完成即可。\n\n## HTTP 插件管理\n\nIstio 中的插件扩展只能通过 EnvoyFilter 来实现，因为它是 xDS 层面的配置，管理和维护这样的配置需要耗费大量的精力，也极容易出错。因此，Slime 在 EnvoyFilter 的基础上做了一层面向插件的抽象。\n\nSlime 共有两个 CRD 用于 HTTP 插件管理，分别是：\n\n- **PluginManager**：配置为哪些负载开启哪些插件，插件的配置顺序即为执行顺序；\n- **EnvoyPlugin**：EnvoyPlugin 不关心每个插件的具体配置，具体配置会被放在 EnvoyFilter 资源的 \u0060patch.typed_config\u0060 结构中透传），EnvoyPlugin 的核心思想是将插件配置在需要的维度中做聚合，从而限定插件的生鲜范围。这样做一方面更加贴合插件使用者的习惯，另一方面也降低了上层配置的冗余，\n\n关于 Slime 中插件管理的详细使用方式请见 [Slime GitHub](https:\/\/github.com\/slime-io\/slime\/blob\/master\/doc\/zh\/plugin_manager.md)。\n\n## 自适应限流\n\nEnvoy 内置的限流组件功能单一，只能以实例维度配置限流值，无法做到根据应用负载的自适应限流。Slime 通过与 Prometheus metric server 对接，实时的获取监控情况，来动态配置限流值。\n\nSlime 自适应限流的流程图如下所示。\n\n![Slime 的自适应限流流程图](slime-smart-limiter.jpg)\n\nSlime 的自适应限流的流程分为两部分，一部分为 SmartLimiter 到 EnvoyFilter 的转换，另一部分为获取监控数据。目前 Slime 支持从 Kubernetes Metric Server 获取服务的 CPU、内存、副本数等数据。Slime 还对外提供了一套监控数据接口（Metric Discovery Server），通过 MDS，可以将自定义的监控指标同步给限流组件。\n\nSlime 创建的 CRD \u0060SmartLimiter\u0060 用于配置自适应限流。其的配置是接近自然语义，例如希望在 CPU 超过 80% 时触发服务 A 的访问限制，限额为 30QPS，对应的 SmartLimiter 定义如下：\n\n\u0060\u0060\u0060yaml\napiVersion: microservice.netease.com\/v1alpha1\nkind: SmartLimiter\nmetadata:\n  name: a\n  namespace: default\nspec:\n  descriptors:\n  - action:\n      fill_interval:\n        seconds: 1\n      quota: \u002230\/{pod}\u0022    # 30 为该服务的额度，将其均分给每个 pod，加入有 3 个 pod，则每个 pod 的限流为 10\n    condition: \u0022{cpu}\u003e0.8\u0022 # 根据监控项{cpu}的值自动填充该模板\n\u0060\u0060\u0060\n\n## 更多\n\nSlime 开源于 2021 年初，本文发稿时该项目仍处于初级阶段，本文大量参考了杨笛航在云原生社区中的分享 [Slime：让 Istio 服务网格变得更加高效与智能](https:\/\/cloudnative.to\/blog\/netease-slime\/) 及 Slime 的 [GitHub](https:\/\/github.com\/slime-io\/slime)。感兴趣的读者可以关注下这个项目的 GitHub，进一步了解它。\n\n另外欢迎关注服务网格和 Istio 的朋友加入云原生社区 Istio SIG，一起参与讨论和交流。\n\n## 参考\n\n- [Slime：让 Istio 服务网格变得更加高效与智能 - cloudnative.to](https:\/\/cloudnative.to\/blog\/netease-slime\/)\n- [Slime GitHub 文档 - github.com](https:\/\/github.com\/slime-io\/slime\/blob\/master\/README_ZH.md)\n- [Sidecar - istio.io](https:\/\/istio.io\/latest\/docs\/reference\/config\/networking\/sidecar\/)\n', '\/blog\/slime-intro\/')">
                <i class="fas fa-file-download"></i>
              </a>
             </li>
          </ul>
      </div>
      <p class="card-text">本文介绍的是由网易数帆微服务团队开源的一款基于 Istio 的智能网格管理器 Slime。</p>
    </div>
  </article>
</div>


<script>
  function convertImageLinks(rawContent, permalink) {
      
      const baseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const blogPath = permalink.replace(/^\/|\/$/g, ''); 
      return rawContent.replace(/!\[([^\]]*)\]\(([^)]+)\)/g, function(match, altText, relativePath) {
          
          if (relativePath.startsWith('http://') || relativePath.startsWith('https://')) {
              return match; 
          }
          return `![${altText}](${baseUrl}${blogPath}/${relativePath})`;
      });
  }
  
  function convertRelativeLinks(rawContent) {
      
      const domain = 'https://jimmysong.io'; 
      return rawContent.replace(/\[([^\]]+)\]\((\/[^)]+)\)/g, function(match, linkText, relativePath) {
          return `[${linkText}](${domain}${relativePath})`;
      });
  }
  
  function exportToMarkdown(title, description, rawContent, permalink) {
      const githubBaseUrl = 'https://raw.githubusercontent.com/rootsongjc/rootsongjc.github.io/master/'; 
      const filename = title + '.md';
  
      
      const convertedContent = convertImageLinks(rawContent, permalink);
      
      
      const contentWithLinks = convertRelativeLinks(convertedContent);
  
      
      const contentWithHeader = `> ${description}\n>\n> 阅读原文请转到：https://jimmysong.io${permalink}\n${contentWithLinks}`;
  
      
      const contentWithFooter = `${contentWithHeader}\n\n---\n`;
  
      
      const element = document.createElement('a');
      element.setAttribute('href', 'data:text/markdown;charset=utf-8,' + encodeURIComponent(contentWithFooter));
      element.setAttribute('download', filename);
  
      element.style.display = 'none';
      document.body.appendChild(element);
  
      element.click();
  
      document.body.removeChild(element);
  }
  
  
  if (window.location.hostname === "localhost" || window.location.hostname === "127.0.0.1") {
      document.querySelectorAll('.export-button').forEach(function(button) {
          button.style.display = 'inline';
      });
  }
</script>
          
          <div class="col-12">
 
 
 
 
 
 
 
 
 
 
 
 <nav aria-label="Page navigation">
   <ul class="pagination justify-content-center">
     
     
     <li class="page-item">
       <a class="page-link" href="/tags/envoy/">
         ««
       </a>
     </li>
     
     
     
     <li class="page-item">
       <a href="/tags/envoy/" class="page-link">
         «
       </a>
     </li>
     
     
     
       
       
       
         
       
       
       
         <li class="page-item">
           <a href="/tags/envoy/" class="page-link">
             1
           </a>
         </li>
       
     
       
       
       
         
       
       
       
         <li class="page-item page-item active ">
           <a href="/tags/envoy/page/2/" class="page-link">
             2
           </a>
         </li>
       
     
       
       
       
         
       
       
       
         <li class="page-item">
           <a href="/tags/envoy/page/3/" class="page-link">
             3
           </a>
         </li>
       
     
     
     
     <li class="page-item">
       <a href="/tags/envoy/page/3/" class="page-link">
         »
       </a>
     </li>
     
     
     
     <li class="page-item">
       <a class="page-link" href="/tags/envoy/page/3/">
         »»
       </a>
     </li>
     
   </ul>
 </nav>
 
</div>

        </div>
      </div>
      <!-- sidebar -->
      <aside class="col-lg-4 order-1 order-lg-2 d-none d-sm-block">
          <div class="sidebar">
          <!-- categories -->
<div class="blog-categories mb-4">
  <p class="sidebar-title">
      专栏
  </p>
  
  
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
  
  <div class="bg-gray">
      
        <a href="/categories/istio" class="sidebar-item">
            <span>Istio</span>
            <span>(81)</span>
        </a>
      
        <a href="/categories/service-mesh" class="sidebar-item">
            <span>Service Mesh</span>
            <span>(42)</span>
        </a>
      
        <a href="/categories/kubernetes" class="sidebar-item">
            <span>Kubernetes</span>
            <span>(25)</span>
        </a>
      
        <a href="/categories/%e9%9a%8f%e7%ac%94" class="sidebar-item">
            <span>随笔</span>
            <span>(22)</span>
        </a>
      
        <a href="/categories/%e5%85%b6%e4%bb%96" class="sidebar-item">
            <span>其他</span>
            <span>(19)</span>
        </a>
      
        <a href="/categories/envoy" class="sidebar-item">
            <span>Envoy</span>
            <span>(18)</span>
        </a>
      
        <a href="/categories/%e4%b8%9a%e6%80%81" class="sidebar-item">
            <span>业态</span>
            <span>(17)</span>
        </a>
      
        <a href="/categories/%e4%ba%91%e5%8e%9f%e7%94%9f" class="sidebar-item">
            <span>云原生</span>
            <span>(14)</span>
        </a>
      
        <a href="/categories/ai" class="sidebar-item">
            <span>AI</span>
            <span>(9)</span>
        </a>
      
        <a href="/categories/%e5%ae%89%e5%85%a8" class="sidebar-item">
            <span>安全</span>
            <span>(9)</span>
        </a>
      
        <a href="/categories/%e5%bc%80%e6%ba%90" class="sidebar-item">
            <span>开源</span>
            <span>(9)</span>
        </a>
      
        <a href="/categories/%e6%97%85%e8%a1%8c" class="sidebar-item">
            <span>旅行</span>
            <span>(8)</span>
        </a>
      
        <a href="/categories/%e5%b7%a5%e5%85%b7" class="sidebar-item">
            <span>工具</span>
            <span>(6)</span>
        </a>
      
        <a href="/categories/%e5%8f%af%e8%a7%82%e6%b5%8b%e6%80%a7" class="sidebar-item">
            <span>可观测性</span>
            <span>(5)</span>
        </a>
  </div>
</div>

<div class="blog-categories mb-4">
  <p class="sidebar-title">
      资料
  </p>
  
  
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
        
      
      
  
  <div class="bg-gray">
      
        <a href="/categories/%e5%87%ba%e7%89%88%e7%89%a9" class="sidebar-item">
            <span>出版物</span>
            <span>(8)</span>
        </a>
      
        <a href="/categories/%e7%bf%bb%e8%af%91%e7%94%b5%e5%ad%90%e4%b9%a6" class="sidebar-item">
            <span>翻译电子书</span>
            <span>(8)</span>
        </a>
      
        <a href="/categories/%e7%bf%bb%e8%af%91%e6%96%87%e6%a1%a3" class="sidebar-item">
            <span>翻译文档</span>
            <span>(7)</span>
        </a>
      
        <a href="/categories/%e7%bf%bb%e8%af%91%e5%9b%be%e4%b9%a6" class="sidebar-item">
            <span>翻译图书</span>
            <span>(6)</span>
        </a>
      
        <a href="/categories/%e5%8e%9f%e5%88%9b%e5%9b%be%e4%b9%a6" class="sidebar-item">
            <span>原创图书</span>
            <span>(2)</span>
        </a>
      
        <a href="/categories/%e6%95%99%e7%a8%8b%e6%89%8b%e5%86%8c" class="sidebar-item">
            <span>教程手册</span>
            <span>(2)</span>
        </a>
  </div>
</div>





          </div>
      </aside>
      <!-- /sidebar -->
    </div>
  </div>
</section>




<footer>
  
  <div class="footer bg-footer section-sm border-bottom overlay ">
    <div class="container-xl">
      <div class="row">
        <div class="col col-xl-4 d-sm-none mb-2 mb-lg-0 d-xl-block d-none">
          
          <p class="h3 text-white mb-4 text-uppercase">联系</p>
          
          <ul class="list-unstyled">
            
            
            <li class="mb-4 text-color">微信公众号</li>
            
            
            <li class="mb-4"><img src="/images/servicemesher-wechat.webp" width="118px" height="118px" alt="footer image"></li>
            
            
            
          
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">博客</p>
          <ul class="list-unstyled">
            
            <li class="mb-3"><a class="text-color" href="/blog/envoy-ext-proc-guide/">深入解析 Envoy 外部处理过滤器（ext_proc）</a></li>
            
            <li class="mb-3"><a class="text-color" href="/blog/istio-ambient-l7-flow-analysis/">深入 Istio Ambient 模式：从 ztunnel 到 Waypoint 代理的 L7 流量路径解析</a></li>
            
            <li class="mb-3"><a class="text-color" href="/blog/building-private-ai-knowledge-base-anythingllm/">探索 AnythingLLM：借助开源 AI 打造私有化智能知识库</a></li>
            
          </ul>
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">链接</p>
          <ul class="list-unstyled">
            
            <li class="mb-3">
              <a class="text-color" href="https://istio.io/latest/zh/" target="_blank" rel="noopener noreferrer">
                  Istio 服务网格
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://tetrate.io/?jimmysong" target="_blank" rel="noopener noreferrer">
                  Tetrate 公司
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://space.bilibili.com/515485124" target="_blank" rel="noopener noreferrer">
                  云原生学院|Bilibili
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="/awesome-cloud-native/" target="_blank" rel="noopener noreferrer">
                  云原生开源项目大全
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://cloudnative.to" target="_blank" rel="noopener noreferrer">
                  云原生社区（中国）
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
          </ul>
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">教程</p>
          <ul class="list-unstyled">
            
            <li class="mb-3">
              <a class="text-color" href="https://academy.tetrate.io/courses/envoy-fundamentals-zh" target="_blank" rel="noopener noreferrer">
                  Envoy 基础教程
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="https://academy.tetrate.io/courses/istio-fundamentals-zh" target="_blank" rel="noopener noreferrer">
                  Istio 基础教程
                  
                  <i class="fa-solid fa-arrow-up-right-from-square icon-small"></i>
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="/book/kubernetes-handbook/" >
                  Kubernetes 基础教程
                  
              </a>
            </li>
            
            <li class="mb-3">
              <a class="text-color" href="/book/envoy-made-simple/" >
                  简明 Envoy 教程
                  
              </a>
            </li>
            
          </ul>
        </div>

        
        <div class="col col-xl-2 col-6 col-sm-3 mb-2">
          <p class="h3 text-white mb-4 text-uppercase">通知</p>
          <ul class="list-unstyled">
            
            <li class="mb-3"><a class="text-color" href="/notice/nist-sp-800-233-service-mesh-proxy-models/">资料分享：云原生应用服务网格代理模型的威胁分析指南</a></li>
            
            <li class="mb-3"><a class="text-color" href="/notice/kubecon-china-2024-panel/">KubeCon China 2024（香港）</a></li>
            
            <li class="mb-3"><a class="text-color" href="/notice/website-revamp-notice/">网站改版通知</a></li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>

  
  <div class="copyright py-4 bg-footer overlay">
    <div class="container-xl">
      <div class="row">
        <div class="col-sm-6 text-sm-left text-center">
          <p class="mb-0 text-color">© 2017-2024 Jimmy Song 保留所有权利</p>
        </div>
        <div class="col-sm-6 text-sm-right text-center">
          <ul class="list-inline">
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="https://twitter.com/jimmysongio" target="_blank" title="Social link" rel="noopener noreferrer">
                    <i class="fa-brands fa-x-twitter text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="/contact/" >
                    <i class="fa-brands fa-weixin text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="https://github.com/rootsongjc" target="_blank" title="Social link" rel="noopener noreferrer">
                    <i class="fa-brands fa-github text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="https://linkedin.com/in/jimmysongio" target="_blank" title="Social link" rel="noopener noreferrer">
                    <i class="fa-brands fa-linkedin text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="mailto:rootsongjc@gmail.com" >
                    <i class="fa-solid fa-envelope text-white"></i>
              </a>
            </li>
            
            <li class="list-inline-item">
              <a class="d-inline-block p-2" href="/blog/index.xml" >
                    <i class="fa-solid fa-rss text-white"></i>
              </a>
            </li>
            
          </ul>
        </div>
      </div>
    </div>
  </div>
</footer>

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>


<!-- JS Plugins -->

<script src="/plugins/popper/popper.min.js"></script>

<script src="/plugins/bootstrap/bootstrap.min.js"></script>

<script src="/plugins/slick/slick.min.js"></script>

<script src="/plugins/filterizr/jquery.filterizr.min.js"></script>

<script src="/plugins/search/fuse.min.js"></script>

<script src="/plugins/search/mark.js"></script>

<script src="/plugins/hex_md5/hex_md5.js"></script>

<script src="/plugins/anchor/anchor.min.js"></script>

<script src="/plugins/tocbot/tocbot.min.js"></script>

<script src="/plugins/bigger-picture/bigger-picture.min.js"></script>


<!-- Main Script -->

<script src="/js/script.min.f94c22b1d478bfc9e2e0a7d954429e47b7e6d36edd423758482e04154ae1842e.js"></script>


<script async src="https://www.googletagmanager.com/gtag/js?id=G-ESY906ZWZ0"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-ESY906ZWZ0');
</script>


<!-- Baidu analysis -->
<meta name="baidu-site-verification" content="g8IYR9SNLF" />










<script src="https://cdnjs.cloudflare.com/ajax/libs/pako/2.0.4/pako.min.js"></script>










<script src="/js/wowchemy-search.min.7a37268e7bbe4a9160c2e4c33b749816.js" type="module"></script>
<script id="search-hit-fuse-template" type="text/x-template">
  <div class="search-hit" id="summary-{{key}}">
    <div class="search-hit-content border-bottom">
      <div class="search-hit-name">
        <div class='search-hit-link'><a href="{{relpermalink}}">{{title}}</a></div>
        <div class="search-hit-metadata d-flex">
            <span class="mr-1"><i class="fa-regular fa-calendar mr-1"></i>{{date}}</span>
            <span class="mr-1"><i class="fa-regular fa-folder-open mr-1"></i>{{section}}</span>
            <span class="d-sm-block d-none"><i class="fa-solid fa-link mr-1"></i>{{relpermalink}}</span>
        </div>
        <div class="search-hit-description">{{snippet}}</div>
      </div>
    </div>
  </div>
</script>



    </body>
</html>
