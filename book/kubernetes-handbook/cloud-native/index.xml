<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jimmy Song&#39;s Blog – 云原生</title>
    <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/</link>
    <description>Recent content in 云原生 on Jimmy Song&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Tue, 03 May 2022 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="https://jimmysong.io/book/kubernetes-handbook/cloud-native/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>什么是云原生？</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/what-is-cloud-native/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0100</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/what-is-cloud-native/</guid>
      <description>
        
        
        &lt;p&gt;云原生（Cloud Native）这个词汇由来已久，以致于何时出现已无据可考。云原生开始大规模出现在受众视线中，与 Pivotal 提出的云原生应用的理念有着莫大的关系。我们现在谈到云原生，更多的指的是&lt;a href=&#34;https://cloudnative.to/blog/cloud-native-culture-not-container/&#34; title=&#34;一种文化&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;一种文化&lt;/a&gt;
，而不具象为哪些技术体系。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Pivotal 推出过 Pivotal Cloud Foundry 云原生应用平台和 &lt;a href=&#34;https://spring.io/&#34; title=&#34;Spring&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Spring&lt;/a&gt;
 开源 Java 开发框架，成为云原生应用架构中先驱者和探路者。Pivotal 是云原生应用平台第一股，2018 年在纽交所上市，2019 年底被 VMWare 以 27 亿美元收购，加入到 VMware 新的产品线 &lt;a href=&#34;https://tanzu.vmware.com/&#34; title=&#34;Tanzu&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tanzu&lt;/a&gt;
。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;pivotal-最初的定义&#34;&gt;Pivotal 最初的定义&lt;/h2&gt;
&lt;p&gt;早在 2015 年 Pivotal 公司的 Matt Stine 写了一本叫做 &lt;a href=&#34;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&#34; title=&#34;迁移到云原生应用架构&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;迁移到云原生应用架构&lt;/a&gt;
 的小册子，其中探讨了云原生应用架构的几个主要特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;符合 12 因素应用&lt;/li&gt;
&lt;li&gt;面向微服务架构&lt;/li&gt;
&lt;li&gt;自服务敏捷架构&lt;/li&gt;
&lt;li&gt;基于 API 的协作&lt;/li&gt;
&lt;li&gt;抗脆弱性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;笔者已于 2017 年翻译了本书，详见 &lt;a href=&#34;https://jimmysong.io/migrating-to-cloud-native-application-architectures/&#34; title=&#34;迁移到云原生应用架构&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;迁移到云原生应用架构&lt;/a&gt;
。&lt;/p&gt;
&lt;h2 id=&#34;cncf-最初的定义&#34;&gt;CNCF 最初的定义&lt;/h2&gt;
&lt;p&gt;到了 2015 年 Google 主导成立了云原生计算基金会（CNCF），起初 CNCF 对云原生（Cloud Native）的定义包含以下三个方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用容器化&lt;/li&gt;
&lt;li&gt;面向微服务架构&lt;/li&gt;
&lt;li&gt;应用支持容器的编排调度&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;重定义&#34;&gt;重定义&lt;/h2&gt;
&lt;p&gt;到了 2018 年，随着近几年来云原生生态的不断壮大，所有主流云计算供应商都加入了该基金会，且从 &lt;a href=&#34;https://i.cncf.io&#34; title=&#34;Cloud Native Landscape&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cloud Native Landscape&lt;/a&gt;
 中可以看出云原生有意蚕食原先非云原生应用的部分。CNCF 基金会中的会员以及容纳的项目越来越多，该定义已经限制了云原生生态的发展，CNCF 为云原生进行了重新定位。&lt;/p&gt;
&lt;p&gt;以下是 CNCF 对云原生的&lt;a href=&#34;https://github.com/cncf/toc/blob/main/DEFINITION.md&#34; title=&#34;重新定义&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;重新定义&lt;/a&gt;
（中英对照）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cloud native technologies empower organizations to build and run scalable applications in modern, dynamic environments such as public, private, and hybrid clouds. Containers, service meshes, microservices, immutable infrastructure, and declarative APIs exemplify this approach.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式 API。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;These techniques enable loosely coupled systems that are resilient, manageable, and observable. Combined with robust automation, they allow engineers to make high-impact changes frequently and predictably with minimal toil.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这些技术能够构建容错性好、易于管理和便于观察的松耦合系统。结合可靠的自动化手段，云原生技术使工程师能够轻松地对系统作出频繁和可预测的重大变更。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Cloud Native Computing Foundation seeks to drive adoption of this paradigm by fostering and sustaining an ecosystem of open source, vendor-neutral projects. We democratize state-of-the-art patterns to make these innovations accessible for everyone.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;云原生计算基金会（CNCF）致力于培育和维护一个厂商中立的开源生态系统，来推广云原生技术。我们通过将最前沿的模式民主化，让这些创新为大众所用。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;关于什么是云原生的争论还在进行中，在笔者看来云原生是一种行为方式和设计理念，究其本质，凡是能够提高云上资源利用率和应用交付效率的行为或方式都是云原生的。云计算的发展史就是一部云原生化的历史。Kubernetes 开启了云原生的序幕，服务网格 Istio 的出现，引领了后 Kubernetes 时代的微服务，serverless 的再次兴起，使得云原生从基础设施层不断向应用架构层挺进，我们正处于一个云原生的新时代。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cncf/toc/blob/master/DEFINITION.md&#34; title=&#34;CNCF Cloud Native Definition v1.0 - github.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF Cloud Native Definition v1.0 - github.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/cloud-native-culture-not-container/&#34; title=&#34;云原生关乎文化，而不是容器 - cloudnative.to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生关乎文化，而不是容器 - cloudnative.to&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>云原生的设计哲学</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/cloud-native-philosophy/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/cloud-native-philosophy/</guid>
      <description>
        
        
        &lt;p&gt;云原生一词已经被过度的采用，很多软件都号称是云原生，很多打着云原生旗号的会议也如雨后春笋般涌现。&lt;/p&gt;
&lt;p&gt;云原生本身甚至不能称为是一种架构，它首先是一种基础设施，运行在其上的应用称作云原生应用，只有符合云原生设计哲学的应用架构才叫云原生应用架构。&lt;/p&gt;
&lt;h2 id=&#34;云原生的设计理念&#34;&gt;云原生的设计理念&lt;/h2&gt;
&lt;p&gt;云原生系统的设计理念如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;面向分布式设计（Distribution）：容器、微服务、API 驱动的开发；&lt;/li&gt;
&lt;li&gt;面向配置设计（Configuration）：一个镜像，多个环境配置；&lt;/li&gt;
&lt;li&gt;面向韧性设计（Resistancy）：故障容忍和自愈；&lt;/li&gt;
&lt;li&gt;面向弹性设计（Elasticity）：弹性扩展和对环境变化（负载）做出响应；&lt;/li&gt;
&lt;li&gt;面向交付设计（Delivery）：自动拉起，缩短交付时间；&lt;/li&gt;
&lt;li&gt;面向性能设计（Performance）：响应式，并发和资源高效利用；&lt;/li&gt;
&lt;li&gt;面向自动化设计（Automation）：自动化的 DevOps；&lt;/li&gt;
&lt;li&gt;面向诊断性设计（Diagnosability）：集群级别的日志、metric 和追踪；&lt;/li&gt;
&lt;li&gt;面向安全性设计（Security）：安全端点、API Gateway、端到端加密；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上的设计理念很多都是继承自分布式应用的设计理念。虽然有如此多的理念但是我们仍然无法辨认什么样的设施才是云原生基础设施，不过可以先用排除法，我将解释什么不是云原生基础设施。&lt;/p&gt;
&lt;h2 id=&#34;什么不是云原生基础设施&#34;&gt;什么不是云原生基础设施？&lt;/h2&gt;
&lt;p&gt;云原生基础设施不等于在公有云上运行的基础设施。光是租用服务器并不会使您的基础设施云原生化。管理 IaaS 的流程与运维物理数据中心没什么两样，将现有架构迁移到云上也未必能获得回报。&lt;/p&gt;
&lt;p&gt;云原生不是指在容器中运行应用程序。Netflix 率先推出云原生基础设施时，几乎所有应用程序部署在虚拟机中，而不是在容器中。改变应用程序的打包方式并不意味着就会增加自治系统的可扩展性和优势。即使应用程序是通过 CI/CD 渠道自动构建和部署的，也不意味着您就可以从增强 API 驱动部署的基础设施中受益。&lt;/p&gt;
&lt;p&gt;这也并不意味着您只能运行容器编排器（例如 Kubernetes 和 Mesos）。容器编排器提供了云原生基础设施所需的许多平台功能，但并未按预期方式使用这些功能，这意味着您的应用程序会在一组服务器上运行，被动态调度。这是一个非常好的起步，但仍有许多工作要做。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;调度器与编排器&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;术语“调度器”和“编排器”通常可以互换使用。&lt;/p&gt;
&lt;p&gt;在大多数情况下，编排器负责集群中的所有资源利用（例如：存储，网络和 CPU）。该术语典型地用于描述执行许多任务的产品，如健康检查和云自动化。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;调度器是编排平台的一个子集，仅负责选择运行在每台服务器上的进程和服务。&lt;/p&gt;
&lt;p&gt;云原生不是微服务或基础设施即代码。微服务意味着更快的开发周期和更小的独特功能，但是单体应用程序可以具有相同的功能，使其能够通过软件有效管理，并且还可以从云原生基础设施中受益。&lt;/p&gt;
&lt;p&gt;基础设施即代码以机器可解析语言或领域特定语言（DSL）定义、自动化您的基础设施。将代码应用于基础架构的传统工具包括配置管理工具（例如 Chef 和 Puppet）。这些工具在自动执行任务和提供一致性方面有很大帮助，但是它们在提供必要的抽象来描述超出单个服务器的基础设施方面存在缺陷。&lt;/p&gt;
&lt;p&gt;配置管理工具一次自动化一台服务器，并依靠人员将服务器提供的功能绑定在一起。这将人类定位为基础设施规模的潜在瓶颈。这些工具也不会使构建完整系统所需的云基础设施（例如存储和网络）的额外部分自动化。&lt;/p&gt;
&lt;p&gt;尽管配置管理工具为操作系统的资源（例如软件包管理器）提供了一些抽象，但它们并没有抽象出足够的底层操作系统来轻松管理它。如果一位工程师想要管理系统中的每个软件包和文件，这将是一个非常艰苦的过程，并且对于每个配置变体都是独一无二的。同样，定义不存在或不正确的资源的配置管理仅消耗系统资源并且不能提供任何价值。&lt;/p&gt;
&lt;p&gt;虽然配置管理工具可以帮助自动化部分基础设施，但它们无法更好地管理应用程序。我们将在后面的章节中通过查看部署，管理，测试和操作基础架构的流程，探讨云原生基础设施的不同之处，但首先，我们将了解哪些应用程序是成功的以及应该何时与原生基础设施一起使用。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用程序&#34;&gt;云原生应用程序&lt;/h2&gt;
&lt;p&gt;就像云改变了业务和基础设施之间的关系一样，云原生应用程序也改变了应用程序和基础设施之间的关系。我们需要了解与传统应用程序相比，云本身有什么不同，因此我们需要了解它们与基础设施的新关系。&lt;/p&gt;
&lt;p&gt;为了写好本书，也为了有一个共享词汇表，我们需要定义“云原生应用程序”是什么意思。云原生与 12 因素应用程序不同，即使它们可能共享一些类似的特征。如果你想了解更多细节，请阅读 Kevin Hoffman 撰写的“超越 12 因素应用程序”（O&amp;rsquo;Reilly，2012）。&lt;/p&gt;
&lt;p&gt;云原生应用程序被设计为在平台上运行，并设计用于弹性，敏捷性，可操作性和可观测性。弹性包含失败而不是试图阻止它们；它利用了在平台上运行的动态特性。敏捷性允许快速部署和快速迭代。可操作性从应用程序内部控制应用程序生命周期，而不是依赖外部进程和监视器。可观测性提供信息来回答有关应用程序状态的问题。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;云原生定义&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;云原生应用程序的定义仍在发展中。还有像 CNCF 这样的组织可以提供其他的定义。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;云原生应用程序通过各种方法获取这些特征。它通常取决于应用程序的运行位置以及企业流程和文化。以下是实现云原生应用程序所需特性的常用方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;微服务&lt;/li&gt;
&lt;li&gt;健康报告&lt;/li&gt;
&lt;li&gt;遥测数据&lt;/li&gt;
&lt;li&gt;弹性&lt;/li&gt;
&lt;li&gt;声明式的，而不是命令式的&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;微服务&#34;&gt;微服务&lt;/h3&gt;
&lt;p&gt;作为单个实体进行管理和部署的应用程序通常称为单体应用。最初开发应用程序时，单体有很多好处。它们更易于理解，并允许您在不影响其他服务的情况下更改主要功能。&lt;/p&gt;
&lt;p&gt;随着应用程序复杂性的增长，单体应用的益处逐渐减少。它们变得更难理解，而且失去了敏捷性，因为工程师很难推断和修改代码。&lt;/p&gt;
&lt;p&gt;对付复杂性的最好方法之一是将明确定义的功能分成更小的服务，并让每个服务独立迭代。这增加了应用程序的灵活性，允许根据需要更轻松地更改部分应用程序。每个微服务可以由单独的团队进行管理，使用适当的语言编写，并根据需要进行独立扩缩容。&lt;/p&gt;
&lt;p&gt;只要每项服务都遵守强有力的合约，应用程序就可以快速改进和改变。当然，转向微服务架构还有许多其他的考虑因素。其中最不重要的是弹性通信，我们在附录 A 中有讨论。&lt;/p&gt;
&lt;p&gt;我们无法考虑转向微服务的所有考虑因素。拥有微服务并不意味着您拥有云原生基础设施。如果您想阅读更多，我们推荐 Sam Newman 的 Building Microservices（O&amp;rsquo;Reilly，2015）。虽然微服务是实现您的应用程序灵活性的一种方式，但正如我们之前所说的，它们不是云原生应用程序的必需条件。&lt;/p&gt;
&lt;h3 id=&#34;健康报告&#34;&gt;健康报告&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;停止逆向工程应用程序并开始从内部进行监控。 —— Kelsey Hightower，Monitorama PDX 2016：healthz&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;没有人比开发人员更了解应用程序需要什么才能以健康的状态运行。很长一段时间，基础设施管理员都试图从他们负责运行的应用程序中找出“健康”该怎么定义。如果不实际了解应用程序的健康状况，他们尝试在应用程序不健康时进行监控并发出警报，这往往是脆弱和不完整的。&lt;/p&gt;
&lt;p&gt;为了提高云原生应用程序的可操作性，应用程序应该暴露健康检查。开发人员可以将其实施为命令或过程信号，以便应用程序在执行自我检查之后响应，或者更常见的是：通过应用程序提供 Web 服务，返回 HTTP 状态码来检查健康状态。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Google Borg 示例&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Google 的 Borg 报告中列出了一个健康报告的例子：&lt;/p&gt;
&lt;p&gt;几乎每个在 Borg 下运行的任务都包含一个内置的 HTTP 服务器，该服务器发布有关任务运行状况和数千个性能指标（如 RPC 延迟）的信息。Borg 会监控运行状况检查 URL 并重新启动不及时响应或返回 HTTP 错误代码的任务。其他数据由监控工具跟踪，用于仪表板和服务级别目标（SLO）违规警报。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;将健康责任转移到应用程序中使应用程序更容易管理和自动化。应用程序应该知道它是否正常运行以及它依赖于什么（例如，访问数据库）来提供业务价值。这意味着开发人员需要与产品经理合作来定义应用服务的业务功能并相应地编写测试。&lt;/p&gt;
&lt;p&gt;提供健康检查的应用程序示例包括 Zookeeper 的 ruok 命令和 etcd 的 HTTP / 健康端点。&lt;/p&gt;
&lt;p&gt;应用程序不仅仅有健康或不健康的状态。它们将经历一个启动和关闭过程，在这个过程中它们应该通过健康检查，报告它们的状态。如果应用程序可以让平台准确了解它所处的状态，平台将更容易知道如何操作它。&lt;/p&gt;
&lt;p&gt;一个很好的例子就是当平台需要知道应用程序何时可以接收流量。在应用程序启动时，如果它不能正确处理流量，它就应该表现为未准备好。此额外状态将防止应用程序过早终止，因为如果运行状况检查失败，平台可能会认为应用程序不健康，并且会反复停止或重新启动它。&lt;/p&gt;
&lt;p&gt;应用程序健康只是能够自动化应用程序生命周期的一部分。除了知道应用程序是否健康之外，您还需要知道应用程序是否正在进行哪些工作。这些信息来自遥测数据。&lt;/p&gt;
&lt;h3 id=&#34;遥测数据&#34;&gt;遥测数据&lt;/h3&gt;
&lt;p&gt;遥测数据是进行决策所需的信息。确实，遥测数据可能与健康报告重叠，但它们有不同的用途。健康报告通知我们应用程序生命周期状态，而遥测数据通知我们应用程序业务目标。&lt;/p&gt;
&lt;p&gt;您测量的指标有时称为服务级指标（SLI）或关键性能指标（KPI）。这些是特定于应用程序的数据，可以确保应用程序的性能处于服务级别目标（SLO）内。如果您需要更多关于这些术语的信息以及它们与您的应用程序、业务需求的关系，我们推荐你阅读来自 Site Reliability Engineering（O&amp;rsquo;Reilly）的第 4 章。&lt;/p&gt;
&lt;p&gt;遥测和度量标准用于解决以下问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序每分钟收到多少请求？&lt;/li&gt;
&lt;li&gt;有没有错误？&lt;/li&gt;
&lt;li&gt;什么是应用程序延迟？&lt;/li&gt;
&lt;li&gt;订购需要多长时间？&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通常会将数据刮取或推送到时间序列数据库（例如 Prometheus 或 InfluxDB）进行聚合。遥测数据的唯一要求是它将被收集数据的系统格式化。&lt;/p&gt;
&lt;p&gt;至少，可能最好实施度量标准的 RED 方法，该方法收集应用程序的速率，错误和执行时间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;请求率&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;收到了多少个请求&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;错误&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;应用程序有多少错误&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;时间&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;多久才能收到回复&lt;/p&gt;
&lt;p&gt;遥测数据应该用于提醒而非健康监测。在动态的、自我修复的环境中，我们更少关注单个应用程序实例的生命周期，更多关注关于整体应用程序 SLO 的内容。健康报告对于自动应用程序管理仍然很重要，但不应该用于页面工程师。&lt;/p&gt;
&lt;p&gt;如果 1 个实例或 50 个应用程序不健康，只要满足应用程序的业务需求，我们可能不会收到警报。度量标准可让您知道您是否符合您的 SLO，应用程序的使用方式以及对于您的应用程序来说什么是“正常”。警报有助于您将系统恢复到已知的良好状态。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果它移动，我们跟踪它。有时候我们会画出一些尚未移动的图形，以防万一它决定为它运行。&lt;/p&gt;
&lt;p&gt;——Ian Malpass，衡量所有，衡量一切&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;警报也不应该与日志记录混淆。记录用于调试，开发和观察模式。它暴露了应用程序的内部功能。度量有时可以从日志（例如错误率）计算，但需要额外的聚合服务（例如 ElasticSearch）和处理。&lt;/p&gt;
&lt;h3 id=&#34;弹性&#34;&gt;弹性&lt;/h3&gt;
&lt;p&gt;一旦你有遥测和监测数据，你需要确保你的应用程序对故障有适应能力。弹性是基础设施的责任，但云原生应用程序也需要承担部分工作。&lt;/p&gt;
&lt;p&gt;基础设施被设计为抵制失败。硬件用于需要多个硬盘驱动器，电源以及全天候监控和部件更换以保持应用程序可用。使用云原生应用程序，应用程序有责任接受失败而不是避免失败。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在任何平台上，尤其是在云中，最重要的特性是其可靠性。&lt;/p&gt;
&lt;p&gt;——David Rensin，e ARCHITECT Show：来自 Google 的关于云计算的速成课程&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;设计具有弹性的应用程序可能是整本书本身。我们将在云原生应用程序中考虑弹性的两个主要方面：为失败设计和优雅降级。&lt;/p&gt;
&lt;h4 id=&#34;为失败设计&#34;&gt;为失败设计&lt;/h4&gt;
&lt;p&gt;唯一永远不会失败的系统是那些让你活着的系统（例如心脏植入物和刹车系统）。如果您的服务永远不会停止运行，您需要花费太多时间设计它们来抵制故障，并且没有足够的时间增加业务价值。您的 SLO 确定服务需要多长时间。您花费在工程设计上超出 SLO 的正常运行时间的任何资源都将被浪费掉。&lt;/p&gt;
&lt;p&gt;您应该为每项服务测量两个值，即平均无故障时间（MTBF）和平均恢复时间（MTTR）。监控和指标可以让您检测您是否符合您的 SLO，但运行应用程序的平台是保持高 MTBF 和低 MTTR 的关键。&lt;/p&gt;
&lt;p&gt;在任何复杂的系统中，都会有失败。您可以管理硬件中的某些故障（例如，RAID 和冗余电源），以及某些基础设施中的故障（例如负载平衡器）。但是因为应用程序知道他们什么时候健康，所以他们也应该尽可能地管理自己的失败。&lt;/p&gt;
&lt;p&gt;设计一个以失败期望为目标的应用程序将比假定可用性的应用程序更具防御性。当故障不可避免时，将会有额外的检查，故障模式和日志内置到应用程序中。&lt;/p&gt;
&lt;p&gt;知道应用程序可能失败的每种方式是不可能的。假设任何事情都可能并且可能会失败，这是一种云原生应用程序的模式。&lt;/p&gt;
&lt;p&gt;您的应用程序的最佳状态是健康状态。第二好的状态是失败状态。其他一切都是非二进制的，难以监控和排除故障。Honeycomb 首席执行官 CharityMajors 在她的文章“Ops：现在每个人都在工作”中指出：“分布式系统永远不会起作用；它们处于部分退化服务的持续状态。接受失败，设计弹性，保护和缩小关键路径。”&lt;/p&gt;
&lt;p&gt;无论发生什么故障，云原生应用程序都应该是可适应的。他们期望失败，所以他们在检测到时进行调整。&lt;/p&gt;
&lt;p&gt;有些故障不能也不应该被设计到应用程序中（例如，网络分区和可用区故障）。该平台应自主处理未集成到应用程序中的故障域。&lt;/p&gt;
&lt;h4 id=&#34;优雅降级&#34;&gt;优雅降级&lt;/h4&gt;
&lt;p&gt;云原生应用程序需要有一种方法来处理过载，无论它是应用程序还是负载下的相关服务。处理负载的一种方式是优雅降级。 “站点可靠性工程”一书中描述了应用程序的优雅降级，因为它提供的响应在负载过重的情况下“不如正常响应准确或含有较少数据的响应，但计算更容易”。&lt;/p&gt;
&lt;p&gt;减少应用程序负载的某些方面由基础设施处理。智能负载平衡和动态扩展可以提供帮助，但是在某些时候，您的应用程序可能承受的负载比它可以处理的负载更多。云原生应用程序需要知道这种必然性并作出相应的反应。&lt;/p&gt;
&lt;p&gt;优雅降级的重点是允许应用程序始终返回请求的答案。如果应用程序没有足够的本地计算资源，并且依赖服务没有及时返回信息，则这是正确的。依赖于一个或多个其他服务的服务应该可用于应答请求，即使依赖于服务不是。当服务退化时，返回部分答案或使用本地缓存中的旧信息进行答案是可能的解决方案。&lt;/p&gt;
&lt;p&gt;尽管优雅的降级和失败处理都应该在应用程序中实现，但平台的多个层面应该提供帮助。如果采用微服务，则网络基础设施成为需要在提供应用弹性方面发挥积极作用的关键组件。有关构建弹性网络层的更多信息，请参阅附录 A。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;可用性数学&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;云原生应用程序需要在基础设施之上建立一个平台，以使基础设施更具弹性。如果您希望将现有应用程序“提升并转移”到云中，则应检查云提供商的服务级别协议（SLA），并考虑在使用多个服务时会发生什么情况。&lt;/p&gt;
&lt;p&gt;让我们拿运行我们的应用程序的云来进行假设。&lt;/p&gt;
&lt;p&gt;计算基础设施的典型可用性是每月 99.95％的正常运行时间。这意味着您的实例每天可能会缩短到 43.2 秒，并且仍在您的云服务提供商的 SLA 中。&lt;/p&gt;
&lt;p&gt;另外，实例的本地存储（例如 EBS 卷）也具有 99.95％的可用性正常运行时间。如果幸运的话，他们都会同时出现故障，但最糟糕的情况是他们可能会在不同的时间停机，让您的实例只有 99.9％的可用性。&lt;/p&gt;
&lt;p&gt;您的应用程序可能还需要一个数据库，而不是自己安装一个计算可能的停机时间为 1 分 26 秒（99.9％可用性）的情况下，选择可靠性为 99.95％的更可靠的托管数据库。这使您的应用程序的可靠性达到 99.85％，或者每天可能发生 2 分钟和 9 秒的宕机时间。&lt;/p&gt;
&lt;p&gt;将可用性乘到一起可以快速了解为什么应以不同方式处理云。真正不好的部分是，如果云提供商不符合其 SLA，它将退还其账单中一定比例的退款。&lt;/p&gt;
&lt;p&gt;虽然您不必为停机支付费用，但我们并不知道世界上存在云计算信用的单一业务。如果您的应用程序的可用性不足以超过您收到的信用额度，那么您应该真正考虑是否应该运行这个应用程序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;声明式非反应式&#34;&gt;声明式，非反应式&lt;/h3&gt;
&lt;p&gt;因为云原生应用程序被设计为在云环境中运行，所以它们与基础设施以及相关依赖应用程序的交互方式不同于传统应用程序。在云原生应用程序中，与任何事物的通信都需要通过网络来进行。很多时候，网络通信是通过 RESTful HTTP 调用完成的，但是也可以通过其他接口实现，比如远程过程调用 (RPC)。&lt;/p&gt;
&lt;p&gt;传统的应用程序会通过向消息队列发送消息、在共享存储上写入文件或触发本地 shell 脚本来执行自动化任务。通信方法基于发生的事件作出反应（例如，如果用户单击提交，运行提交脚本）并且通常需要存在于同一物理或虚拟服务器上的信息。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Serverless&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;无服务器平台是云原生化的，并被设计为对事件做出反应。他们在云中工作得很好的原因是他们通过 HTTP API 进行通信，（这些 API）是单一用途的函数，并且在它们的调用中是声明性的。该平台还使它们可伸缩并可从云内访问。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;传统应用程序中的反应式通信通常是构建弹性的一种尝试。如果应用程序（以反应式的方式）在磁盘上或消息队列中写入了一个文件，然后应用程序死亡，那么该消息或文件的结果仍然可以完成。&lt;/p&gt;
&lt;p&gt;这里并不是说不应该使用像消息队列这样的技术，而是说在动态且经常出现故障的系统中，不能将它们作为惟一的弹性层来依赖。从根本上说，在云原生环境之中，应用程序之间的通信方法应该有所变化 - 这不仅是因为还存在其他方法来构建通信弹性（请参阅附录 A），而且还因为如果要让传统的通信方法在云中实现复制，我们往往需要做更多工作。&lt;/p&gt;
&lt;p&gt;当应用程序可以信任通信的弹性时，它们应该放弃反应式并使用声明式。声明式通信信任网络会将消息送达。它也相信应用程序将返回成功或错误。这并不是说让应用程序观察变化不重要。Kubernetes 的控制器对 API 服务器做的就是这个。但是，一旦发现变更，他们就会声明一个新的状态，并相信 API 服务器和 kubelets 会做必要的事情。&lt;/p&gt;
&lt;p&gt;声明式通信模型由于多种原因而变得更加健壮。最重要的是，它规范了通信模型，并且它将（如何从某种状态到达期望状态的）功能实现从应用程序转移到远程 API 或服务端点。这有助于简化应用程序，并使它们彼此的行为更具可预测性。&lt;/p&gt;
&lt;h3 id=&#34;云原生应用程序如何影响基础设施&#34;&gt;云原生应用程序如何影响基础设施？&lt;/h3&gt;
&lt;p&gt;希望你可以知道云原生应用程序与传统应用程序不同。云原生应用程序不能直接在 PaaS 上运行或与服务器的操作系统紧密耦合。它们期望在一个拥有大多数自治系统的动态环境中运行。&lt;/p&gt;
&lt;p&gt;云原生基础设施在提供自主应用管理的 IaaS 之上创建了一个平台。该平台建立在动态创建的基础设施之上，以抽象出单个服务器并促进动态资源分配调度。&lt;/p&gt;
&lt;p&gt;自动化与自治不一样。自动化使人类对他们所采取的行动产生更大的影响。&lt;/p&gt;
&lt;p&gt;云原生是关于不需要人类做出决定的自治系统。它仍然使用自动化，但只有在决定了所需的操作之后。只有在系统不能自动确定正确的事情时才应该通知人。&lt;/p&gt;
&lt;p&gt;具有这些特征的应用程序需要一个能够实际监控，收集度量标准并在发生故障时做出反应的平台。云原生应用程序不依赖于人员设置 ping 检查或创建 Syslog 规则。他们需要从选择基本操作系统或软件包管理器的过程中提取自助服务资源，并依靠服务发现和强大的网络通信来提供丰富的功能体验。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.heptio.com/i-still-remember-the-first-time-i-logged-into-a-production-server-over-ssh-and-telling-myself-i-53ab1d1e7f46&#34; title=&#34;“Cloud Native Infrastructure”, a Free O’Reilly eBook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;“Cloud Native Infrastructure”, a Free O’Reilly eBook&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>Kubernetes 次世代的云原生应用</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/</guid>
      <description>
        
        
        &lt;h2 id=&#34;重点&#34;&gt;重点&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;云原生基础设施已渡过了野蛮生长期，正朝着统一应用标准方向迈进。&lt;/li&gt;
&lt;li&gt;Kubernetes 的原语无法完整描述云原生应用体系，且在资源的配置上开发与运维功能耦合严重。&lt;/li&gt;
&lt;li&gt;Operator 在扩展了 Kubernetes 生态的同时导致云原生应用碎片化，亟需一个统一的应用定义标准。&lt;/li&gt;
&lt;li&gt;OAM 的本质是将云原生应用定义中的研发、运维关注点分离，资源对象进行进一步抽象，化繁为简，包罗万象。&lt;/li&gt;
&lt;li&gt;“Kubernetes 次世代”是指在 Kubernetes 成为基础设施层标准之后，云原生生态的关注点正在向应用层过度，近两年来火热的 Service Mesh 正是该过程中的一次有力探索，而基于 Kubernetes 的云原生&lt;strong&gt;应用&lt;/strong&gt;架构的时代即将到来。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Kubernetes 已成为云原生应用的既定运行平台，本文以 Kubernetes 为默认平台展开，包括云原生应用的分层模型。&lt;/p&gt;
&lt;h2 id=&#34;云原生的不同发展阶段&#34;&gt;云原生的不同发展阶段&lt;/h2&gt;
&lt;p&gt;Kubernetes 从开源至今已经走过快&lt;a href=&#34;https://jimmysong.io/cloud-native/memo/open-source/&#34; title=&#34;六个年头&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;六个年头&lt;/a&gt;
（2014 年 6 月开源）了，可以说是 Kubernetes 的诞生开启了整个云原生的时代。我粗略的将云原生的发展划分为以下几个时期。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/cloud-native-stages.svg&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/post-kubernetes-era/cloud-native-stages.svg&#34; alt=&#34;image&#34; data-caption=&#34;云原生的发展阶段&#34;&gt;
    
  
  &lt;figcaption&gt;云原生的发展阶段&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第一阶段：孵化期（2014 年）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2014 年，Google 开源 Kubernetes，在此之前的 2013 年，Docker 开源，DevOps、微服务已变得十分流行，云原生的概念已经初出茅庐。在开源了 Kubernetes 之后，Google 联合其他厂商发起成立了 CNCF，并将 Kubernetes 作为初创项目捐献给了 CNCF。CNCF 作为云原生的背后推手，开始推广 Kubernetes。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第二阶段：高速发展期（2015 年 - 2016 年）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这几年间，Kubernetes 保持着高速发展，并于 2017 年打败了 Docker Swarm、Mesos，确立了容器编排工具领导者的地位。CRD 和 Operator 模式的诞生，大大增强了 Kubernetes 的扩展性，促进了周边生态的繁荣。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第三阶段：野蛮生长期（2017 年 - 2018 年）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;2016 年之后的云原生基本都默认运行在 Kubernetes 平台上，2017、2018 年 Google 主导的 Istio、Knative 相继开源，这些开源项目都大量利用了 Kubernetes 的 Operator 进行了扩展，Istio 刚发布时就有 50 多个 CRD 定义。Istio 号称是&lt;a href=&#34;https://jimmysong.io/blog/service-mesh-the-microservices-in-post-kubernetes-era/&#34; title=&#34;后 Kubernetes 时代的微服务&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;后 Kubernetes 时代的微服务&lt;/a&gt;
，它的出现第一次使得云原生以服务（应用）为中心。Knative 是 Google 在基于 Kubernetes 之上开源的 Serverless 领域的一次尝试。2018 年 Kubernetes 正式从 CNCF &lt;a href=&#34;https://www.cncf.io/blog/2018/03/06/kubernetes-first-cncf-project-graduate/&#34; title=&#34;毕业&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;毕业&lt;/a&gt;
，Prometheus、Envoy 也陆续从 CNCF 毕业。CNCF 也与 2018 年修改了 charter，对云原生进行了重定义，从原来的三要素：”应用容器化；面向微服务架构；应用支持容器的编排调度“，修改为”云原生技术有利于各组织在公有云、私有云和混合云等新型动态环境中，构建和运行可弹性扩展的应用。云原生的代表技术包括容器、服务网格、微服务、不可变基础设施和声明式API“。这一年，我曾写过两篇 Kubernetes 及云原生发展的年终总结和展望，见 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/appendix/kubernetes-and-cloud-native-summary-in-2017-and-outlook-for-2018.html&#34; title=&#34;2017 年&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2017 年&lt;/a&gt;
和 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/appendix/kubernetes-and-cloud-native-summary-in-2018-and-outlook-for-2019.html&#34; title=&#34;2018 年&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;2018 年&lt;/a&gt;
的预测和总结。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;第四阶段：普及推广期（2019 年至今）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;经过几年的发展，Kubernetes 已经得到的大规模的应用，云原生的概念开始深入人心，Kubernetes 号称是云原生的操作系统，基于 Operator 模式的生态大放异彩。整合 Kubernetes 和云基础设施，研发和运维关注点分离。Kubernetes 到 Service Mesh（后 Kubernetes 时代的微服务），基于 Kubernetes 的 Serverless 都在快速发展，OAM 诞生，旨在定义云原生应用标准。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-开辟了云原生时代&#34;&gt;Kubernetes 开辟了云原生时代&lt;/h2&gt;
&lt;p&gt;Kubernetes 开源之初就继承了 Google 内部调度系统 Borg 的经验，屏蔽掉了底层物理机、虚拟机之间的差异，经过几年时间的发展成为了容器编排标准，进而统一了 PaaS 平台的基础设施层。&lt;/p&gt;
&lt;p&gt;下图是Kubernetes 原生内置的可以应用到一个 Pod 上的所有控制器、资源对象等。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/kubernetes-concepts.png&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/post-kubernetes-era/kubernetes-concepts.png&#34; data-width=&#34;800&#34; data-height=&#34;596&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes 概念&#34;&gt;
    
  
  &lt;figcaption&gt;Kubernetes 概念&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图片来自图书 &lt;a href=&#34;https://www.redhat.com/cms/managed-files/cm-oreilly-kubernetes-patterns-ebook-f19824-201910-en.pdf&#34; title=&#34;Kubernetes Patterns（O’Reilly）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Patterns（O’Reilly）&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Kubernetes 作为云原生基础设施设计之初遵循了以下原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;基础设施即代码（声明式 API）&lt;/li&gt;
&lt;li&gt;不可变基础设施&lt;/li&gt;
&lt;li&gt;幂等性&lt;/li&gt;
&lt;li&gt;调节器模式（Operator 的原理）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;其中声明式 API 可谓开创了云原生时代的基调，而调节器模式是 Kubernetes 区别于其他&lt;a href=&#34;https://jimmysong.io/cloud-native-infra/evolution-of-cloud-native-developments.html&#34; title=&#34;云部署形式&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云部署形式&lt;/a&gt;
的主要区别之一，这也为后来的 &lt;a href=&#34;https://zhuanlan.zhihu.com/p/54633203&#34; title=&#34;Operator 框架的诞生&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Operator 框架的诞生&lt;/a&gt;
打下了基础。&lt;/p&gt;
&lt;h3 id=&#34;声明式-api&#34;&gt;声明式 API&lt;/h3&gt;
&lt;p&gt;根据声明式 API 可以做应用编排，定义组件间的依赖，通常使用人类易读的 YAML 文件来表示。但是，YAML 文件声明的字段真的就是最终的状态吗？有没有可能动态改变？&lt;/p&gt;
&lt;p&gt;我们在创建 &lt;code&gt;Deployment&lt;/code&gt; 时会指定 Pod 的副本数，但是其实际副本数并不一定是一成不变的。假如集群中还有定义 HPA，那么 Pod 的副本数就可能随着一些外界因素（比如内存、CPU 使用率或者自定义 metric）而改变，而且如果集群中还有运行自定义的控制器话，那么也有可能修改应用的实例数量。在有多个控制器同时控制某个资源对象时，如何确保控制器之间不会发生冲突，资源对象的状态可预期？可使用&lt;a href=&#34;https://kubernetes.io/zh/docs/reference/access-authn-authz/extensible-admission-controllers/#monitoring-admission-webhooks&#34; title=&#34;动态准入控制&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;动态准入控制&lt;/a&gt;
来达到这一点。&lt;/p&gt;
&lt;h3 id=&#34;kubernetes-原生应用&#34;&gt;Kubernetes 原生应用&lt;/h3&gt;
&lt;p&gt;我们都知道要想运行一个应用至少需要以下几点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用的业务逻辑（代码）、运行时（可运行的二进制文件、字节码或脚本）。&lt;/li&gt;
&lt;li&gt;应用的配置注入（配置文件、环境变量等），身份、路由、服务暴露等满足应用的安全性和可访问性。&lt;/li&gt;
&lt;li&gt;应用的生命周期管理（各种 Controller 登场）。&lt;/li&gt;
&lt;li&gt;可观察性、可运维、网络和资源及环境依赖、隔离性等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图展示了基于 Kubernetes 原语及 PaaS 平台资源的 Kubernetes 原生应用的组成。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/kubernetes-native-application-motion.gif&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/post-kubernetes-era/kubernetes-native-application-motion.gif&#34; data-width=&#34;600&#34; data-height=&#34;334&#34; alt=&#34;image&#34; data-caption=&#34;Kubernetes 原生应用&#34;&gt;
    
  
  &lt;figcaption&gt;Kubernetes 原生应用&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们都知道 Kubernetes 提供了大量的&lt;a href=&#34;https://kubernetes.io/docs/concepts/&#34; title=&#34;原语&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原语&lt;/a&gt;
，用户可以基于这些原语来编排服务，管理应用的生命周期。上图展示的是基于 Kubernetes 原生应用可以使用的 Kubernetes 原语、扩展及平台层资源，从内向外的对象跟应用程序（业务逻辑）的关联度依次降低，到最外层基本只剩下平台资源依赖，已经与 Kubernetes 几乎没有关系了。该图里仅展示了部分资源和对象（包含阿里巴巴开源的 &lt;a href=&#34;https://github.com/openkruise/kruise&#34; title=&#34;OpenKruise&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenKruise&lt;/a&gt;
、Istio），实际上 &lt;a href=&#34;https://operatorhub.io/&#34; title=&#34;Operator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Operator&lt;/a&gt;
 资源之丰富，也是 Kubernetes 生态如此繁荣的原因之一。&lt;/p&gt;
&lt;p&gt;Kubernetes 本身的原语、资源对象、配置、常用的 CRD 扩展有几十、上百个之多。开发者需要了解这些复杂的概念吗？我只是想部署一个应用而已！不用所对于应用开发者，即使对于基础实施开发和运维人员也需要很陡峭的学习曲线才能完全掌握它。&lt;/p&gt;
&lt;p&gt;我将 Kubernetes 原生应用所需要的定义和资源进行了分层：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;核心层&lt;/strong&gt;：应用逻辑、服务定义、生命周期控制；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;隔离与服务访问层&lt;/strong&gt;：资源限制与隔离、配置、身份、路由规则等；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;调度层&lt;/strong&gt;：各种调度控制器，这也是 Kubernetes 原生应用的主要扩展层；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;资源层&lt;/strong&gt;：提供网络、存储和其他平台资源；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;而这些不同的层，完全可以将其职责分配给相应的人员，比如核心层是由应用程序开发者负责，将其职责分离，可以很大程度上降低开发和运维的复杂度。&lt;/p&gt;
&lt;p&gt;云原生应用落实到 Kubernetes 平台之上，仅仅利用 Kubernetes 的对象原语已很难描述一个复杂的应用程序，所以诞生了各种各样的 Operator，但这也仅仅解决了单个应用的定义，对于应用的打包封装则无能为力。&lt;/p&gt;
&lt;p&gt;同一个资源对象又有多种实现方式，比如 Ingress 就有 &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1DnsHtdHbxjvHmxvlu7VhzWcWgLAn_Mc5L1WlhLDA__k/edit#gid=0&#34; title=&#34;10 多种实现&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;10 多种实现&lt;/a&gt;
，PV 就更不用说，对于开发者究竟如何选择，平台如何管理，这都是让人很头疼的问题。而且有时候平台所提供的扩展能力还可能会有冲突，这些能力有的可能互不相干，有的可能会有正交，有的可能完全重合。且应用本身与运维特性之间存在太多耦合，不便于复用。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/resources-motion.gif&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/post-kubernetes-era/resources-motion.gif&#34; data-width=&#34;600&#34; data-height=&#34;363&#34; alt=&#34;image&#34; data-caption=&#34;资源交集动画&#34;&gt;
    
  
  &lt;figcaption&gt;资源交集动画&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;上图中不同颜色的方框代表不同的资源类别，红线框代表不能为一个资源同时应用该配置，否则会出现冲突，不同的颜色上面是一个动画，展示的是部分资源组合。图中仅包含了部分 Kubernetes 中的原语和 Istio 中的资源对象组合及自定义扩展，实际上用户可以根据应用的自身特点，基于 Kubernetes 原语和 CRD 创建出千变万化的组合。&lt;/p&gt;
&lt;p&gt;为了管理这些应用诞生出了众多的 &lt;a href=&#34;https://github.com/operator-framework/awesome-operators&#34; title=&#34;Operator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Operator&lt;/a&gt;
。Kubernetes 1.7 版本以来就引入了&lt;a href=&#34;https://kubernetes.io/docs/concepts/api-extension/custom-resources/&#34; title=&#34;自定义控制器&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自定义控制器&lt;/a&gt;
的概念，该功能可以让开发人员扩展添加新功能，更新现有的功能，并且可以自动执行一些管理任务，这些自定义的控制器就像 Kubernetes 原生的组件一样，Operator 直接使用 Kubernetes API进行开发，也就是说它们可以根据这些控制器内部编写的自定义规则来监控集群、更改 Pods/Services、对正在运行的应用进行扩缩容。&lt;/p&gt;
&lt;p&gt;Operator 的本质是一种调节器模式（Reconciler Pattern）的应用，跟 Kubernetes 本身的实现模式是一样的，用于管理云原生应用，协调应用的实际状态达到预期状态。&lt;/p&gt;
&lt;p&gt;调节器模式的四个原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;所有的输入和输出都使用数据结构。&lt;/li&gt;
&lt;li&gt;确保数据结构是不可变的。&lt;/li&gt;
&lt;li&gt;保持资源映射简单。&lt;/li&gt;
&lt;li&gt;使实际状态符合预期状态。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;云原生应用走向碎片化&#34;&gt;云原生应用走向碎片化&lt;/h2&gt;
&lt;p&gt;利用声明式 API 及调节器模式，理论上可以在 Kubernetes 上部署任何可声明应用，但是在 Operator 出现之前，管理 Kubernetes 上的有状态应用一直是一个难题，随着 Operator 模式的确立，该难题已得以解决，并促进了 Kubernetes 生态的进一步发展。随着该生态的繁荣，有一种碎片化的特征正在显现。&lt;/p&gt;
&lt;div class=&#34;alert&#34;&gt;

&lt;div class=&#34;alert-warn-title py-1 px-2&#34;&gt;
  云原生应用碎片化的体现
&lt;/div&gt;

&lt;div class=&#34;alert-warn py-1 px-2&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Operator 模式将运维人员的反应式经验转化成基于 &lt;code&gt;Reconcile&lt;/code&gt; 模式的代码，统一了有状态应用的管理模式，极大得扩展了 Kubernetes 应用生态。&lt;/li&gt;
&lt;li&gt;开发者在引用 Operator 所提供的能力时没有统一的视图，加大了基础设施运维与开发者之间的沟通成本。&lt;/li&gt;
&lt;li&gt;Operator 总体上治理松散，没有统一的管控机制，在同时应用时可能导致互相冲突或无法预期的结果发生。&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&#34;有状态应用管理难题&#34;&gt;有状态应用管理难题&lt;/h3&gt;
&lt;p&gt;Kubernetes 对于无状态应用的管理很出色，但是对于有状态应用就不是那么回事了。虽然 StatefulSet 可以帮助管理有状态应用，但是这还远远不够，有状态应用往往有复杂的依赖。声明式的 API 里往往要加载着大量的配置和启动脚本，才能实现一个复杂应用的 Kubernetes 化。&lt;/p&gt;
&lt;p&gt;例如在 2017 年初，Operator Framework 出现之前，需要使用大量的 &lt;code&gt;ConfigMap&lt;/code&gt;、复杂的启动脚本才能&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/guide/migrating-hadoop-yarn-to-kubernetes.html&#34; title=&#34;在 Kubernetes 上定义 Hadoop YARN&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;在 Kubernetes 上定义 Hadoop YARN&lt;/a&gt;
 和&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/usecases/running-spark-with-kubernetes-native-scheduler.html&#34; title=&#34;运行 Spark&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运行 Spark&lt;/a&gt;
。虽然 &lt;a href=&#34;https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/&#34; title=&#34;&amp;lt;code&amp;gt;StatefulSet&amp;lt;/code&amp;gt;&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&lt;code&gt;StatefulSet&lt;/code&gt;&lt;/a&gt;
 号称可以解决有状态应用的部署问题，但是它主要是保证了 Pod 的在启动、伸缩时的顺序和使 Pod 具有稳定的标识。但是很多分布式应用来说并不仅依靠启动顺序就可以保证其状态，根据其在分布式应用中的角色不同（master/worker）而需要有大量的自定义配置，在没有 Operator 之前这些配置通常是通过一些自定义脚本来实现，这些脚本可能存在于应用镜像中，也可以通过 &lt;code&gt;ConfigMap&lt;/code&gt; 挂在到容器运行时，但无论如何这些脚本都可能因为散落在各处，这些脚本还是面向过程的，跟在 Kubernetes 诞生之前的运维方式毫无二致，这极其不便于版本控制和运维管理。&lt;/p&gt;
&lt;h3 id=&#34;operator-统一了-kubernetes-应用运维框架&#34;&gt;Operator 统一了 Kubernetes 应用运维框架&lt;/h3&gt;
&lt;p&gt;Operator 大大增强了 Kubernetes 的可扩展性，丰富了以 Kubernetes 为基础的云原生生态，许多原先不是为 Kubernetes 而构建的应用纷纷通过&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54633203&#34; title=&#34;构建自己的 Operator&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;构建自己的 Operator&lt;/a&gt;
 迁移到 Kubernetes 上。还有一些直接基于 Kubernetes 构建的 Service Mesh、Serverless 框架，它们应用 Operator 模式（如 &lt;a href=&#34;https://istio.io&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
、&lt;a href=&#34;https://knative.dev&#34; title=&#34;Knative&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Knative&lt;/a&gt;
），试图成为云原生应用的基础设施层，补齐 Kubernetes 在服务治理、无服务架构等方面的短板，随着大量的 CRD、Operator 控制器的出现，而 Kubernetes 却无法以应用的视角来管理这些能力及其背后零散的 CRD，这使得云原生应用碎片化。&lt;/p&gt;
&lt;p&gt;Operator 百花齐放，在没有一个大一统的视图之前，各个控制器之间存在着这样的关系：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;独立&lt;/strong&gt;：互不干涉，比如 Controller 与服务发现之间就不存在冲突。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;可组合&lt;/strong&gt;：例如 &lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt; 同属一类资源（可访问性与路由），就是可组合的（后两者是 Istio 中的 CRD，用于流量管理）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;有冲突&lt;/strong&gt;：例如图中的 &lt;code&gt;CronHorizontalPodAutoscaler&lt;/code&gt;（CRD）、&lt;code&gt;HorizontalPodAutoscaler&lt;/code&gt;（Kubernetes 内置），同时使用可能导致无法意料的情况发生。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;正是以为这样复杂的关系，导致其无法做到开箱即用，还需要基础设施团队基于云原生社区和生态自己构建出来的，比如&lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/#application-delivery&#34; title=&#34;应用交付领域&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用交付领域&lt;/a&gt;
的系列开源项目。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用管理工具-helm&#34;&gt;云原生应用管理工具 Helm&lt;/h2&gt;
&lt;p&gt;Kubernetes 之上有很多能力缺失，比如应用构建、发布、管理和运维等，Helm 的出现主要补偿了应用打包和版本管理的缺陷。其中云原生应用的配置包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序启动时加载的配置文件；&lt;/li&gt;
&lt;li&gt;应用程序的运维配置，如资源申请限额；&lt;/li&gt;
&lt;li&gt;应用程序的服务发现配置；&lt;/li&gt;
&lt;li&gt;应用程序的工作负载、发布策略、依赖等；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些配置可以存在于 &lt;code&gt;ConfigMap&lt;/code&gt;、&lt;code&gt;Deployment&lt;/code&gt;、&lt;code&gt;Service&lt;/code&gt;、&lt;code&gt;Ingress&lt;/code&gt; 等 Kubernetes 的多个资源文件中，如何保证应用程序的复用性？应用程序之间有依赖该如何解决？这是时候你可能自然的想到了 Helm。&lt;/p&gt;
&lt;div class=&#34;alert&#34;&gt;

&lt;div class=&#34;alert-warn-title py-1 px-2&#34;&gt;
  云原生应用打包和发布管理
&lt;/div&gt;

&lt;div class=&#34;alert-warn py-1 px-2&#34;&gt;
  &lt;ul&gt;
&lt;li&gt;Helm 通过 chart 模板，提高了应用程序的复用性并解决了部分依赖问题；&lt;/li&gt;
&lt;li&gt;Chart 仓库提供了云原生应用程序的统一管控视图；&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Release&lt;/code&gt; 概念的引入，使得云原生应用版本化管理进一步加强；&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;Helm 主要关注的是 &lt;a href=&#34;https://12factor.net/zh_cn/&#34; title=&#34;12 因素应用&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;12 因素应用&lt;/a&gt;
法则&lt;a href=&#34;https://12factor.net/zh_cn/build-release-run&#34; title=&#34;构建、发布、运行&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;构建、发布、运行&lt;/a&gt;
这一原则中的”发布”这一环节。下图是 Helm v3 的架构图。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/helm-chart.svg&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/post-kubernetes-era/helm-chart.svg&#34; alt=&#34;image&#34; data-caption=&#34;Helm3 架构&#34;&gt;
    
  
  &lt;figcaption&gt;Helm3 架构&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Helm 可以安装本地或者远程的 chart，当 chart 安装到 Kubernetes 中后就会创建一个 release，每次更新该 chart 的配置并执行 &lt;code&gt;helm upgrade&lt;/code&gt;， release 的版本数就会加 1，开发者可以升级 chart 或回滚到历史版本。&lt;/p&gt;
&lt;h3 id=&#34;打包配置和发布&#34;&gt;打包、配置和发布&lt;/h3&gt;
&lt;p&gt;Helm 和 chart 的主要作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用程序封装&lt;/li&gt;
&lt;li&gt;版本管理&lt;/li&gt;
&lt;li&gt;依赖检查&lt;/li&gt;
&lt;li&gt;便于应用程序分发&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;打包&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Helm 采用 &lt;a href=&#34;https://helm.sh/docs/topics/charts/&#34; title=&#34;Chart&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Chart&lt;/a&gt;
 的格式来标准化描述应用，可以将目录打包成版本化的压缩包进行部署理论上一个 Chart 是可以嵌套若干个 Chart 并定义依赖关系，组织形式非常灵活。Helm chart 用于打包 Kubernetes 原生应用。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;应用配置参数，在 Chart 中由 &lt;code&gt;values.yaml&lt;/code&gt; 和命令行参数组成。Chart 采用 Go Template 的特性和 &lt;code&gt;values.yaml&lt;/code&gt; 对部署的模板文件进行参数渲染，也可以通过 &lt;code&gt;helm&lt;/code&gt; 命令 &lt;code&gt;--set key=value&lt;/code&gt; 的方式进行参数赋值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;发布&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Release 代表 Chart 在集群中的运行实例，Helm 围绕 Release 对应用提供了强大的生命周期管理能力，包括 Release 的查询、安装、更新、删除、回滚等。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用&#34;&gt;云原生应用&lt;/h2&gt;
&lt;p&gt;以上关注的点都是基于 Kubernetes 原语的实现，虽然基于 Kubernetes 构建的 PaaS 平台部分屏蔽了底层基础设施的差异，但是仍有很多云服务是无法通过 Kubernetes 创建，或者需要提前创建供 Kubernetes 原生应用使用的，这些应用通常不运行在 Kubernetes 集群中。因此创建和管理一个云原生应用程序需要考虑以下方面：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;运行时：ECS、Docker、KataContainer、gVisor 等；&lt;/li&gt;
&lt;li&gt;资源隔离性：多租户、VPC、Namespace、防火墙；&lt;/li&gt;
&lt;li&gt;资源调度：各种类型的 controller；&lt;/li&gt;
&lt;li&gt;网络可达性：Service、Ingress、Egress、Gateway、VirtualService、DestinationRule、LoadBalancer、ServiceEntry 等；&lt;/li&gt;
&lt;li&gt;可观测性：日志、分布式追踪、指标；&lt;/li&gt;
&lt;li&gt;安全性：SecurityPolicy、NetworkPolicy、AuthorizationPolicy；&lt;/li&gt;
&lt;li&gt;平台资源申请：数据库、存储等；&lt;/li&gt;
&lt;li&gt;运行与隔离：ECS、Docker、KataContainer 等；&lt;/li&gt;
&lt;li&gt;资源分配和调度：各种控制器；&lt;/li&gt;
&lt;li&gt;环境隔离：Namespace、多租户、VPC、防火墙、LimitRange、Resources；&lt;/li&gt;
&lt;li&gt;可访问性：Service、Ingress、Egress、Gateway、LoadBalancer、VirtualService、DestinationRule、ServiceEntry；&lt;/li&gt;
&lt;li&gt;状态管理：Operator；&lt;/li&gt;
&lt;li&gt;可观察性：日志、监控、指标；&lt;/li&gt;
&lt;li&gt;安全性：SecurityPolicy、ServiceAccount；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;云原生应用分层模型&#34;&gt;云原生应用分层模型&lt;/h3&gt;
&lt;p&gt;那么究竟如何来给云原生应用分层，化繁就简？近几年来，基于 Kubernetes 的应用呈爆炸式发展，光是在&lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/#application-delivery&#34; title=&#34;应用交付领域&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用交付领域&lt;/a&gt;
的开源项目就达几十个之多。下图展示我根据这些项目的特性而绘制的 App Delivery Landscape。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/post-kubernetes-era/cloud-native-app.svg&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/post-kubernetes-era/cloud-native-app.svg&#34; alt=&#34;image&#34; data-caption=&#34;云原生应用的分层模型&#34;&gt;
    
  
  &lt;figcaption&gt;云原生应用的分层模型&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;应用定义和包装&lt;/strong&gt;：云原生应用的最上层，直接定义云原生应用的组成形式，解决云原生应用之间的依赖关系，并封装成发布包，如 Helm、CNAB，还有云原生变成语言 Pulumi 和 Ballerina，基于 API 的方式来编排云原生应用；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;负载定义&lt;/strong&gt;：基于 Kubernetes Operator，大多是 Serverless 负载，既负责了负载的定义又负责了生命周期管理。&lt;a href=&#34;https://istio.io&#34; title=&#34;Istio&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Istio&lt;/a&gt;
 是比较特殊的存在，它不仅管理服务间的流量，还负责安全性、可观察性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;应用发布和上线&lt;/strong&gt;：关注应用的构建和发布、GitOps、发布策略等，这也是云原生应用全景中最丰富的部分之一；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kubernetes 原语&lt;/strong&gt;：Kubernetes 本身提供的原语，Operator 基于此构建；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;以上为我个人分类的云原生应用全景模型，仅限于 Kubernetes 之上的应用，对于其他非 Kubernetes 应用非本文的考虑范围。另外，CNCF SIG App Delivery 中也给出的云原生应用的分层模型，其模型将非 Kubernetes 应用场景也纳入了考虑，详见：&lt;a href=&#34;https://docs.google.com/document/d/1gMhRz4vEwiHa3uD8DqFKHGTSxrVJNgkLG2WZWvi9lXo/edit#heading=h.h9so53gv5zen&#34; title=&#34;The Dictionary of Cloud-Native App Delivery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Dictionary of Cloud-Native App Delivery&lt;/a&gt;
。&lt;/p&gt;
&lt;p&gt;Platform/Kuberntes，Kubernetes 仅仅是屏蔽了平台的一些差异，但是对于最上层的应用来说，没有涉及，用户需要自己来基于各种开源组件来搭积木。&lt;/p&gt;
&lt;h3 id=&#34;oam开放应用模型&#34;&gt;OAM（开放应用模型）&lt;/h3&gt;
&lt;p&gt;那么以上这么多应用有哪些共性，能不能再进一步抽象呢？&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;所有应用是都以容器作为运行时环境（ContainerizedWorkload），这是 OAM 中的核心 Workload 类型；&lt;/li&gt;
&lt;li&gt;在应用发布和上线方面，有些是属于应用的运维特征，需要根据实际需求组合和变更，这些是持续变动的部分；&lt;/li&gt;
&lt;li&gt;要实现某些复杂的应用管控，需要使用到多个 CRD 的组合，比如 Istio 中的让流量根据百分比切分到不同的而服务，就需要部署 Istio Operator，并声明 &lt;code&gt;VirtualService&lt;/code&gt;、&lt;code&gt;DestinationRule&lt;/code&gt;，二者同时使用；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;一个 &lt;code&gt;ApplicationConfiguration&lt;/code&gt; 的 Runtime 的正常流程应该是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用开发者创建自己的 &lt;code&gt;Component&lt;/code&gt;，在 &lt;code&gt;Component&lt;/code&gt; 中描述要应用相关的信息，如应用名称、镜像配置、环境变量等，应用到 Kubernetes cluster 中；&lt;/li&gt;
&lt;li&gt;运维创建各种运维策略，如发布策略、网络策略等等，发布时由 AppConfig 对象关联要发布的 &lt;code&gt;Component&lt;/code&gt; 和本次的运维策略，apply 到集群中，集群的 OAM operator watch 到一次 &lt;code&gt;ApplicationConfiguration&lt;/code&gt;的下发，生成 &lt;code&gt;Component&lt;/code&gt; 对应的 &lt;code&gt;Workload&lt;/code&gt; 和 &lt;code&gt;Trait&lt;/code&gt;，&lt;code&gt;Trait&lt;/code&gt; controller 将本次的 &lt;code&gt;Trait&lt;/code&gt; 策略应用到本次要管理的 &lt;code&gt;Workload&lt;/code&gt; 当中，最终到达终态，完成一次发布。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OAM 是对 Kubernetes 友好的，一样采用声明式 API 的理念开发。如果你已经编写了现成的 CRD Operator，可以平滑地接入到 OAM 体系中。OAM 以应用为中心，高度可扩展，扩展点包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Workload：扩展各种运行时类型，不仅限于容器运行时，还可以定义更多其他运行时，比如 Serverless 负载、虚拟机、数据库、网络等；例如，Pod、无服务器函数、数据存储、消息队列或任何其他类型的工作负载，这些都是应用程序开发人员需要设计一个完整的应用程序所需要的，可以直接引用 Kubernetes 的 CRD；&lt;/li&gt;
&lt;li&gt;Trait：各种运维规则，比如扩缩容、流量控制、安全性；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;生态&#34;&gt;生态&lt;/h3&gt;
&lt;p&gt;以前 CNCF 的主要关注群体大多是基础设施领域的技术人员，但是自 2019 年 9 月，&lt;a href=&#34;https://www.infoq.cn/article/Cdw7ISlEqKilGyN9V3Pj&#34; title=&#34;CNCF 宣布成立 SIG App Delivery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 宣布成立 SIG App Delivery&lt;/a&gt;
 后，CNCF 正在将应用开发者和运维人员更紧密的联系在一起。&lt;a href=&#34;https://github.com/cncf/sig-app-delivery&#34; title=&#34;应用交付 SIG&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;应用交付 SIG&lt;/a&gt;
 的使命是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在与开发、分发、部署、管理和运行安全的云原生应用相关的领域进行合作，目标是以云原生方式交付应用。&lt;/li&gt;
&lt;li&gt;发展信息资源，包括指南、教程和白皮书，让社区了解最佳实践和应用交付的价值。&lt;/li&gt;
&lt;li&gt;识别合适的项目和现状的差距，定期向 TOC 更新，并以结构化的方式向 TOC 提出行动建议。这包括帮助 TOC 评估和对潜在的新项目进行尽职调查。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;目前 OAM 定义的云原生应用模型已有以下项目支持。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://crossplane.io/&#34; title=&#34;Crossplane&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Crossplane&lt;/a&gt;
：这是一个开源的 Kubernetes 扩展组件，适用于主流公有云平台，使用 &lt;code&gt;kubectl&lt;/code&gt; 配置和管理基础架构、服务和应用。对于 OAM 的支持详见&lt;a href=&#34;https://crossplane.io/docs/v0.11/getting-started/run-applications.html&#34; title=&#34;运行应用程序&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;运行应用程序&lt;/a&gt;
。&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://googlecontainertools.github.io/kpt/&#34; title=&#34;KPT&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;KPT&lt;/a&gt;
：Kpt（发音为 &amp;ldquo;keep&amp;rdquo;）是一个在资源配置之上构建声明性工作流的开源工具。它的 git + YAML 架构意味着它只需与现有的工具、框架和平台一起工作。Kpt 包括了获取、显示、自定义、更新、验证和应用 Kubernetes 配置的解决方案。对 OAM 的支持详见 &lt;a href=&#34;https://googlecontainertools.github.io/kpt/guides/ecosystem/oam/&#34; title=&#34;使用 kpt 来管理由开放应用模型（OAM）定义的自定义 Kubernetes 应用程序&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;使用 kpt 来管理由开放应用模型（OAM）定义的自定义 Kubernetes 应用程序&lt;/a&gt;
。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;应用交付领域相关的开源项目还有很多，详见 &lt;a href=&#34;https://jimmysong.io/awesome-cloud-native/#application-delivery&#34; title=&#34;Awesome Cloud Native&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Cloud Native&lt;/a&gt;
。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;基于 Kubernetes 的云原生生态发展至今已有 6 年时间，当前已步入了普及推广阶段。可以说谁云原生应用定义的制高点，就可以掌握云原生的未来。从前我们是新技术浪潮的追随者，现在我们抓住时代的基于，参与标准制定、引领云原生的浪潮！欢迎加入 &lt;a href=&#34;https://oam.dev/&#34; title=&#34;OAM 社区&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM 社区&lt;/a&gt;
，一起参与进来，把国人参与指定的标准推向世界。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.ibm.com/technologies/containers/blogs/kubernetes-helm-3/&#34; title=&#34;Do you know what’s in Helm 3? - developer.ibm.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Do you know what’s in Helm 3? - developer.ibm.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.redhat.com/cms/managed-files/cm-oreilly-kubernetes-patterns-ebook-f19824-201910-en.pdf&#34; title=&#34;O’Reilly: Kubernetes patterns for designing cloud-native apps - redhat.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;O’Reilly: Kubernetes patterns for designing cloud-native apps - redhat.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1gMhRz4vEwiHa3uD8DqFKHGTSxrVJNgkLG2WZWvi9lXo/edit#heading=h.h9so53gv5zen&#34; title=&#34;The Dictionary of Cloud-Native App Delivery - docs.google.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Dictionary of Cloud-Native App Delivery - docs.google.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/Cdw7ISlEqKilGyN9V3Pj&#34; title=&#34;CNCF 宣布成立应用交付领域小组，正式开启云原生应用时代 - infoq.cn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 宣布成立应用交付领域小组，正式开启云原生应用时代 - infoq.cn&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/c7A8lOdAKkW25GoqmwOgWg&#34; title=&#34;OAM v1alpha2 新版发布：平衡标准与可扩展性，灵活接入 CRD operator - mp.weixin.qq.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM v1alpha2 新版发布：平衡标准与可扩展性，灵活接入 CRD operator - mp.weixin.qq.com&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/54633203&#34; title=&#34;Kubernetes API 与 Operator，不为人知的开发者战争&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes API 与 Operator，不为人知的开发者战争&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>云原生应用的定义</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/apps/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/apps/</guid>
      <description>
        
        
        &lt;div class=&#34;alert&#34;&gt;

&lt;div class=&#34;alert-note-title py-1 px-2&#34;&gt;
  注意
&lt;/div&gt;

&lt;div class=&#34;alert-note py-1 px-2&#34;&gt;
  本文参考的是 &lt;a href=&#34;https://github.com/oam-dev/spec&#34; title=&#34;OAM 规范&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OAM 规范&lt;/a&gt;
中对云原生应用的定义，并做出了引申。
&lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;云原生应用是一个相互关联但又不独立的组件（service、task、worker）的集合，这些组件与配置结合在一起并在适当的运行时实例化后，共同完成统一的功能目的。&lt;/p&gt;
&lt;h2 id=&#34;云原生应用模型&#34;&gt;云原生应用模型&lt;/h2&gt;
&lt;p&gt;下图是 OAM 定义的云原生应用模型示意图，为了便于理解，图中相同颜色的部分为同一类别的对象定义。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/apps/cloud-native-app-model.png&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/apps/cloud-native-app-model.png&#34; data-width=&#34;1850&#34; data-height=&#34;550&#34; alt=&#34;image&#34; data-caption=&#34;云原生应用模型&#34;&gt;
    
  
  &lt;figcaption&gt;云原生应用模型&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;OAM 的规范中定义了以下对象，它们既是 OAM 规范中的基本术语也是云原生应用的基本组成。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;../spec/workload&#34; title=&#34;Workload&#34;&gt;Workload&lt;/a&gt;
（工作负载）&lt;/strong&gt;：应用程序的工作负载类型，由平台提供。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;../spec/component&#34; title=&#34;Component&#34;&gt;Component&lt;/a&gt;
（组件）&lt;/strong&gt;：定义了一个 &lt;code&gt;Workload&lt;/code&gt; 的实例，并以基础设施中立的术语声明其运维特性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;../spec/trait&#34; title=&#34;Trait&#34;&gt;Trait&lt;/a&gt;
（特征）&lt;/strong&gt;：用于将运维特性分配给组件实例。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;../spec/application-scope&#34; title=&#34;ApplicationScope&#34;&gt;ApplicationScope&lt;/a&gt;
（应用作用域）&lt;/strong&gt;：用于将组件分组成具有共同特性的松散耦合的应用。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;../spec/application-configuration&#34; title=&#34;ApplicationConfiguration&#34;&gt;ApplicationConfiguration&lt;/a&gt;
（应用配置）&lt;/strong&gt;：描述 &lt;code&gt;Component&lt;/code&gt; 的部署、&lt;code&gt;Trait&lt;/code&gt; 和 &lt;code&gt;ApplicationScope&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OAM 规范中提供了一个使用以上对象定义云原生应用的&lt;a href=&#34;https://github.com/oam-dev/spec/blob/master/examples/workflow.md&#34; title=&#34;工作流示例&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;工作流示例&lt;/a&gt;
。&lt;/p&gt;
&lt;h2 id=&#34;关注点分离&#34;&gt;关注点分离&lt;/h2&gt;
&lt;p&gt;下图是不同角色对于该模型的关注点示意图。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/apps/roles.svg&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/apps/roles.svg&#34; alt=&#34;image&#34; data-caption=&#34;云原生应用模型中的目标角色&#34;&gt;
    
  
  &lt;figcaption&gt;云原生应用模型中的目标角色&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;我们可以看到对于一个云原生应用来说，不同的对象是由不同的角色来负责的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基础设施运维：提供不同的 &lt;code&gt;Workload&lt;/code&gt; 类型供开发者使用；&lt;/li&gt;
&lt;li&gt;应用运维：定义适用于不同 &lt;code&gt;Workload&lt;/code&gt; 的运维属性 &lt;code&gt;Trait&lt;/code&gt; 和管理 &lt;code&gt;Component&lt;/code&gt; 的 &lt;code&gt;ApplicationScope&lt;/code&gt; 即作用域；&lt;/li&gt;
&lt;li&gt;应用开发者：负责应用组件 &lt;code&gt;Component&lt;/code&gt; 的定义；&lt;/li&gt;
&lt;li&gt;应用开发者和运维：共同将 &lt;code&gt;Component&lt;/code&gt; 与运维属性 &lt;code&gt;Trait&lt;/code&gt; 绑定在一起，维护应用程序的生命周期。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;基于 OAM 中的对象定义的云原生应用可以充分利用平台能力自由组合，开发者和运维人员的职责可以得到有效分离，组件的复用性得到大幅提高。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/oam-dev/spec&#34; title=&#34;The Open Application Model specification - github.com&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The Open Application Model specification - github.com&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>云原生快速入门</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/quick-start/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0100</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/quick-start/</guid>
      <description>
        
        
        &lt;p&gt;&lt;a href=&#34;https://kubernetes.io/&#34; title=&#34;Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes&lt;/a&gt;
 一词来自希腊语，意思是“飞行员”或“舵手”。这个名字很贴切，Kubernetes 可以帮助你在波涛汹涌的容器海洋中航行。&lt;/p&gt;
&lt;p&gt;Kubernetes 是做什么的？什么是 Docker？什么是容器编排？Kubernetes 是如何工作和扩展的？你可能还有很多其他的问题，本文将一一为你解答。&lt;/p&gt;
&lt;p&gt;这篇文章适合初学者，尤其是那些工作忙碌，没有办法抽出太多时间来了解 Kubernetes 和云原生的开发者们，希望本文可以帮助你进入 Kubernetes 的世界。&lt;/p&gt;
&lt;p&gt;简而言之，Kubernetes 提供了一个平台或工具来帮助你快速协调或扩展容器化应用，特别是在 &lt;a href=&#34;https://docker.com/&#34; title=&#34;Docker&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker&lt;/a&gt;
 容器。让我们深入了解一下这些概念。&lt;/p&gt;
&lt;h2 id=&#34;容器和容器化&#34;&gt;容器和容器化&lt;/h2&gt;
&lt;p&gt;那么什么是容器呢？&lt;/p&gt;
&lt;p&gt;要讨论容器化首先要谈到虚拟机 (VM)，顾名思义，虚拟机就是可以远程连接的虚拟服务器，比如 AWS 的 EC2 或阿里云的 ECS。&lt;/p&gt;
&lt;p&gt;接下来，假如你要在虚拟机上运行一个网络应用 —— 包括一个 MySQL 数据库、一个 Vue 前端和一些 Java 库，在 Ubuntu 操作系统 (OS) 上运行。你不用熟悉其中的每一个技术 —— 你只要记住，一个应用程序由各种组件、服务和库组成，它们运行在操作系统上。&lt;/p&gt;
&lt;p&gt;现在，将应用程序打包成一个虚拟机镜像，这个镜像中包括了 Ubuntu 操作系统。这使得虚拟机变得非常笨重 —— 通常有几个 G 的大小。&lt;/p&gt;
&lt;p&gt;虚拟机镜像包含了整个操作系统及所有的库，对应用程序来说，这个镜像过于臃肿，其中大部分组件并没有被应用程序直接调用。如果你需要重新创建、备份或扩展这个应用程序，就需要复制整个环境（虚拟机镜像），在新环境中启动应用通常需要几十秒甚至几分钟时间。如果你想单独升级应用中的某个组件，比如说 Vue 应用，就需要重建整个虚拟机镜像。另外，如果你的两个应用依赖同一个底层镜像，升级底层镜像会同时影响这两个应用，而有时候，你只需要升级其中一个应用的依赖而已。这就是所谓的“依赖陷阱”。&lt;/p&gt;
&lt;p&gt;解决这个问题的办法就是容器。容器是继虚拟机之后更高层次的抽象，在这层抽象中，整个应用程序的每个组件被单独打包成一个个独立的单元，这个单元就是所谓的容器。通过这种方式，可以将代码和应用服务从底层架构中分离出来，实现了完全的可移植性（在任何操作系统或环境上运行应用的能力）。所以在上面的例子中，Ubuntu 操作系统就是一个单元（容器）。MySQL 数据库是另一个容器，Vue 环境和随之而来的库也是一个容器。&lt;/p&gt;
&lt;p&gt;但是，MySQL 数据库是如何自己“运行”的？数据库本身肯定也要在操作系统上运行吧？没错！&lt;/p&gt;
&lt;p&gt;更高层次的容器，比如 MySQL 容器，实际上会包含必要的库来与底层的操作系统容器通信和集成。所以你可以把容器看成是整个应用堆栈中的一层，每层都依赖于下层的单元。而这就类似于船舶或港口中集装箱的堆叠方式，每个容器的稳定性都依赖于下面的容器的支持。所以应用容器的核心是一个受控的执行环境。它们允许你从头开始定义整个环境，从操作系统开始，到你要使用的各个版本的库，再到你要添加的代码版本。&lt;/p&gt;
&lt;p&gt;与容器相关的一个重要概念是&lt;strong&gt;微服务&lt;/strong&gt;。将应用程序的各个组件拆分并打包成独立的服务，这样每个组件都可以很容易地被替换、升级、调试。上面的例子中，我们会为 Vue 前端创建一个微服务，为 MySQL 数据库创建另一个微服务，为 Java 中间件部分创建另一个微服务，以此类推。很明显，微服务与容器化是相辅相成的。&lt;/p&gt;
&lt;h2 id=&#34;从-docker-开始&#34;&gt;从 Docker 开始&lt;/h2&gt;
&lt;p&gt;现在你已经对容器有一定了解了吧？Docker 是最常用的容器化工具，也是最流行的容器运行时。&lt;/p&gt;
&lt;p&gt;Docker 开源于 2013 年。用于打包和创建容器，管理基于容器的应用。所有 Linux 发行版、Windows 和 macOS 都支持 Docker。&lt;/p&gt;
&lt;p&gt;还有其他的容器化工具，如 &lt;a href=&#34;https://coreos.com/rkt/&#34; title=&#34;CoreOS rkt&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CoreOS rkt&lt;/a&gt;
、&lt;a href=&#34;https://mesos.apache.org/documentation/latest/mesos-containerizer/&#34; title=&#34;Mesos Containerizer&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mesos Containerizer&lt;/a&gt;
 和 &lt;a href=&#34;https://linuxcontainers.org/&#34; title=&#34;LXC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LXC&lt;/a&gt;
。但是目前，绝大多数的容器化应用都是在 Docker 上运行的。&lt;/p&gt;
&lt;h2 id=&#34;再到-kubernetes&#34;&gt;再到 Kubernetes&lt;/h2&gt;
&lt;p&gt;首先，简单介绍一下历史。Kubernetes 是 Google 基于其内部容器调度平台 Borg 的经验开发的。2014 年开源，并作为 CNCF（云原生计算基金会）的核心发起项目。&lt;/p&gt;
&lt;p&gt;那么 Kubernetes 又跟容器是什么关系呢？让我们再回到上面的例子。假设我们的应用爆火，每天的注册用户越来越多。&lt;/p&gt;
&lt;p&gt;现在，我们需要增加后端资源，使浏览我们网站的用户在浏览页面时加载时间不会过长或者超时。最简单的方式就是增加容器的数量，然后使用负载均衡器将传入的负载（以用户请求的形式）分配给容器。&lt;/p&gt;
&lt;p&gt;这样做虽然行之有效，但也只能在用户规模有限的情况下使用。当用户请求达到几十万或几百万时，这种方法也是不可扩展的。你需要管理几十个也许是几百个负载均衡器，这本身就是另一个令人头疼的问题。如果我们想对网站或应用进行任何升级，也会遇到问题，因为负载均衡不会考虑到应用升级的问题。我们需要单独配置每个负载均衡器，然后升级该均衡器所服务的容器。想象一下，当你有 20 个负载均衡器和每周 5 或 6 个小的更新时，你将不得不进行大量的手工劳动。&lt;/p&gt;
&lt;p&gt;我们需要的是一种可以一次性将变更传递给所有受控容器的方法，同时也需要一种可以轻松地调度可用容器的方法，这个过程还必须要是自动化的，这正是 Kubernetes 所做的事情。&lt;/p&gt;
&lt;p&gt;接下来，我们将探讨 Kubernetes 究竟是如何工作的，它的各种组件和服务，以及更多关于如何使用 Kubernetes 来编排、管理和监控容器化环境。为了简单起见，假设我们使用的是 Docker 容器，尽管如前所述，Kubernetes 除了支持 Docker 之外，还支持其他几种容器平台。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-架构和组件&#34;&gt;Kubernetes 架构和组件&lt;/h2&gt;
&lt;p&gt;首先，最重要的是你需要认识到 Kubernetes 利用了“期望状态”原则。就是说，你定义了组件的期望状态，而 Kubernetes 要将它们始终调整到这个状态。&lt;/p&gt;
&lt;p&gt;例如，你想让你的 Web 服务器始终运行在 4 个容器中，以达到负载均衡的目的，你的数据库复制到 3 个不同的容器中，以达到冗余的目的。这就是你想要的状态。如果这 7 个容器中的任何一个出现故障，Kubernetes 引擎会检测到这一点，并自动创建出一个新的容器，以确保维持所需的状态。&lt;/p&gt;
&lt;p&gt;现在我们来定义一些 Kubernetes 的重要组件。&lt;/p&gt;
&lt;p&gt;当你第一次设置 Kubernetes 时，你会创建一个集群。所有其他组件都是集群的一部分。你也可以创建多个虚拟集群，称为命名空间 (namespace)，它们是同一个物理集群的一部分。这与你可以在同一物理服务器上创建多个虚拟机的方式非常相似。如果你不需要，也没有明确定义的命名空间，那么你的集群将在始终存在的默认命名空间中创建。&lt;/p&gt;
&lt;p&gt;Kubernetes 运行在节点 (node) 上，节点是集群中的单个机器。如果你有自己的硬件，节点可能对应于物理机器，但更可能对应于在云中运行的虚拟机。节点是部署你的应用或服务的地方，是 Kubernetes 工作的地方。有 2 种类型的节点 ——master 节点和 worker 节点，所以说 Kubernetes 是主从结构的。&lt;/p&gt;
&lt;p&gt;主节点是一个控制其他所有节点的特殊节点。一方面，它和集群中的任何其他节点一样，这意味着它只是另一台机器或虚拟机。另一方面，它运行着控制集群其他部分的软件。它向集群中的所有其他节点发送消息，将工作分配给它们，工作节点向主节点上的 API Server 汇报。&lt;/p&gt;
&lt;p&gt;Master 节点本身也包含一个名为 API Server 的组件。这个 API 是节点与控制平面通信的唯一端点。API Server 至关重要，因为这是 worker 节点和 master 节点就 pod、deployment 和所有其他 Kubernetes API 对象的状态进行通信的点。&lt;/p&gt;
&lt;p&gt;Worker 节点是 Kubernetes 中真正干活的节点。当你在应用中部署容器或 pod（稍后定义）时，其实是在将它们部署到 worker 节点上运行。Worker 节点托管和运行一个或多个容器的资源。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的逻辑而非物理的工作单位称为 pod。一个 pod 类似于 Docker 中的容器。记得我们在前面讲到，容器可以让你创建独立、隔离的工作单元，可以独立运行。但是要创建复杂的应用程序，比如 Web 服务器，你经常需要结合多个容器，然后在一个 pod 中一起运行和管理。这就是 pod 的设计目的 —— 一个 pod 允许你把多个容器，并指定它们如何组合在一起来创建应用程序。而这也进一步明确了 Docker 和 Kubernetes 之间的关系 —— 一个 Kubernetes pod 通常包含一个或多个 Docker 容器，所有的容器都作为一个单元来管理。&lt;/p&gt;
&lt;p&gt;Kubernetes 中的 service 是一组逻辑上的 pod。把一个 service 看成是一个 pod 的逻辑分组，它提供了一个单一的 IP 地址和 DNS 名称，你可以通过它访问服务内的所有 pod。有了服务，就可以非常容易地设置和管理负载均衡，当你需要扩展 Kubernetes pod 时，这对你有很大的帮助，我们很快就会看到。&lt;/p&gt;
&lt;p&gt;ReplicationController 或 ReplicaSet 是 Kubernetes 的另一个关键功能。它是负责实际管理 pod 生命周期的组件 —— 当收到指令时或 pod 离线或意外停止时启动 pod，也会在收到指示时杀死 pod，也许是因为用户负载减少。所以换句话说，ReplicationController 有助于实现我们所期望的指定运行的 pod 数量的状态。&lt;/p&gt;
&lt;h2 id=&#34;什么是-kubectl&#34;&gt;什么是 Kubectl？&lt;/h2&gt;
&lt;p&gt;kubectl 是一个命令行工具，用于与 Kubernetes 集群和其中的 pod 通信。使用它你可以查看集群的状态，列出集群中的所有 pod，进入 pod 中执行命令等。你还可以使用 YAML 文件定义资源对象，然后使用 kubectl 将其应用到集群中。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-中的自动扩展&#34;&gt;Kubernetes 中的自动扩展&lt;/h2&gt;
&lt;p&gt;请记住，我们使用 Kubernetes 而不是直接使用 Docker 的原因之一，是因为 Kubernetes 能够自动扩展应用实例的数量以满足工作负载的需求。&lt;/p&gt;
&lt;p&gt;自动缩放是通过集群设置来实现的，当服务需求增加时，增加节点数量，当需求减少时，则减少节点数量。但也要记住，节点是“物理”结构 —— 我们把“物理”放在引号里，因为要记住，很多时候，它们实际上是虚拟机。&lt;/p&gt;
&lt;p&gt;无论如何，节点是物理机器的事实意味着我们的云平台必须允许 Kubernetes 引擎创建新机器。各种云提供商对 Kubernetes 支持基本都满足这一点。&lt;/p&gt;
&lt;p&gt;我们再继续说一些概念，这次是和网络有关的。&lt;/p&gt;
&lt;h2 id=&#34;什么是-kubernetes-ingress-和-egress&#34;&gt;什么是 kubernetes Ingress 和 Egress？&lt;/h2&gt;
&lt;p&gt;外部用户或应用程序与 Kubernetes pod 交互，就像 pod 是一个真正的服务器一样。我们需要设置安全规则允许哪些流量可以进入和离开“服务器”，就像我们为托管应用程序的服务器定义安全规则一样。&lt;/p&gt;
&lt;p&gt;进入 Kubernetes pod 的流量称为 Ingress，而从 pod 到集群外的出站流量称为 egress。我们创建入口策略和出口策略的目的是限制不需要的流量进入和流出服务。而这些策略也是定义 pod 使用的端口来接受传入和传输传出数据 / 流量的地方。&lt;/p&gt;
&lt;h2 id=&#34;什么是-ingress-controller&#34;&gt;什么是 Ingress Controller？&lt;/h2&gt;
&lt;p&gt;但是在定义入口和出口策略之前，你必须首先启动被称为 Ingress Controller（入口控制器）的组件；这个在集群中默认不启动。有不同类型的入口控制器，Kubernetes 项目默认只支持 Google Cloud 和开箱即用的 Nginx 入口控制器。通常云供应商都会提供自己的入口控制器。&lt;/p&gt;
&lt;h2 id=&#34;什么是-replica-和-replicaset&#34;&gt;什么是 Replica 和 ReplicaSet？&lt;/h2&gt;
&lt;p&gt;为了保证应用程序的弹性，需要在不同节点上创建多个 pod 的副本。这些被称为 Replica。假设你所需的状态策略是“让名为 webserver-1 的 pod 始终维持在 3 个副本”，这意味着 ReplicationController 或 ReplicaSet 将监控活动副本的数量，如果其中有任何一个 replica 因任何原因不可用（例如节点的故障），那么 Deployment Controller 将自动创建一个新的系统（定义如下）。&lt;/p&gt;
&lt;p&gt;所需状态是在 deployment 中定义的。Master 节点的中有一个子系统叫做 Deployment Controller，负责实际执行并使当前状态不断趋向于所需状态。&lt;/p&gt;
&lt;p&gt;因此，举例来说，如果你目前有 2 个 pod 的副本，而你所希望的状态应该有 3 个，那么 Replication Controller 或 ReplicaSet 会自动检测到这个要求，并指示 Deployment Controller 根据预定义的设置部署一个新的 pod。&lt;/p&gt;
&lt;h2 id=&#34;什么是服务网格&#34;&gt;什么是服务网格？&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://jimmysong.io/blog/what-is-a-service-mesh/&#34; title=&#34;服务网格 (Service Mesh)&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;服务网格 (Service Mesh)&lt;/a&gt;
 用于管理服务之间的网络流量，是云原生的网络基础设施层，也是 &lt;a href=&#34;https://jimmysong.io/blog/post-kubernetes-era/&#34; title=&#34;Kubernetes 次世代的云原生应用&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes 次世代的云原生应用&lt;/a&gt;
 的重要组成部分。&lt;/p&gt;
&lt;p&gt;服务网格利用容器之间的网络设置来控制或改变应用程序中不同组件之间的交互。下面，我们用一个例子来说明。假设你想测试 Nginx 的新版本，检查它是否与你的 Web 应用兼容。你用新的 Nginx 版本创建了一个新的容器 (Container2)，并从当前容器 (Container1) 中复制了当前的 Nginx webserver 配置。但你不想影响组成 web 应用的其他微服务（假设每个容器对应一个单独的微服务）—— 就是 MySQL 数据库、Node.js 前端、负载均衡器等。&lt;/p&gt;
&lt;p&gt;所以使用服务网格，你可以立即只把 webserver 微服务改成 Container2（新 Nginx 版本的那个）进行测试。如果确定它不能工作，比如因为它导致网站出现一些兼容性问题，那么你就调用服务网格来快速切换回原来的 Container1。而这一切都不需要对其他容器进行任何配置变更 —— 这些变更对其他容器是完全透明的。&lt;/p&gt;
&lt;p&gt;如果没有服务网格，对容器来说这项工作将十分繁琐，因为这涉及到逐一更改所有其他容器上的配置，将它们所包含的服务从 Container1 指向 Container2，然后在测试失败后，将它们全部改回来。&lt;/p&gt;
&lt;p&gt;在前面这部分 Kubernetes 指南中，我们介绍了一些与 Kubernetes 网络相关的概念。Kubernetes 中的网络可能很棘手，很难理解，如果你刚刚开始，你可能需要一些实践来理解这里。关于服务网格的更多内容请参考 &lt;a href=&#34;https://jimmysong.io/istio-handbook/&#34; title=&#34;《Istio 服务网格》&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;《Istio 服务网格》&lt;/a&gt;
。&lt;/p&gt;
&lt;p&gt;在下一部分中，我们将展开更多关于 Kubernetes 的话题：如何开始学习 Kubernetes，如何在本地安装和测试 Kubernetes，以及 Kubernetes 的一些优秀的监控工具。&lt;/p&gt;
&lt;h2 id=&#34;如何学习-kubernetes&#34;&gt;如何学习 Kubernetes？&lt;/h2&gt;
&lt;p&gt;自学 Kubernetes 知识基本上有三种不同的途径，我们在这里只提供了一个指导大纲。&lt;/p&gt;
&lt;h3 id=&#34;一从零开始学习和安装-kubernetes&#34;&gt;一、从零开始学习和安装 Kubernetes&lt;/h3&gt;
&lt;p&gt;要想真正掌握 Kubernetes，最好的办法莫过于自己从头开始安装 Kubernetes。不过要注意的是，从零开始安装 Kubernetes 并不是一件容易的事情。安装 Kubernetes 并不是简单的“下载文件 -&amp;gt; 点击安装”式的操作，Kubernetes 由多个组件组成，这些组件必须单独安装和配置。而在此之前，你也需要相当的技术储备来做安装前的准备，比如熟悉 Linux 操作系统。如果你决定使用这种方式学习的话，推荐你阅读 &lt;a href=&#34;https://github.com/rootsongjc/kubernetes-handbook&#34; title=&#34;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&lt;/a&gt;
。此外，请记住，尽管 Kubernetes 作为一个开源解决方案在技术上是免费的，但它确实有一些隐藏的成本，只不过对初学者来说可能并不明显。&lt;/p&gt;
&lt;h3 id=&#34;二kubernetes-自托管解决方案&#34;&gt;二、Kubernetes 自托管解决方案&lt;/h3&gt;
&lt;p&gt;这些解决方案样是一些工具和实用程序，大大简化了在本地计算机上安装和配置小型 Kubernetes 集群的任务。它们是学习 Kubernetes 的好方法，同时对于新手来说也不会太难，又足够小巧可以到安装在个人电脑上。最流行的自托管 Kubernetes 工具和环境是 &lt;a href=&#34;https://github.com/kubernetes/minikube&#34; title=&#34;Minikube&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Minikube&lt;/a&gt;
、&lt;a href=&#34;https://github.com/ubuntu/microk8s&#34; title=&#34;MicroK8s&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MicroK8s&lt;/a&gt;
、&lt;a href=&#34;https://docs.docker.com/docker-for-windows/kubernetes/&#34; title=&#34;Docker Desktop&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Docker Desktop&lt;/a&gt;
 和 &lt;a href=&#34;https://github.com/kubernetes-sigs/kind&#34; title=&#34;Kind&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kind&lt;/a&gt;
。这些解决方案往往有一些限制，例如，Minikube 只允许创建一个节点。尽管有这些缺点，但这些工具还是非常值得推荐，因为它们将易学性和成本效益结合起来，对于刚开始使用 Kubernetes 的初学者来说，是一个很好的选择。&lt;/p&gt;
&lt;h3 id=&#34;三云托管的解决方案&#34;&gt;三、云托管的解决方案&lt;/h3&gt;
&lt;p&gt;如今各大云供应商都提供了定制化的 Kubernetes 解决方案来。你也可以通过线上教学平台如 &lt;a href=&#34;https://katacoda.com/&#34; title=&#34;Katacoda&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Katacoda&lt;/a&gt;
 上的免费课程来学习 Kubernetes，它们都是云托管的，你不需要自己安装，只不过你需要云供应商的集群需要付费。&lt;/p&gt;
&lt;h2 id=&#34;本地测试和调试-kubernetes&#34;&gt;本地测试和调试 Kubernetes&lt;/h2&gt;
&lt;p&gt;作为本地安装 Kubernetes 的一部分，你很可能还需要一些测试和调试能力，以确保一切都在顺利运行，特别是定义入口和出口策略等棘手的任务。此外，还有 Kubernetes 附加组件的生态系统，你可能想使用这些组件来扩展 Kubernetes 集群的功能。添加所有这些都需要进行更多的测试，以确保它们能与你的 Kubernetes 集群完美的集成。&lt;/p&gt;
&lt;p&gt;用于在本地开发和调试 Kubernetes 服务的工具有：&lt;a href=&#34;https://github.com/microsoft/mindaro&#34; title=&#34;Microsoft Bridge to Kubernetes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Microsoft Bridge to Kubernetes&lt;/a&gt;
 和 &lt;a href=&#34;https://github.com/telepresenceio/telepresence&#34; title=&#34;telepresence&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;telepresence&lt;/a&gt;
。这些工具可以让你在本地运行单个服务，同时将该服务连接到远程 Kubernetes 集群。这样你就可以让自己的本地机器作为 Kubernetes 集群中的一部分来运行 —— 这对于在本地而不是在生产集群上开发服务非常有用。&lt;/p&gt;
&lt;p&gt;Kubernetes 项目也了解到了 Kubernetes 安装对端到端 (E2E) 测试的需求。为此，项目核心团队一直在确保在最近的版本中更恰当地支持 E2E 测试。这包括诸如允许测试重用和纳入更多附加组件和驱动程序的测试等。&lt;/p&gt;
&lt;h2 id=&#34;kubernetes-监控工具&#34;&gt;Kubernetes 监控工具&lt;/h2&gt;
&lt;p&gt;Kubernetes 提供了应用程序在集群的每个层次上的资源使用情况的详细信息 —— 容器、pod、服务。这些详细信息使你能够评估应用程序的性能，确定哪些瓶颈可以解决以提高整体性能。&lt;/p&gt;
&lt;p&gt;毕竟，监控可以帮助你了解应用和集群运行情况的详细信息，这对于学习 Kubernetes 是十分有帮助的。&lt;/p&gt;
&lt;p&gt;Kubernetes 包含两个内置度量收集工具用于监控：资源管道和全度量管道。资源管道是一个较低级和较有限的工具，主要集中在与各种控制器相关的指标上。全指标管道，顾名思义，从几乎所有集群组件中获取并显示更丰富的指标。&lt;/p&gt;
&lt;p&gt;还有一些第三方工具可以安装并集成到 Kubernetes 集群中。对于 Kubernetes 来说，最普遍使用的两个工具是 Prometheus 和 Grafana。&lt;/p&gt;
&lt;h3 id=&#34;prometheus-监控&#34;&gt;Prometheus 监控&lt;/h3&gt;
&lt;p&gt;Prometheus 是一个功能丰富的开源监控和警报工具。Prometheus 包含一个内部数据存储用来收集指标，如生成的时间序列数据。Prometheus 还拥有众多插件，允许它将数据暴露给各种外部解决方案，并从其他数据源导入数据，包括所有主要公有云监控解决方案。&lt;/p&gt;
&lt;h3 id=&#34;grafana-仪表盘&#34;&gt;Grafana 仪表盘&lt;/h3&gt;
&lt;p&gt;Grafana 是一个优秀的仪表盘、分析和数据可视化工具。它没有 Prometheus 的全功能数据收集能力，但 Prometheus 又没有 Grafana 的数据呈现界面。事实上，他们最好是结合在一起使用 ——Prometheus 负责数据收集和汇总，Grafana 负责数据展示。它们共同创造了一个强大的组合，涵盖了数据收集、基本警报和可视化。&lt;/p&gt;
&lt;h3 id=&#34;高级警报&#34;&gt;高级警报&lt;/h3&gt;
&lt;p&gt;对于高级警报，你可以添加 &lt;a href=&#34;https://www.nagios.org/&#34; title=&#34;Nagios&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Nagios&lt;/a&gt;
 或 &lt;a href=&#34;https://github.com/prometheus/alertmanager&#34; title=&#34;Prometheus Alertmanager&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Prometheus Alertmanager&lt;/a&gt;
 等工具。这些警报工具通常有大量的集成。你可以为自定义值班团队，然后定义你想要监控的参数，例如“当任何 pod 不可用时”或“当任何节点无法访问时”、“当容量达到 90%”等，然后通过电子邮件、短信、手机应用提醒、电话呼叫等方式向值班人员发送自定义通知。你还可以创建升级策略，比如，如果一个被定义为“危急”的警报在 10 分钟内没有值班人员确认，那么就将警报升级（发送警报）到该人员的经理。&lt;/p&gt;
&lt;p&gt;现在，你应该已经对 Docker 和 Kubernetes 有了大体的认识。了解了 Kubernetes 的作用，知道它是如何进行容器化应用部署和管理的。&lt;/p&gt;
&lt;p&gt;调试和监控技术不仅仅是运维需要，你也可以把它当作学习方式。有什么比边做边学更好呢？&lt;/p&gt;
&lt;p&gt;请记住，如果你的应用规模太小，而且预计用户需求不会有太大变化或重大波动（比如一个只在公司内部使用的应用），那么 Kubernetes 对你来说可能没有必要，这种情况下，直接使用 Docker 就足够了。&lt;/p&gt;
&lt;h2 id=&#34;更多&#34;&gt;更多&lt;/h2&gt;
&lt;p&gt;云原生领域的开源项目众多（见 &lt;a href=&#34;https://jimmysong.io/awesome-cloud-native&#34; title=&#34;Awesome Cloud Native / 云原生开源项目大全&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Awesome Cloud Native / 云原生开源项目大全&lt;/a&gt;
），其中有大量的优秀项目可供我们学习。此外，Kubernetes 开源已经多年时间，网上有大量的学习资料，业界出版过很多&lt;a href=&#34;https://jimmysong.io/cloud-native/note/books/&#34; title=&#34;书籍&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;书籍&lt;/a&gt;
，建议大家通过阅读&lt;a href=&#34;https://kubernetes.io/&#34; title=&#34;官方文档&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;官方文档&lt;/a&gt;
和实践来学习，也可以参考我编写的 &lt;a href=&#34;https://jimmysong.io/kubernetes-handbook&#34; title=&#34;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kubernetes Handbook——Kubernetes 中文指南 / 云原生架构实践手册&lt;/a&gt;
。&lt;/p&gt;
&lt;p&gt;推荐大家加入笔者发起创办的&lt;a href=&#34;https://cloudnative.to/&#34; title=&#34;云原生社区&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生社区&lt;/a&gt;
，这是一个立足中国，放眼世界的云原生终端用户社区，致力于云原生技术的传播和应用。云原生社区主办的&lt;a href=&#34;https://github.com/cloudnativeto/academy&#34; title=&#34;云原生学院&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生学院&lt;/a&gt;
定期邀请云原生和开源领域的大咖进行直播分享，成员自发组织了多个 SIG（特别兴趣小组）进行讨论学习。欢迎加入我们，共同学习和交流云原生技术。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>云原生计算基金会（CNCF）</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/cncf/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/cncf/</guid>
      <description>
        
        
        &lt;p&gt;CNCF，全称 Cloud Native Computing Foundation（云原生计算基金会），成立于 2015 年 7 月 21 日（&lt;a href=&#34;https://www.cncf.io/announcement/2015/06/21/new-cloud-native-computing-foundation-to-drive-alignment-among-container-technologies/&#34; title=&#34;于美国波特兰 OSCON 2015 上宣布&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;于美国波特兰 OSCON 2015 上宣布&lt;/a&gt;
），其最初的口号是&lt;strong&gt;坚持和整合开源技术来让编排容器作为微服务架构的一部分&lt;/strong&gt;，其作为致力于云原生应用推广和普及的一支重要力量，不论您是云原生应用的开发者、管理者还是研究人员都有必要了解。&lt;/p&gt;
&lt;p&gt;CNCF 作为一个厂商中立的基金会，致力于 Github 上的快速成长的开源技术的推广，如 Kubernetes、Prometheus、Envoy 等，帮助开发人员更快更好的构建出色的产品。CNCF 维护了一个全景图项目，详见 &lt;a href=&#34;https://github.com/cncf/landscape&#34; title=&#34;GitHub&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub&lt;/a&gt;
。&lt;/p&gt;
&lt;p&gt;关于 CNCF 的使命与组织方式请参考&lt;a href=&#34;https://www.cncf.io/about/charter/&#34; title=&#34;CNCF 章程&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CNCF 章程&lt;/a&gt;
，概括的讲 CNCF 的使命包括以下三点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;容器化包装。&lt;/li&gt;
&lt;li&gt;通过中心编排系统的动态资源管理。&lt;/li&gt;
&lt;li&gt;面向微服务。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CNCF 这个角色的作用是推广技术，形成社区，开源项目管理与推进生态系统健康发展。&lt;/p&gt;
&lt;p&gt;另外 CNCF 组织由以下部分组成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;会员&lt;/strong&gt;：白金、金牌、银牌、最终用户、学术和非赢利成员，不同级别的会员在治理委员会中的投票权不同。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;理事会&lt;/strong&gt;：负责事务管理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TOC（技术监督委员会）&lt;/strong&gt;：技术管理&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最终用户社区&lt;/strong&gt;：推动 CNCF 技术的采纳并选举最终用户技术咨询委员会&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最终用户技术咨询委员会&lt;/strong&gt;：为最终用户会议或向理事会提供咨询&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;营销委员会&lt;/strong&gt;：市场推广&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;cncf-项目成熟度分级与毕业条件&#34;&gt;CNCF 项目成熟度分级与毕业条件&lt;/h2&gt;
&lt;p&gt;每个 CNCF 项目都需要有个成熟度等级，申请成为 CNCF 项目的时候需要确定项目的成熟度级别。&lt;/p&gt;
&lt;p&gt;成熟度级别（Maturity Level）包括以下三种：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sandbox（初级）&lt;/li&gt;
&lt;li&gt;incubating（孵化中）&lt;/li&gt;
&lt;li&gt;graduated（毕业）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;是否可以成为 CNCF 项目需要通过 Technical Oversight Committee (技术监督委员会）简称&lt;a href=&#34;https://github.com/cncf/toc&#34; title=&#34;TOC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;TOC&lt;/a&gt;
，投票采取 fallback 策略，即&lt;strong&gt;回退策略&lt;/strong&gt;，先从最高级别（graduated）开始，如果 2/3 多数投票通过的话则确认为该级别，如果没通过的话，则进行下一低级别的投票，如果一直到 inception 级别都没得到 2/3 多数投票通过的话，则拒绝其进入 CNCF 项目。&lt;/p&gt;
&lt;p&gt;当前所有的 CNCF 项目可以访问&lt;a href=&#34;https://www.cncf.io/projects/&#34; title=&#34;https://www.cncf.io/projects/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cncf.io/projects/&lt;/a&gt;
 。&lt;/p&gt;
&lt;p&gt;项目所达到相应成熟度需要满足的条件和投票机制见下图：&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
  &lt;figcaption&gt;CNCF项目成熟度级别&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;toc技术监督委员会&#34;&gt;TOC（技术监督委员会）&lt;/h2&gt;
&lt;p&gt;TOC（Technical Oversight Committee）作为 CNCF 中的一个重要组织，它的作用是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;定义和维护技术视野&lt;/li&gt;
&lt;li&gt;审批新项目加入组织，为项目设定概念架构&lt;/li&gt;
&lt;li&gt;接受最终用户的反馈并映射到项目中&lt;/li&gt;
&lt;li&gt;调整组件间的访问接口，协调组件之间兼容性&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;TOC 成员通过选举产生，见&lt;a href=&#34;https://github.com/cncf/toc/blob/master/process/election-schedule.md&#34; title=&#34;选举时间表&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;选举时间表&lt;/a&gt;
。&lt;/p&gt;
&lt;p&gt;参考 CNCF TOC：&lt;a href=&#34;https://github.com/cncf/toc&#34; title=&#34;https://github.com/cncf/toc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/cncf/toc&lt;/a&gt;
&lt;/p&gt;
&lt;h2 id=&#34;cncf-ambassador&#34;&gt;CNCF Ambassador&lt;/h2&gt;
&lt;p&gt;CNCF Ambassador（CNCF 大使），人员名单详见 &lt;a href=&#34;https://www.cncf.io/people/ambassadors/&#34; title=&#34;https://www.cncf.io/people/ambassadors/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.cncf.io/people/ambassadors/&lt;/a&gt;
，笔者很荣幸作为第二位成为 CNCF Ambassador 的中国人。&lt;/p&gt;
&lt;h3 id=&#34;如何成为-cncf-ambassador&#34;&gt;如何成为 CNCF Ambassador&lt;/h3&gt;
&lt;p&gt;可以通过以下方式成为 CNCF Ambassador：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;成为 CNCF 会员或对成为某个 CNCF 的项目的贡献者&lt;/li&gt;
&lt;li&gt;以 contributor、blogger、演讲者等身份参与 CNCF 社区项目&lt;/li&gt;
&lt;li&gt;在社区中演讲或撰写博客&lt;/li&gt;
&lt;li&gt;主持云原生社区 meetup&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cncf.io/announcement/2015/06/21/new-cloud-native-computing-foundation-to-drive-alignment-among-container-technologies/&#34; title=&#34;AT&amp;amp;amp;T, Box, Cisco, Cloud Foundry Foundation, CoreOS, Cycle Computing, Docker, eBay, Goldman Sachs, Google, Huawei, IBM, Intel, Joyent, Kismatic, Mesosphere, Red Hat, Switch SUPERNAP, Twitter, Univa, VMware and Weaveworks join new effort to build and maintain cloud native distributed systems - cncf.io&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;AT&amp;amp;T, Box, Cisco, Cloud Foundry Foundation, CoreOS, Cycle Computing, Docker, eBay, Goldman Sachs, Google, Huawei, IBM, Intel, Joyent, Kismatic, Mesosphere, Red Hat, Switch SUPERNAP, Twitter, Univa, VMware and Weaveworks join new effort to build and maintain cloud native distributed systems - cncf.io&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>云原生社区（中国）</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/community/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/community/</guid>
      <description>
        
        
        &lt;p&gt;云原生社区是由 &lt;a href=&#34;https://jimmysong.io&#34; title=&#34;宋净超（Jimmy Song）&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;宋净超（Jimmy Song）&lt;/a&gt;
 于 2020 年 5 月发起的，企业中立的云原生终端用户社区。社区秉持“共识、共治、共建、共享”的原则。社区的宗旨是：连接、中立、开源。立足中国，面向世界，企业中立，关注开源，回馈开源。了解更多请访问云原生社区官网：&lt;a href=&#34;https://cloudnative.to&#34; title=&#34;https://cloudnative.to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://cloudnative.to&lt;/a&gt;
。&lt;/p&gt;
&lt;h2 id=&#34;成立背景&#34;&gt;成立背景&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Software is eating the world. —— Marc Andreessen&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“软件正在吞噬这个世界”已被大家多次引用，随着云原生（Cloud Native）的崛起，我们想说的是“Cloud Native is eating the software”。随着越来越多的企业将服务迁移上云，企业原有的开发模式以及技术架构已无法适应云的应用场景，其正在被重塑，向着云原生的方向演进。&lt;/p&gt;
&lt;p&gt;那么什么是云原生？云原生是一系列架构、研发流程、团队文化的最佳实践组合，以此支撑更快的创新速度、极致的用户体验、稳定可靠的用户服务、高效的研发效率。开源社区与云原生的关系密不可分，正是开源社区尤其是终端用户社区的存在，极大地促进了以容器、服务网格、微服务等为代表的云原生技术的持续演进！&lt;/p&gt;
&lt;p&gt;随着云计算的不断发展，云原生技术在全球范围内变得越来越受关注，同时国内社区同学也展现了对云原生技术热爱。近些年中国已经孕育众多的云原生技术爱好者，也有自发组织的一些相关技术交流和 meetup，同时在云原生领域也涌现了众多优秀的开源项目，在这样的背景下，一个有理想，有组织，有温度的云原生社区应运而生。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cloudnative.to/blog/cnc-announcement/&#34; title=&#34;云原生社区成立 - cloudnative.to&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;云原生社区成立 - cloudnative.to&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

      </description>
    </item>
    
    <item>
      <title>角色与分工</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/roles/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/roles/</guid>
      <description>
        
        
        &lt;p&gt;云原生应用在诞生之初就是面向云而设计，适应云环境，为了在云上运行而开发的应用，既然是应用就涉及到生命周期管理，在一个云原生应用的生命周期中，存在以下几种角色，如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/roles/roles.svg&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/roles/roles.svg&#34; alt=&#34;image&#34; data-caption=&#34;云原生应用中的角色&#34;&gt;
    
  
  &lt;figcaption&gt;云原生应用中的角色&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;三者之间不是完全独立，而是互有交集。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;应用开发者：关注的是代码，对应用的生命周期负责，需要了解业务逻辑。&lt;/li&gt;
&lt;li&gt;应用运维：维护应用平台，负责管理应用的生命周期管，需要具有应用的领域知识。&lt;/li&gt;
&lt;li&gt;基础设施运维：维护计算、存储和网络资源，需要具有底层系统的知识。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下面将分别阐述这三种角色之间的区别和联系。&lt;/p&gt;
&lt;h2 id=&#34;应用开发者&#34;&gt;应用开发者&lt;/h2&gt;
&lt;p&gt;应用开发者负责编写代码，实现应用程序的业务逻辑和数据的处理，是应用程序的拥有者、负责人。底层的计算、存储、网络的复杂性全部通过编程语言层面给屏蔽掉了，比如开发者需要发起远程过程调用（RPC），只需要指定对应的协议，调用相应的接口，传递符合规范的数据即可，而不需要自己去实现一个协议。&lt;/p&gt;
&lt;p&gt;注意这里之所以在开发者前面加上了”应用“两个字，是为了强调这部分开发者是面向业务的开发者，而非基础设施、中间件或者平台开发者，虽然他们本质上都是开发者，但是面向的对象不同。应用开发者负责生产应用程序，并负责它的升级换代，但是对于应用生产出来后如何维护，就要交给应用运维了。&lt;/p&gt;
&lt;h2 id=&#34;应用运维&#34;&gt;应用运维&lt;/h2&gt;
&lt;p&gt;应用运维人员通常基于 PaaS 平台为应用程序提供运行时所需的资源或能力，负责管理应用程序的生命周期，更加关注应用交付，如应用的构建、打包、编排、调度、发布、升级、回滚、配置、备份等，这些操作通常与开发者要运行的应用程序的本身逻辑无关。当需要为某些类型的应用提供平台层能力的时候，应用运维还需要具有这些应用所处领域的专业知识。比如数据科学家需要使用的大数据集群，这些集群通常会有专人来维护，这些人可能不会直接参与底层基础设施的建设，而是负责在 PaaS 平台上维护这套集群。但是对于一些简单的 web 应用，应用运维的角色有时候也会由开发者兼任，也就是 DevOps。&lt;/p&gt;
&lt;h2 id=&#34;基础设施运维&#34;&gt;基础设施运维&lt;/h2&gt;
&lt;p&gt;基础设施运维可能是管理公有云中的资源（虚拟机或容器），也可能直接管理底层的物理资源，他们不必了解这些资源上具体运行的是什么应用，也不需要相关领域的背景知识，在他们眼里一切皆为资源（计算、存储、网络），他们需要负责基础设施的稳定性，资源的利用率，账号的权限管理等。&lt;/p&gt;
&lt;h2 id=&#34;关系&#34;&gt;关系&lt;/h2&gt;
&lt;p&gt;这三个角色不是孤立存在的，他们之间存在很多交集，其中应用运维是将开发者与程序运行资源、环境串联起来的关键，这个角色部分职能可以由 PaaS 平台来完成。&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>云原生应用规范模型</title>
      <link>https://jimmysong.io/book/kubernetes-handbook/cloud-native/spec/</link>
      <pubDate>Tue, 03 May 2022 00:00:00 +0000</pubDate>
      
      <guid>https://jimmysong.io/book/kubernetes-handbook/cloud-native/spec/</guid>
      <description>
        
        
        &lt;p&gt;OAM 规范的设计遵循了以下&lt;a href=&#34;https://github.com/oam-dev/spec/blob/master/9.design_principles.md&#34; title=&#34;原则&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;原则&lt;/a&gt;
：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;关注点分离：根据功能和行为来定义模型，以此划分不同角色的职责;&lt;/li&gt;
&lt;li&gt;平台中立：OAM 的实现不绑定到特定平台；&lt;/li&gt;
&lt;li&gt;优雅：尽量减少设计复杂性；&lt;/li&gt;
&lt;li&gt;复用性：可移植性好，同一个应用程序可以在不同的平台上不加改动地执行；&lt;/li&gt;
&lt;li&gt;不作为编程模型：OAM 提供的是应用程序模型，描述了应用程序的组成和组件的拓扑结构，而不关注应用程序的具体实现。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图是 OAM 规范示意图。&lt;/p&gt;
&lt;p&gt;&lt;figure class=&#34;mx-auto text-center&#34;&gt;
  
  
  
  
    
    &lt;img src=&#34;https://jimmysong.io/book/kubernetes-handbook/cloud-native/spec/oam-spec.png&#34; data-img=&#34;/book/kubernetes-handbook/cloud-native/spec/oam-spec.png&#34; data-width=&#34;1361&#34; data-height=&#34;811&#34; alt=&#34;image&#34; data-caption=&#34;OAM 规范示意图&#34;&gt;
    
  
  &lt;figcaption&gt;OAM 规范示意图&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;图片来自 &lt;a href=&#34;https://github.com/oam-dev/spec/issues/346&#34; title=&#34;oam/spec issue #346&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;oam/spec issue #346&lt;/a&gt;
。&lt;/p&gt;

      </description>
    </item>
    
  </channel>
</rss>
